2018-09-17 15:05:24,995   INFO --- [main]  org.apache.spark.SparkContext(line:54) : Running Spark version 2.1.1
2018-09-17 15:05:25,457   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing view acls to: wshs
2018-09-17 15:05:25,460   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing modify acls to: wshs
2018-09-17 15:05:25,462   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing view acls groups to: 
2018-09-17 15:05:25,463   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing modify acls groups to: 
2018-09-17 15:05:25,464   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(wshs); groups with view permissions: Set(); users  with modify permissions: Set(wshs); groups with modify permissions: Set()
2018-09-17 15:05:25,980   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'sparkDriver' on port 53278.
2018-09-17 15:05:25,998   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering MapOutputTracker
2018-09-17 15:05:26,015   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering BlockManagerMaster
2018-09-17 15:05:26,017   INFO --- [main]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-09-17 15:05:26,018   INFO --- [main]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : BlockManagerMasterEndpoint up
2018-09-17 15:05:26,033   INFO --- [main]  org.apache.spark.storage.DiskBlockManager(line:54) : Created local directory at C:\Users\wshs\AppData\Local\Temp\blockmgr-1a887191-6e42-4c39-a725-ddb2fd778235
2018-09-17 15:05:26,050   INFO --- [main]  org.apache.spark.storage.memory.MemoryStore(line:54) : MemoryStore started with capacity 3.0 GB
2018-09-17 15:05:26,109   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering OutputCommitCoordinator
2018-09-17 15:05:26,184   INFO --- [main]  org.spark_project.jetty.util.log(line:186) : Logging initialized @2316ms
2018-09-17 15:05:26,289   INFO --- [main]  org.spark_project.jetty.server.Server(line:327) : jetty-9.2.z-SNAPSHOT
2018-09-17 15:05:26,303   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@1c3b9394{/jobs,null,AVAILABLE,@Spark}
2018-09-17 15:05:26,303   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@6f2cfcc2{/jobs/json,null,AVAILABLE,@Spark}
2018-09-17 15:05:26,304   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@7f6f61c8{/jobs/job,null,AVAILABLE,@Spark}
2018-09-17 15:05:26,304   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@4c2cc639{/jobs/job/json,null,AVAILABLE,@Spark}
2018-09-17 15:05:26,305   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@ccb4b1b{/stages,null,AVAILABLE,@Spark}
2018-09-17 15:05:26,305   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@4097cac{/stages/json,null,AVAILABLE,@Spark}
2018-09-17 15:05:26,305   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@ec2cc4{/stages/stage,null,AVAILABLE,@Spark}
2018-09-17 15:05:26,305   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@2a5b3fee{/stages/stage/json,null,AVAILABLE,@Spark}
2018-09-17 15:05:26,305   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@7c1e2a2d{/stages/pool,null,AVAILABLE,@Spark}
2018-09-17 15:05:26,306   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@333dd51e{/stages/pool/json,null,AVAILABLE,@Spark}
2018-09-17 15:05:26,306   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@52d645b1{/storage,null,AVAILABLE,@Spark}
2018-09-17 15:05:26,306   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@2101b44a{/storage/json,null,AVAILABLE,@Spark}
2018-09-17 15:05:26,306   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@2cc3ad05{/storage/rdd,null,AVAILABLE,@Spark}
2018-09-17 15:05:26,307   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@710b18a6{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-09-17 15:05:26,307   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@119020fb{/environment,null,AVAILABLE,@Spark}
2018-09-17 15:05:26,307   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@3d9f6567{/environment/json,null,AVAILABLE,@Spark}
2018-09-17 15:05:26,307   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@c055c54{/executors,null,AVAILABLE,@Spark}
2018-09-17 15:05:26,308   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@25e2ab5a{/executors/json,null,AVAILABLE,@Spark}
2018-09-17 15:05:26,308   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@35e5d0e5{/executors/threadDump,null,AVAILABLE,@Spark}
2018-09-17 15:05:26,308   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@73173f63{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-09-17 15:05:26,313   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@55562aa9{/static,null,AVAILABLE,@Spark}
2018-09-17 15:05:26,313   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@655ef322{/,null,AVAILABLE,@Spark}
2018-09-17 15:05:26,314   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@7e276594{/api,null,AVAILABLE,@Spark}
2018-09-17 15:05:26,314   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@3401a114{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-09-17 15:05:26,314   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@5066d65f{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-09-17 15:05:26,327   INFO --- [main]  org.spark_project.jetty.server.ServerConnector(line:266) : Started Spark@5553d0f5{HTTP/1.1}{0.0.0.0:4040}
2018-09-17 15:05:26,327   INFO --- [main]  org.spark_project.jetty.server.Server(line:379) : Started @2460ms
2018-09-17 15:05:26,328   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'SparkUI' on port 4040.
2018-09-17 15:05:26,331   INFO --- [main]  org.apache.spark.ui.SparkUI(line:54) : Bound SparkUI to 0.0.0.0, and started at http://192.168.3.199:4040
2018-09-17 15:05:26,428   INFO --- [main]  org.apache.spark.executor.Executor(line:54) : Starting executor ID driver on host localhost
2018-09-17 15:05:26,479   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 53322.
2018-09-17 15:05:26,480   INFO --- [main]  org.apache.spark.network.netty.NettyBlockTransferService(line:54) : Server created on 192.168.3.199:53322
2018-09-17 15:05:26,482   INFO --- [main]  org.apache.spark.storage.BlockManager(line:54) : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-09-17 15:05:26,484   INFO --- [main]  org.apache.spark.storage.BlockManagerMaster(line:54) : Registering BlockManager BlockManagerId(driver, 192.168.3.199, 53322, None)
2018-09-17 15:05:26,487   INFO --- [dispatcher-event-loop-3]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : Registering block manager 192.168.3.199:53322 with 3.0 GB RAM, BlockManagerId(driver, 192.168.3.199, 53322, None)
2018-09-17 15:05:26,490   INFO --- [main]  org.apache.spark.storage.BlockManagerMaster(line:54) : Registered BlockManager BlockManagerId(driver, 192.168.3.199, 53322, None)
2018-09-17 15:05:26,490   INFO --- [main]  org.apache.spark.storage.BlockManager(line:54) : Initialized BlockManager: BlockManagerId(driver, 192.168.3.199, 53322, None)
2018-09-17 15:05:26,663   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@19b30c92{/metrics/json,null,AVAILABLE,@Spark}
2018-09-17 15:05:27,077   INFO --- [main]  org.apache.spark.storage.memory.MemoryStore(line:54) : Block broadcast_0 stored as values in memory (estimated size 127.1 KB, free 3.0 GB)
2018-09-17 15:05:27,206   INFO --- [main]  org.apache.spark.storage.memory.MemoryStore(line:54) : Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.3 KB, free 3.0 GB)
2018-09-17 15:05:27,210   INFO --- [dispatcher-event-loop-1]  org.apache.spark.storage.BlockManagerInfo(line:54) : Added broadcast_0_piece0 in memory on 192.168.3.199:53322 (size: 14.3 KB, free: 3.0 GB)
2018-09-17 15:05:27,215   INFO --- [main]  org.apache.spark.SparkContext(line:54) : Created broadcast 0 from textFile at logSession.scala:13
2018-09-17 15:05:27,348   INFO --- [main]  org.apache.spark.SparkContext(line:54) : Starting job: collect at logSession.scala:16
2018-09-17 15:05:27,411   INFO --- [dag-scheduler-event-loop]  org.apache.hadoop.mapred.FileInputFormat(line:253) : Total input paths to process : 1
2018-09-17 15:05:27,628   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Registering RDD 3 (map at logSession.scala:13)
2018-09-17 15:05:27,628   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Registering RDD 5 (sortBy at logSession.scala:13)
2018-09-17 15:05:27,630   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Got job 0 (collect at logSession.scala:16) with 1 output partitions
2018-09-17 15:05:27,631   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Final stage: ResultStage 2 (collect at logSession.scala:16)
2018-09-17 15:05:27,631   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Parents of final stage: List(ShuffleMapStage 1)
2018-09-17 15:05:27,633   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Missing parents: List(ShuffleMapStage 1)
2018-09-17 15:05:27,640   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Submitting ShuffleMapStage 0 (MapPartitionsRDD[3] at map at logSession.scala:13), which has no missing parents
2018-09-17 15:05:27,667   INFO --- [dag-scheduler-event-loop]  org.apache.spark.storage.memory.MemoryStore(line:54) : Block broadcast_1 stored as values in memory (estimated size 4.7 KB, free 3.0 GB)
2018-09-17 15:05:27,671   INFO --- [dag-scheduler-event-loop]  org.apache.spark.storage.memory.MemoryStore(line:54) : Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.7 KB, free 3.0 GB)
2018-09-17 15:05:27,672   INFO --- [dispatcher-event-loop-5]  org.apache.spark.storage.BlockManagerInfo(line:54) : Added broadcast_1_piece0 in memory on 192.168.3.199:53322 (size: 2.7 KB, free: 3.0 GB)
2018-09-17 15:05:27,672   INFO --- [dag-scheduler-event-loop]  org.apache.spark.SparkContext(line:54) : Created broadcast 1 from broadcast at DAGScheduler.scala:996
2018-09-17 15:05:27,676   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Submitting 2 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[3] at map at logSession.scala:13)
2018-09-17 15:05:27,677   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.TaskSchedulerImpl(line:54) : Adding task set 0.0 with 2 tasks
2018-09-17 15:05:27,742   INFO --- [dispatcher-event-loop-6]  org.apache.spark.scheduler.TaskSetManager(line:54) : Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 5955 bytes)
2018-09-17 15:05:27,751   INFO --- [dispatcher-event-loop-6]  org.apache.spark.scheduler.TaskSetManager(line:54) : Starting task 1.0 in stage 0.0 (TID 1, localhost, executor driver, partition 1, PROCESS_LOCAL, 5955 bytes)
2018-09-17 15:05:27,760   INFO --- [Executor task launch worker for task 0]  org.apache.spark.executor.Executor(line:54) : Running task 0.0 in stage 0.0 (TID 0)
2018-09-17 15:05:27,760   INFO --- [Executor task launch worker for task 1]  org.apache.spark.executor.Executor(line:54) : Running task 1.0 in stage 0.0 (TID 1)
2018-09-17 15:05:27,811   INFO --- [Executor task launch worker for task 1]  org.apache.spark.rdd.HadoopRDD(line:54) : Input split: file:/E:/hello.txt:91+92
2018-09-17 15:05:27,811   INFO --- [Executor task launch worker for task 0]  org.apache.spark.rdd.HadoopRDD(line:54) : Input split: file:/E:/hello.txt:0+91
2018-09-17 15:05:27,823   INFO --- [Executor task launch worker for task 0]  org.apache.hadoop.conf.Configuration.deprecation(line:840) : mapred.tip.id is deprecated. Instead, use mapreduce.task.id
2018-09-17 15:05:27,824   INFO --- [Executor task launch worker for task 0]  org.apache.hadoop.conf.Configuration.deprecation(line:840) : mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
2018-09-17 15:05:27,823   INFO --- [Executor task launch worker for task 1]  org.apache.hadoop.conf.Configuration.deprecation(line:840) : mapred.tip.id is deprecated. Instead, use mapreduce.task.id
2018-09-17 15:05:27,824   INFO --- [Executor task launch worker for task 0]  org.apache.hadoop.conf.Configuration.deprecation(line:840) : mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
2018-09-17 15:05:27,824   INFO --- [Executor task launch worker for task 1]  org.apache.hadoop.conf.Configuration.deprecation(line:840) : mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
2018-09-17 15:05:27,824   INFO --- [Executor task launch worker for task 0]  org.apache.hadoop.conf.Configuration.deprecation(line:840) : mapred.job.id is deprecated. Instead, use mapreduce.job.id
2018-09-17 15:05:27,941   INFO --- [Executor task launch worker for task 1]  org.apache.spark.executor.Executor(line:54) : Finished task 1.0 in stage 0.0 (TID 1). 1658 bytes result sent to driver
2018-09-17 15:05:27,941   INFO --- [Executor task launch worker for task 0]  org.apache.spark.executor.Executor(line:54) : Finished task 0.0 in stage 0.0 (TID 0). 1745 bytes result sent to driver
2018-09-17 15:05:27,948   INFO --- [task-result-getter-1]  org.apache.spark.scheduler.TaskSetManager(line:54) : Finished task 0.0 in stage 0.0 (TID 0) in 241 ms on localhost (executor driver) (1/2)
2018-09-17 15:05:27,948   INFO --- [task-result-getter-0]  org.apache.spark.scheduler.TaskSetManager(line:54) : Finished task 1.0 in stage 0.0 (TID 1) in 199 ms on localhost (executor driver) (2/2)
2018-09-17 15:05:27,949   INFO --- [task-result-getter-0]  org.apache.spark.scheduler.TaskSchedulerImpl(line:54) : Removed TaskSet 0.0, whose tasks have all completed, from pool 
2018-09-17 15:05:27,953   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : ShuffleMapStage 0 (map at logSession.scala:13) finished in 0.264 s
2018-09-17 15:05:27,954   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : looking for newly runnable stages
2018-09-17 15:05:27,954   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : running: Set()
2018-09-17 15:05:27,955   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : waiting: Set(ShuffleMapStage 1, ResultStage 2)
2018-09-17 15:05:27,955   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : failed: Set()
2018-09-17 15:05:27,959   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Submitting ShuffleMapStage 1 (MapPartitionsRDD[5] at sortBy at logSession.scala:13), which has no missing parents
2018-09-17 15:05:27,966   INFO --- [dag-scheduler-event-loop]  org.apache.spark.storage.memory.MemoryStore(line:54) : Block broadcast_2 stored as values in memory (estimated size 4.2 KB, free 3.0 GB)
2018-09-17 15:05:27,970   INFO --- [dag-scheduler-event-loop]  org.apache.spark.storage.memory.MemoryStore(line:54) : Block broadcast_2_piece0 stored as bytes in memory (estimated size 2.4 KB, free 3.0 GB)
2018-09-17 15:05:27,973   INFO --- [dispatcher-event-loop-4]  org.apache.spark.storage.BlockManagerInfo(line:54) : Added broadcast_2_piece0 in memory on 192.168.3.199:53322 (size: 2.4 KB, free: 3.0 GB)
2018-09-17 15:05:27,974   INFO --- [dag-scheduler-event-loop]  org.apache.spark.SparkContext(line:54) : Created broadcast 2 from broadcast at DAGScheduler.scala:996
2018-09-17 15:05:27,974   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[5] at sortBy at logSession.scala:13)
2018-09-17 15:05:27,974   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.TaskSchedulerImpl(line:54) : Adding task set 1.0 with 1 tasks
2018-09-17 15:05:27,979   INFO --- [dispatcher-event-loop-1]  org.apache.spark.scheduler.TaskSetManager(line:54) : Starting task 0.0 in stage 1.0 (TID 2, localhost, executor driver, partition 0, ANY, 5739 bytes)
2018-09-17 15:05:27,979   INFO --- [Executor task launch worker for task 2]  org.apache.spark.executor.Executor(line:54) : Running task 0.0 in stage 1.0 (TID 2)
2018-09-17 15:05:27,996   INFO --- [Executor task launch worker for task 2]  org.apache.spark.storage.ShuffleBlockFetcherIterator(line:54) : Getting 2 non-empty blocks out of 2 blocks
2018-09-17 15:05:27,998   INFO --- [Executor task launch worker for task 2]  org.apache.spark.storage.ShuffleBlockFetcherIterator(line:54) : Started 0 remote fetches in 5 ms
2018-09-17 15:05:28,063   INFO --- [Executor task launch worker for task 2]  org.apache.spark.executor.Executor(line:54) : Finished task 0.0 in stage 1.0 (TID 2). 2047 bytes result sent to driver
2018-09-17 15:05:28,065   INFO --- [task-result-getter-2]  org.apache.spark.scheduler.TaskSetManager(line:54) : Finished task 0.0 in stage 1.0 (TID 2) in 88 ms on localhost (executor driver) (1/1)
2018-09-17 15:05:28,065   INFO --- [task-result-getter-2]  org.apache.spark.scheduler.TaskSchedulerImpl(line:54) : Removed TaskSet 1.0, whose tasks have all completed, from pool 
2018-09-17 15:05:28,066   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : ShuffleMapStage 1 (sortBy at logSession.scala:13) finished in 0.088 s
2018-09-17 15:05:28,066   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : looking for newly runnable stages
2018-09-17 15:05:28,066   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : running: Set()
2018-09-17 15:05:28,066   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : waiting: Set(ResultStage 2)
2018-09-17 15:05:28,066   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : failed: Set()
2018-09-17 15:05:28,067   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Submitting ResultStage 2 (MapPartitionsRDD[7] at sortBy at logSession.scala:13), which has no missing parents
2018-09-17 15:05:28,073   INFO --- [dag-scheduler-event-loop]  org.apache.spark.storage.memory.MemoryStore(line:54) : Block broadcast_3 stored as values in memory (estimated size 3.5 KB, free 3.0 GB)
2018-09-17 15:05:28,078   INFO --- [dag-scheduler-event-loop]  org.apache.spark.storage.memory.MemoryStore(line:54) : Block broadcast_3_piece0 stored as bytes in memory (estimated size 2017.0 B, free 3.0 GB)
2018-09-17 15:05:28,081   INFO --- [dispatcher-event-loop-0]  org.apache.spark.storage.BlockManagerInfo(line:54) : Added broadcast_3_piece0 in memory on 192.168.3.199:53322 (size: 2017.0 B, free: 3.0 GB)
2018-09-17 15:05:28,082   INFO --- [dag-scheduler-event-loop]  org.apache.spark.SparkContext(line:54) : Created broadcast 3 from broadcast at DAGScheduler.scala:996
2018-09-17 15:05:28,084   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[7] at sortBy at logSession.scala:13)
2018-09-17 15:05:28,084   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.TaskSchedulerImpl(line:54) : Adding task set 2.0 with 1 tasks
2018-09-17 15:05:28,087   INFO --- [dispatcher-event-loop-7]  org.apache.spark.scheduler.TaskSetManager(line:54) : Starting task 0.0 in stage 2.0 (TID 3, localhost, executor driver, partition 0, ANY, 5750 bytes)
2018-09-17 15:05:28,088   INFO --- [Executor task launch worker for task 3]  org.apache.spark.executor.Executor(line:54) : Running task 0.0 in stage 2.0 (TID 3)
2018-09-17 15:05:28,092   INFO --- [Executor task launch worker for task 3]  org.apache.spark.storage.ShuffleBlockFetcherIterator(line:54) : Getting 1 non-empty blocks out of 1 blocks
2018-09-17 15:05:28,092   INFO --- [Executor task launch worker for task 3]  org.apache.spark.storage.ShuffleBlockFetcherIterator(line:54) : Started 0 remote fetches in 0 ms
2018-09-17 15:05:28,106   INFO --- [Executor task launch worker for task 3]  org.apache.spark.executor.Executor(line:54) : Finished task 0.0 in stage 2.0 (TID 3). 2340 bytes result sent to driver
2018-09-17 15:05:28,108   INFO --- [task-result-getter-3]  org.apache.spark.scheduler.TaskSetManager(line:54) : Finished task 0.0 in stage 2.0 (TID 3) in 22 ms on localhost (executor driver) (1/1)
2018-09-17 15:05:28,108   INFO --- [task-result-getter-3]  org.apache.spark.scheduler.TaskSchedulerImpl(line:54) : Removed TaskSet 2.0, whose tasks have all completed, from pool 
2018-09-17 15:05:28,108   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : ResultStage 2 (collect at logSession.scala:16) finished in 0.023 s
2018-09-17 15:05:28,116   INFO --- [main]  org.apache.spark.scheduler.DAGScheduler(line:54) : Job 0 finished: collect at logSession.scala:16, took 0.767218 s
2018-09-17 15:05:28,144   INFO --- [main]  org.spark_project.jetty.server.ServerConnector(line:306) : Stopped Spark@5553d0f5{HTTP/1.1}{0.0.0.0:4040}
2018-09-17 15:05:28,146   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@5066d65f{/stages/stage/kill,null,UNAVAILABLE,@Spark}
2018-09-17 15:05:28,146   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@3401a114{/jobs/job/kill,null,UNAVAILABLE,@Spark}
2018-09-17 15:05:28,146   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@7e276594{/api,null,UNAVAILABLE,@Spark}
2018-09-17 15:05:28,146   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@655ef322{/,null,UNAVAILABLE,@Spark}
2018-09-17 15:05:28,147   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@55562aa9{/static,null,UNAVAILABLE,@Spark}
2018-09-17 15:05:28,147   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@73173f63{/executors/threadDump/json,null,UNAVAILABLE,@Spark}
2018-09-17 15:05:28,147   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@35e5d0e5{/executors/threadDump,null,UNAVAILABLE,@Spark}
2018-09-17 15:05:28,147   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@25e2ab5a{/executors/json,null,UNAVAILABLE,@Spark}
2018-09-17 15:05:28,148   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@c055c54{/executors,null,UNAVAILABLE,@Spark}
2018-09-17 15:05:28,148   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@3d9f6567{/environment/json,null,UNAVAILABLE,@Spark}
2018-09-17 15:05:28,148   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@119020fb{/environment,null,UNAVAILABLE,@Spark}
2018-09-17 15:05:28,148   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@710b18a6{/storage/rdd/json,null,UNAVAILABLE,@Spark}
2018-09-17 15:05:28,148   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@2cc3ad05{/storage/rdd,null,UNAVAILABLE,@Spark}
2018-09-17 15:05:28,149   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@2101b44a{/storage/json,null,UNAVAILABLE,@Spark}
2018-09-17 15:05:28,149   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@52d645b1{/storage,null,UNAVAILABLE,@Spark}
2018-09-17 15:05:28,149   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@333dd51e{/stages/pool/json,null,UNAVAILABLE,@Spark}
2018-09-17 15:05:28,149   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@7c1e2a2d{/stages/pool,null,UNAVAILABLE,@Spark}
2018-09-17 15:05:28,150   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@2a5b3fee{/stages/stage/json,null,UNAVAILABLE,@Spark}
2018-09-17 15:05:28,150   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@ec2cc4{/stages/stage,null,UNAVAILABLE,@Spark}
2018-09-17 15:05:28,150   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@4097cac{/stages/json,null,UNAVAILABLE,@Spark}
2018-09-17 15:05:28,150   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@ccb4b1b{/stages,null,UNAVAILABLE,@Spark}
2018-09-17 15:05:28,150   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@4c2cc639{/jobs/job/json,null,UNAVAILABLE,@Spark}
2018-09-17 15:05:28,151   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@7f6f61c8{/jobs/job,null,UNAVAILABLE,@Spark}
2018-09-17 15:05:28,151   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@6f2cfcc2{/jobs/json,null,UNAVAILABLE,@Spark}
2018-09-17 15:05:28,151   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@1c3b9394{/jobs,null,UNAVAILABLE,@Spark}
2018-09-17 15:05:28,153   INFO --- [main]  org.apache.spark.ui.SparkUI(line:54) : Stopped Spark web UI at http://192.168.3.199:4040
2018-09-17 15:05:28,165   INFO --- [dispatcher-event-loop-5]  org.apache.spark.MapOutputTrackerMasterEndpoint(line:54) : MapOutputTrackerMasterEndpoint stopped!
2018-09-17 15:05:28,269   INFO --- [main]  org.apache.spark.storage.memory.MemoryStore(line:54) : MemoryStore cleared
2018-09-17 15:05:28,270   INFO --- [main]  org.apache.spark.storage.BlockManager(line:54) : BlockManager stopped
2018-09-17 15:05:28,275   INFO --- [main]  org.apache.spark.storage.BlockManagerMaster(line:54) : BlockManagerMaster stopped
2018-09-17 15:05:28,277   INFO --- [dispatcher-event-loop-2]  org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint(line:54) : OutputCommitCoordinator stopped!
2018-09-17 15:05:28,283   INFO --- [main]  org.apache.spark.SparkContext(line:54) : Successfully stopped SparkContext
2018-09-17 15:05:28,286   INFO --- [Thread-1]  org.apache.spark.util.ShutdownHookManager(line:54) : Shutdown hook called
2018-09-17 15:05:28,287   INFO --- [Thread-1]  org.apache.spark.util.ShutdownHookManager(line:54) : Deleting directory C:\Users\wshs\AppData\Local\Temp\spark-f210f660-d245-4746-b6b9-70da84adf5e8
2018-09-17 16:00:22,094   INFO --- [main]  org.apache.spark.SparkContext(line:54) : Running Spark version 2.1.1
2018-09-17 16:00:22,601   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing view acls to: wshs
2018-09-17 16:00:22,604   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing modify acls to: wshs
2018-09-17 16:00:22,606   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing view acls groups to: 
2018-09-17 16:00:22,607   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing modify acls groups to: 
2018-09-17 16:00:22,608   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(wshs); groups with view permissions: Set(); users  with modify permissions: Set(wshs); groups with modify permissions: Set()
2018-09-17 16:00:23,170   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'sparkDriver' on port 58692.
2018-09-17 16:00:23,188   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering MapOutputTracker
2018-09-17 16:00:23,206   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering BlockManagerMaster
2018-09-17 16:00:23,208   INFO --- [main]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-09-17 16:00:23,209   INFO --- [main]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : BlockManagerMasterEndpoint up
2018-09-17 16:00:23,222   INFO --- [main]  org.apache.spark.storage.DiskBlockManager(line:54) : Created local directory at C:\Users\wshs\AppData\Local\Temp\blockmgr-430551f6-f6da-497e-a9ba-f96cb3953f99
2018-09-17 16:00:23,237   INFO --- [main]  org.apache.spark.storage.memory.MemoryStore(line:54) : MemoryStore started with capacity 3.0 GB
2018-09-17 16:00:23,300   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering OutputCommitCoordinator
2018-09-17 16:00:23,394   INFO --- [main]  org.spark_project.jetty.util.log(line:186) : Logging initialized @2471ms
2018-09-17 16:00:23,484   INFO --- [main]  org.spark_project.jetty.server.Server(line:327) : jetty-9.2.z-SNAPSHOT
2018-09-17 16:00:23,499   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@1c3b9394{/jobs,null,AVAILABLE,@Spark}
2018-09-17 16:00:23,499   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@6f2cfcc2{/jobs/json,null,AVAILABLE,@Spark}
2018-09-17 16:00:23,500   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@7f6f61c8{/jobs/job,null,AVAILABLE,@Spark}
2018-09-17 16:00:23,500   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@4c2cc639{/jobs/job/json,null,AVAILABLE,@Spark}
2018-09-17 16:00:23,500   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@ccb4b1b{/stages,null,AVAILABLE,@Spark}
2018-09-17 16:00:23,501   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@4097cac{/stages/json,null,AVAILABLE,@Spark}
2018-09-17 16:00:23,501   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@ec2cc4{/stages/stage,null,AVAILABLE,@Spark}
2018-09-17 16:00:23,501   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@2a5b3fee{/stages/stage/json,null,AVAILABLE,@Spark}
2018-09-17 16:00:23,501   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@7c1e2a2d{/stages/pool,null,AVAILABLE,@Spark}
2018-09-17 16:00:23,502   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@333dd51e{/stages/pool/json,null,AVAILABLE,@Spark}
2018-09-17 16:00:23,502   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@52d645b1{/storage,null,AVAILABLE,@Spark}
2018-09-17 16:00:23,502   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@2101b44a{/storage/json,null,AVAILABLE,@Spark}
2018-09-17 16:00:23,502   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@2cc3ad05{/storage/rdd,null,AVAILABLE,@Spark}
2018-09-17 16:00:23,503   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@710b18a6{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-09-17 16:00:23,503   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@119020fb{/environment,null,AVAILABLE,@Spark}
2018-09-17 16:00:23,504   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@3d9f6567{/environment/json,null,AVAILABLE,@Spark}
2018-09-17 16:00:23,504   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@c055c54{/executors,null,AVAILABLE,@Spark}
2018-09-17 16:00:23,504   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@25e2ab5a{/executors/json,null,AVAILABLE,@Spark}
2018-09-17 16:00:23,505   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@35e5d0e5{/executors/threadDump,null,AVAILABLE,@Spark}
2018-09-17 16:00:23,505   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@73173f63{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-09-17 16:00:23,510   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@55562aa9{/static,null,AVAILABLE,@Spark}
2018-09-17 16:00:23,511   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@655ef322{/,null,AVAILABLE,@Spark}
2018-09-17 16:00:23,512   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@7e276594{/api,null,AVAILABLE,@Spark}
2018-09-17 16:00:23,512   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@3401a114{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-09-17 16:00:23,513   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@5066d65f{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-09-17 16:00:23,529   INFO --- [main]  org.spark_project.jetty.server.ServerConnector(line:266) : Started Spark@5553d0f5{HTTP/1.1}{0.0.0.0:4040}
2018-09-17 16:00:23,529   INFO --- [main]  org.spark_project.jetty.server.Server(line:379) : Started @2608ms
2018-09-17 16:00:23,530   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'SparkUI' on port 4040.
2018-09-17 16:00:23,533   INFO --- [main]  org.apache.spark.ui.SparkUI(line:54) : Bound SparkUI to 0.0.0.0, and started at http://192.168.3.199:4040
2018-09-17 16:00:23,611   INFO --- [main]  org.apache.spark.executor.Executor(line:54) : Starting executor ID driver on host localhost
2018-09-17 16:00:23,658   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 58733.
2018-09-17 16:00:23,659   INFO --- [main]  org.apache.spark.network.netty.NettyBlockTransferService(line:54) : Server created on 192.168.3.199:58733
2018-09-17 16:00:23,660   INFO --- [main]  org.apache.spark.storage.BlockManager(line:54) : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-09-17 16:00:23,661   INFO --- [main]  org.apache.spark.storage.BlockManagerMaster(line:54) : Registering BlockManager BlockManagerId(driver, 192.168.3.199, 58733, None)
2018-09-17 16:00:23,664   INFO --- [dispatcher-event-loop-2]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : Registering block manager 192.168.3.199:58733 with 3.0 GB RAM, BlockManagerId(driver, 192.168.3.199, 58733, None)
2018-09-17 16:00:23,667   INFO --- [main]  org.apache.spark.storage.BlockManagerMaster(line:54) : Registered BlockManager BlockManagerId(driver, 192.168.3.199, 58733, None)
2018-09-17 16:00:23,667   INFO --- [main]  org.apache.spark.storage.BlockManager(line:54) : Initialized BlockManager: BlockManagerId(driver, 192.168.3.199, 58733, None)
2018-09-17 16:00:23,830   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@19b30c92{/metrics/json,null,AVAILABLE,@Spark}
2018-09-17 16:00:23,847   INFO --- [Thread-1]  org.apache.spark.SparkContext(line:54) : Invoking stop() from shutdown hook
2018-09-17 16:00:23,853   INFO --- [Thread-1]  org.spark_project.jetty.server.ServerConnector(line:306) : Stopped Spark@5553d0f5{HTTP/1.1}{0.0.0.0:4040}
2018-09-17 16:00:23,854   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@5066d65f{/stages/stage/kill,null,UNAVAILABLE,@Spark}
2018-09-17 16:00:23,855   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@3401a114{/jobs/job/kill,null,UNAVAILABLE,@Spark}
2018-09-17 16:00:23,855   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@7e276594{/api,null,UNAVAILABLE,@Spark}
2018-09-17 16:00:23,855   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@655ef322{/,null,UNAVAILABLE,@Spark}
2018-09-17 16:00:23,855   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@55562aa9{/static,null,UNAVAILABLE,@Spark}
2018-09-17 16:00:23,855   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@73173f63{/executors/threadDump/json,null,UNAVAILABLE,@Spark}
2018-09-17 16:00:23,856   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@35e5d0e5{/executors/threadDump,null,UNAVAILABLE,@Spark}
2018-09-17 16:00:23,856   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@25e2ab5a{/executors/json,null,UNAVAILABLE,@Spark}
2018-09-17 16:00:23,856   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@c055c54{/executors,null,UNAVAILABLE,@Spark}
2018-09-17 16:00:23,856   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@3d9f6567{/environment/json,null,UNAVAILABLE,@Spark}
2018-09-17 16:00:23,857   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@119020fb{/environment,null,UNAVAILABLE,@Spark}
2018-09-17 16:00:23,857   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@710b18a6{/storage/rdd/json,null,UNAVAILABLE,@Spark}
2018-09-17 16:00:23,858   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@2cc3ad05{/storage/rdd,null,UNAVAILABLE,@Spark}
2018-09-17 16:00:23,858   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@2101b44a{/storage/json,null,UNAVAILABLE,@Spark}
2018-09-17 16:00:23,858   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@52d645b1{/storage,null,UNAVAILABLE,@Spark}
2018-09-17 16:00:23,859   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@333dd51e{/stages/pool/json,null,UNAVAILABLE,@Spark}
2018-09-17 16:00:23,859   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@7c1e2a2d{/stages/pool,null,UNAVAILABLE,@Spark}
2018-09-17 16:00:23,859   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@2a5b3fee{/stages/stage/json,null,UNAVAILABLE,@Spark}
2018-09-17 16:00:23,859   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@ec2cc4{/stages/stage,null,UNAVAILABLE,@Spark}
2018-09-17 16:00:23,860   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@4097cac{/stages/json,null,UNAVAILABLE,@Spark}
2018-09-17 16:00:23,860   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@ccb4b1b{/stages,null,UNAVAILABLE,@Spark}
2018-09-17 16:00:23,860   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@4c2cc639{/jobs/job/json,null,UNAVAILABLE,@Spark}
2018-09-17 16:00:23,860   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@7f6f61c8{/jobs/job,null,UNAVAILABLE,@Spark}
2018-09-17 16:00:23,860   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@6f2cfcc2{/jobs/json,null,UNAVAILABLE,@Spark}
2018-09-17 16:00:23,861   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@1c3b9394{/jobs,null,UNAVAILABLE,@Spark}
2018-09-17 16:00:23,862   INFO --- [Thread-1]  org.apache.spark.ui.SparkUI(line:54) : Stopped Spark web UI at http://192.168.3.199:4040
2018-09-17 16:00:23,873   INFO --- [dispatcher-event-loop-6]  org.apache.spark.MapOutputTrackerMasterEndpoint(line:54) : MapOutputTrackerMasterEndpoint stopped!
2018-09-17 16:00:23,886   INFO --- [Thread-1]  org.apache.spark.storage.memory.MemoryStore(line:54) : MemoryStore cleared
2018-09-17 16:00:23,887   INFO --- [Thread-1]  org.apache.spark.storage.BlockManager(line:54) : BlockManager stopped
2018-09-17 16:00:23,894   INFO --- [Thread-1]  org.apache.spark.storage.BlockManagerMaster(line:54) : BlockManagerMaster stopped
2018-09-17 16:00:23,898   INFO --- [dispatcher-event-loop-3]  org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint(line:54) : OutputCommitCoordinator stopped!
2018-09-17 16:00:23,903   INFO --- [Thread-1]  org.apache.spark.SparkContext(line:54) : Successfully stopped SparkContext
2018-09-17 16:00:23,903   INFO --- [Thread-1]  org.apache.spark.util.ShutdownHookManager(line:54) : Shutdown hook called
2018-09-17 16:00:23,905   INFO --- [Thread-1]  org.apache.spark.util.ShutdownHookManager(line:54) : Deleting directory C:\Users\wshs\AppData\Local\Temp\spark-0be66b5a-5aff-47d4-95d3-128d26af1f9d
2018-09-17 16:34:57,916   INFO --- [main]  org.apache.spark.SparkContext(line:54) : Running Spark version 2.1.1
2018-09-17 16:34:58,349   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing view acls to: wshs
2018-09-17 16:34:58,353   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing modify acls to: wshs
2018-09-17 16:34:58,355   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing view acls groups to: 
2018-09-17 16:34:58,356   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing modify acls groups to: 
2018-09-17 16:34:58,357   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(wshs); groups with view permissions: Set(); users  with modify permissions: Set(wshs); groups with modify permissions: Set()
2018-09-17 16:34:58,941   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'sparkDriver' on port 53686.
2018-09-17 16:34:58,957   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering MapOutputTracker
2018-09-17 16:34:58,975   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering BlockManagerMaster
2018-09-17 16:34:58,979   INFO --- [main]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-09-17 16:34:58,979   INFO --- [main]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : BlockManagerMasterEndpoint up
2018-09-17 16:34:58,993   INFO --- [main]  org.apache.spark.storage.DiskBlockManager(line:54) : Created local directory at C:\Users\wshs\AppData\Local\Temp\blockmgr-dcc37544-9e53-4aad-9a71-e69f164b311b
2018-09-17 16:34:59,012   INFO --- [main]  org.apache.spark.storage.memory.MemoryStore(line:54) : MemoryStore started with capacity 3.0 GB
2018-09-17 16:34:59,075   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering OutputCommitCoordinator
2018-09-17 16:34:59,162   INFO --- [main]  org.spark_project.jetty.util.log(line:186) : Logging initialized @2437ms
2018-09-17 16:34:59,251   INFO --- [main]  org.spark_project.jetty.server.Server(line:327) : jetty-9.2.z-SNAPSHOT
2018-09-17 16:34:59,265   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@1c3b9394{/jobs,null,AVAILABLE,@Spark}
2018-09-17 16:34:59,265   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@6f2cfcc2{/jobs/json,null,AVAILABLE,@Spark}
2018-09-17 16:34:59,266   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@7f6f61c8{/jobs/job,null,AVAILABLE,@Spark}
2018-09-17 16:34:59,266   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@4c2cc639{/jobs/job/json,null,AVAILABLE,@Spark}
2018-09-17 16:34:59,266   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@ccb4b1b{/stages,null,AVAILABLE,@Spark}
2018-09-17 16:34:59,266   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@4097cac{/stages/json,null,AVAILABLE,@Spark}
2018-09-17 16:34:59,267   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@ec2cc4{/stages/stage,null,AVAILABLE,@Spark}
2018-09-17 16:34:59,267   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@2a5b3fee{/stages/stage/json,null,AVAILABLE,@Spark}
2018-09-17 16:34:59,267   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@7c1e2a2d{/stages/pool,null,AVAILABLE,@Spark}
2018-09-17 16:34:59,267   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@333dd51e{/stages/pool/json,null,AVAILABLE,@Spark}
2018-09-17 16:34:59,267   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@52d645b1{/storage,null,AVAILABLE,@Spark}
2018-09-17 16:34:59,268   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@2101b44a{/storage/json,null,AVAILABLE,@Spark}
2018-09-17 16:34:59,268   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@2cc3ad05{/storage/rdd,null,AVAILABLE,@Spark}
2018-09-17 16:34:59,268   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@710b18a6{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-09-17 16:34:59,268   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@119020fb{/environment,null,AVAILABLE,@Spark}
2018-09-17 16:34:59,269   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@3d9f6567{/environment/json,null,AVAILABLE,@Spark}
2018-09-17 16:34:59,269   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@c055c54{/executors,null,AVAILABLE,@Spark}
2018-09-17 16:34:59,269   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@25e2ab5a{/executors/json,null,AVAILABLE,@Spark}
2018-09-17 16:34:59,269   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@35e5d0e5{/executors/threadDump,null,AVAILABLE,@Spark}
2018-09-17 16:34:59,269   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@73173f63{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-09-17 16:34:59,274   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@55562aa9{/static,null,AVAILABLE,@Spark}
2018-09-17 16:34:59,275   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@655ef322{/,null,AVAILABLE,@Spark}
2018-09-17 16:34:59,276   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@7e276594{/api,null,AVAILABLE,@Spark}
2018-09-17 16:34:59,276   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@3401a114{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-09-17 16:34:59,277   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@5066d65f{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-09-17 16:34:59,291   INFO --- [main]  org.spark_project.jetty.server.ServerConnector(line:266) : Started Spark@5553d0f5{HTTP/1.1}{0.0.0.0:4040}
2018-09-17 16:34:59,292   INFO --- [main]  org.spark_project.jetty.server.Server(line:379) : Started @2567ms
2018-09-17 16:34:59,292   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'SparkUI' on port 4040.
2018-09-17 16:34:59,296   INFO --- [main]  org.apache.spark.ui.SparkUI(line:54) : Bound SparkUI to 0.0.0.0, and started at http://192.168.3.199:4040
2018-09-17 16:34:59,379   INFO --- [main]  org.apache.spark.executor.Executor(line:54) : Starting executor ID driver on host localhost
2018-09-17 16:34:59,435   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 53733.
2018-09-17 16:34:59,436   INFO --- [main]  org.apache.spark.network.netty.NettyBlockTransferService(line:54) : Server created on 192.168.3.199:53733
2018-09-17 16:34:59,438   INFO --- [main]  org.apache.spark.storage.BlockManager(line:54) : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-09-17 16:34:59,440   INFO --- [main]  org.apache.spark.storage.BlockManagerMaster(line:54) : Registering BlockManager BlockManagerId(driver, 192.168.3.199, 53733, None)
2018-09-17 16:34:59,443   INFO --- [dispatcher-event-loop-2]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : Registering block manager 192.168.3.199:53733 with 3.0 GB RAM, BlockManagerId(driver, 192.168.3.199, 53733, None)
2018-09-17 16:34:59,446   INFO --- [main]  org.apache.spark.storage.BlockManagerMaster(line:54) : Registered BlockManager BlockManagerId(driver, 192.168.3.199, 53733, None)
2018-09-17 16:34:59,446   INFO --- [main]  org.apache.spark.storage.BlockManager(line:54) : Initialized BlockManager: BlockManagerId(driver, 192.168.3.199, 53733, None)
2018-09-17 16:34:59,629   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@19b30c92{/metrics/json,null,AVAILABLE,@Spark}
2018-09-17 16:35:00,085   INFO --- [main]  org.apache.spark.storage.memory.MemoryStore(line:54) : Block broadcast_0 stored as values in memory (estimated size 127.1 KB, free 3.0 GB)
2018-09-17 16:35:00,277   INFO --- [main]  org.apache.spark.storage.memory.MemoryStore(line:54) : Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.3 KB, free 3.0 GB)
2018-09-17 16:35:00,281   INFO --- [dispatcher-event-loop-4]  org.apache.spark.storage.BlockManagerInfo(line:54) : Added broadcast_0_piece0 in memory on 192.168.3.199:53733 (size: 14.3 KB, free: 3.0 GB)
2018-09-17 16:35:00,286   INFO --- [main]  org.apache.spark.SparkContext(line:54) : Created broadcast 0 from textFile at logSession.scala:14
2018-09-17 16:35:00,438   INFO --- [main]  org.apache.spark.SparkContext(line:54) : Starting job: collect at logSession.scala:17
2018-09-17 16:35:00,498   INFO --- [dag-scheduler-event-loop]  org.apache.hadoop.mapred.FileInputFormat(line:253) : Total input paths to process : 1
2018-09-17 16:35:00,696   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Registering RDD 3 (map at logSession.scala:14)
2018-09-17 16:35:00,697   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Registering RDD 5 (sortBy at logSession.scala:14)
2018-09-17 16:35:00,699   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Got job 0 (collect at logSession.scala:17) with 1 output partitions
2018-09-17 16:35:00,700   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Final stage: ResultStage 2 (collect at logSession.scala:17)
2018-09-17 16:35:00,700   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Parents of final stage: List(ShuffleMapStage 1)
2018-09-17 16:35:00,702   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Missing parents: List(ShuffleMapStage 1)
2018-09-17 16:35:00,711   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Submitting ShuffleMapStage 0 (MapPartitionsRDD[3] at map at logSession.scala:14), which has no missing parents
2018-09-17 16:35:00,737   INFO --- [dag-scheduler-event-loop]  org.apache.spark.storage.memory.MemoryStore(line:54) : Block broadcast_1 stored as values in memory (estimated size 4.7 KB, free 3.0 GB)
2018-09-17 16:35:00,742   INFO --- [dag-scheduler-event-loop]  org.apache.spark.storage.memory.MemoryStore(line:54) : Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.7 KB, free 3.0 GB)
2018-09-17 16:35:00,743   INFO --- [dispatcher-event-loop-5]  org.apache.spark.storage.BlockManagerInfo(line:54) : Added broadcast_1_piece0 in memory on 192.168.3.199:53733 (size: 2.7 KB, free: 3.0 GB)
2018-09-17 16:35:00,744   INFO --- [dag-scheduler-event-loop]  org.apache.spark.SparkContext(line:54) : Created broadcast 1 from broadcast at DAGScheduler.scala:996
2018-09-17 16:35:00,747   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Submitting 2 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[3] at map at logSession.scala:14)
2018-09-17 16:35:00,749   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.TaskSchedulerImpl(line:54) : Adding task set 0.0 with 2 tasks
2018-09-17 16:35:00,803   INFO --- [dispatcher-event-loop-6]  org.apache.spark.scheduler.TaskSetManager(line:54) : Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 5955 bytes)
2018-09-17 16:35:00,807   INFO --- [dispatcher-event-loop-6]  org.apache.spark.scheduler.TaskSetManager(line:54) : Starting task 1.0 in stage 0.0 (TID 1, localhost, executor driver, partition 1, PROCESS_LOCAL, 5955 bytes)
2018-09-17 16:35:00,817   INFO --- [Executor task launch worker for task 1]  org.apache.spark.executor.Executor(line:54) : Running task 1.0 in stage 0.0 (TID 1)
2018-09-17 16:35:00,817   INFO --- [Executor task launch worker for task 0]  org.apache.spark.executor.Executor(line:54) : Running task 0.0 in stage 0.0 (TID 0)
2018-09-17 16:35:00,854   INFO --- [Executor task launch worker for task 1]  org.apache.spark.rdd.HadoopRDD(line:54) : Input split: file:/E:/hello.txt:91+92
2018-09-17 16:35:00,854   INFO --- [Executor task launch worker for task 0]  org.apache.spark.rdd.HadoopRDD(line:54) : Input split: file:/E:/hello.txt:0+91
2018-09-17 16:35:00,862   INFO --- [Executor task launch worker for task 0]  org.apache.hadoop.conf.Configuration.deprecation(line:840) : mapred.tip.id is deprecated. Instead, use mapreduce.task.id
2018-09-17 16:35:00,862   INFO --- [Executor task launch worker for task 1]  org.apache.hadoop.conf.Configuration.deprecation(line:840) : mapred.tip.id is deprecated. Instead, use mapreduce.task.id
2018-09-17 16:35:00,863   INFO --- [Executor task launch worker for task 0]  org.apache.hadoop.conf.Configuration.deprecation(line:840) : mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
2018-09-17 16:35:00,863   INFO --- [Executor task launch worker for task 1]  org.apache.hadoop.conf.Configuration.deprecation(line:840) : mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
2018-09-17 16:35:00,863   INFO --- [Executor task launch worker for task 0]  org.apache.hadoop.conf.Configuration.deprecation(line:840) : mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
2018-09-17 16:35:00,863   INFO --- [Executor task launch worker for task 1]  org.apache.hadoop.conf.Configuration.deprecation(line:840) : mapred.job.id is deprecated. Instead, use mapreduce.job.id
2018-09-17 16:35:00,964   INFO --- [Executor task launch worker for task 1]  org.apache.spark.executor.Executor(line:54) : Finished task 1.0 in stage 0.0 (TID 1). 1658 bytes result sent to driver
2018-09-17 16:35:00,964   INFO --- [Executor task launch worker for task 0]  org.apache.spark.executor.Executor(line:54) : Finished task 0.0 in stage 0.0 (TID 0). 1745 bytes result sent to driver
2018-09-17 16:35:00,974   INFO --- [task-result-getter-1]  org.apache.spark.scheduler.TaskSetManager(line:54) : Finished task 0.0 in stage 0.0 (TID 0) in 196 ms on localhost (executor driver) (1/2)
2018-09-17 16:35:00,974   INFO --- [task-result-getter-0]  org.apache.spark.scheduler.TaskSetManager(line:54) : Finished task 1.0 in stage 0.0 (TID 1) in 168 ms on localhost (executor driver) (2/2)
2018-09-17 16:35:00,975   INFO --- [task-result-getter-0]  org.apache.spark.scheduler.TaskSchedulerImpl(line:54) : Removed TaskSet 0.0, whose tasks have all completed, from pool 
2018-09-17 16:35:00,979   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : ShuffleMapStage 0 (map at logSession.scala:14) finished in 0.217 s
2018-09-17 16:35:00,980   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : looking for newly runnable stages
2018-09-17 16:35:00,980   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : running: Set()
2018-09-17 16:35:00,981   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : waiting: Set(ShuffleMapStage 1, ResultStage 2)
2018-09-17 16:35:00,981   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : failed: Set()
2018-09-17 16:35:00,985   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Submitting ShuffleMapStage 1 (MapPartitionsRDD[5] at sortBy at logSession.scala:14), which has no missing parents
2018-09-17 16:35:00,993   INFO --- [dag-scheduler-event-loop]  org.apache.spark.storage.memory.MemoryStore(line:54) : Block broadcast_2 stored as values in memory (estimated size 4.2 KB, free 3.0 GB)
2018-09-17 16:35:00,997   INFO --- [dag-scheduler-event-loop]  org.apache.spark.storage.memory.MemoryStore(line:54) : Block broadcast_2_piece0 stored as bytes in memory (estimated size 2.4 KB, free 3.0 GB)
2018-09-17 16:35:01,001   INFO --- [dispatcher-event-loop-3]  org.apache.spark.storage.BlockManagerInfo(line:54) : Added broadcast_2_piece0 in memory on 192.168.3.199:53733 (size: 2.4 KB, free: 3.0 GB)
2018-09-17 16:35:01,002   INFO --- [dag-scheduler-event-loop]  org.apache.spark.SparkContext(line:54) : Created broadcast 2 from broadcast at DAGScheduler.scala:996
2018-09-17 16:35:01,002   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[5] at sortBy at logSession.scala:14)
2018-09-17 16:35:01,002   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.TaskSchedulerImpl(line:54) : Adding task set 1.0 with 1 tasks
2018-09-17 16:35:01,006   INFO --- [dispatcher-event-loop-4]  org.apache.spark.scheduler.TaskSetManager(line:54) : Starting task 0.0 in stage 1.0 (TID 2, localhost, executor driver, partition 0, ANY, 5739 bytes)
2018-09-17 16:35:01,007   INFO --- [Executor task launch worker for task 2]  org.apache.spark.executor.Executor(line:54) : Running task 0.0 in stage 1.0 (TID 2)
2018-09-17 16:35:01,020   INFO --- [Executor task launch worker for task 2]  org.apache.spark.storage.ShuffleBlockFetcherIterator(line:54) : Getting 2 non-empty blocks out of 2 blocks
2018-09-17 16:35:01,022   INFO --- [Executor task launch worker for task 2]  org.apache.spark.storage.ShuffleBlockFetcherIterator(line:54) : Started 0 remote fetches in 4 ms
2018-09-17 16:35:01,115   INFO --- [Executor task launch worker for task 2]  org.apache.spark.executor.Executor(line:54) : Finished task 0.0 in stage 1.0 (TID 2). 1960 bytes result sent to driver
2018-09-17 16:35:01,116   INFO --- [task-result-getter-2]  org.apache.spark.scheduler.TaskSetManager(line:54) : Finished task 0.0 in stage 1.0 (TID 2) in 111 ms on localhost (executor driver) (1/1)
2018-09-17 16:35:01,116   INFO --- [task-result-getter-2]  org.apache.spark.scheduler.TaskSchedulerImpl(line:54) : Removed TaskSet 1.0, whose tasks have all completed, from pool 
2018-09-17 16:35:01,117   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : ShuffleMapStage 1 (sortBy at logSession.scala:14) finished in 0.111 s
2018-09-17 16:35:01,117   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : looking for newly runnable stages
2018-09-17 16:35:01,117   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : running: Set()
2018-09-17 16:35:01,117   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : waiting: Set(ResultStage 2)
2018-09-17 16:35:01,117   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : failed: Set()
2018-09-17 16:35:01,118   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Submitting ResultStage 2 (MapPartitionsRDD[7] at sortBy at logSession.scala:14), which has no missing parents
2018-09-17 16:35:01,121   INFO --- [dag-scheduler-event-loop]  org.apache.spark.storage.memory.MemoryStore(line:54) : Block broadcast_3 stored as values in memory (estimated size 3.5 KB, free 3.0 GB)
2018-09-17 16:35:01,124   INFO --- [dag-scheduler-event-loop]  org.apache.spark.storage.memory.MemoryStore(line:54) : Block broadcast_3_piece0 stored as bytes in memory (estimated size 2017.0 B, free 3.0 GB)
2018-09-17 16:35:01,125   INFO --- [dispatcher-event-loop-0]  org.apache.spark.storage.BlockManagerInfo(line:54) : Added broadcast_3_piece0 in memory on 192.168.3.199:53733 (size: 2017.0 B, free: 3.0 GB)
2018-09-17 16:35:01,125   INFO --- [dag-scheduler-event-loop]  org.apache.spark.SparkContext(line:54) : Created broadcast 3 from broadcast at DAGScheduler.scala:996
2018-09-17 16:35:01,126   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[7] at sortBy at logSession.scala:14)
2018-09-17 16:35:01,126   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.TaskSchedulerImpl(line:54) : Adding task set 2.0 with 1 tasks
2018-09-17 16:35:01,129   INFO --- [dispatcher-event-loop-7]  org.apache.spark.scheduler.TaskSetManager(line:54) : Starting task 0.0 in stage 2.0 (TID 3, localhost, executor driver, partition 0, ANY, 5750 bytes)
2018-09-17 16:35:01,130   INFO --- [Executor task launch worker for task 3]  org.apache.spark.executor.Executor(line:54) : Running task 0.0 in stage 2.0 (TID 3)
2018-09-17 16:35:01,133   INFO --- [Executor task launch worker for task 3]  org.apache.spark.storage.ShuffleBlockFetcherIterator(line:54) : Getting 1 non-empty blocks out of 1 blocks
2018-09-17 16:35:01,133   INFO --- [Executor task launch worker for task 3]  org.apache.spark.storage.ShuffleBlockFetcherIterator(line:54) : Started 0 remote fetches in 0 ms
2018-09-17 16:35:01,145   INFO --- [Executor task launch worker for task 3]  org.apache.spark.executor.Executor(line:54) : Finished task 0.0 in stage 2.0 (TID 3). 2351 bytes result sent to driver
2018-09-17 16:35:01,146   INFO --- [task-result-getter-3]  org.apache.spark.scheduler.TaskSetManager(line:54) : Finished task 0.0 in stage 2.0 (TID 3) in 19 ms on localhost (executor driver) (1/1)
2018-09-17 16:35:01,146   INFO --- [task-result-getter-3]  org.apache.spark.scheduler.TaskSchedulerImpl(line:54) : Removed TaskSet 2.0, whose tasks have all completed, from pool 
2018-09-17 16:35:01,147   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : ResultStage 2 (collect at logSession.scala:17) finished in 0.020 s
2018-09-17 16:35:01,152   INFO --- [main]  org.apache.spark.scheduler.DAGScheduler(line:54) : Job 0 finished: collect at logSession.scala:17, took 0.712934 s
2018-09-17 16:35:01,161   INFO --- [main]  org.spark_project.jetty.server.ServerConnector(line:306) : Stopped Spark@5553d0f5{HTTP/1.1}{0.0.0.0:4040}
2018-09-17 16:35:01,163   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@5066d65f{/stages/stage/kill,null,UNAVAILABLE,@Spark}
2018-09-17 16:35:01,163   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@3401a114{/jobs/job/kill,null,UNAVAILABLE,@Spark}
2018-09-17 16:35:01,163   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@7e276594{/api,null,UNAVAILABLE,@Spark}
2018-09-17 16:35:01,163   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@655ef322{/,null,UNAVAILABLE,@Spark}
2018-09-17 16:35:01,163   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@55562aa9{/static,null,UNAVAILABLE,@Spark}
2018-09-17 16:35:01,163   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@73173f63{/executors/threadDump/json,null,UNAVAILABLE,@Spark}
2018-09-17 16:35:01,164   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@35e5d0e5{/executors/threadDump,null,UNAVAILABLE,@Spark}
2018-09-17 16:35:01,164   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@25e2ab5a{/executors/json,null,UNAVAILABLE,@Spark}
2018-09-17 16:35:01,164   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@c055c54{/executors,null,UNAVAILABLE,@Spark}
2018-09-17 16:35:01,164   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@3d9f6567{/environment/json,null,UNAVAILABLE,@Spark}
2018-09-17 16:35:01,164   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@119020fb{/environment,null,UNAVAILABLE,@Spark}
2018-09-17 16:35:01,164   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@710b18a6{/storage/rdd/json,null,UNAVAILABLE,@Spark}
2018-09-17 16:35:01,165   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@2cc3ad05{/storage/rdd,null,UNAVAILABLE,@Spark}
2018-09-17 16:35:01,165   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@2101b44a{/storage/json,null,UNAVAILABLE,@Spark}
2018-09-17 16:35:01,165   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@52d645b1{/storage,null,UNAVAILABLE,@Spark}
2018-09-17 16:35:01,165   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@333dd51e{/stages/pool/json,null,UNAVAILABLE,@Spark}
2018-09-17 16:35:01,165   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@7c1e2a2d{/stages/pool,null,UNAVAILABLE,@Spark}
2018-09-17 16:35:01,165   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@2a5b3fee{/stages/stage/json,null,UNAVAILABLE,@Spark}
2018-09-17 16:35:01,165   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@ec2cc4{/stages/stage,null,UNAVAILABLE,@Spark}
2018-09-17 16:35:01,166   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@4097cac{/stages/json,null,UNAVAILABLE,@Spark}
2018-09-17 16:35:01,166   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@ccb4b1b{/stages,null,UNAVAILABLE,@Spark}
2018-09-17 16:35:01,166   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@4c2cc639{/jobs/job/json,null,UNAVAILABLE,@Spark}
2018-09-17 16:35:01,166   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@7f6f61c8{/jobs/job,null,UNAVAILABLE,@Spark}
2018-09-17 16:35:01,166   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@6f2cfcc2{/jobs/json,null,UNAVAILABLE,@Spark}
2018-09-17 16:35:01,167   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@1c3b9394{/jobs,null,UNAVAILABLE,@Spark}
2018-09-17 16:35:01,168   INFO --- [main]  org.apache.spark.ui.SparkUI(line:54) : Stopped Spark web UI at http://192.168.3.199:4040
2018-09-17 16:35:01,176   INFO --- [dispatcher-event-loop-5]  org.apache.spark.MapOutputTrackerMasterEndpoint(line:54) : MapOutputTrackerMasterEndpoint stopped!
2018-09-17 16:35:01,274   INFO --- [main]  org.apache.spark.storage.memory.MemoryStore(line:54) : MemoryStore cleared
2018-09-17 16:35:01,275   INFO --- [main]  org.apache.spark.storage.BlockManager(line:54) : BlockManager stopped
2018-09-17 16:35:01,281   INFO --- [main]  org.apache.spark.storage.BlockManagerMaster(line:54) : BlockManagerMaster stopped
2018-09-17 16:35:01,284   INFO --- [dispatcher-event-loop-1]  org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint(line:54) : OutputCommitCoordinator stopped!
2018-09-17 16:35:01,290   INFO --- [main]  org.apache.spark.SparkContext(line:54) : Successfully stopped SparkContext
2018-09-17 16:35:01,292   INFO --- [Thread-1]  org.apache.spark.util.ShutdownHookManager(line:54) : Shutdown hook called
2018-09-17 16:35:01,293   INFO --- [Thread-1]  org.apache.spark.util.ShutdownHookManager(line:54) : Deleting directory C:\Users\wshs\AppData\Local\Temp\spark-83681275-092a-4d0a-8b20-1631b61ab17f
2018-09-17 17:10:11,671   INFO --- [main]  org.apache.spark.SparkContext(line:54) : Running Spark version 2.1.1
2018-09-17 17:10:12,036   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing view acls to: wshs
2018-09-17 17:10:12,037   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing modify acls to: wshs
2018-09-17 17:10:12,037   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing view acls groups to: 
2018-09-17 17:10:12,038   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing modify acls groups to: 
2018-09-17 17:10:12,039   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(wshs); groups with view permissions: Set(); users  with modify permissions: Set(wshs); groups with modify permissions: Set()
2018-09-17 17:10:12,489   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'sparkDriver' on port 51180.
2018-09-17 17:10:12,506   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering MapOutputTracker
2018-09-17 17:10:12,524   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering BlockManagerMaster
2018-09-17 17:10:12,527   INFO --- [main]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-09-17 17:10:12,527   INFO --- [main]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : BlockManagerMasterEndpoint up
2018-09-17 17:10:12,540   INFO --- [main]  org.apache.spark.storage.DiskBlockManager(line:54) : Created local directory at C:\Users\wshs\AppData\Local\Temp\blockmgr-ed9965f1-646e-4350-a2eb-6fcfd6fb9df7
2018-09-17 17:10:12,556   INFO --- [main]  org.apache.spark.storage.memory.MemoryStore(line:54) : MemoryStore started with capacity 3.0 GB
2018-09-17 17:10:12,600   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering OutputCommitCoordinator
2018-09-17 17:10:12,683   INFO --- [main]  org.spark_project.jetty.util.log(line:186) : Logging initialized @2802ms
2018-09-17 17:10:12,787   INFO --- [main]  org.spark_project.jetty.server.Server(line:327) : jetty-9.2.z-SNAPSHOT
2018-09-17 17:10:12,803   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@295eaa7c{/jobs,null,AVAILABLE,@Spark}
2018-09-17 17:10:12,804   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@3918c187{/jobs/json,null,AVAILABLE,@Spark}
2018-09-17 17:10:12,804   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@2c88b9fc{/jobs/job,null,AVAILABLE,@Spark}
2018-09-17 17:10:12,804   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@64dafeed{/jobs/job/json,null,AVAILABLE,@Spark}
2018-09-17 17:10:12,805   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@388ba540{/stages,null,AVAILABLE,@Spark}
2018-09-17 17:10:12,805   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@47605f2f{/stages/json,null,AVAILABLE,@Spark}
2018-09-17 17:10:12,806   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@2ece4966{/stages/stage,null,AVAILABLE,@Spark}
2018-09-17 17:10:12,806   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@1dd0e7c4{/stages/stage/json,null,AVAILABLE,@Spark}
2018-09-17 17:10:12,807   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@7894f09b{/stages/pool,null,AVAILABLE,@Spark}
2018-09-17 17:10:12,807   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@3d484181{/stages/pool/json,null,AVAILABLE,@Spark}
2018-09-17 17:10:12,808   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@6111ba37{/storage,null,AVAILABLE,@Spark}
2018-09-17 17:10:12,808   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@7be58f16{/storage/json,null,AVAILABLE,@Spark}
2018-09-17 17:10:12,808   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@242aa8d9{/storage/rdd,null,AVAILABLE,@Spark}
2018-09-17 17:10:12,809   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@5b11a194{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-09-17 17:10:12,809   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@37bd68c3{/environment,null,AVAILABLE,@Spark}
2018-09-17 17:10:12,809   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@60f7cc1d{/environment/json,null,AVAILABLE,@Spark}
2018-09-17 17:10:12,810   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@11eadcba{/executors,null,AVAILABLE,@Spark}
2018-09-17 17:10:12,810   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@4721d212{/executors/json,null,AVAILABLE,@Spark}
2018-09-17 17:10:12,810   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@1b065145{/executors/threadDump,null,AVAILABLE,@Spark}
2018-09-17 17:10:12,810   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@45cff11c{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-09-17 17:10:12,816   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@207ea13{/static,null,AVAILABLE,@Spark}
2018-09-17 17:10:12,817   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@4bff1903{/,null,AVAILABLE,@Spark}
2018-09-17 17:10:12,817   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@62dae540{/api,null,AVAILABLE,@Spark}
2018-09-17 17:10:12,818   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@5827af16{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-09-17 17:10:12,818   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@654d8173{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-09-17 17:10:12,830   INFO --- [main]  org.spark_project.jetty.server.ServerConnector(line:266) : Started Spark@3234f74e{HTTP/1.1}{0.0.0.0:4040}
2018-09-17 17:10:12,830   INFO --- [main]  org.spark_project.jetty.server.Server(line:379) : Started @2950ms
2018-09-17 17:10:12,831   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'SparkUI' on port 4040.
2018-09-17 17:10:12,834   INFO --- [main]  org.apache.spark.ui.SparkUI(line:54) : Bound SparkUI to 0.0.0.0, and started at http://192.168.3.199:4040
2018-09-17 17:10:12,898   INFO --- [main]  org.apache.spark.executor.Executor(line:54) : Starting executor ID driver on host localhost
2018-09-17 17:10:12,953   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 51235.
2018-09-17 17:10:12,953   INFO --- [main]  org.apache.spark.network.netty.NettyBlockTransferService(line:54) : Server created on 192.168.3.199:51235
2018-09-17 17:10:12,955   INFO --- [main]  org.apache.spark.storage.BlockManager(line:54) : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-09-17 17:10:12,957   INFO --- [main]  org.apache.spark.storage.BlockManagerMaster(line:54) : Registering BlockManager BlockManagerId(driver, 192.168.3.199, 51235, None)
2018-09-17 17:10:12,959   INFO --- [dispatcher-event-loop-2]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : Registering block manager 192.168.3.199:51235 with 3.0 GB RAM, BlockManagerId(driver, 192.168.3.199, 51235, None)
2018-09-17 17:10:12,962   INFO --- [main]  org.apache.spark.storage.BlockManagerMaster(line:54) : Registered BlockManager BlockManagerId(driver, 192.168.3.199, 51235, None)
2018-09-17 17:10:12,963   INFO --- [main]  org.apache.spark.storage.BlockManager(line:54) : Initialized BlockManager: BlockManagerId(driver, 192.168.3.199, 51235, None)
2018-09-17 17:10:13,142   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@344561e0{/metrics/json,null,AVAILABLE,@Spark}
2018-09-17 17:10:13,169   INFO --- [main]  org.apache.spark.sql.internal.SharedState(line:54) : Warehouse path is '/spark-warehouse'.
2018-09-17 17:10:13,176   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@33c2bd{/SQL,null,AVAILABLE,@Spark}
2018-09-17 17:10:13,176   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@3c321bdb{/SQL/json,null,AVAILABLE,@Spark}
2018-09-17 17:10:13,177   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@6f0628de{/SQL/execution,null,AVAILABLE,@Spark}
2018-09-17 17:10:13,178   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@1e392345{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-09-17 17:10:13,182   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@51b01960{/static/sql,null,AVAILABLE,@Spark}
2018-09-17 17:10:13,190   INFO --- [Thread-1]  org.apache.spark.SparkContext(line:54) : Invoking stop() from shutdown hook
2018-09-17 17:10:13,196   INFO --- [Thread-1]  org.spark_project.jetty.server.ServerConnector(line:306) : Stopped Spark@3234f74e{HTTP/1.1}{0.0.0.0:4040}
2018-09-17 17:10:13,198   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@654d8173{/stages/stage/kill,null,UNAVAILABLE,@Spark}
2018-09-17 17:10:13,198   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@5827af16{/jobs/job/kill,null,UNAVAILABLE,@Spark}
2018-09-17 17:10:13,198   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@62dae540{/api,null,UNAVAILABLE,@Spark}
2018-09-17 17:10:13,199   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@4bff1903{/,null,UNAVAILABLE,@Spark}
2018-09-17 17:10:13,199   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@207ea13{/static,null,UNAVAILABLE,@Spark}
2018-09-17 17:10:13,199   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@45cff11c{/executors/threadDump/json,null,UNAVAILABLE,@Spark}
2018-09-17 17:10:13,199   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@1b065145{/executors/threadDump,null,UNAVAILABLE,@Spark}
2018-09-17 17:10:13,199   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@4721d212{/executors/json,null,UNAVAILABLE,@Spark}
2018-09-17 17:10:13,200   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@11eadcba{/executors,null,UNAVAILABLE,@Spark}
2018-09-17 17:10:13,200   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@60f7cc1d{/environment/json,null,UNAVAILABLE,@Spark}
2018-09-17 17:10:13,200   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@37bd68c3{/environment,null,UNAVAILABLE,@Spark}
2018-09-17 17:10:13,200   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@5b11a194{/storage/rdd/json,null,UNAVAILABLE,@Spark}
2018-09-17 17:10:13,201   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@242aa8d9{/storage/rdd,null,UNAVAILABLE,@Spark}
2018-09-17 17:10:13,201   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@7be58f16{/storage/json,null,UNAVAILABLE,@Spark}
2018-09-17 17:10:13,201   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@6111ba37{/storage,null,UNAVAILABLE,@Spark}
2018-09-17 17:10:13,201   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@3d484181{/stages/pool/json,null,UNAVAILABLE,@Spark}
2018-09-17 17:10:13,202   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@7894f09b{/stages/pool,null,UNAVAILABLE,@Spark}
2018-09-17 17:10:13,202   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@1dd0e7c4{/stages/stage/json,null,UNAVAILABLE,@Spark}
2018-09-17 17:10:13,202   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@2ece4966{/stages/stage,null,UNAVAILABLE,@Spark}
2018-09-17 17:10:13,202   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@47605f2f{/stages/json,null,UNAVAILABLE,@Spark}
2018-09-17 17:10:13,203   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@388ba540{/stages,null,UNAVAILABLE,@Spark}
2018-09-17 17:10:13,203   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@64dafeed{/jobs/job/json,null,UNAVAILABLE,@Spark}
2018-09-17 17:10:13,203   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@2c88b9fc{/jobs/job,null,UNAVAILABLE,@Spark}
2018-09-17 17:10:13,203   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@3918c187{/jobs/json,null,UNAVAILABLE,@Spark}
2018-09-17 17:10:13,204   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@295eaa7c{/jobs,null,UNAVAILABLE,@Spark}
2018-09-17 17:10:13,205   INFO --- [Thread-1]  org.apache.spark.ui.SparkUI(line:54) : Stopped Spark web UI at http://192.168.3.199:4040
2018-09-17 17:10:13,218   INFO --- [dispatcher-event-loop-6]  org.apache.spark.MapOutputTrackerMasterEndpoint(line:54) : MapOutputTrackerMasterEndpoint stopped!
2018-09-17 17:10:13,229   INFO --- [Thread-1]  org.apache.spark.storage.memory.MemoryStore(line:54) : MemoryStore cleared
2018-09-17 17:10:13,230   INFO --- [Thread-1]  org.apache.spark.storage.BlockManager(line:54) : BlockManager stopped
2018-09-17 17:10:13,235   INFO --- [Thread-1]  org.apache.spark.storage.BlockManagerMaster(line:54) : BlockManagerMaster stopped
2018-09-17 17:10:13,239   INFO --- [dispatcher-event-loop-3]  org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint(line:54) : OutputCommitCoordinator stopped!
2018-09-17 17:10:13,245   INFO --- [Thread-1]  org.apache.spark.SparkContext(line:54) : Successfully stopped SparkContext
2018-09-17 17:10:13,246   INFO --- [Thread-1]  org.apache.spark.util.ShutdownHookManager(line:54) : Shutdown hook called
2018-09-17 17:10:13,247   INFO --- [Thread-1]  org.apache.spark.util.ShutdownHookManager(line:54) : Deleting directory C:\Users\wshs\AppData\Local\Temp\spark-9f3278eb-2a07-4749-a1e6-975c8471b4a5
2018-09-17 17:14:13,898   INFO --- [main]  org.apache.spark.SparkContext(line:54) : Running Spark version 2.1.1
2018-09-17 17:14:14,287   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing view acls to: wshs
2018-09-17 17:14:14,288   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing modify acls to: wshs
2018-09-17 17:14:14,289   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing view acls groups to: 
2018-09-17 17:14:14,290   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing modify acls groups to: 
2018-09-17 17:14:14,290   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(wshs); groups with view permissions: Set(); users  with modify permissions: Set(wshs); groups with modify permissions: Set()
2018-09-17 17:14:14,778   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'sparkDriver' on port 59828.
2018-09-17 17:14:14,799   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering MapOutputTracker
2018-09-17 17:14:14,820   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering BlockManagerMaster
2018-09-17 17:14:14,823   INFO --- [main]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-09-17 17:14:14,823   INFO --- [main]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : BlockManagerMasterEndpoint up
2018-09-17 17:14:14,838   INFO --- [main]  org.apache.spark.storage.DiskBlockManager(line:54) : Created local directory at C:\Users\wshs\AppData\Local\Temp\blockmgr-ab38ba9a-e581-4692-babb-4dda7a956c9a
2018-09-17 17:14:14,856   INFO --- [main]  org.apache.spark.storage.memory.MemoryStore(line:54) : MemoryStore started with capacity 3.0 GB
2018-09-17 17:14:14,899   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering OutputCommitCoordinator
2018-09-17 17:14:14,990   INFO --- [main]  org.spark_project.jetty.util.log(line:186) : Logging initialized @2960ms
2018-09-17 17:14:15,083   INFO --- [main]  org.spark_project.jetty.server.Server(line:327) : jetty-9.2.z-SNAPSHOT
2018-09-17 17:14:15,098   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@295eaa7c{/jobs,null,AVAILABLE,@Spark}
2018-09-17 17:14:15,099   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@3918c187{/jobs/json,null,AVAILABLE,@Spark}
2018-09-17 17:14:15,099   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@2c88b9fc{/jobs/job,null,AVAILABLE,@Spark}
2018-09-17 17:14:15,100   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@64dafeed{/jobs/job/json,null,AVAILABLE,@Spark}
2018-09-17 17:14:15,100   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@388ba540{/stages,null,AVAILABLE,@Spark}
2018-09-17 17:14:15,100   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@47605f2f{/stages/json,null,AVAILABLE,@Spark}
2018-09-17 17:14:15,100   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@2ece4966{/stages/stage,null,AVAILABLE,@Spark}
2018-09-17 17:14:15,100   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@1dd0e7c4{/stages/stage/json,null,AVAILABLE,@Spark}
2018-09-17 17:14:15,101   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@7894f09b{/stages/pool,null,AVAILABLE,@Spark}
2018-09-17 17:14:15,101   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@3d484181{/stages/pool/json,null,AVAILABLE,@Spark}
2018-09-17 17:14:15,101   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@6111ba37{/storage,null,AVAILABLE,@Spark}
2018-09-17 17:14:15,102   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@7be58f16{/storage/json,null,AVAILABLE,@Spark}
2018-09-17 17:14:15,102   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@242aa8d9{/storage/rdd,null,AVAILABLE,@Spark}
2018-09-17 17:14:15,102   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@5b11a194{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-09-17 17:14:15,102   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@37bd68c3{/environment,null,AVAILABLE,@Spark}
2018-09-17 17:14:15,103   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@60f7cc1d{/environment/json,null,AVAILABLE,@Spark}
2018-09-17 17:14:15,103   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@11eadcba{/executors,null,AVAILABLE,@Spark}
2018-09-17 17:14:15,103   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@4721d212{/executors/json,null,AVAILABLE,@Spark}
2018-09-17 17:14:15,103   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@1b065145{/executors/threadDump,null,AVAILABLE,@Spark}
2018-09-17 17:14:15,103   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@45cff11c{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-09-17 17:14:15,109   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@207ea13{/static,null,AVAILABLE,@Spark}
2018-09-17 17:14:15,109   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@4bff1903{/,null,AVAILABLE,@Spark}
2018-09-17 17:14:15,110   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@62dae540{/api,null,AVAILABLE,@Spark}
2018-09-17 17:14:15,110   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@5827af16{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-09-17 17:14:15,111   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@654d8173{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-09-17 17:14:15,123   INFO --- [main]  org.spark_project.jetty.server.ServerConnector(line:266) : Started Spark@3234f74e{HTTP/1.1}{0.0.0.0:4040}
2018-09-17 17:14:15,123   INFO --- [main]  org.spark_project.jetty.server.Server(line:379) : Started @3095ms
2018-09-17 17:14:15,124   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'SparkUI' on port 4040.
2018-09-17 17:14:15,126   INFO --- [main]  org.apache.spark.ui.SparkUI(line:54) : Bound SparkUI to 0.0.0.0, and started at http://192.168.3.199:4040
2018-09-17 17:14:15,185   INFO --- [main]  org.apache.spark.executor.Executor(line:54) : Starting executor ID driver on host localhost
2018-09-17 17:14:15,248   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 59886.
2018-09-17 17:14:15,249   INFO --- [main]  org.apache.spark.network.netty.NettyBlockTransferService(line:54) : Server created on 192.168.3.199:59886
2018-09-17 17:14:15,252   INFO --- [main]  org.apache.spark.storage.BlockManager(line:54) : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-09-17 17:14:15,254   INFO --- [main]  org.apache.spark.storage.BlockManagerMaster(line:54) : Registering BlockManager BlockManagerId(driver, 192.168.3.199, 59886, None)
2018-09-17 17:14:15,258   INFO --- [dispatcher-event-loop-2]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : Registering block manager 192.168.3.199:59886 with 3.0 GB RAM, BlockManagerId(driver, 192.168.3.199, 59886, None)
2018-09-17 17:14:15,262   INFO --- [main]  org.apache.spark.storage.BlockManagerMaster(line:54) : Registered BlockManager BlockManagerId(driver, 192.168.3.199, 59886, None)
2018-09-17 17:14:15,262   INFO --- [main]  org.apache.spark.storage.BlockManager(line:54) : Initialized BlockManager: BlockManagerId(driver, 192.168.3.199, 59886, None)
2018-09-17 17:14:15,435   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@344561e0{/metrics/json,null,AVAILABLE,@Spark}
2018-09-17 17:14:15,465   INFO --- [main]  org.apache.spark.sql.internal.SharedState(line:54) : Warehouse path is '/spark-warehouse'.
2018-09-17 17:14:15,471   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@3c321bdb{/SQL,null,AVAILABLE,@Spark}
2018-09-17 17:14:15,472   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@3abd581e{/SQL/json,null,AVAILABLE,@Spark}
2018-09-17 17:14:15,473   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@1e392345{/SQL/execution,null,AVAILABLE,@Spark}
2018-09-17 17:14:15,474   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@4ced35ed{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-09-17 17:14:15,476   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@27dc79f7{/static/sql,null,AVAILABLE,@Spark}
2018-09-17 17:14:15,487   INFO --- [Thread-1]  org.apache.spark.SparkContext(line:54) : Invoking stop() from shutdown hook
2018-09-17 17:14:15,492   INFO --- [Thread-1]  org.spark_project.jetty.server.ServerConnector(line:306) : Stopped Spark@3234f74e{HTTP/1.1}{0.0.0.0:4040}
2018-09-17 17:14:15,495   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@654d8173{/stages/stage/kill,null,UNAVAILABLE,@Spark}
2018-09-17 17:14:15,495   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@5827af16{/jobs/job/kill,null,UNAVAILABLE,@Spark}
2018-09-17 17:14:15,496   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@62dae540{/api,null,UNAVAILABLE,@Spark}
2018-09-17 17:14:15,496   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@4bff1903{/,null,UNAVAILABLE,@Spark}
2018-09-17 17:14:15,496   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@207ea13{/static,null,UNAVAILABLE,@Spark}
2018-09-17 17:14:15,496   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@45cff11c{/executors/threadDump/json,null,UNAVAILABLE,@Spark}
2018-09-17 17:14:15,497   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@1b065145{/executors/threadDump,null,UNAVAILABLE,@Spark}
2018-09-17 17:14:15,497   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@4721d212{/executors/json,null,UNAVAILABLE,@Spark}
2018-09-17 17:14:15,497   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@11eadcba{/executors,null,UNAVAILABLE,@Spark}
2018-09-17 17:14:15,497   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@60f7cc1d{/environment/json,null,UNAVAILABLE,@Spark}
2018-09-17 17:14:15,498   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@37bd68c3{/environment,null,UNAVAILABLE,@Spark}
2018-09-17 17:14:15,498   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@5b11a194{/storage/rdd/json,null,UNAVAILABLE,@Spark}
2018-09-17 17:14:15,498   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@242aa8d9{/storage/rdd,null,UNAVAILABLE,@Spark}
2018-09-17 17:14:15,498   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@7be58f16{/storage/json,null,UNAVAILABLE,@Spark}
2018-09-17 17:14:15,498   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@6111ba37{/storage,null,UNAVAILABLE,@Spark}
2018-09-17 17:14:15,499   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@3d484181{/stages/pool/json,null,UNAVAILABLE,@Spark}
2018-09-17 17:14:15,499   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@7894f09b{/stages/pool,null,UNAVAILABLE,@Spark}
2018-09-17 17:14:15,499   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@1dd0e7c4{/stages/stage/json,null,UNAVAILABLE,@Spark}
2018-09-17 17:14:15,499   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@2ece4966{/stages/stage,null,UNAVAILABLE,@Spark}
2018-09-17 17:14:15,499   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@47605f2f{/stages/json,null,UNAVAILABLE,@Spark}
2018-09-17 17:14:15,499   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@388ba540{/stages,null,UNAVAILABLE,@Spark}
2018-09-17 17:14:15,501   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@64dafeed{/jobs/job/json,null,UNAVAILABLE,@Spark}
2018-09-17 17:14:15,501   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@2c88b9fc{/jobs/job,null,UNAVAILABLE,@Spark}
2018-09-17 17:14:15,501   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@3918c187{/jobs/json,null,UNAVAILABLE,@Spark}
2018-09-17 17:14:15,502   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@295eaa7c{/jobs,null,UNAVAILABLE,@Spark}
2018-09-17 17:14:15,503   INFO --- [Thread-1]  org.apache.spark.ui.SparkUI(line:54) : Stopped Spark web UI at http://192.168.3.199:4040
2018-09-17 17:14:15,518   INFO --- [dispatcher-event-loop-6]  org.apache.spark.MapOutputTrackerMasterEndpoint(line:54) : MapOutputTrackerMasterEndpoint stopped!
2018-09-17 17:14:15,532   INFO --- [Thread-1]  org.apache.spark.storage.memory.MemoryStore(line:54) : MemoryStore cleared
2018-09-17 17:14:15,532   INFO --- [Thread-1]  org.apache.spark.storage.BlockManager(line:54) : BlockManager stopped
2018-09-17 17:14:15,540   INFO --- [Thread-1]  org.apache.spark.storage.BlockManagerMaster(line:54) : BlockManagerMaster stopped
2018-09-17 17:14:15,544   INFO --- [dispatcher-event-loop-3]  org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint(line:54) : OutputCommitCoordinator stopped!
2018-09-17 17:14:15,552   INFO --- [Thread-1]  org.apache.spark.SparkContext(line:54) : Successfully stopped SparkContext
2018-09-17 17:14:15,552   INFO --- [Thread-1]  org.apache.spark.util.ShutdownHookManager(line:54) : Shutdown hook called
2018-09-17 17:14:15,553   INFO --- [Thread-1]  org.apache.spark.util.ShutdownHookManager(line:54) : Deleting directory C:\Users\wshs\AppData\Local\Temp\spark-4670dc0c-f5d3-4e17-8b73-6c4fb70e3d54
2018-09-17 17:16:28,345   INFO --- [main]  org.apache.spark.SparkContext(line:54) : Running Spark version 2.1.1
2018-09-17 17:16:28,653   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing view acls to: wshs
2018-09-17 17:16:28,654   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing modify acls to: wshs
2018-09-17 17:16:28,655   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing view acls groups to: 
2018-09-17 17:16:28,655   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing modify acls groups to: 
2018-09-17 17:16:28,656   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(wshs); groups with view permissions: Set(); users  with modify permissions: Set(wshs); groups with modify permissions: Set()
2018-09-17 17:16:29,098   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'sparkDriver' on port 64713.
2018-09-17 17:16:29,115   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering MapOutputTracker
2018-09-17 17:16:29,131   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering BlockManagerMaster
2018-09-17 17:16:29,134   INFO --- [main]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-09-17 17:16:29,135   INFO --- [main]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : BlockManagerMasterEndpoint up
2018-09-17 17:16:29,147   INFO --- [main]  org.apache.spark.storage.DiskBlockManager(line:54) : Created local directory at C:\Users\wshs\AppData\Local\Temp\blockmgr-01e64797-486b-4386-9071-36c83512da39
2018-09-17 17:16:29,162   INFO --- [main]  org.apache.spark.storage.memory.MemoryStore(line:54) : MemoryStore started with capacity 3.0 GB
2018-09-17 17:16:29,199   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering OutputCommitCoordinator
2018-09-17 17:16:29,276   INFO --- [main]  org.spark_project.jetty.util.log(line:186) : Logging initialized @2561ms
2018-09-17 17:16:29,362   INFO --- [main]  org.spark_project.jetty.server.Server(line:327) : jetty-9.2.z-SNAPSHOT
2018-09-17 17:16:29,377   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@295eaa7c{/jobs,null,AVAILABLE,@Spark}
2018-09-17 17:16:29,378   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@3918c187{/jobs/json,null,AVAILABLE,@Spark}
2018-09-17 17:16:29,378   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@2c88b9fc{/jobs/job,null,AVAILABLE,@Spark}
2018-09-17 17:16:29,378   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@64dafeed{/jobs/job/json,null,AVAILABLE,@Spark}
2018-09-17 17:16:29,378   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@388ba540{/stages,null,AVAILABLE,@Spark}
2018-09-17 17:16:29,379   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@47605f2f{/stages/json,null,AVAILABLE,@Spark}
2018-09-17 17:16:29,379   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@2ece4966{/stages/stage,null,AVAILABLE,@Spark}
2018-09-17 17:16:29,379   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@1dd0e7c4{/stages/stage/json,null,AVAILABLE,@Spark}
2018-09-17 17:16:29,379   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@7894f09b{/stages/pool,null,AVAILABLE,@Spark}
2018-09-17 17:16:29,380   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@3d484181{/stages/pool/json,null,AVAILABLE,@Spark}
2018-09-17 17:16:29,380   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@6111ba37{/storage,null,AVAILABLE,@Spark}
2018-09-17 17:16:29,380   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@7be58f16{/storage/json,null,AVAILABLE,@Spark}
2018-09-17 17:16:29,380   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@242aa8d9{/storage/rdd,null,AVAILABLE,@Spark}
2018-09-17 17:16:29,381   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@5b11a194{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-09-17 17:16:29,381   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@37bd68c3{/environment,null,AVAILABLE,@Spark}
2018-09-17 17:16:29,381   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@60f7cc1d{/environment/json,null,AVAILABLE,@Spark}
2018-09-17 17:16:29,381   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@11eadcba{/executors,null,AVAILABLE,@Spark}
2018-09-17 17:16:29,381   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@4721d212{/executors/json,null,AVAILABLE,@Spark}
2018-09-17 17:16:29,381   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@1b065145{/executors/threadDump,null,AVAILABLE,@Spark}
2018-09-17 17:16:29,381   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@45cff11c{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-09-17 17:16:29,386   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@207ea13{/static,null,AVAILABLE,@Spark}
2018-09-17 17:16:29,386   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@4bff1903{/,null,AVAILABLE,@Spark}
2018-09-17 17:16:29,387   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@62dae540{/api,null,AVAILABLE,@Spark}
2018-09-17 17:16:29,387   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@5827af16{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-09-17 17:16:29,388   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@654d8173{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-09-17 17:16:29,398   INFO --- [main]  org.spark_project.jetty.server.ServerConnector(line:266) : Started Spark@3234f74e{HTTP/1.1}{0.0.0.0:4040}
2018-09-17 17:16:29,399   INFO --- [main]  org.spark_project.jetty.server.Server(line:379) : Started @2686ms
2018-09-17 17:16:29,399   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'SparkUI' on port 4040.
2018-09-17 17:16:29,402   INFO --- [main]  org.apache.spark.ui.SparkUI(line:54) : Bound SparkUI to 0.0.0.0, and started at http://192.168.3.199:4040
2018-09-17 17:16:29,464   INFO --- [main]  org.apache.spark.executor.Executor(line:54) : Starting executor ID driver on host localhost
2018-09-17 17:16:29,522   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 64758.
2018-09-17 17:16:29,522   INFO --- [main]  org.apache.spark.network.netty.NettyBlockTransferService(line:54) : Server created on 192.168.3.199:64758
2018-09-17 17:16:29,524   INFO --- [main]  org.apache.spark.storage.BlockManager(line:54) : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-09-17 17:16:29,526   INFO --- [main]  org.apache.spark.storage.BlockManagerMaster(line:54) : Registering BlockManager BlockManagerId(driver, 192.168.3.199, 64758, None)
2018-09-17 17:16:29,528   INFO --- [dispatcher-event-loop-2]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : Registering block manager 192.168.3.199:64758 with 3.0 GB RAM, BlockManagerId(driver, 192.168.3.199, 64758, None)
2018-09-17 17:16:29,531   INFO --- [main]  org.apache.spark.storage.BlockManagerMaster(line:54) : Registered BlockManager BlockManagerId(driver, 192.168.3.199, 64758, None)
2018-09-17 17:16:29,531   INFO --- [main]  org.apache.spark.storage.BlockManager(line:54) : Initialized BlockManager: BlockManagerId(driver, 192.168.3.199, 64758, None)
2018-09-17 17:16:29,714   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@344561e0{/metrics/json,null,AVAILABLE,@Spark}
2018-09-17 17:16:29,745   INFO --- [main]  org.apache.spark.sql.internal.SharedState(line:54) : Warehouse path is '/spark-warehouse'.
2018-09-17 17:16:29,751   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@3c321bdb{/SQL,null,AVAILABLE,@Spark}
2018-09-17 17:16:29,752   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@3abd581e{/SQL/json,null,AVAILABLE,@Spark}
2018-09-17 17:16:29,753   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@1e392345{/SQL/execution,null,AVAILABLE,@Spark}
2018-09-17 17:16:29,754   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@4ced35ed{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-09-17 17:16:29,755   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@27dc79f7{/static/sql,null,AVAILABLE,@Spark}
2018-09-17 17:16:29,765   INFO --- [Thread-1]  org.apache.spark.SparkContext(line:54) : Invoking stop() from shutdown hook
2018-09-17 17:16:29,770   INFO --- [Thread-1]  org.spark_project.jetty.server.ServerConnector(line:306) : Stopped Spark@3234f74e{HTTP/1.1}{0.0.0.0:4040}
2018-09-17 17:16:29,772   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@654d8173{/stages/stage/kill,null,UNAVAILABLE,@Spark}
2018-09-17 17:16:29,772   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@5827af16{/jobs/job/kill,null,UNAVAILABLE,@Spark}
2018-09-17 17:16:29,773   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@62dae540{/api,null,UNAVAILABLE,@Spark}
2018-09-17 17:16:29,773   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@4bff1903{/,null,UNAVAILABLE,@Spark}
2018-09-17 17:16:29,773   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@207ea13{/static,null,UNAVAILABLE,@Spark}
2018-09-17 17:16:29,773   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@45cff11c{/executors/threadDump/json,null,UNAVAILABLE,@Spark}
2018-09-17 17:16:29,774   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@1b065145{/executors/threadDump,null,UNAVAILABLE,@Spark}
2018-09-17 17:16:29,774   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@4721d212{/executors/json,null,UNAVAILABLE,@Spark}
2018-09-17 17:16:29,774   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@11eadcba{/executors,null,UNAVAILABLE,@Spark}
2018-09-17 17:16:29,774   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@60f7cc1d{/environment/json,null,UNAVAILABLE,@Spark}
2018-09-17 17:16:29,775   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@37bd68c3{/environment,null,UNAVAILABLE,@Spark}
2018-09-17 17:16:29,775   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@5b11a194{/storage/rdd/json,null,UNAVAILABLE,@Spark}
2018-09-17 17:16:29,775   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@242aa8d9{/storage/rdd,null,UNAVAILABLE,@Spark}
2018-09-17 17:16:29,775   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@7be58f16{/storage/json,null,UNAVAILABLE,@Spark}
2018-09-17 17:16:29,775   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@6111ba37{/storage,null,UNAVAILABLE,@Spark}
2018-09-17 17:16:29,776   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@3d484181{/stages/pool/json,null,UNAVAILABLE,@Spark}
2018-09-17 17:16:29,776   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@7894f09b{/stages/pool,null,UNAVAILABLE,@Spark}
2018-09-17 17:16:29,776   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@1dd0e7c4{/stages/stage/json,null,UNAVAILABLE,@Spark}
2018-09-17 17:16:29,777   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@2ece4966{/stages/stage,null,UNAVAILABLE,@Spark}
2018-09-17 17:16:29,777   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@47605f2f{/stages/json,null,UNAVAILABLE,@Spark}
2018-09-17 17:16:29,777   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@388ba540{/stages,null,UNAVAILABLE,@Spark}
2018-09-17 17:16:29,777   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@64dafeed{/jobs/job/json,null,UNAVAILABLE,@Spark}
2018-09-17 17:16:29,778   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@2c88b9fc{/jobs/job,null,UNAVAILABLE,@Spark}
2018-09-17 17:16:29,778   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@3918c187{/jobs/json,null,UNAVAILABLE,@Spark}
2018-09-17 17:16:29,778   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@295eaa7c{/jobs,null,UNAVAILABLE,@Spark}
2018-09-17 17:16:29,780   INFO --- [Thread-1]  org.apache.spark.ui.SparkUI(line:54) : Stopped Spark web UI at http://192.168.3.199:4040
2018-09-17 17:16:29,795   INFO --- [dispatcher-event-loop-6]  org.apache.spark.MapOutputTrackerMasterEndpoint(line:54) : MapOutputTrackerMasterEndpoint stopped!
2018-09-17 17:16:29,808   INFO --- [Thread-1]  org.apache.spark.storage.memory.MemoryStore(line:54) : MemoryStore cleared
2018-09-17 17:16:29,808   INFO --- [Thread-1]  org.apache.spark.storage.BlockManager(line:54) : BlockManager stopped
2018-09-17 17:16:29,815   INFO --- [Thread-1]  org.apache.spark.storage.BlockManagerMaster(line:54) : BlockManagerMaster stopped
2018-09-17 17:16:29,819   INFO --- [dispatcher-event-loop-3]  org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint(line:54) : OutputCommitCoordinator stopped!
2018-09-17 17:16:29,825   INFO --- [Thread-1]  org.apache.spark.SparkContext(line:54) : Successfully stopped SparkContext
2018-09-17 17:16:29,826   INFO --- [Thread-1]  org.apache.spark.util.ShutdownHookManager(line:54) : Shutdown hook called
2018-09-17 17:16:29,827   INFO --- [Thread-1]  org.apache.spark.util.ShutdownHookManager(line:54) : Deleting directory C:\Users\wshs\AppData\Local\Temp\spark-62c43b31-2d59-449c-a1f3-67a20d464787
2018-09-17 17:17:08,876   INFO --- [main]  org.apache.spark.SparkContext(line:54) : Running Spark version 2.1.1
2018-09-17 17:17:09,206   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing view acls to: wshs
2018-09-17 17:17:09,208   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing modify acls to: wshs
2018-09-17 17:17:09,209   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing view acls groups to: 
2018-09-17 17:17:09,209   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing modify acls groups to: 
2018-09-17 17:17:09,210   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(wshs); groups with view permissions: Set(); users  with modify permissions: Set(wshs); groups with modify permissions: Set()
2018-09-17 17:17:09,663   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'sparkDriver' on port 49351.
2018-09-17 17:17:09,682   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering MapOutputTracker
2018-09-17 17:17:09,700   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering BlockManagerMaster
2018-09-17 17:17:09,706   INFO --- [main]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-09-17 17:17:09,707   INFO --- [main]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : BlockManagerMasterEndpoint up
2018-09-17 17:17:09,720   INFO --- [main]  org.apache.spark.storage.DiskBlockManager(line:54) : Created local directory at C:\Users\wshs\AppData\Local\Temp\blockmgr-15bc5cc3-15d2-4958-af18-d68bdbb4fb40
2018-09-17 17:17:09,736   INFO --- [main]  org.apache.spark.storage.memory.MemoryStore(line:54) : MemoryStore started with capacity 3.0 GB
2018-09-17 17:17:09,782   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering OutputCommitCoordinator
2018-09-17 17:17:09,866   INFO --- [main]  org.spark_project.jetty.util.log(line:186) : Logging initialized @2614ms
2018-09-17 17:17:09,957   INFO --- [main]  org.spark_project.jetty.server.Server(line:327) : jetty-9.2.z-SNAPSHOT
2018-09-17 17:17:09,972   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@295eaa7c{/jobs,null,AVAILABLE,@Spark}
2018-09-17 17:17:09,973   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@3918c187{/jobs/json,null,AVAILABLE,@Spark}
2018-09-17 17:17:09,973   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@2c88b9fc{/jobs/job,null,AVAILABLE,@Spark}
2018-09-17 17:17:09,974   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@64dafeed{/jobs/job/json,null,AVAILABLE,@Spark}
2018-09-17 17:17:09,974   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@388ba540{/stages,null,AVAILABLE,@Spark}
2018-09-17 17:17:09,974   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@47605f2f{/stages/json,null,AVAILABLE,@Spark}
2018-09-17 17:17:09,975   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@2ece4966{/stages/stage,null,AVAILABLE,@Spark}
2018-09-17 17:17:09,975   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@1dd0e7c4{/stages/stage/json,null,AVAILABLE,@Spark}
2018-09-17 17:17:09,975   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@7894f09b{/stages/pool,null,AVAILABLE,@Spark}
2018-09-17 17:17:09,976   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@3d484181{/stages/pool/json,null,AVAILABLE,@Spark}
2018-09-17 17:17:09,976   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@6111ba37{/storage,null,AVAILABLE,@Spark}
2018-09-17 17:17:09,976   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@7be58f16{/storage/json,null,AVAILABLE,@Spark}
2018-09-17 17:17:09,977   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@242aa8d9{/storage/rdd,null,AVAILABLE,@Spark}
2018-09-17 17:17:09,977   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@5b11a194{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-09-17 17:17:09,977   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@37bd68c3{/environment,null,AVAILABLE,@Spark}
2018-09-17 17:17:09,978   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@60f7cc1d{/environment/json,null,AVAILABLE,@Spark}
2018-09-17 17:17:09,978   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@11eadcba{/executors,null,AVAILABLE,@Spark}
2018-09-17 17:17:09,978   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@4721d212{/executors/json,null,AVAILABLE,@Spark}
2018-09-17 17:17:09,978   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@1b065145{/executors/threadDump,null,AVAILABLE,@Spark}
2018-09-17 17:17:09,979   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@45cff11c{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-09-17 17:17:09,983   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@207ea13{/static,null,AVAILABLE,@Spark}
2018-09-17 17:17:09,984   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@4bff1903{/,null,AVAILABLE,@Spark}
2018-09-17 17:17:09,985   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@62dae540{/api,null,AVAILABLE,@Spark}
2018-09-17 17:17:09,985   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@5827af16{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-09-17 17:17:09,985   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@654d8173{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-09-17 17:17:09,999   INFO --- [main]  org.spark_project.jetty.server.ServerConnector(line:266) : Started Spark@3234f74e{HTTP/1.1}{0.0.0.0:4040}
2018-09-17 17:17:09,999   INFO --- [main]  org.spark_project.jetty.server.Server(line:379) : Started @2749ms
2018-09-17 17:17:10,000   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'SparkUI' on port 4040.
2018-09-17 17:17:10,003   INFO --- [main]  org.apache.spark.ui.SparkUI(line:54) : Bound SparkUI to 0.0.0.0, and started at http://192.168.3.199:4040
2018-09-17 17:17:10,069   INFO --- [main]  org.apache.spark.executor.Executor(line:54) : Starting executor ID driver on host localhost
2018-09-17 17:17:10,137   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 49404.
2018-09-17 17:17:10,138   INFO --- [main]  org.apache.spark.network.netty.NettyBlockTransferService(line:54) : Server created on 192.168.3.199:49404
2018-09-17 17:17:10,140   INFO --- [main]  org.apache.spark.storage.BlockManager(line:54) : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-09-17 17:17:10,142   INFO --- [main]  org.apache.spark.storage.BlockManagerMaster(line:54) : Registering BlockManager BlockManagerId(driver, 192.168.3.199, 49404, None)
2018-09-17 17:17:10,146   INFO --- [dispatcher-event-loop-2]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : Registering block manager 192.168.3.199:49404 with 3.0 GB RAM, BlockManagerId(driver, 192.168.3.199, 49404, None)
2018-09-17 17:17:10,150   INFO --- [main]  org.apache.spark.storage.BlockManagerMaster(line:54) : Registered BlockManager BlockManagerId(driver, 192.168.3.199, 49404, None)
2018-09-17 17:17:10,150   INFO --- [main]  org.apache.spark.storage.BlockManager(line:54) : Initialized BlockManager: BlockManagerId(driver, 192.168.3.199, 49404, None)
2018-09-17 17:17:10,335   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@344561e0{/metrics/json,null,AVAILABLE,@Spark}
2018-09-17 17:17:10,362   INFO --- [main]  org.apache.spark.sql.internal.SharedState(line:54) : Warehouse path is 'd:/spark-warehouse'.
2018-09-17 17:17:10,368   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@3c321bdb{/SQL,null,AVAILABLE,@Spark}
2018-09-17 17:17:10,369   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@3abd581e{/SQL/json,null,AVAILABLE,@Spark}
2018-09-17 17:17:10,369   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@1e392345{/SQL/execution,null,AVAILABLE,@Spark}
2018-09-17 17:17:10,370   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@4ced35ed{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-09-17 17:17:10,371   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@27dc79f7{/static/sql,null,AVAILABLE,@Spark}
2018-09-17 17:17:10,380   INFO --- [Thread-1]  org.apache.spark.SparkContext(line:54) : Invoking stop() from shutdown hook
2018-09-17 17:17:10,384   INFO --- [Thread-1]  org.spark_project.jetty.server.ServerConnector(line:306) : Stopped Spark@3234f74e{HTTP/1.1}{0.0.0.0:4040}
2018-09-17 17:17:10,386   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@654d8173{/stages/stage/kill,null,UNAVAILABLE,@Spark}
2018-09-17 17:17:10,386   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@5827af16{/jobs/job/kill,null,UNAVAILABLE,@Spark}
2018-09-17 17:17:10,386   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@62dae540{/api,null,UNAVAILABLE,@Spark}
2018-09-17 17:17:10,386   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@4bff1903{/,null,UNAVAILABLE,@Spark}
2018-09-17 17:17:10,387   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@207ea13{/static,null,UNAVAILABLE,@Spark}
2018-09-17 17:17:10,387   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@45cff11c{/executors/threadDump/json,null,UNAVAILABLE,@Spark}
2018-09-17 17:17:10,387   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@1b065145{/executors/threadDump,null,UNAVAILABLE,@Spark}
2018-09-17 17:17:10,387   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@4721d212{/executors/json,null,UNAVAILABLE,@Spark}
2018-09-17 17:17:10,387   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@11eadcba{/executors,null,UNAVAILABLE,@Spark}
2018-09-17 17:17:10,387   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@60f7cc1d{/environment/json,null,UNAVAILABLE,@Spark}
2018-09-17 17:17:10,388   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@37bd68c3{/environment,null,UNAVAILABLE,@Spark}
2018-09-17 17:17:10,388   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@5b11a194{/storage/rdd/json,null,UNAVAILABLE,@Spark}
2018-09-17 17:17:10,388   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@242aa8d9{/storage/rdd,null,UNAVAILABLE,@Spark}
2018-09-17 17:17:10,389   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@7be58f16{/storage/json,null,UNAVAILABLE,@Spark}
2018-09-17 17:17:10,389   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@6111ba37{/storage,null,UNAVAILABLE,@Spark}
2018-09-17 17:17:10,389   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@3d484181{/stages/pool/json,null,UNAVAILABLE,@Spark}
2018-09-17 17:17:10,389   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@7894f09b{/stages/pool,null,UNAVAILABLE,@Spark}
2018-09-17 17:17:10,390   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@1dd0e7c4{/stages/stage/json,null,UNAVAILABLE,@Spark}
2018-09-17 17:17:10,390   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@2ece4966{/stages/stage,null,UNAVAILABLE,@Spark}
2018-09-17 17:17:10,390   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@47605f2f{/stages/json,null,UNAVAILABLE,@Spark}
2018-09-17 17:17:10,390   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@388ba540{/stages,null,UNAVAILABLE,@Spark}
2018-09-17 17:17:10,390   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@64dafeed{/jobs/job/json,null,UNAVAILABLE,@Spark}
2018-09-17 17:17:10,391   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@2c88b9fc{/jobs/job,null,UNAVAILABLE,@Spark}
2018-09-17 17:17:10,391   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@3918c187{/jobs/json,null,UNAVAILABLE,@Spark}
2018-09-17 17:17:10,391   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@295eaa7c{/jobs,null,UNAVAILABLE,@Spark}
2018-09-17 17:17:10,393   INFO --- [Thread-1]  org.apache.spark.ui.SparkUI(line:54) : Stopped Spark web UI at http://192.168.3.199:4040
2018-09-17 17:17:10,405   INFO --- [dispatcher-event-loop-6]  org.apache.spark.MapOutputTrackerMasterEndpoint(line:54) : MapOutputTrackerMasterEndpoint stopped!
2018-09-17 17:17:10,416   INFO --- [Thread-1]  org.apache.spark.storage.memory.MemoryStore(line:54) : MemoryStore cleared
2018-09-17 17:17:10,416   INFO --- [Thread-1]  org.apache.spark.storage.BlockManager(line:54) : BlockManager stopped
2018-09-17 17:17:10,422   INFO --- [Thread-1]  org.apache.spark.storage.BlockManagerMaster(line:54) : BlockManagerMaster stopped
2018-09-17 17:17:10,426   INFO --- [dispatcher-event-loop-3]  org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint(line:54) : OutputCommitCoordinator stopped!
2018-09-17 17:17:10,431   INFO --- [Thread-1]  org.apache.spark.SparkContext(line:54) : Successfully stopped SparkContext
2018-09-17 17:17:10,432   INFO --- [Thread-1]  org.apache.spark.util.ShutdownHookManager(line:54) : Shutdown hook called
2018-09-17 17:17:10,433   INFO --- [Thread-1]  org.apache.spark.util.ShutdownHookManager(line:54) : Deleting directory C:\Users\wshs\AppData\Local\Temp\spark-18e15d02-b26c-4e1f-b525-446b573a115a
2018-09-17 17:32:39,687   INFO --- [main]  org.apache.spark.SparkContext(line:54) : Running Spark version 2.1.1
2018-09-17 17:32:40,016   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing view acls to: wshs
2018-09-17 17:32:40,017   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing modify acls to: wshs
2018-09-17 17:32:40,018   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing view acls groups to: 
2018-09-17 17:32:40,019   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing modify acls groups to: 
2018-09-17 17:32:40,020   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(wshs); groups with view permissions: Set(); users  with modify permissions: Set(wshs); groups with modify permissions: Set()
2018-09-17 17:32:40,511   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'sparkDriver' on port 60426.
2018-09-17 17:32:40,529   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering MapOutputTracker
2018-09-17 17:32:40,548   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering BlockManagerMaster
2018-09-17 17:32:40,552   INFO --- [main]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-09-17 17:32:40,553   INFO --- [main]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : BlockManagerMasterEndpoint up
2018-09-17 17:32:40,568   INFO --- [main]  org.apache.spark.storage.DiskBlockManager(line:54) : Created local directory at C:\Users\wshs\AppData\Local\Temp\blockmgr-ce3c8cc2-fa22-4cf4-9572-6549022f185a
2018-09-17 17:32:40,585   INFO --- [main]  org.apache.spark.storage.memory.MemoryStore(line:54) : MemoryStore started with capacity 3.0 GB
2018-09-17 17:32:40,632   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering OutputCommitCoordinator
2018-09-17 17:32:40,713   INFO --- [main]  org.spark_project.jetty.util.log(line:186) : Logging initialized @2691ms
2018-09-17 17:32:40,800   INFO --- [main]  org.spark_project.jetty.server.Server(line:327) : jetty-9.2.z-SNAPSHOT
2018-09-17 17:32:40,814   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@295eaa7c{/jobs,null,AVAILABLE,@Spark}
2018-09-17 17:32:40,814   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@3918c187{/jobs/json,null,AVAILABLE,@Spark}
2018-09-17 17:32:40,815   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@2c88b9fc{/jobs/job,null,AVAILABLE,@Spark}
2018-09-17 17:32:40,815   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@64dafeed{/jobs/job/json,null,AVAILABLE,@Spark}
2018-09-17 17:32:40,815   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@388ba540{/stages,null,AVAILABLE,@Spark}
2018-09-17 17:32:40,816   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@47605f2f{/stages/json,null,AVAILABLE,@Spark}
2018-09-17 17:32:40,816   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@2ece4966{/stages/stage,null,AVAILABLE,@Spark}
2018-09-17 17:32:40,816   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@1dd0e7c4{/stages/stage/json,null,AVAILABLE,@Spark}
2018-09-17 17:32:40,817   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@7894f09b{/stages/pool,null,AVAILABLE,@Spark}
2018-09-17 17:32:40,817   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@3d484181{/stages/pool/json,null,AVAILABLE,@Spark}
2018-09-17 17:32:40,817   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@6111ba37{/storage,null,AVAILABLE,@Spark}
2018-09-17 17:32:40,818   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@7be58f16{/storage/json,null,AVAILABLE,@Spark}
2018-09-17 17:32:40,818   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@242aa8d9{/storage/rdd,null,AVAILABLE,@Spark}
2018-09-17 17:32:40,818   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@5b11a194{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-09-17 17:32:40,819   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@37bd68c3{/environment,null,AVAILABLE,@Spark}
2018-09-17 17:32:40,819   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@60f7cc1d{/environment/json,null,AVAILABLE,@Spark}
2018-09-17 17:32:40,820   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@11eadcba{/executors,null,AVAILABLE,@Spark}
2018-09-17 17:32:40,820   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@4721d212{/executors/json,null,AVAILABLE,@Spark}
2018-09-17 17:32:40,820   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@1b065145{/executors/threadDump,null,AVAILABLE,@Spark}
2018-09-17 17:32:40,821   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@45cff11c{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-09-17 17:32:40,826   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@207ea13{/static,null,AVAILABLE,@Spark}
2018-09-17 17:32:40,826   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@4bff1903{/,null,AVAILABLE,@Spark}
2018-09-17 17:32:40,827   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@62dae540{/api,null,AVAILABLE,@Spark}
2018-09-17 17:32:40,827   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@5827af16{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-09-17 17:32:40,828   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@654d8173{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-09-17 17:32:40,843   INFO --- [main]  org.spark_project.jetty.server.ServerConnector(line:266) : Started Spark@3234f74e{HTTP/1.1}{0.0.0.0:4040}
2018-09-17 17:32:40,843   INFO --- [main]  org.spark_project.jetty.server.Server(line:379) : Started @2823ms
2018-09-17 17:32:40,844   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'SparkUI' on port 4040.
2018-09-17 17:32:40,848   INFO --- [main]  org.apache.spark.ui.SparkUI(line:54) : Bound SparkUI to 0.0.0.0, and started at http://192.168.3.199:4040
2018-09-17 17:32:40,908   INFO --- [main]  org.apache.spark.executor.Executor(line:54) : Starting executor ID driver on host localhost
2018-09-17 17:32:40,969   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 60481.
2018-09-17 17:32:40,970   INFO --- [main]  org.apache.spark.network.netty.NettyBlockTransferService(line:54) : Server created on 192.168.3.199:60481
2018-09-17 17:32:40,971   INFO --- [main]  org.apache.spark.storage.BlockManager(line:54) : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-09-17 17:32:40,973   INFO --- [main]  org.apache.spark.storage.BlockManagerMaster(line:54) : Registering BlockManager BlockManagerId(driver, 192.168.3.199, 60481, None)
2018-09-17 17:32:40,977   INFO --- [dispatcher-event-loop-2]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : Registering block manager 192.168.3.199:60481 with 3.0 GB RAM, BlockManagerId(driver, 192.168.3.199, 60481, None)
2018-09-17 17:32:40,979   INFO --- [main]  org.apache.spark.storage.BlockManagerMaster(line:54) : Registered BlockManager BlockManagerId(driver, 192.168.3.199, 60481, None)
2018-09-17 17:32:40,980   INFO --- [main]  org.apache.spark.storage.BlockManager(line:54) : Initialized BlockManager: BlockManagerId(driver, 192.168.3.199, 60481, None)
2018-09-17 17:32:41,141   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@344561e0{/metrics/json,null,AVAILABLE,@Spark}
2018-09-17 17:32:41,170   INFO --- [main]  org.apache.spark.sql.internal.SharedState(line:54) : Warehouse path is 'C:\Users\wshs\IdeaProjects\logdataSession\spark-warehouse'.
2018-09-17 17:32:41,177   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@3c321bdb{/SQL,null,AVAILABLE,@Spark}
2018-09-17 17:32:41,177   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@3abd581e{/SQL/json,null,AVAILABLE,@Spark}
2018-09-17 17:32:41,178   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@1e392345{/SQL/execution,null,AVAILABLE,@Spark}
2018-09-17 17:32:41,179   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@4ced35ed{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-09-17 17:32:41,180   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@27dc79f7{/static/sql,null,AVAILABLE,@Spark}
2018-09-17 17:32:41,188   INFO --- [Thread-1]  org.apache.spark.SparkContext(line:54) : Invoking stop() from shutdown hook
2018-09-17 17:32:41,193   INFO --- [Thread-1]  org.spark_project.jetty.server.ServerConnector(line:306) : Stopped Spark@3234f74e{HTTP/1.1}{0.0.0.0:4040}
2018-09-17 17:32:41,194   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@654d8173{/stages/stage/kill,null,UNAVAILABLE,@Spark}
2018-09-17 17:32:41,195   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@5827af16{/jobs/job/kill,null,UNAVAILABLE,@Spark}
2018-09-17 17:32:41,195   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@62dae540{/api,null,UNAVAILABLE,@Spark}
2018-09-17 17:32:41,196   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@4bff1903{/,null,UNAVAILABLE,@Spark}
2018-09-17 17:32:41,196   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@207ea13{/static,null,UNAVAILABLE,@Spark}
2018-09-17 17:32:41,196   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@45cff11c{/executors/threadDump/json,null,UNAVAILABLE,@Spark}
2018-09-17 17:32:41,196   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@1b065145{/executors/threadDump,null,UNAVAILABLE,@Spark}
2018-09-17 17:32:41,197   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@4721d212{/executors/json,null,UNAVAILABLE,@Spark}
2018-09-17 17:32:41,197   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@11eadcba{/executors,null,UNAVAILABLE,@Spark}
2018-09-17 17:32:41,197   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@60f7cc1d{/environment/json,null,UNAVAILABLE,@Spark}
2018-09-17 17:32:41,197   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@37bd68c3{/environment,null,UNAVAILABLE,@Spark}
2018-09-17 17:32:41,198   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@5b11a194{/storage/rdd/json,null,UNAVAILABLE,@Spark}
2018-09-17 17:32:41,198   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@242aa8d9{/storage/rdd,null,UNAVAILABLE,@Spark}
2018-09-17 17:32:41,198   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@7be58f16{/storage/json,null,UNAVAILABLE,@Spark}
2018-09-17 17:32:41,199   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@6111ba37{/storage,null,UNAVAILABLE,@Spark}
2018-09-17 17:32:41,199   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@3d484181{/stages/pool/json,null,UNAVAILABLE,@Spark}
2018-09-17 17:32:41,199   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@7894f09b{/stages/pool,null,UNAVAILABLE,@Spark}
2018-09-17 17:32:41,199   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@1dd0e7c4{/stages/stage/json,null,UNAVAILABLE,@Spark}
2018-09-17 17:32:41,200   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@2ece4966{/stages/stage,null,UNAVAILABLE,@Spark}
2018-09-17 17:32:41,200   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@47605f2f{/stages/json,null,UNAVAILABLE,@Spark}
2018-09-17 17:32:41,200   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@388ba540{/stages,null,UNAVAILABLE,@Spark}
2018-09-17 17:32:41,201   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@64dafeed{/jobs/job/json,null,UNAVAILABLE,@Spark}
2018-09-17 17:32:41,201   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@2c88b9fc{/jobs/job,null,UNAVAILABLE,@Spark}
2018-09-17 17:32:41,201   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@3918c187{/jobs/json,null,UNAVAILABLE,@Spark}
2018-09-17 17:32:41,201   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@295eaa7c{/jobs,null,UNAVAILABLE,@Spark}
2018-09-17 17:32:41,203   INFO --- [Thread-1]  org.apache.spark.ui.SparkUI(line:54) : Stopped Spark web UI at http://192.168.3.199:4040
2018-09-17 17:32:41,216   INFO --- [dispatcher-event-loop-6]  org.apache.spark.MapOutputTrackerMasterEndpoint(line:54) : MapOutputTrackerMasterEndpoint stopped!
2018-09-17 17:32:41,228   INFO --- [Thread-1]  org.apache.spark.storage.memory.MemoryStore(line:54) : MemoryStore cleared
2018-09-17 17:32:41,229   INFO --- [Thread-1]  org.apache.spark.storage.BlockManager(line:54) : BlockManager stopped
2018-09-17 17:32:41,234   INFO --- [Thread-1]  org.apache.spark.storage.BlockManagerMaster(line:54) : BlockManagerMaster stopped
2018-09-17 17:32:41,238   INFO --- [dispatcher-event-loop-3]  org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint(line:54) : OutputCommitCoordinator stopped!
2018-09-17 17:32:41,243   INFO --- [Thread-1]  org.apache.spark.SparkContext(line:54) : Successfully stopped SparkContext
2018-09-17 17:32:41,243   INFO --- [Thread-1]  org.apache.spark.util.ShutdownHookManager(line:54) : Shutdown hook called
2018-09-17 17:32:41,244   INFO --- [Thread-1]  org.apache.spark.util.ShutdownHookManager(line:54) : Deleting directory C:\Users\wshs\AppData\Local\Temp\spark-98d0203f-557c-4def-aec4-515b13352ee5
2018-09-17 17:34:21,951   INFO --- [main]  org.apache.spark.SparkContext(line:54) : Running Spark version 2.1.1
2018-09-17 17:34:22,234  ERROR --- [main]  org.apache.spark.SparkContext(line:91) : Error initializing SparkContext.
org.apache.spark.SparkException: A master URL must be set in your configuration
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:379)
	at org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2320)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$6.apply(SparkSession.scala:868)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$6.apply(SparkSession.scala:860)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:860)
	at logSession$.main(logSession.scala:30)
	at logSession.main(logSession.scala)
2018-09-17 17:34:22,274   INFO --- [main]  org.apache.spark.SparkContext(line:54) : Successfully stopped SparkContext
2018-09-17 17:37:40,451   INFO --- [main]  org.apache.spark.SparkContext(line:54) : Running Spark version 2.1.1
2018-09-17 17:37:40,842   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing view acls to: wshs
2018-09-17 17:37:40,842   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing modify acls to: wshs
2018-09-17 17:37:40,842   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing view acls groups to: 
2018-09-17 17:37:40,843   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing modify acls groups to: 
2018-09-17 17:37:40,844   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(wshs); groups with view permissions: Set(); users  with modify permissions: Set(wshs); groups with modify permissions: Set()
2018-09-17 17:37:41,302   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'sparkDriver' on port 53298.
2018-09-17 17:37:41,321   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering MapOutputTracker
2018-09-17 17:37:41,339   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering BlockManagerMaster
2018-09-17 17:37:41,342   INFO --- [main]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-09-17 17:37:41,343   INFO --- [main]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : BlockManagerMasterEndpoint up
2018-09-17 17:37:41,357   INFO --- [main]  org.apache.spark.storage.DiskBlockManager(line:54) : Created local directory at C:\Users\wshs\AppData\Local\Temp\blockmgr-b8622915-7381-491a-853c-fda78ddeda60
2018-09-17 17:37:41,373   INFO --- [main]  org.apache.spark.storage.memory.MemoryStore(line:54) : MemoryStore started with capacity 3.0 GB
2018-09-17 17:37:41,419   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering OutputCommitCoordinator
2018-09-17 17:37:41,496   INFO --- [main]  org.spark_project.jetty.util.log(line:186) : Logging initialized @2704ms
2018-09-17 17:37:41,587   INFO --- [main]  org.spark_project.jetty.server.Server(line:327) : jetty-9.2.z-SNAPSHOT
2018-09-17 17:37:41,602   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@295eaa7c{/jobs,null,AVAILABLE,@Spark}
2018-09-17 17:37:41,602   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@3918c187{/jobs/json,null,AVAILABLE,@Spark}
2018-09-17 17:37:41,603   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@2c88b9fc{/jobs/job,null,AVAILABLE,@Spark}
2018-09-17 17:37:41,603   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@64dafeed{/jobs/job/json,null,AVAILABLE,@Spark}
2018-09-17 17:37:41,603   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@388ba540{/stages,null,AVAILABLE,@Spark}
2018-09-17 17:37:41,604   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@47605f2f{/stages/json,null,AVAILABLE,@Spark}
2018-09-17 17:37:41,604   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@2ece4966{/stages/stage,null,AVAILABLE,@Spark}
2018-09-17 17:37:41,604   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@1dd0e7c4{/stages/stage/json,null,AVAILABLE,@Spark}
2018-09-17 17:37:41,605   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@7894f09b{/stages/pool,null,AVAILABLE,@Spark}
2018-09-17 17:37:41,605   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@3d484181{/stages/pool/json,null,AVAILABLE,@Spark}
2018-09-17 17:37:41,605   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@6111ba37{/storage,null,AVAILABLE,@Spark}
2018-09-17 17:37:41,606   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@7be58f16{/storage/json,null,AVAILABLE,@Spark}
2018-09-17 17:37:41,606   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@242aa8d9{/storage/rdd,null,AVAILABLE,@Spark}
2018-09-17 17:37:41,606   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@5b11a194{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-09-17 17:37:41,607   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@37bd68c3{/environment,null,AVAILABLE,@Spark}
2018-09-17 17:37:41,607   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@60f7cc1d{/environment/json,null,AVAILABLE,@Spark}
2018-09-17 17:37:41,607   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@11eadcba{/executors,null,AVAILABLE,@Spark}
2018-09-17 17:37:41,608   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@4721d212{/executors/json,null,AVAILABLE,@Spark}
2018-09-17 17:37:41,608   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@1b065145{/executors/threadDump,null,AVAILABLE,@Spark}
2018-09-17 17:37:41,608   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@45cff11c{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-09-17 17:37:41,613   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@207ea13{/static,null,AVAILABLE,@Spark}
2018-09-17 17:37:41,613   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@4bff1903{/,null,AVAILABLE,@Spark}
2018-09-17 17:37:41,614   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@62dae540{/api,null,AVAILABLE,@Spark}
2018-09-17 17:37:41,614   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@5827af16{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-09-17 17:37:41,615   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@654d8173{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-09-17 17:37:41,627   INFO --- [main]  org.spark_project.jetty.server.ServerConnector(line:266) : Started Spark@3234f74e{HTTP/1.1}{0.0.0.0:4040}
2018-09-17 17:37:41,627   INFO --- [main]  org.spark_project.jetty.server.Server(line:379) : Started @2838ms
2018-09-17 17:37:41,628   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'SparkUI' on port 4040.
2018-09-17 17:37:41,631   INFO --- [main]  org.apache.spark.ui.SparkUI(line:54) : Bound SparkUI to 0.0.0.0, and started at http://192.168.3.199:4040
2018-09-17 17:37:41,697   INFO --- [main]  org.apache.spark.executor.Executor(line:54) : Starting executor ID driver on host localhost
2018-09-17 17:37:41,752   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 53356.
2018-09-17 17:37:41,753   INFO --- [main]  org.apache.spark.network.netty.NettyBlockTransferService(line:54) : Server created on 192.168.3.199:53356
2018-09-17 17:37:41,755   INFO --- [main]  org.apache.spark.storage.BlockManager(line:54) : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-09-17 17:37:41,757   INFO --- [main]  org.apache.spark.storage.BlockManagerMaster(line:54) : Registering BlockManager BlockManagerId(driver, 192.168.3.199, 53356, None)
2018-09-17 17:37:41,760   INFO --- [dispatcher-event-loop-2]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : Registering block manager 192.168.3.199:53356 with 3.0 GB RAM, BlockManagerId(driver, 192.168.3.199, 53356, None)
2018-09-17 17:37:41,764   INFO --- [main]  org.apache.spark.storage.BlockManagerMaster(line:54) : Registered BlockManager BlockManagerId(driver, 192.168.3.199, 53356, None)
2018-09-17 17:37:41,765   INFO --- [main]  org.apache.spark.storage.BlockManager(line:54) : Initialized BlockManager: BlockManagerId(driver, 192.168.3.199, 53356, None)
2018-09-17 17:37:41,949   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@344561e0{/metrics/json,null,AVAILABLE,@Spark}
2018-09-17 17:37:41,979   INFO --- [main]  org.apache.spark.sql.internal.SharedState(line:54) : Warehouse path is 'C:\Users\wshs\IdeaProjects\logdataSession\spark-warehouse'.
2018-09-17 17:37:41,987   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@33c2bd{/SQL,null,AVAILABLE,@Spark}
2018-09-17 17:37:41,988   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@3c321bdb{/SQL/json,null,AVAILABLE,@Spark}
2018-09-17 17:37:41,988   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@6f0628de{/SQL/execution,null,AVAILABLE,@Spark}
2018-09-17 17:37:41,989   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@1e392345{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-09-17 17:37:41,991   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@51b01960{/static/sql,null,AVAILABLE,@Spark}
2018-09-17 17:37:41,999   INFO --- [Thread-1]  org.apache.spark.SparkContext(line:54) : Invoking stop() from shutdown hook
2018-09-17 17:37:42,003   INFO --- [Thread-1]  org.spark_project.jetty.server.ServerConnector(line:306) : Stopped Spark@3234f74e{HTTP/1.1}{0.0.0.0:4040}
2018-09-17 17:37:42,006   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@654d8173{/stages/stage/kill,null,UNAVAILABLE,@Spark}
2018-09-17 17:37:42,006   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@5827af16{/jobs/job/kill,null,UNAVAILABLE,@Spark}
2018-09-17 17:37:42,006   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@62dae540{/api,null,UNAVAILABLE,@Spark}
2018-09-17 17:37:42,007   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@4bff1903{/,null,UNAVAILABLE,@Spark}
2018-09-17 17:37:42,007   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@207ea13{/static,null,UNAVAILABLE,@Spark}
2018-09-17 17:37:42,007   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@45cff11c{/executors/threadDump/json,null,UNAVAILABLE,@Spark}
2018-09-17 17:37:42,007   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@1b065145{/executors/threadDump,null,UNAVAILABLE,@Spark}
2018-09-17 17:37:42,008   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@4721d212{/executors/json,null,UNAVAILABLE,@Spark}
2018-09-17 17:37:42,008   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@11eadcba{/executors,null,UNAVAILABLE,@Spark}
2018-09-17 17:37:42,008   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@60f7cc1d{/environment/json,null,UNAVAILABLE,@Spark}
2018-09-17 17:37:42,008   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@37bd68c3{/environment,null,UNAVAILABLE,@Spark}
2018-09-17 17:37:42,008   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@5b11a194{/storage/rdd/json,null,UNAVAILABLE,@Spark}
2018-09-17 17:37:42,008   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@242aa8d9{/storage/rdd,null,UNAVAILABLE,@Spark}
2018-09-17 17:37:42,009   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@7be58f16{/storage/json,null,UNAVAILABLE,@Spark}
2018-09-17 17:37:42,009   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@6111ba37{/storage,null,UNAVAILABLE,@Spark}
2018-09-17 17:37:42,009   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@3d484181{/stages/pool/json,null,UNAVAILABLE,@Spark}
2018-09-17 17:37:42,009   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@7894f09b{/stages/pool,null,UNAVAILABLE,@Spark}
2018-09-17 17:37:42,009   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@1dd0e7c4{/stages/stage/json,null,UNAVAILABLE,@Spark}
2018-09-17 17:37:42,010   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@2ece4966{/stages/stage,null,UNAVAILABLE,@Spark}
2018-09-17 17:37:42,010   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@47605f2f{/stages/json,null,UNAVAILABLE,@Spark}
2018-09-17 17:37:42,010   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@388ba540{/stages,null,UNAVAILABLE,@Spark}
2018-09-17 17:37:42,010   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@64dafeed{/jobs/job/json,null,UNAVAILABLE,@Spark}
2018-09-17 17:37:42,010   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@2c88b9fc{/jobs/job,null,UNAVAILABLE,@Spark}
2018-09-17 17:37:42,011   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@3918c187{/jobs/json,null,UNAVAILABLE,@Spark}
2018-09-17 17:37:42,011   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@295eaa7c{/jobs,null,UNAVAILABLE,@Spark}
2018-09-17 17:37:42,013   INFO --- [Thread-1]  org.apache.spark.ui.SparkUI(line:54) : Stopped Spark web UI at http://192.168.3.199:4040
2018-09-17 17:37:42,021   INFO --- [dispatcher-event-loop-6]  org.apache.spark.MapOutputTrackerMasterEndpoint(line:54) : MapOutputTrackerMasterEndpoint stopped!
2018-09-17 17:37:42,037   INFO --- [Thread-1]  org.apache.spark.storage.memory.MemoryStore(line:54) : MemoryStore cleared
2018-09-17 17:37:42,038   INFO --- [Thread-1]  org.apache.spark.storage.BlockManager(line:54) : BlockManager stopped
2018-09-17 17:37:42,043   INFO --- [Thread-1]  org.apache.spark.storage.BlockManagerMaster(line:54) : BlockManagerMaster stopped
2018-09-17 17:37:42,047   INFO --- [dispatcher-event-loop-3]  org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint(line:54) : OutputCommitCoordinator stopped!
2018-09-17 17:37:42,052   INFO --- [Thread-1]  org.apache.spark.SparkContext(line:54) : Successfully stopped SparkContext
2018-09-17 17:37:42,052   INFO --- [Thread-1]  org.apache.spark.util.ShutdownHookManager(line:54) : Shutdown hook called
2018-09-17 17:37:42,053   INFO --- [Thread-1]  org.apache.spark.util.ShutdownHookManager(line:54) : Deleting directory C:\Users\wshs\AppData\Local\Temp\spark-8637d6ff-dcbf-44e5-bb40-be298831693e
2018-09-17 17:52:43,646   INFO --- [main]  org.apache.spark.SparkContext(line:54) : Running Spark version 2.1.1
2018-09-17 17:52:44,066   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing view acls to: wshs
2018-09-17 17:52:44,067   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing modify acls to: wshs
2018-09-17 17:52:44,068   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing view acls groups to: 
2018-09-17 17:52:44,069   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing modify acls groups to: 
2018-09-17 17:52:44,070   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(wshs); groups with view permissions: Set(); users  with modify permissions: Set(wshs); groups with modify permissions: Set()
2018-09-17 17:52:44,588   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'sparkDriver' on port 65523.
2018-09-17 17:52:44,615   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering MapOutputTracker
2018-09-17 17:52:44,643   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering BlockManagerMaster
2018-09-17 17:52:44,647   INFO --- [main]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-09-17 17:52:44,647   INFO --- [main]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : BlockManagerMasterEndpoint up
2018-09-17 17:52:44,662   INFO --- [main]  org.apache.spark.storage.DiskBlockManager(line:54) : Created local directory at C:\Users\wshs\AppData\Local\Temp\blockmgr-3e690542-24a3-45ae-81d1-5be7229f67bb
2018-09-17 17:52:44,684   INFO --- [main]  org.apache.spark.storage.memory.MemoryStore(line:54) : MemoryStore started with capacity 3.0 GB
2018-09-17 17:52:44,750   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering OutputCommitCoordinator
2018-09-17 17:52:44,853   INFO --- [main]  org.spark_project.jetty.util.log(line:186) : Logging initialized @72714ms
2018-09-17 17:52:44,962   INFO --- [main]  org.spark_project.jetty.server.Server(line:327) : jetty-9.2.z-SNAPSHOT
2018-09-17 17:52:44,980   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@173f73e7{/jobs,null,AVAILABLE,@Spark}
2018-09-17 17:52:44,980   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@43a51d00{/jobs/json,null,AVAILABLE,@Spark}
2018-09-17 17:52:44,981   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@2e23c180{/jobs/job,null,AVAILABLE,@Spark}
2018-09-17 17:52:44,981   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@499683c4{/jobs/job/json,null,AVAILABLE,@Spark}
2018-09-17 17:52:44,981   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@25da615a{/stages,null,AVAILABLE,@Spark}
2018-09-17 17:52:44,981   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@4efc25fc{/stages/json,null,AVAILABLE,@Spark}
2018-09-17 17:52:44,982   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@7ee3d262{/stages/stage,null,AVAILABLE,@Spark}
2018-09-17 17:52:44,982   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@396e6d9{/stages/stage/json,null,AVAILABLE,@Spark}
2018-09-17 17:52:44,982   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@75308740{/stages/pool,null,AVAILABLE,@Spark}
2018-09-17 17:52:44,982   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@5acc9fdf{/stages/pool/json,null,AVAILABLE,@Spark}
2018-09-17 17:52:44,983   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@3a5c2626{/storage,null,AVAILABLE,@Spark}
2018-09-17 17:52:44,983   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@e48bf9a{/storage/json,null,AVAILABLE,@Spark}
2018-09-17 17:52:44,983   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@7fb33394{/storage/rdd,null,AVAILABLE,@Spark}
2018-09-17 17:52:44,984   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@41bf79da{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-09-17 17:52:44,984   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@1a891add{/environment,null,AVAILABLE,@Spark}
2018-09-17 17:52:44,984   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@5176d279{/environment/json,null,AVAILABLE,@Spark}
2018-09-17 17:52:44,985   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@373f7450{/executors,null,AVAILABLE,@Spark}
2018-09-17 17:52:44,985   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@d74bac4{/executors/json,null,AVAILABLE,@Spark}
2018-09-17 17:52:44,985   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@5ff90645{/executors/threadDump,null,AVAILABLE,@Spark}
2018-09-17 17:52:44,986   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@387bf2d9{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-09-17 17:52:44,992   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@74aa9c72{/static,null,AVAILABLE,@Spark}
2018-09-17 17:52:44,993   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@5c20aab9{/,null,AVAILABLE,@Spark}
2018-09-17 17:52:44,993   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@4b7c4456{/api,null,AVAILABLE,@Spark}
2018-09-17 17:52:44,994   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@2c768ada{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-09-17 17:52:44,994   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@c1fca2a{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-09-17 17:52:45,010   INFO --- [main]  org.spark_project.jetty.server.ServerConnector(line:266) : Started Spark@6e1b9411{HTTP/1.1}{0.0.0.0:4040}
2018-09-17 17:52:45,011   INFO --- [main]  org.spark_project.jetty.server.Server(line:379) : Started @72874ms
2018-09-17 17:52:45,012   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'SparkUI' on port 4040.
2018-09-17 17:52:45,015   INFO --- [main]  org.apache.spark.ui.SparkUI(line:54) : Bound SparkUI to 0.0.0.0, and started at http://192.168.3.199:4040
2018-09-17 17:52:45,102   INFO --- [main]  org.apache.spark.executor.Executor(line:54) : Starting executor ID driver on host localhost
2018-09-17 17:52:45,177   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 49200.
2018-09-17 17:52:45,178   INFO --- [main]  org.apache.spark.network.netty.NettyBlockTransferService(line:54) : Server created on 192.168.3.199:49200
2018-09-17 17:52:45,180   INFO --- [main]  org.apache.spark.storage.BlockManager(line:54) : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-09-17 17:52:45,183   INFO --- [main]  org.apache.spark.storage.BlockManagerMaster(line:54) : Registering BlockManager BlockManagerId(driver, 192.168.3.199, 49200, None)
2018-09-17 17:52:45,186   INFO --- [dispatcher-event-loop-2]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : Registering block manager 192.168.3.199:49200 with 3.0 GB RAM, BlockManagerId(driver, 192.168.3.199, 49200, None)
2018-09-17 17:52:45,202   INFO --- [main]  org.apache.spark.storage.BlockManagerMaster(line:54) : Registered BlockManager BlockManagerId(driver, 192.168.3.199, 49200, None)
2018-09-17 17:52:45,203   INFO --- [main]  org.apache.spark.storage.BlockManager(line:54) : Initialized BlockManager: BlockManagerId(driver, 192.168.3.199, 49200, None)
2018-09-17 17:52:45,375   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@15639440{/metrics/json,null,AVAILABLE,@Spark}
2018-09-17 17:52:45,579   INFO --- [main]  org.apache.spark.sql.internal.SharedState(line:54) : Warehouse path is 'C:\Users\wshs\IdeaProjects\logdataSession\spark-warehouse'.
2018-09-17 17:52:45,586   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@25aeb5ac{/SQL,null,AVAILABLE,@Spark}
2018-09-17 17:52:45,587   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@3bd2af5b{/SQL/json,null,AVAILABLE,@Spark}
2018-09-17 17:52:45,588   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@16727bf0{/SQL/execution,null,AVAILABLE,@Spark}
2018-09-17 17:52:45,588   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@291373d3{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-09-17 17:52:45,591   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@1d9bd4da{/static/sql,null,AVAILABLE,@Spark}
2018-09-17 17:52:45,603   INFO --- [Thread-1]  org.apache.spark.SparkContext(line:54) : Invoking stop() from shutdown hook
2018-09-17 17:52:45,610   INFO --- [Thread-1]  org.spark_project.jetty.server.ServerConnector(line:306) : Stopped Spark@6e1b9411{HTTP/1.1}{0.0.0.0:4040}
2018-09-17 17:52:45,613   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@c1fca2a{/stages/stage/kill,null,UNAVAILABLE,@Spark}
2018-09-17 17:52:45,613   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@2c768ada{/jobs/job/kill,null,UNAVAILABLE,@Spark}
2018-09-17 17:52:45,614   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@4b7c4456{/api,null,UNAVAILABLE,@Spark}
2018-09-17 17:52:45,614   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@5c20aab9{/,null,UNAVAILABLE,@Spark}
2018-09-17 17:52:45,615   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@74aa9c72{/static,null,UNAVAILABLE,@Spark}
2018-09-17 17:52:45,615   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@387bf2d9{/executors/threadDump/json,null,UNAVAILABLE,@Spark}
2018-09-17 17:52:45,616   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@5ff90645{/executors/threadDump,null,UNAVAILABLE,@Spark}
2018-09-17 17:52:45,616   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@d74bac4{/executors/json,null,UNAVAILABLE,@Spark}
2018-09-17 17:52:45,616   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@373f7450{/executors,null,UNAVAILABLE,@Spark}
2018-09-17 17:52:45,616   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@5176d279{/environment/json,null,UNAVAILABLE,@Spark}
2018-09-17 17:52:45,617   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@1a891add{/environment,null,UNAVAILABLE,@Spark}
2018-09-17 17:52:45,617   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@41bf79da{/storage/rdd/json,null,UNAVAILABLE,@Spark}
2018-09-17 17:52:45,617   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@7fb33394{/storage/rdd,null,UNAVAILABLE,@Spark}
2018-09-17 17:52:45,618   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@e48bf9a{/storage/json,null,UNAVAILABLE,@Spark}
2018-09-17 17:52:45,618   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@3a5c2626{/storage,null,UNAVAILABLE,@Spark}
2018-09-17 17:52:45,618   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@5acc9fdf{/stages/pool/json,null,UNAVAILABLE,@Spark}
2018-09-17 17:52:45,619   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@75308740{/stages/pool,null,UNAVAILABLE,@Spark}
2018-09-17 17:52:45,619   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@396e6d9{/stages/stage/json,null,UNAVAILABLE,@Spark}
2018-09-17 17:52:45,620   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@7ee3d262{/stages/stage,null,UNAVAILABLE,@Spark}
2018-09-17 17:52:45,620   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@4efc25fc{/stages/json,null,UNAVAILABLE,@Spark}
2018-09-17 17:52:45,620   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@25da615a{/stages,null,UNAVAILABLE,@Spark}
2018-09-17 17:52:45,621   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@499683c4{/jobs/job/json,null,UNAVAILABLE,@Spark}
2018-09-17 17:52:45,621   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@2e23c180{/jobs/job,null,UNAVAILABLE,@Spark}
2018-09-17 17:52:45,621   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@43a51d00{/jobs/json,null,UNAVAILABLE,@Spark}
2018-09-17 17:52:45,621   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@173f73e7{/jobs,null,UNAVAILABLE,@Spark}
2018-09-17 17:52:45,624   INFO --- [Thread-1]  org.apache.spark.ui.SparkUI(line:54) : Stopped Spark web UI at http://192.168.3.199:4040
2018-09-17 17:52:45,640   INFO --- [dispatcher-event-loop-6]  org.apache.spark.MapOutputTrackerMasterEndpoint(line:54) : MapOutputTrackerMasterEndpoint stopped!
2018-09-17 17:52:45,679   INFO --- [Thread-1]  org.apache.spark.storage.memory.MemoryStore(line:54) : MemoryStore cleared
2018-09-17 17:52:45,680   INFO --- [Thread-1]  org.apache.spark.storage.BlockManager(line:54) : BlockManager stopped
2018-09-17 17:52:45,689   INFO --- [Thread-1]  org.apache.spark.storage.BlockManagerMaster(line:54) : BlockManagerMaster stopped
2018-09-17 17:52:45,694   INFO --- [dispatcher-event-loop-3]  org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint(line:54) : OutputCommitCoordinator stopped!
2018-09-17 17:52:45,703   INFO --- [Thread-1]  org.apache.spark.SparkContext(line:54) : Successfully stopped SparkContext
2018-09-17 17:52:45,704   INFO --- [Thread-1]  org.apache.spark.util.ShutdownHookManager(line:54) : Shutdown hook called
2018-09-17 17:52:45,705   INFO --- [Thread-1]  org.apache.spark.util.ShutdownHookManager(line:54) : Deleting directory C:\Users\wshs\AppData\Local\Temp\spark-dd3d1c67-d582-4952-8a88-469ed118cd66
2018-09-17 17:54:02,513   INFO --- [main]  org.apache.spark.SparkContext(line:54) : Running Spark version 2.1.1
2018-09-17 17:54:03,723   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing view acls to: wshs
2018-09-17 17:54:03,726   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing modify acls to: wshs
2018-09-17 17:54:03,729   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing view acls groups to: 
2018-09-17 17:54:03,731   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing modify acls groups to: 
2018-09-17 17:54:03,734   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(wshs); groups with view permissions: Set(); users  with modify permissions: Set(wshs); groups with modify permissions: Set()
2018-09-17 17:54:05,136   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'sparkDriver' on port 51886.
2018-09-17 17:54:05,239   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering MapOutputTracker
2018-09-17 17:54:05,305   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering BlockManagerMaster
2018-09-17 17:54:05,314   INFO --- [main]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-09-17 17:54:05,316   INFO --- [main]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : BlockManagerMasterEndpoint up
2018-09-17 17:54:05,348   INFO --- [main]  org.apache.spark.storage.DiskBlockManager(line:54) : Created local directory at C:\Users\wshs\AppData\Local\Temp\blockmgr-d9d73156-2e05-4df4-97ff-34b13dee7c13
2018-09-17 17:54:05,403   INFO --- [main]  org.apache.spark.storage.memory.MemoryStore(line:54) : MemoryStore started with capacity 3.0 GB
2018-09-17 17:54:05,791   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering OutputCommitCoordinator
2018-09-17 17:54:06,086   INFO --- [main]  org.spark_project.jetty.util.log(line:186) : Logging initialized @51266ms
2018-09-17 17:54:06,388   INFO --- [main]  org.spark_project.jetty.server.Server(line:327) : jetty-9.2.z-SNAPSHOT
2018-09-17 17:54:06,435   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@7c447c76{/jobs,null,AVAILABLE,@Spark}
2018-09-17 17:54:06,436   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@64fc097e{/jobs/json,null,AVAILABLE,@Spark}
2018-09-17 17:54:06,437   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@1640c151{/jobs/job,null,AVAILABLE,@Spark}
2018-09-17 17:54:06,438   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@5d5b5fa7{/jobs/job/json,null,AVAILABLE,@Spark}
2018-09-17 17:54:06,439   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@2a32fb6{/stages,null,AVAILABLE,@Spark}
2018-09-17 17:54:06,440   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@6107165{/stages/json,null,AVAILABLE,@Spark}
2018-09-17 17:54:06,441   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@164a62bf{/stages/stage,null,AVAILABLE,@Spark}
2018-09-17 17:54:06,442   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@11ebb1b6{/stages/stage/json,null,AVAILABLE,@Spark}
2018-09-17 17:54:06,443   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@aaee2a2{/stages/pool,null,AVAILABLE,@Spark}
2018-09-17 17:54:06,444   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@f3021cb{/stages/pool/json,null,AVAILABLE,@Spark}
2018-09-17 17:54:06,445   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@4aaae508{/storage,null,AVAILABLE,@Spark}
2018-09-17 17:54:06,446   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@6009bea{/storage/json,null,AVAILABLE,@Spark}
2018-09-17 17:54:06,448   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@7bc6d27a{/storage/rdd,null,AVAILABLE,@Spark}
2018-09-17 17:54:06,449   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@75769ab0{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-09-17 17:54:06,450   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@6869a3b3{/environment,null,AVAILABLE,@Spark}
2018-09-17 17:54:06,452   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@6ab4ba9f{/environment/json,null,AVAILABLE,@Spark}
2018-09-17 17:54:06,453   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@27ace0b1{/executors,null,AVAILABLE,@Spark}
2018-09-17 17:54:06,454   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@664e5dee{/executors/json,null,AVAILABLE,@Spark}
2018-09-17 17:54:06,455   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@431f1eaf{/executors/threadDump,null,AVAILABLE,@Spark}
2018-09-17 17:54:06,456   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@cb03411{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-09-17 17:54:06,469   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@4c59e45e{/static,null,AVAILABLE,@Spark}
2018-09-17 17:54:06,470   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@58ec7116{/,null,AVAILABLE,@Spark}
2018-09-17 17:54:06,472   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@63bde6c2{/api,null,AVAILABLE,@Spark}
2018-09-17 17:54:06,473   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@6ea04618{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-09-17 17:54:06,474   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@6dd82486{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-09-17 17:54:06,498   INFO --- [main]  org.spark_project.jetty.server.ServerConnector(line:266) : Started Spark@4b1a43d8{HTTP/1.1}{0.0.0.0:4040}
2018-09-17 17:54:06,499   INFO --- [main]  org.spark_project.jetty.server.Server(line:379) : Started @51684ms
2018-09-17 17:54:06,501   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'SparkUI' on port 4040.
2018-09-17 17:54:06,509   INFO --- [main]  org.apache.spark.ui.SparkUI(line:54) : Bound SparkUI to 0.0.0.0, and started at http://192.168.3.199:4040
2018-09-17 17:54:06,981   INFO --- [main]  org.apache.spark.executor.Executor(line:54) : Starting executor ID driver on host localhost
2018-09-17 17:54:07,093   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 51988.
2018-09-17 17:54:07,095   INFO --- [main]  org.apache.spark.network.netty.NettyBlockTransferService(line:54) : Server created on 192.168.3.199:51988
2018-09-17 17:54:07,099   INFO --- [main]  org.apache.spark.storage.BlockManager(line:54) : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-09-17 17:54:07,104   INFO --- [main]  org.apache.spark.storage.BlockManagerMaster(line:54) : Registering BlockManager BlockManagerId(driver, 192.168.3.199, 51988, None)
2018-09-17 17:54:07,109   INFO --- [dispatcher-event-loop-2]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : Registering block manager 192.168.3.199:51988 with 3.0 GB RAM, BlockManagerId(driver, 192.168.3.199, 51988, None)
2018-09-17 17:54:07,122   INFO --- [main]  org.apache.spark.storage.BlockManagerMaster(line:54) : Registered BlockManager BlockManagerId(driver, 192.168.3.199, 51988, None)
2018-09-17 17:54:07,124   INFO --- [main]  org.apache.spark.storage.BlockManager(line:54) : Initialized BlockManager: BlockManagerId(driver, 192.168.3.199, 51988, None)
2018-09-17 17:54:07,818   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@7e642b88{/metrics/json,null,AVAILABLE,@Spark}
2018-09-17 17:54:49,680   INFO --- [main]  org.apache.spark.sql.internal.SharedState(line:54) : Warehouse path is 'C:\Users\wshs\IdeaProjects\logdataSession\spark-warehouse'.
2018-09-17 17:54:49,710   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@2630dbc4{/SQL,null,AVAILABLE,@Spark}
2018-09-17 17:54:49,714   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@5a1c3cb4{/SQL/json,null,AVAILABLE,@Spark}
2018-09-17 17:54:49,718   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@ff23ae7{/SQL/execution,null,AVAILABLE,@Spark}
2018-09-17 17:54:49,721   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@2b7962a2{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-09-17 17:54:49,729   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@2f5b8250{/static/sql,null,AVAILABLE,@Spark}
2018-09-17 17:55:11,509   INFO --- [Thread-1]  org.apache.spark.SparkContext(line:54) : Invoking stop() from shutdown hook
2018-09-17 17:55:11,524   INFO --- [Thread-1]  org.spark_project.jetty.server.ServerConnector(line:306) : Stopped Spark@4b1a43d8{HTTP/1.1}{0.0.0.0:4040}
2018-09-17 17:55:11,527   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@6dd82486{/stages/stage/kill,null,UNAVAILABLE,@Spark}
2018-09-17 17:55:11,528   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@6ea04618{/jobs/job/kill,null,UNAVAILABLE,@Spark}
2018-09-17 17:55:11,529   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@63bde6c2{/api,null,UNAVAILABLE,@Spark}
2018-09-17 17:55:11,529   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@58ec7116{/,null,UNAVAILABLE,@Spark}
2018-09-17 17:55:11,530   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@4c59e45e{/static,null,UNAVAILABLE,@Spark}
2018-09-17 17:55:11,530   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@cb03411{/executors/threadDump/json,null,UNAVAILABLE,@Spark}
2018-09-17 17:55:11,530   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@431f1eaf{/executors/threadDump,null,UNAVAILABLE,@Spark}
2018-09-17 17:55:11,531   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@664e5dee{/executors/json,null,UNAVAILABLE,@Spark}
2018-09-17 17:55:11,531   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@27ace0b1{/executors,null,UNAVAILABLE,@Spark}
2018-09-17 17:55:11,532   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@6ab4ba9f{/environment/json,null,UNAVAILABLE,@Spark}
2018-09-17 17:55:11,532   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@6869a3b3{/environment,null,UNAVAILABLE,@Spark}
2018-09-17 17:55:11,533   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@75769ab0{/storage/rdd/json,null,UNAVAILABLE,@Spark}
2018-09-17 17:55:11,533   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@7bc6d27a{/storage/rdd,null,UNAVAILABLE,@Spark}
2018-09-17 17:55:11,534   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@6009bea{/storage/json,null,UNAVAILABLE,@Spark}
2018-09-17 17:55:11,534   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@4aaae508{/storage,null,UNAVAILABLE,@Spark}
2018-09-17 17:55:11,535   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@f3021cb{/stages/pool/json,null,UNAVAILABLE,@Spark}
2018-09-17 17:55:11,535   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@aaee2a2{/stages/pool,null,UNAVAILABLE,@Spark}
2018-09-17 17:55:11,536   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@11ebb1b6{/stages/stage/json,null,UNAVAILABLE,@Spark}
2018-09-17 17:55:11,536   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@164a62bf{/stages/stage,null,UNAVAILABLE,@Spark}
2018-09-17 17:55:11,537   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@6107165{/stages/json,null,UNAVAILABLE,@Spark}
2018-09-17 17:55:11,537   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@2a32fb6{/stages,null,UNAVAILABLE,@Spark}
2018-09-17 17:55:11,537   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@5d5b5fa7{/jobs/job/json,null,UNAVAILABLE,@Spark}
2018-09-17 17:55:11,538   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@1640c151{/jobs/job,null,UNAVAILABLE,@Spark}
2018-09-17 17:55:11,538   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@64fc097e{/jobs/json,null,UNAVAILABLE,@Spark}
2018-09-17 17:55:11,538   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@7c447c76{/jobs,null,UNAVAILABLE,@Spark}
2018-09-17 17:55:11,540   INFO --- [Thread-1]  org.apache.spark.ui.SparkUI(line:54) : Stopped Spark web UI at http://192.168.3.199:4040
2018-09-17 17:55:11,557   INFO --- [dispatcher-event-loop-1]  org.apache.spark.MapOutputTrackerMasterEndpoint(line:54) : MapOutputTrackerMasterEndpoint stopped!
2018-09-17 17:55:11,583   INFO --- [Thread-1]  org.apache.spark.storage.memory.MemoryStore(line:54) : MemoryStore cleared
2018-09-17 17:55:11,584   INFO --- [Thread-1]  org.apache.spark.storage.BlockManager(line:54) : BlockManager stopped
2018-09-17 17:55:11,585   INFO --- [Thread-1]  org.apache.spark.storage.BlockManagerMaster(line:54) : BlockManagerMaster stopped
2018-09-17 17:55:11,591   INFO --- [dispatcher-event-loop-6]  org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint(line:54) : OutputCommitCoordinator stopped!
2018-09-17 17:55:11,604   INFO --- [Thread-1]  org.apache.spark.SparkContext(line:54) : Successfully stopped SparkContext
2018-09-17 17:55:11,605   INFO --- [Thread-1]  org.apache.spark.util.ShutdownHookManager(line:54) : Shutdown hook called
2018-09-17 17:55:11,607   INFO --- [Thread-1]  org.apache.spark.util.ShutdownHookManager(line:54) : Deleting directory C:\Users\wshs\AppData\Local\Temp\spark-09118918-f036-4461-b3ca-141f9e69f25d
2018-09-17 18:00:25,759   INFO --- [main]  org.apache.spark.SparkContext(line:54) : Running Spark version 2.1.1
2018-09-17 18:00:26,096   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing view acls to: wshs
2018-09-17 18:00:26,097   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing modify acls to: wshs
2018-09-17 18:00:26,098   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing view acls groups to: 
2018-09-17 18:00:26,098   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing modify acls groups to: 
2018-09-17 18:00:26,099   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(wshs); groups with view permissions: Set(); users  with modify permissions: Set(wshs); groups with modify permissions: Set()
2018-09-17 18:00:26,553   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'sparkDriver' on port 64692.
2018-09-17 18:00:26,574   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering MapOutputTracker
2018-09-17 18:00:26,594   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering BlockManagerMaster
2018-09-17 18:00:26,597   INFO --- [main]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-09-17 18:00:26,598   INFO --- [main]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : BlockManagerMasterEndpoint up
2018-09-17 18:00:26,612   INFO --- [main]  org.apache.spark.storage.DiskBlockManager(line:54) : Created local directory at C:\Users\wshs\AppData\Local\Temp\blockmgr-015c1a21-c114-4069-b5c7-8fa016021fa8
2018-09-17 18:00:26,628   INFO --- [main]  org.apache.spark.storage.memory.MemoryStore(line:54) : MemoryStore started with capacity 3.0 GB
2018-09-17 18:00:26,672   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering OutputCommitCoordinator
2018-09-17 18:00:26,757   INFO --- [main]  org.spark_project.jetty.util.log(line:186) : Logging initialized @2681ms
2018-09-17 18:00:26,858   INFO --- [main]  org.spark_project.jetty.server.Server(line:327) : jetty-9.2.z-SNAPSHOT
2018-09-17 18:00:26,873   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@295eaa7c{/jobs,null,AVAILABLE,@Spark}
2018-09-17 18:00:26,873   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@3918c187{/jobs/json,null,AVAILABLE,@Spark}
2018-09-17 18:00:26,873   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@2c88b9fc{/jobs/job,null,AVAILABLE,@Spark}
2018-09-17 18:00:26,874   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@64dafeed{/jobs/job/json,null,AVAILABLE,@Spark}
2018-09-17 18:00:26,874   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@388ba540{/stages,null,AVAILABLE,@Spark}
2018-09-17 18:00:26,874   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@47605f2f{/stages/json,null,AVAILABLE,@Spark}
2018-09-17 18:00:26,875   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@2ece4966{/stages/stage,null,AVAILABLE,@Spark}
2018-09-17 18:00:26,875   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@1dd0e7c4{/stages/stage/json,null,AVAILABLE,@Spark}
2018-09-17 18:00:26,875   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@7894f09b{/stages/pool,null,AVAILABLE,@Spark}
2018-09-17 18:00:26,876   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@3d484181{/stages/pool/json,null,AVAILABLE,@Spark}
2018-09-17 18:00:26,876   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@6111ba37{/storage,null,AVAILABLE,@Spark}
2018-09-17 18:00:26,876   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@7be58f16{/storage/json,null,AVAILABLE,@Spark}
2018-09-17 18:00:26,877   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@242aa8d9{/storage/rdd,null,AVAILABLE,@Spark}
2018-09-17 18:00:26,877   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@5b11a194{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-09-17 18:00:26,878   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@37bd68c3{/environment,null,AVAILABLE,@Spark}
2018-09-17 18:00:26,878   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@60f7cc1d{/environment/json,null,AVAILABLE,@Spark}
2018-09-17 18:00:26,878   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@11eadcba{/executors,null,AVAILABLE,@Spark}
2018-09-17 18:00:26,879   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@4721d212{/executors/json,null,AVAILABLE,@Spark}
2018-09-17 18:00:26,879   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@1b065145{/executors/threadDump,null,AVAILABLE,@Spark}
2018-09-17 18:00:26,879   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@45cff11c{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-09-17 18:00:26,885   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@207ea13{/static,null,AVAILABLE,@Spark}
2018-09-17 18:00:26,886   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@4bff1903{/,null,AVAILABLE,@Spark}
2018-09-17 18:00:26,887   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@62dae540{/api,null,AVAILABLE,@Spark}
2018-09-17 18:00:26,887   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@5827af16{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-09-17 18:00:26,888   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@654d8173{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-09-17 18:00:26,901   INFO --- [main]  org.spark_project.jetty.server.ServerConnector(line:266) : Started Spark@3234f74e{HTTP/1.1}{0.0.0.0:4040}
2018-09-17 18:00:26,902   INFO --- [main]  org.spark_project.jetty.server.Server(line:379) : Started @2827ms
2018-09-17 18:00:26,902   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'SparkUI' on port 4040.
2018-09-17 18:00:26,905   INFO --- [main]  org.apache.spark.ui.SparkUI(line:54) : Bound SparkUI to 0.0.0.0, and started at http://192.168.3.199:4040
2018-09-17 18:00:26,964   INFO --- [main]  org.apache.spark.executor.Executor(line:54) : Starting executor ID driver on host localhost
2018-09-17 18:00:27,031   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 64750.
2018-09-17 18:00:27,032   INFO --- [main]  org.apache.spark.network.netty.NettyBlockTransferService(line:54) : Server created on 192.168.3.199:64750
2018-09-17 18:00:27,034   INFO --- [main]  org.apache.spark.storage.BlockManager(line:54) : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-09-17 18:00:27,036   INFO --- [main]  org.apache.spark.storage.BlockManagerMaster(line:54) : Registering BlockManager BlockManagerId(driver, 192.168.3.199, 64750, None)
2018-09-17 18:00:27,039   INFO --- [dispatcher-event-loop-2]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : Registering block manager 192.168.3.199:64750 with 3.0 GB RAM, BlockManagerId(driver, 192.168.3.199, 64750, None)
2018-09-17 18:00:27,043   INFO --- [main]  org.apache.spark.storage.BlockManagerMaster(line:54) : Registered BlockManager BlockManagerId(driver, 192.168.3.199, 64750, None)
2018-09-17 18:00:27,043   INFO --- [main]  org.apache.spark.storage.BlockManager(line:54) : Initialized BlockManager: BlockManagerId(driver, 192.168.3.199, 64750, None)
2018-09-17 18:00:27,221   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@344561e0{/metrics/json,null,AVAILABLE,@Spark}
2018-09-17 18:00:27,252   INFO --- [main]  org.apache.spark.sql.internal.SharedState(line:54) : Warehouse path is 'file:/C:/Users/wshs/IdeaProjects/logdataSession/spark-warehouse'.
2018-09-17 18:00:27,257   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@33c2bd{/SQL,null,AVAILABLE,@Spark}
2018-09-17 18:00:27,258   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@3c321bdb{/SQL/json,null,AVAILABLE,@Spark}
2018-09-17 18:00:27,258   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@6f0628de{/SQL/execution,null,AVAILABLE,@Spark}
2018-09-17 18:00:27,259   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@1e392345{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-09-17 18:00:27,261   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@51b01960{/static/sql,null,AVAILABLE,@Spark}
2018-09-17 18:00:27,269   INFO --- [Thread-1]  org.apache.spark.SparkContext(line:54) : Invoking stop() from shutdown hook
2018-09-17 18:00:27,274   INFO --- [Thread-1]  org.spark_project.jetty.server.ServerConnector(line:306) : Stopped Spark@3234f74e{HTTP/1.1}{0.0.0.0:4040}
2018-09-17 18:00:27,275   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@654d8173{/stages/stage/kill,null,UNAVAILABLE,@Spark}
2018-09-17 18:00:27,276   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@5827af16{/jobs/job/kill,null,UNAVAILABLE,@Spark}
2018-09-17 18:00:27,276   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@62dae540{/api,null,UNAVAILABLE,@Spark}
2018-09-17 18:00:27,276   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@4bff1903{/,null,UNAVAILABLE,@Spark}
2018-09-17 18:00:27,276   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@207ea13{/static,null,UNAVAILABLE,@Spark}
2018-09-17 18:00:27,277   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@45cff11c{/executors/threadDump/json,null,UNAVAILABLE,@Spark}
2018-09-17 18:00:27,277   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@1b065145{/executors/threadDump,null,UNAVAILABLE,@Spark}
2018-09-17 18:00:27,277   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@4721d212{/executors/json,null,UNAVAILABLE,@Spark}
2018-09-17 18:00:27,277   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@11eadcba{/executors,null,UNAVAILABLE,@Spark}
2018-09-17 18:00:27,277   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@60f7cc1d{/environment/json,null,UNAVAILABLE,@Spark}
2018-09-17 18:00:27,278   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@37bd68c3{/environment,null,UNAVAILABLE,@Spark}
2018-09-17 18:00:27,278   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@5b11a194{/storage/rdd/json,null,UNAVAILABLE,@Spark}
2018-09-17 18:00:27,278   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@242aa8d9{/storage/rdd,null,UNAVAILABLE,@Spark}
2018-09-17 18:00:27,278   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@7be58f16{/storage/json,null,UNAVAILABLE,@Spark}
2018-09-17 18:00:27,279   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@6111ba37{/storage,null,UNAVAILABLE,@Spark}
2018-09-17 18:00:27,279   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@3d484181{/stages/pool/json,null,UNAVAILABLE,@Spark}
2018-09-17 18:00:27,279   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@7894f09b{/stages/pool,null,UNAVAILABLE,@Spark}
2018-09-17 18:00:27,279   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@1dd0e7c4{/stages/stage/json,null,UNAVAILABLE,@Spark}
2018-09-17 18:00:27,280   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@2ece4966{/stages/stage,null,UNAVAILABLE,@Spark}
2018-09-17 18:00:27,280   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@47605f2f{/stages/json,null,UNAVAILABLE,@Spark}
2018-09-17 18:00:27,280   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@388ba540{/stages,null,UNAVAILABLE,@Spark}
2018-09-17 18:00:27,280   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@64dafeed{/jobs/job/json,null,UNAVAILABLE,@Spark}
2018-09-17 18:00:27,280   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@2c88b9fc{/jobs/job,null,UNAVAILABLE,@Spark}
2018-09-17 18:00:27,281   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@3918c187{/jobs/json,null,UNAVAILABLE,@Spark}
2018-09-17 18:00:27,281   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@295eaa7c{/jobs,null,UNAVAILABLE,@Spark}
2018-09-17 18:00:27,282   INFO --- [Thread-1]  org.apache.spark.ui.SparkUI(line:54) : Stopped Spark web UI at http://192.168.3.199:4040
2018-09-17 18:00:27,296   INFO --- [dispatcher-event-loop-6]  org.apache.spark.MapOutputTrackerMasterEndpoint(line:54) : MapOutputTrackerMasterEndpoint stopped!
2018-09-17 18:00:27,309   INFO --- [Thread-1]  org.apache.spark.storage.memory.MemoryStore(line:54) : MemoryStore cleared
2018-09-17 18:00:27,310   INFO --- [Thread-1]  org.apache.spark.storage.BlockManager(line:54) : BlockManager stopped
2018-09-17 18:00:27,316   INFO --- [Thread-1]  org.apache.spark.storage.BlockManagerMaster(line:54) : BlockManagerMaster stopped
2018-09-17 18:00:27,320   INFO --- [dispatcher-event-loop-3]  org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint(line:54) : OutputCommitCoordinator stopped!
2018-09-17 18:00:27,325   INFO --- [Thread-1]  org.apache.spark.SparkContext(line:54) : Successfully stopped SparkContext
2018-09-17 18:00:27,325   INFO --- [Thread-1]  org.apache.spark.util.ShutdownHookManager(line:54) : Shutdown hook called
2018-09-17 18:00:27,326   INFO --- [Thread-1]  org.apache.spark.util.ShutdownHookManager(line:54) : Deleting directory C:\Users\wshs\AppData\Local\Temp\spark-fd187548-04c0-4ad3-84b1-6b61d474a0f9
2018-09-17 18:17:39,540   INFO --- [main]  org.apache.spark.SparkContext(line:54) : Running Spark version 2.1.1
2018-09-17 18:17:39,923   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing view acls to: wshs
2018-09-17 18:17:39,924   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing modify acls to: wshs
2018-09-17 18:17:39,924   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing view acls groups to: 
2018-09-17 18:17:39,925   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing modify acls groups to: 
2018-09-17 18:17:39,926   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(wshs); groups with view permissions: Set(); users  with modify permissions: Set(wshs); groups with modify permissions: Set()
2018-09-17 18:17:40,381   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'sparkDriver' on port 49430.
2018-09-17 18:17:40,397   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering MapOutputTracker
2018-09-17 18:17:40,416   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering BlockManagerMaster
2018-09-17 18:17:40,419   INFO --- [main]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-09-17 18:17:40,420   INFO --- [main]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : BlockManagerMasterEndpoint up
2018-09-17 18:17:40,433   INFO --- [main]  org.apache.spark.storage.DiskBlockManager(line:54) : Created local directory at C:\Users\wshs\AppData\Local\Temp\blockmgr-7ab955e6-fc71-4017-9786-e0ad5d9ffca9
2018-09-17 18:17:40,449   INFO --- [main]  org.apache.spark.storage.memory.MemoryStore(line:54) : MemoryStore started with capacity 3.0 GB
2018-09-17 18:17:40,496   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering OutputCommitCoordinator
2018-09-17 18:17:40,595   INFO --- [main]  org.spark_project.jetty.util.log(line:186) : Logging initialized @2768ms
2018-09-17 18:17:40,692   INFO --- [main]  org.spark_project.jetty.server.Server(line:327) : jetty-9.2.z-SNAPSHOT
2018-09-17 18:17:40,708   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@295eaa7c{/jobs,null,AVAILABLE,@Spark}
2018-09-17 18:17:40,708   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@3918c187{/jobs/json,null,AVAILABLE,@Spark}
2018-09-17 18:17:40,709   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@2c88b9fc{/jobs/job,null,AVAILABLE,@Spark}
2018-09-17 18:17:40,709   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@64dafeed{/jobs/job/json,null,AVAILABLE,@Spark}
2018-09-17 18:17:40,709   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@388ba540{/stages,null,AVAILABLE,@Spark}
2018-09-17 18:17:40,710   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@47605f2f{/stages/json,null,AVAILABLE,@Spark}
2018-09-17 18:17:40,710   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@2ece4966{/stages/stage,null,AVAILABLE,@Spark}
2018-09-17 18:17:40,711   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@1dd0e7c4{/stages/stage/json,null,AVAILABLE,@Spark}
2018-09-17 18:17:40,712   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@7894f09b{/stages/pool,null,AVAILABLE,@Spark}
2018-09-17 18:17:40,712   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@3d484181{/stages/pool/json,null,AVAILABLE,@Spark}
2018-09-17 18:17:40,712   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@6111ba37{/storage,null,AVAILABLE,@Spark}
2018-09-17 18:17:40,713   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@7be58f16{/storage/json,null,AVAILABLE,@Spark}
2018-09-17 18:17:40,713   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@242aa8d9{/storage/rdd,null,AVAILABLE,@Spark}
2018-09-17 18:17:40,714   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@5b11a194{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-09-17 18:17:40,714   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@37bd68c3{/environment,null,AVAILABLE,@Spark}
2018-09-17 18:17:40,715   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@60f7cc1d{/environment/json,null,AVAILABLE,@Spark}
2018-09-17 18:17:40,715   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@11eadcba{/executors,null,AVAILABLE,@Spark}
2018-09-17 18:17:40,716   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@4721d212{/executors/json,null,AVAILABLE,@Spark}
2018-09-17 18:17:40,716   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@1b065145{/executors/threadDump,null,AVAILABLE,@Spark}
2018-09-17 18:17:40,716   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@45cff11c{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-09-17 18:17:40,722   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@207ea13{/static,null,AVAILABLE,@Spark}
2018-09-17 18:17:40,723   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@4bff1903{/,null,AVAILABLE,@Spark}
2018-09-17 18:17:40,723   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@62dae540{/api,null,AVAILABLE,@Spark}
2018-09-17 18:17:40,724   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@5827af16{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-09-17 18:17:40,724   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@654d8173{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-09-17 18:17:40,737   INFO --- [main]  org.spark_project.jetty.server.ServerConnector(line:266) : Started Spark@3234f74e{HTTP/1.1}{0.0.0.0:4040}
2018-09-17 18:17:40,738   INFO --- [main]  org.spark_project.jetty.server.Server(line:379) : Started @2911ms
2018-09-17 18:17:40,738   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'SparkUI' on port 4040.
2018-09-17 18:17:40,741   INFO --- [main]  org.apache.spark.ui.SparkUI(line:54) : Bound SparkUI to 0.0.0.0, and started at http://192.168.3.199:4040
2018-09-17 18:17:40,807   INFO --- [main]  org.apache.spark.executor.Executor(line:54) : Starting executor ID driver on host localhost
2018-09-17 18:17:40,872   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 49488.
2018-09-17 18:17:40,873   INFO --- [main]  org.apache.spark.network.netty.NettyBlockTransferService(line:54) : Server created on 192.168.3.199:49488
2018-09-17 18:17:40,875   INFO --- [main]  org.apache.spark.storage.BlockManager(line:54) : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-09-17 18:17:40,876   INFO --- [main]  org.apache.spark.storage.BlockManagerMaster(line:54) : Registering BlockManager BlockManagerId(driver, 192.168.3.199, 49488, None)
2018-09-17 18:17:40,880   INFO --- [dispatcher-event-loop-2]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : Registering block manager 192.168.3.199:49488 with 3.0 GB RAM, BlockManagerId(driver, 192.168.3.199, 49488, None)
2018-09-17 18:17:40,883   INFO --- [main]  org.apache.spark.storage.BlockManagerMaster(line:54) : Registered BlockManager BlockManagerId(driver, 192.168.3.199, 49488, None)
2018-09-17 18:17:40,884   INFO --- [main]  org.apache.spark.storage.BlockManager(line:54) : Initialized BlockManager: BlockManagerId(driver, 192.168.3.199, 49488, None)
2018-09-17 18:17:41,045   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@344561e0{/metrics/json,null,AVAILABLE,@Spark}
2018-09-17 18:17:41,077   INFO --- [main]  org.apache.spark.sql.internal.SharedState(line:54) : Warehouse path is 'C:\Users\wshs\IdeaProjects\logdataSession\spark-warehouse'.
2018-09-17 18:17:41,082   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@3c321bdb{/SQL,null,AVAILABLE,@Spark}
2018-09-17 18:17:41,083   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@3abd581e{/SQL/json,null,AVAILABLE,@Spark}
2018-09-17 18:17:41,083   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@1e392345{/SQL/execution,null,AVAILABLE,@Spark}
2018-09-17 18:17:41,084   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@4ced35ed{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-09-17 18:17:41,086   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@27dc79f7{/static/sql,null,AVAILABLE,@Spark}
2018-09-17 18:17:41,096   INFO --- [Thread-1]  org.apache.spark.SparkContext(line:54) : Invoking stop() from shutdown hook
2018-09-17 18:17:41,101   INFO --- [Thread-1]  org.spark_project.jetty.server.ServerConnector(line:306) : Stopped Spark@3234f74e{HTTP/1.1}{0.0.0.0:4040}
2018-09-17 18:17:41,103   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@654d8173{/stages/stage/kill,null,UNAVAILABLE,@Spark}
2018-09-17 18:17:41,104   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@5827af16{/jobs/job/kill,null,UNAVAILABLE,@Spark}
2018-09-17 18:17:41,104   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@62dae540{/api,null,UNAVAILABLE,@Spark}
2018-09-17 18:17:41,104   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@4bff1903{/,null,UNAVAILABLE,@Spark}
2018-09-17 18:17:41,104   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@207ea13{/static,null,UNAVAILABLE,@Spark}
2018-09-17 18:17:41,105   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@45cff11c{/executors/threadDump/json,null,UNAVAILABLE,@Spark}
2018-09-17 18:17:41,105   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@1b065145{/executors/threadDump,null,UNAVAILABLE,@Spark}
2018-09-17 18:17:41,105   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@4721d212{/executors/json,null,UNAVAILABLE,@Spark}
2018-09-17 18:17:41,105   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@11eadcba{/executors,null,UNAVAILABLE,@Spark}
2018-09-17 18:17:41,105   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@60f7cc1d{/environment/json,null,UNAVAILABLE,@Spark}
2018-09-17 18:17:41,106   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@37bd68c3{/environment,null,UNAVAILABLE,@Spark}
2018-09-17 18:17:41,106   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@5b11a194{/storage/rdd/json,null,UNAVAILABLE,@Spark}
2018-09-17 18:17:41,106   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@242aa8d9{/storage/rdd,null,UNAVAILABLE,@Spark}
2018-09-17 18:17:41,106   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@7be58f16{/storage/json,null,UNAVAILABLE,@Spark}
2018-09-17 18:17:41,106   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@6111ba37{/storage,null,UNAVAILABLE,@Spark}
2018-09-17 18:17:41,107   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@3d484181{/stages/pool/json,null,UNAVAILABLE,@Spark}
2018-09-17 18:17:41,107   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@7894f09b{/stages/pool,null,UNAVAILABLE,@Spark}
2018-09-17 18:17:41,107   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@1dd0e7c4{/stages/stage/json,null,UNAVAILABLE,@Spark}
2018-09-17 18:17:41,107   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@2ece4966{/stages/stage,null,UNAVAILABLE,@Spark}
2018-09-17 18:17:41,108   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@47605f2f{/stages/json,null,UNAVAILABLE,@Spark}
2018-09-17 18:17:41,108   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@388ba540{/stages,null,UNAVAILABLE,@Spark}
2018-09-17 18:17:41,109   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@64dafeed{/jobs/job/json,null,UNAVAILABLE,@Spark}
2018-09-17 18:17:41,109   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@2c88b9fc{/jobs/job,null,UNAVAILABLE,@Spark}
2018-09-17 18:17:41,109   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@3918c187{/jobs/json,null,UNAVAILABLE,@Spark}
2018-09-17 18:17:41,109   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@295eaa7c{/jobs,null,UNAVAILABLE,@Spark}
2018-09-17 18:17:41,111   INFO --- [Thread-1]  org.apache.spark.ui.SparkUI(line:54) : Stopped Spark web UI at http://192.168.3.199:4040
2018-09-17 18:17:41,120   INFO --- [dispatcher-event-loop-6]  org.apache.spark.MapOutputTrackerMasterEndpoint(line:54) : MapOutputTrackerMasterEndpoint stopped!
2018-09-17 18:17:41,136   INFO --- [Thread-1]  org.apache.spark.storage.memory.MemoryStore(line:54) : MemoryStore cleared
2018-09-17 18:17:41,137   INFO --- [Thread-1]  org.apache.spark.storage.BlockManager(line:54) : BlockManager stopped
2018-09-17 18:17:41,144   INFO --- [Thread-1]  org.apache.spark.storage.BlockManagerMaster(line:54) : BlockManagerMaster stopped
2018-09-17 18:17:41,147   INFO --- [dispatcher-event-loop-3]  org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint(line:54) : OutputCommitCoordinator stopped!
2018-09-17 18:17:41,154   INFO --- [Thread-1]  org.apache.spark.SparkContext(line:54) : Successfully stopped SparkContext
2018-09-17 18:17:41,155   INFO --- [Thread-1]  org.apache.spark.util.ShutdownHookManager(line:54) : Shutdown hook called
2018-09-17 18:17:41,156   INFO --- [Thread-1]  org.apache.spark.util.ShutdownHookManager(line:54) : Deleting directory C:\Users\wshs\AppData\Local\Temp\spark-5f5ff871-aaae-4f3c-891f-a6cd65ce2374
2018-09-17 18:26:41,635   INFO --- [main]  org.apache.spark.SparkContext(line:54) : Running Spark version 2.1.1
2018-09-17 18:26:41,984   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing view acls to: wshs
2018-09-17 18:26:41,985   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing modify acls to: wshs
2018-09-17 18:26:41,986   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing view acls groups to: 
2018-09-17 18:26:41,987   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing modify acls groups to: 
2018-09-17 18:26:41,988   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(wshs); groups with view permissions: Set(); users  with modify permissions: Set(wshs); groups with modify permissions: Set()
2018-09-17 18:26:42,438   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'sparkDriver' on port 64243.
2018-09-17 18:26:42,453   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering MapOutputTracker
2018-09-17 18:26:42,469   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering BlockManagerMaster
2018-09-17 18:26:42,471   INFO --- [main]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-09-17 18:26:42,472   INFO --- [main]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : BlockManagerMasterEndpoint up
2018-09-17 18:26:42,485   INFO --- [main]  org.apache.spark.storage.DiskBlockManager(line:54) : Created local directory at C:\Users\wshs\AppData\Local\Temp\blockmgr-e20d5852-61cd-45f9-8dca-cc1e9654838d
2018-09-17 18:26:42,506   INFO --- [main]  org.apache.spark.storage.memory.MemoryStore(line:54) : MemoryStore started with capacity 3.0 GB
2018-09-17 18:26:42,546   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering OutputCommitCoordinator
2018-09-17 18:26:42,615   INFO --- [main]  org.spark_project.jetty.util.log(line:186) : Logging initialized @2399ms
2018-09-17 18:26:42,699   INFO --- [main]  org.spark_project.jetty.server.Server(line:327) : jetty-9.2.z-SNAPSHOT
2018-09-17 18:26:42,713   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@295eaa7c{/jobs,null,AVAILABLE,@Spark}
2018-09-17 18:26:42,714   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@3918c187{/jobs/json,null,AVAILABLE,@Spark}
2018-09-17 18:26:42,714   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@2c88b9fc{/jobs/job,null,AVAILABLE,@Spark}
2018-09-17 18:26:42,714   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@64dafeed{/jobs/job/json,null,AVAILABLE,@Spark}
2018-09-17 18:26:42,714   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@388ba540{/stages,null,AVAILABLE,@Spark}
2018-09-17 18:26:42,715   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@47605f2f{/stages/json,null,AVAILABLE,@Spark}
2018-09-17 18:26:42,715   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@2ece4966{/stages/stage,null,AVAILABLE,@Spark}
2018-09-17 18:26:42,715   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@1dd0e7c4{/stages/stage/json,null,AVAILABLE,@Spark}
2018-09-17 18:26:42,715   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@7894f09b{/stages/pool,null,AVAILABLE,@Spark}
2018-09-17 18:26:42,716   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@3d484181{/stages/pool/json,null,AVAILABLE,@Spark}
2018-09-17 18:26:42,716   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@6111ba37{/storage,null,AVAILABLE,@Spark}
2018-09-17 18:26:42,716   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@7be58f16{/storage/json,null,AVAILABLE,@Spark}
2018-09-17 18:26:42,717   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@242aa8d9{/storage/rdd,null,AVAILABLE,@Spark}
2018-09-17 18:26:42,717   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@5b11a194{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-09-17 18:26:42,718   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@37bd68c3{/environment,null,AVAILABLE,@Spark}
2018-09-17 18:26:42,718   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@60f7cc1d{/environment/json,null,AVAILABLE,@Spark}
2018-09-17 18:26:42,718   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@11eadcba{/executors,null,AVAILABLE,@Spark}
2018-09-17 18:26:42,718   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@4721d212{/executors/json,null,AVAILABLE,@Spark}
2018-09-17 18:26:42,719   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@1b065145{/executors/threadDump,null,AVAILABLE,@Spark}
2018-09-17 18:26:42,719   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@45cff11c{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-09-17 18:26:42,724   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@207ea13{/static,null,AVAILABLE,@Spark}
2018-09-17 18:26:42,724   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@4bff1903{/,null,AVAILABLE,@Spark}
2018-09-17 18:26:42,725   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@62dae540{/api,null,AVAILABLE,@Spark}
2018-09-17 18:26:42,725   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@5827af16{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-09-17 18:26:42,726   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@654d8173{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-09-17 18:26:42,739   INFO --- [main]  org.spark_project.jetty.server.ServerConnector(line:266) : Started Spark@3234f74e{HTTP/1.1}{0.0.0.0:4040}
2018-09-17 18:26:42,739   INFO --- [main]  org.spark_project.jetty.server.Server(line:379) : Started @2524ms
2018-09-17 18:26:42,740   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'SparkUI' on port 4040.
2018-09-17 18:26:42,743   INFO --- [main]  org.apache.spark.ui.SparkUI(line:54) : Bound SparkUI to 0.0.0.0, and started at http://192.168.3.199:4040
2018-09-17 18:26:42,805   INFO --- [main]  org.apache.spark.executor.Executor(line:54) : Starting executor ID driver on host localhost
2018-09-17 18:26:42,873   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 64291.
2018-09-17 18:26:42,874   INFO --- [main]  org.apache.spark.network.netty.NettyBlockTransferService(line:54) : Server created on 192.168.3.199:64291
2018-09-17 18:26:42,878   INFO --- [main]  org.apache.spark.storage.BlockManager(line:54) : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-09-17 18:26:42,880   INFO --- [main]  org.apache.spark.storage.BlockManagerMaster(line:54) : Registering BlockManager BlockManagerId(driver, 192.168.3.199, 64291, None)
2018-09-17 18:26:42,883   INFO --- [dispatcher-event-loop-2]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : Registering block manager 192.168.3.199:64291 with 3.0 GB RAM, BlockManagerId(driver, 192.168.3.199, 64291, None)
2018-09-17 18:26:42,886   INFO --- [main]  org.apache.spark.storage.BlockManagerMaster(line:54) : Registered BlockManager BlockManagerId(driver, 192.168.3.199, 64291, None)
2018-09-17 18:26:42,887   INFO --- [main]  org.apache.spark.storage.BlockManager(line:54) : Initialized BlockManager: BlockManagerId(driver, 192.168.3.199, 64291, None)
2018-09-17 18:26:43,067   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@344561e0{/metrics/json,null,AVAILABLE,@Spark}
2018-09-17 18:26:43,098   INFO --- [main]  org.apache.spark.sql.internal.SharedState(line:54) : Warehouse path is 'C:\Users\wshs\IdeaProjects\logdataSession\spark-warehouse'.
2018-09-17 18:26:43,106   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@3c321bdb{/SQL,null,AVAILABLE,@Spark}
2018-09-17 18:26:43,106   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@3abd581e{/SQL/json,null,AVAILABLE,@Spark}
2018-09-17 18:26:43,107   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@1e392345{/SQL/execution,null,AVAILABLE,@Spark}
2018-09-17 18:26:43,108   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@4ced35ed{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-09-17 18:26:43,110   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@27dc79f7{/static/sql,null,AVAILABLE,@Spark}
2018-09-17 18:26:43,121   INFO --- [Thread-1]  org.apache.spark.SparkContext(line:54) : Invoking stop() from shutdown hook
2018-09-17 18:26:43,126   INFO --- [Thread-1]  org.spark_project.jetty.server.ServerConnector(line:306) : Stopped Spark@3234f74e{HTTP/1.1}{0.0.0.0:4040}
2018-09-17 18:26:43,128   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@654d8173{/stages/stage/kill,null,UNAVAILABLE,@Spark}
2018-09-17 18:26:43,129   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@5827af16{/jobs/job/kill,null,UNAVAILABLE,@Spark}
2018-09-17 18:26:43,129   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@62dae540{/api,null,UNAVAILABLE,@Spark}
2018-09-17 18:26:43,130   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@4bff1903{/,null,UNAVAILABLE,@Spark}
2018-09-17 18:26:43,130   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@207ea13{/static,null,UNAVAILABLE,@Spark}
2018-09-17 18:26:43,130   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@45cff11c{/executors/threadDump/json,null,UNAVAILABLE,@Spark}
2018-09-17 18:26:43,130   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@1b065145{/executors/threadDump,null,UNAVAILABLE,@Spark}
2018-09-17 18:26:43,131   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@4721d212{/executors/json,null,UNAVAILABLE,@Spark}
2018-09-17 18:26:43,131   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@11eadcba{/executors,null,UNAVAILABLE,@Spark}
2018-09-17 18:26:43,131   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@60f7cc1d{/environment/json,null,UNAVAILABLE,@Spark}
2018-09-17 18:26:43,132   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@37bd68c3{/environment,null,UNAVAILABLE,@Spark}
2018-09-17 18:26:43,132   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@5b11a194{/storage/rdd/json,null,UNAVAILABLE,@Spark}
2018-09-17 18:26:43,132   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@242aa8d9{/storage/rdd,null,UNAVAILABLE,@Spark}
2018-09-17 18:26:43,132   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@7be58f16{/storage/json,null,UNAVAILABLE,@Spark}
2018-09-17 18:26:43,133   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@6111ba37{/storage,null,UNAVAILABLE,@Spark}
2018-09-17 18:26:43,133   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@3d484181{/stages/pool/json,null,UNAVAILABLE,@Spark}
2018-09-17 18:26:43,133   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@7894f09b{/stages/pool,null,UNAVAILABLE,@Spark}
2018-09-17 18:26:43,133   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@1dd0e7c4{/stages/stage/json,null,UNAVAILABLE,@Spark}
2018-09-17 18:26:43,134   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@2ece4966{/stages/stage,null,UNAVAILABLE,@Spark}
2018-09-17 18:26:43,134   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@47605f2f{/stages/json,null,UNAVAILABLE,@Spark}
2018-09-17 18:26:43,134   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@388ba540{/stages,null,UNAVAILABLE,@Spark}
2018-09-17 18:26:43,134   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@64dafeed{/jobs/job/json,null,UNAVAILABLE,@Spark}
2018-09-17 18:26:43,134   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@2c88b9fc{/jobs/job,null,UNAVAILABLE,@Spark}
2018-09-17 18:26:43,135   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@3918c187{/jobs/json,null,UNAVAILABLE,@Spark}
2018-09-17 18:26:43,135   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@295eaa7c{/jobs,null,UNAVAILABLE,@Spark}
2018-09-17 18:26:43,137   INFO --- [Thread-1]  org.apache.spark.ui.SparkUI(line:54) : Stopped Spark web UI at http://192.168.3.199:4040
2018-09-17 18:26:43,152   INFO --- [dispatcher-event-loop-6]  org.apache.spark.MapOutputTrackerMasterEndpoint(line:54) : MapOutputTrackerMasterEndpoint stopped!
2018-09-17 18:26:43,163   INFO --- [Thread-1]  org.apache.spark.storage.memory.MemoryStore(line:54) : MemoryStore cleared
2018-09-17 18:26:43,164   INFO --- [Thread-1]  org.apache.spark.storage.BlockManager(line:54) : BlockManager stopped
2018-09-17 18:26:43,169   INFO --- [Thread-1]  org.apache.spark.storage.BlockManagerMaster(line:54) : BlockManagerMaster stopped
2018-09-17 18:26:43,173   INFO --- [dispatcher-event-loop-3]  org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint(line:54) : OutputCommitCoordinator stopped!
2018-09-17 18:26:43,179   INFO --- [Thread-1]  org.apache.spark.SparkContext(line:54) : Successfully stopped SparkContext
2018-09-17 18:26:43,179   INFO --- [Thread-1]  org.apache.spark.util.ShutdownHookManager(line:54) : Shutdown hook called
2018-09-17 18:26:43,180   INFO --- [Thread-1]  org.apache.spark.util.ShutdownHookManager(line:54) : Deleting directory C:\Users\wshs\AppData\Local\Temp\spark-2467bc5f-b639-497f-8ed5-29d6b097764b
2018-09-18 09:34:18,498   INFO --- [main]  org.apache.spark.SparkContext(line:54) : Running Spark version 2.1.1
2018-09-18 09:34:19,070   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing view acls to: wshs
2018-09-18 09:34:19,071   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing modify acls to: wshs
2018-09-18 09:34:19,071   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing view acls groups to: 
2018-09-18 09:34:19,072   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing modify acls groups to: 
2018-09-18 09:34:19,072   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(wshs); groups with view permissions: Set(); users  with modify permissions: Set(wshs); groups with modify permissions: Set()
2018-09-18 09:34:19,696   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'sparkDriver' on port 52379.
2018-09-18 09:34:19,718   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering MapOutputTracker
2018-09-18 09:34:19,735   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering BlockManagerMaster
2018-09-18 09:34:19,737   INFO --- [main]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-09-18 09:34:19,738   INFO --- [main]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : BlockManagerMasterEndpoint up
2018-09-18 09:34:19,751   INFO --- [main]  org.apache.spark.storage.DiskBlockManager(line:54) : Created local directory at C:\Users\wshs\AppData\Local\Temp\blockmgr-90fb789b-48f4-4f18-96d8-eb2583f346ab
2018-09-18 09:34:19,812   INFO --- [main]  org.apache.spark.storage.memory.MemoryStore(line:54) : MemoryStore started with capacity 3.0 GB
2018-09-18 09:34:19,864   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering OutputCommitCoordinator
2018-09-18 09:34:20,011   INFO --- [main]  org.spark_project.jetty.util.log(line:186) : Logging initialized @3540ms
2018-09-18 09:34:20,123   INFO --- [main]  org.spark_project.jetty.server.Server(line:327) : jetty-9.2.z-SNAPSHOT
2018-09-18 09:34:20,139   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@2c88b9fc{/jobs,null,AVAILABLE,@Spark}
2018-09-18 09:34:20,139   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@64dafeed{/jobs/json,null,AVAILABLE,@Spark}
2018-09-18 09:34:20,139   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@388ba540{/jobs/job,null,AVAILABLE,@Spark}
2018-09-18 09:34:20,140   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@47605f2f{/jobs/job/json,null,AVAILABLE,@Spark}
2018-09-18 09:34:20,140   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@2ece4966{/stages,null,AVAILABLE,@Spark}
2018-09-18 09:34:20,140   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@1dd0e7c4{/stages/json,null,AVAILABLE,@Spark}
2018-09-18 09:34:20,140   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@7894f09b{/stages/stage,null,AVAILABLE,@Spark}
2018-09-18 09:34:20,140   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@3d484181{/stages/stage/json,null,AVAILABLE,@Spark}
2018-09-18 09:34:20,141   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@6111ba37{/stages/pool,null,AVAILABLE,@Spark}
2018-09-18 09:34:20,141   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@7be58f16{/stages/pool/json,null,AVAILABLE,@Spark}
2018-09-18 09:34:20,141   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@242aa8d9{/storage,null,AVAILABLE,@Spark}
2018-09-18 09:34:20,141   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@5b11a194{/storage/json,null,AVAILABLE,@Spark}
2018-09-18 09:34:20,142   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@37bd68c3{/storage/rdd,null,AVAILABLE,@Spark}
2018-09-18 09:34:20,142   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@60f7cc1d{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-09-18 09:34:20,142   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@11eadcba{/environment,null,AVAILABLE,@Spark}
2018-09-18 09:34:20,143   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@4721d212{/environment/json,null,AVAILABLE,@Spark}
2018-09-18 09:34:20,143   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@1b065145{/executors,null,AVAILABLE,@Spark}
2018-09-18 09:34:20,143   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@45cff11c{/executors/json,null,AVAILABLE,@Spark}
2018-09-18 09:34:20,143   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@207ea13{/executors/threadDump,null,AVAILABLE,@Spark}
2018-09-18 09:34:20,144   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@4bff1903{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-09-18 09:34:20,160   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@62dae540{/static,null,AVAILABLE,@Spark}
2018-09-18 09:34:20,160   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@5827af16{/,null,AVAILABLE,@Spark}
2018-09-18 09:34:20,161   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@654d8173{/api,null,AVAILABLE,@Spark}
2018-09-18 09:34:20,161   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@56c9bbd8{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-09-18 09:34:20,161   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@630cb4a4{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-09-18 09:34:20,173   INFO --- [main]  org.spark_project.jetty.server.ServerConnector(line:266) : Started Spark@275fe372{HTTP/1.1}{0.0.0.0:4040}
2018-09-18 09:34:20,174   INFO --- [main]  org.spark_project.jetty.server.Server(line:379) : Started @3705ms
2018-09-18 09:34:20,175   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'SparkUI' on port 4040.
2018-09-18 09:34:20,178   INFO --- [main]  org.apache.spark.ui.SparkUI(line:54) : Bound SparkUI to 0.0.0.0, and started at http://192.168.3.199:4040
2018-09-18 09:34:20,258   INFO --- [main]  org.apache.spark.executor.Executor(line:54) : Starting executor ID driver on host localhost
2018-09-18 09:34:20,317   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 52422.
2018-09-18 09:34:20,318   INFO --- [main]  org.apache.spark.network.netty.NettyBlockTransferService(line:54) : Server created on 192.168.3.199:52422
2018-09-18 09:34:20,321   INFO --- [main]  org.apache.spark.storage.BlockManager(line:54) : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-09-18 09:34:20,323   INFO --- [main]  org.apache.spark.storage.BlockManagerMaster(line:54) : Registering BlockManager BlockManagerId(driver, 192.168.3.199, 52422, None)
2018-09-18 09:34:20,327   INFO --- [dispatcher-event-loop-2]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : Registering block manager 192.168.3.199:52422 with 3.0 GB RAM, BlockManagerId(driver, 192.168.3.199, 52422, None)
2018-09-18 09:34:20,330   INFO --- [main]  org.apache.spark.storage.BlockManagerMaster(line:54) : Registered BlockManager BlockManagerId(driver, 192.168.3.199, 52422, None)
2018-09-18 09:34:20,331   INFO --- [main]  org.apache.spark.storage.BlockManager(line:54) : Initialized BlockManager: BlockManagerId(driver, 192.168.3.199, 52422, None)
2018-09-18 09:34:20,557   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@36ac8a63{/metrics/json,null,AVAILABLE,@Spark}
2018-09-18 09:34:20,589   INFO --- [main]  org.apache.spark.sql.internal.SharedState(line:54) : Warehouse path is 'file:/C:/Users/wshs/IdeaProjects/logdataSession/spark-warehouse'.
2018-09-18 09:34:20,595   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@3abd581e{/SQL,null,AVAILABLE,@Spark}
2018-09-18 09:34:20,596   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@610db97e{/SQL/json,null,AVAILABLE,@Spark}
2018-09-18 09:34:20,596   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@4ced35ed{/SQL/execution,null,AVAILABLE,@Spark}
2018-09-18 09:34:20,597   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@7bd69e82{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-09-18 09:34:20,599   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@3aaf4f07{/static/sql,null,AVAILABLE,@Spark}
2018-09-18 09:34:20,626   INFO --- [Thread-1]  org.apache.spark.SparkContext(line:54) : Invoking stop() from shutdown hook
2018-09-18 09:34:20,631   INFO --- [Thread-1]  org.spark_project.jetty.server.ServerConnector(line:306) : Stopped Spark@275fe372{HTTP/1.1}{0.0.0.0:4040}
2018-09-18 09:34:20,633   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@630cb4a4{/stages/stage/kill,null,UNAVAILABLE,@Spark}
2018-09-18 09:34:20,634   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@56c9bbd8{/jobs/job/kill,null,UNAVAILABLE,@Spark}
2018-09-18 09:34:20,634   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@654d8173{/api,null,UNAVAILABLE,@Spark}
2018-09-18 09:34:20,634   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@5827af16{/,null,UNAVAILABLE,@Spark}
2018-09-18 09:34:20,635   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@62dae540{/static,null,UNAVAILABLE,@Spark}
2018-09-18 09:34:20,635   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@4bff1903{/executors/threadDump/json,null,UNAVAILABLE,@Spark}
2018-09-18 09:34:20,635   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@207ea13{/executors/threadDump,null,UNAVAILABLE,@Spark}
2018-09-18 09:34:20,635   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@45cff11c{/executors/json,null,UNAVAILABLE,@Spark}
2018-09-18 09:34:20,636   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@1b065145{/executors,null,UNAVAILABLE,@Spark}
2018-09-18 09:34:20,636   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@4721d212{/environment/json,null,UNAVAILABLE,@Spark}
2018-09-18 09:34:20,636   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@11eadcba{/environment,null,UNAVAILABLE,@Spark}
2018-09-18 09:34:20,636   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@60f7cc1d{/storage/rdd/json,null,UNAVAILABLE,@Spark}
2018-09-18 09:34:20,636   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@37bd68c3{/storage/rdd,null,UNAVAILABLE,@Spark}
2018-09-18 09:34:20,636   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@5b11a194{/storage/json,null,UNAVAILABLE,@Spark}
2018-09-18 09:34:20,637   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@242aa8d9{/storage,null,UNAVAILABLE,@Spark}
2018-09-18 09:34:20,637   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@7be58f16{/stages/pool/json,null,UNAVAILABLE,@Spark}
2018-09-18 09:34:20,637   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@6111ba37{/stages/pool,null,UNAVAILABLE,@Spark}
2018-09-18 09:34:20,637   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@3d484181{/stages/stage/json,null,UNAVAILABLE,@Spark}
2018-09-18 09:34:20,638   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@7894f09b{/stages/stage,null,UNAVAILABLE,@Spark}
2018-09-18 09:34:20,638   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@1dd0e7c4{/stages/json,null,UNAVAILABLE,@Spark}
2018-09-18 09:34:20,638   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@2ece4966{/stages,null,UNAVAILABLE,@Spark}
2018-09-18 09:34:20,639   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@47605f2f{/jobs/job/json,null,UNAVAILABLE,@Spark}
2018-09-18 09:34:20,639   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@388ba540{/jobs/job,null,UNAVAILABLE,@Spark}
2018-09-18 09:34:20,639   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@64dafeed{/jobs/json,null,UNAVAILABLE,@Spark}
2018-09-18 09:34:20,639   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@2c88b9fc{/jobs,null,UNAVAILABLE,@Spark}
2018-09-18 09:34:20,641   INFO --- [Thread-1]  org.apache.spark.ui.SparkUI(line:54) : Stopped Spark web UI at http://192.168.3.199:4040
2018-09-18 09:34:20,654   INFO --- [dispatcher-event-loop-6]  org.apache.spark.MapOutputTrackerMasterEndpoint(line:54) : MapOutputTrackerMasterEndpoint stopped!
2018-09-18 09:34:20,673   INFO --- [Thread-1]  org.apache.spark.storage.memory.MemoryStore(line:54) : MemoryStore cleared
2018-09-18 09:34:20,673   INFO --- [Thread-1]  org.apache.spark.storage.BlockManager(line:54) : BlockManager stopped
2018-09-18 09:34:20,679   INFO --- [Thread-1]  org.apache.spark.storage.BlockManagerMaster(line:54) : BlockManagerMaster stopped
2018-09-18 09:34:20,683   INFO --- [dispatcher-event-loop-3]  org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint(line:54) : OutputCommitCoordinator stopped!
2018-09-18 09:34:20,687   INFO --- [Thread-1]  org.apache.spark.SparkContext(line:54) : Successfully stopped SparkContext
2018-09-18 09:34:20,688   INFO --- [Thread-1]  org.apache.spark.util.ShutdownHookManager(line:54) : Shutdown hook called
2018-09-18 09:34:20,689   INFO --- [Thread-1]  org.apache.spark.util.ShutdownHookManager(line:54) : Deleting directory C:\Users\wshs\AppData\Local\Temp\spark-74b3a62e-7c81-4af4-8b7b-4aa3c5e5c2dc
2018-09-18 09:34:42,412   INFO --- [main]  org.apache.spark.SparkContext(line:54) : Running Spark version 2.1.1
2018-09-18 09:34:42,772   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing view acls to: wshs
2018-09-18 09:34:42,776   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing modify acls to: wshs
2018-09-18 09:34:42,777   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing view acls groups to: 
2018-09-18 09:34:42,778   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing modify acls groups to: 
2018-09-18 09:34:42,778   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(wshs); groups with view permissions: Set(); users  with modify permissions: Set(wshs); groups with modify permissions: Set()
2018-09-18 09:34:43,244   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'sparkDriver' on port 52478.
2018-09-18 09:34:43,263   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering MapOutputTracker
2018-09-18 09:34:43,282   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering BlockManagerMaster
2018-09-18 09:34:43,285   INFO --- [main]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-09-18 09:34:43,285   INFO --- [main]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : BlockManagerMasterEndpoint up
2018-09-18 09:34:43,305   INFO --- [main]  org.apache.spark.storage.DiskBlockManager(line:54) : Created local directory at C:\Users\wshs\AppData\Local\Temp\blockmgr-803d04f4-7672-45b0-97f4-e24754ecec26
2018-09-18 09:34:43,322   INFO --- [main]  org.apache.spark.storage.memory.MemoryStore(line:54) : MemoryStore started with capacity 3.0 GB
2018-09-18 09:34:43,390   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering OutputCommitCoordinator
2018-09-18 09:34:43,476   INFO --- [main]  org.spark_project.jetty.util.log(line:186) : Logging initialized @2111ms
2018-09-18 09:34:43,559   INFO --- [main]  org.spark_project.jetty.server.Server(line:327) : jetty-9.2.z-SNAPSHOT
2018-09-18 09:34:43,573   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@784b990c{/jobs,null,AVAILABLE,@Spark}
2018-09-18 09:34:43,573   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@3d3ba765{/jobs/json,null,AVAILABLE,@Spark}
2018-09-18 09:34:43,573   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@25bc0606{/jobs/job,null,AVAILABLE,@Spark}
2018-09-18 09:34:43,574   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@5d1659ea{/jobs/job/json,null,AVAILABLE,@Spark}
2018-09-18 09:34:43,574   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@793138bd{/stages,null,AVAILABLE,@Spark}
2018-09-18 09:34:43,574   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@1951b871{/stages/json,null,AVAILABLE,@Spark}
2018-09-18 09:34:43,574   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@5c18016b{/stages/stage,null,AVAILABLE,@Spark}
2018-09-18 09:34:43,575   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@33aeca0b{/stages/stage/json,null,AVAILABLE,@Spark}
2018-09-18 09:34:43,575   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@43aaf813{/stages/pool,null,AVAILABLE,@Spark}
2018-09-18 09:34:43,575   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@57ac5227{/stages/pool/json,null,AVAILABLE,@Spark}
2018-09-18 09:34:43,575   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@4ba302e0{/storage,null,AVAILABLE,@Spark}
2018-09-18 09:34:43,576   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@e98770d{/storage/json,null,AVAILABLE,@Spark}
2018-09-18 09:34:43,576   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@1ae67cad{/storage/rdd,null,AVAILABLE,@Spark}
2018-09-18 09:34:43,576   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@2f6e28bc{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-09-18 09:34:43,576   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@7c098bb3{/environment,null,AVAILABLE,@Spark}
2018-09-18 09:34:43,577   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@31e4bb20{/environment/json,null,AVAILABLE,@Spark}
2018-09-18 09:34:43,577   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@18cebaa5{/executors,null,AVAILABLE,@Spark}
2018-09-18 09:34:43,577   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@463b4ac8{/executors/json,null,AVAILABLE,@Spark}
2018-09-18 09:34:43,578   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@765f05af{/executors/threadDump,null,AVAILABLE,@Spark}
2018-09-18 09:34:43,578   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@62f68dff{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-09-18 09:34:43,583   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@f001896{/static,null,AVAILABLE,@Spark}
2018-09-18 09:34:43,583   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@13f17eb4{/,null,AVAILABLE,@Spark}
2018-09-18 09:34:43,584   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@1d0d6318{/api,null,AVAILABLE,@Spark}
2018-09-18 09:34:43,584   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@4bc28c33{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-09-18 09:34:43,584   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@4409e975{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-09-18 09:34:43,596   INFO --- [main]  org.spark_project.jetty.server.ServerConnector(line:266) : Started Spark@6035b93b{HTTP/1.1}{0.0.0.0:4040}
2018-09-18 09:34:43,597   INFO --- [main]  org.spark_project.jetty.server.Server(line:379) : Started @2232ms
2018-09-18 09:34:43,597   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'SparkUI' on port 4040.
2018-09-18 09:34:43,601   INFO --- [main]  org.apache.spark.ui.SparkUI(line:54) : Bound SparkUI to 0.0.0.0, and started at http://192.168.3.199:4040
2018-09-18 09:34:43,673   INFO --- [main]  org.apache.spark.executor.Executor(line:54) : Starting executor ID driver on host localhost
2018-09-18 09:34:43,726   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 52519.
2018-09-18 09:34:43,727   INFO --- [main]  org.apache.spark.network.netty.NettyBlockTransferService(line:54) : Server created on 192.168.3.199:52519
2018-09-18 09:34:43,729   INFO --- [main]  org.apache.spark.storage.BlockManager(line:54) : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-09-18 09:34:43,731   INFO --- [main]  org.apache.spark.storage.BlockManagerMaster(line:54) : Registering BlockManager BlockManagerId(driver, 192.168.3.199, 52519, None)
2018-09-18 09:34:43,734   INFO --- [dispatcher-event-loop-2]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : Registering block manager 192.168.3.199:52519 with 3.0 GB RAM, BlockManagerId(driver, 192.168.3.199, 52519, None)
2018-09-18 09:34:43,737   INFO --- [main]  org.apache.spark.storage.BlockManagerMaster(line:54) : Registered BlockManager BlockManagerId(driver, 192.168.3.199, 52519, None)
2018-09-18 09:34:43,738   INFO --- [main]  org.apache.spark.storage.BlockManager(line:54) : Initialized BlockManager: BlockManagerId(driver, 192.168.3.199, 52519, None)
2018-09-18 09:34:43,919   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@3deb2326{/metrics/json,null,AVAILABLE,@Spark}
2018-09-18 09:34:43,977   INFO --- [main]  org.apache.spark.sql.internal.SharedState(line:54) : Warehouse path is 'file:/C:/Users/wshs/IdeaProjects/logdataSession/spark-warehouse'.
2018-09-18 09:34:43,984   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@63fd4873{/SQL,null,AVAILABLE,@Spark}
2018-09-18 09:34:43,984   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@7544a1e4{/SQL/json,null,AVAILABLE,@Spark}
2018-09-18 09:34:43,985   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@4fdfa676{/SQL/execution,null,AVAILABLE,@Spark}
2018-09-18 09:34:43,986   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@5be82d43{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-09-18 09:34:43,988   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@1734f68{/static/sql,null,AVAILABLE,@Spark}
2018-09-18 09:34:46,060   INFO --- [main]  org.apache.spark.sql.execution.datasources.FileSourceStrategy(line:54) : Pruning directories with: 
2018-09-18 09:34:46,062   INFO --- [main]  org.apache.spark.sql.execution.datasources.FileSourceStrategy(line:54) : Post-Scan Filters: 
2018-09-18 09:34:46,066   INFO --- [main]  org.apache.spark.sql.execution.datasources.FileSourceStrategy(line:54) : Output Data Schema: struct<value: string>
2018-09-18 09:34:46,067   INFO --- [main]  org.apache.spark.sql.execution.datasources.FileSourceStrategy(line:54) : Pushed Filters: 
2018-09-18 09:34:46,652   INFO --- [main]  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator(line:54) : Code generated in 251.879584 ms
2018-09-18 09:34:46,849   INFO --- [main]  org.apache.spark.storage.memory.MemoryStore(line:54) : Block broadcast_0 stored as values in memory (estimated size 131.1 KB, free 3.0 GB)
2018-09-18 09:34:47,034   INFO --- [main]  org.apache.spark.storage.memory.MemoryStore(line:54) : Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.6 KB, free 3.0 GB)
2018-09-18 09:34:47,038   INFO --- [dispatcher-event-loop-4]  org.apache.spark.storage.BlockManagerInfo(line:54) : Added broadcast_0_piece0 in memory on 192.168.3.199:52519 (size: 14.6 KB, free: 3.0 GB)
2018-09-18 09:34:47,041   INFO --- [main]  org.apache.spark.SparkContext(line:54) : Created broadcast 0 from show at logSession.scala:15
2018-09-18 09:34:47,048   INFO --- [main]  org.apache.spark.sql.execution.FileSourceScanExec(line:54) : Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2018-09-18 09:34:47,138   INFO --- [main]  org.apache.spark.SparkContext(line:54) : Starting job: show at logSession.scala:15
2018-09-18 09:34:47,174   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Got job 0 (show at logSession.scala:15) with 1 output partitions
2018-09-18 09:34:47,175   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Final stage: ResultStage 0 (show at logSession.scala:15)
2018-09-18 09:34:47,175   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Parents of final stage: List()
2018-09-18 09:34:47,176   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Missing parents: List()
2018-09-18 09:34:47,181   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Submitting ResultStage 0 (MapPartitionsRDD[2] at show at logSession.scala:15), which has no missing parents
2018-09-18 09:34:47,223   INFO --- [dag-scheduler-event-loop]  org.apache.spark.storage.memory.MemoryStore(line:54) : Block broadcast_1 stored as values in memory (estimated size 6.7 KB, free 3.0 GB)
2018-09-18 09:34:47,227   INFO --- [dag-scheduler-event-loop]  org.apache.spark.storage.memory.MemoryStore(line:54) : Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.6 KB, free 3.0 GB)
2018-09-18 09:34:47,228   INFO --- [dispatcher-event-loop-5]  org.apache.spark.storage.BlockManagerInfo(line:54) : Added broadcast_1_piece0 in memory on 192.168.3.199:52519 (size: 3.6 KB, free: 3.0 GB)
2018-09-18 09:34:47,229   INFO --- [dag-scheduler-event-loop]  org.apache.spark.SparkContext(line:54) : Created broadcast 1 from broadcast at DAGScheduler.scala:996
2018-09-18 09:34:47,232   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at show at logSession.scala:15)
2018-09-18 09:34:47,233   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.TaskSchedulerImpl(line:54) : Adding task set 0.0 with 1 tasks
2018-09-18 09:34:47,277   INFO --- [dispatcher-event-loop-6]  org.apache.spark.scheduler.TaskSetManager(line:54) : Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 6417 bytes)
2018-09-18 09:34:47,288   INFO --- [Executor task launch worker for task 0]  org.apache.spark.executor.Executor(line:54) : Running task 0.0 in stage 0.0 (TID 0)
2018-09-18 09:34:47,336   INFO --- [Executor task launch worker for task 0]  org.apache.spark.sql.execution.datasources.FileScanRDD(line:54) : Reading File path: file:///e:/hello.txt, range: 0-183, partition values: [empty row]
2018-09-18 09:34:47,355   INFO --- [Executor task launch worker for task 0]  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator(line:54) : Code generated in 9.456061 ms
2018-09-18 09:34:47,439   INFO --- [Executor task launch worker for task 0]  org.apache.spark.executor.Executor(line:54) : Finished task 0.0 in stage 0.0 (TID 0). 1685 bytes result sent to driver
2018-09-18 09:34:47,540   INFO --- [task-result-getter-0]  org.apache.spark.scheduler.TaskSetManager(line:54) : Finished task 0.0 in stage 0.0 (TID 0) in 193 ms on localhost (executor driver) (1/1)
2018-09-18 09:34:47,545   INFO --- [task-result-getter-0]  org.apache.spark.scheduler.TaskSchedulerImpl(line:54) : Removed TaskSet 0.0, whose tasks have all completed, from pool 
2018-09-18 09:34:47,547   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : ResultStage 0 (show at logSession.scala:15) finished in 0.306 s
2018-09-18 09:34:47,553   INFO --- [main]  org.apache.spark.scheduler.DAGScheduler(line:54) : Job 0 finished: show at logSession.scala:15, took 0.413834 s
2018-09-18 09:34:47,577   INFO --- [main]  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator(line:54) : Code generated in 12.297296 ms
2018-09-18 09:34:47,593   INFO --- [main]  org.spark_project.jetty.server.ServerConnector(line:306) : Stopped Spark@6035b93b{HTTP/1.1}{0.0.0.0:4040}
2018-09-18 09:34:47,595   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@4409e975{/stages/stage/kill,null,UNAVAILABLE,@Spark}
2018-09-18 09:34:47,595   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@4bc28c33{/jobs/job/kill,null,UNAVAILABLE,@Spark}
2018-09-18 09:34:47,595   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@1d0d6318{/api,null,UNAVAILABLE,@Spark}
2018-09-18 09:34:47,595   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@13f17eb4{/,null,UNAVAILABLE,@Spark}
2018-09-18 09:34:47,596   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@f001896{/static,null,UNAVAILABLE,@Spark}
2018-09-18 09:34:47,596   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@62f68dff{/executors/threadDump/json,null,UNAVAILABLE,@Spark}
2018-09-18 09:34:47,596   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@765f05af{/executors/threadDump,null,UNAVAILABLE,@Spark}
2018-09-18 09:34:47,596   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@463b4ac8{/executors/json,null,UNAVAILABLE,@Spark}
2018-09-18 09:34:47,596   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@18cebaa5{/executors,null,UNAVAILABLE,@Spark}
2018-09-18 09:34:47,596   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@31e4bb20{/environment/json,null,UNAVAILABLE,@Spark}
2018-09-18 09:34:47,596   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@7c098bb3{/environment,null,UNAVAILABLE,@Spark}
2018-09-18 09:34:47,597   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@2f6e28bc{/storage/rdd/json,null,UNAVAILABLE,@Spark}
2018-09-18 09:34:47,597   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@1ae67cad{/storage/rdd,null,UNAVAILABLE,@Spark}
2018-09-18 09:34:47,597   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@e98770d{/storage/json,null,UNAVAILABLE,@Spark}
2018-09-18 09:34:47,597   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@4ba302e0{/storage,null,UNAVAILABLE,@Spark}
2018-09-18 09:34:47,597   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@57ac5227{/stages/pool/json,null,UNAVAILABLE,@Spark}
2018-09-18 09:34:47,597   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@43aaf813{/stages/pool,null,UNAVAILABLE,@Spark}
2018-09-18 09:34:47,598   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@33aeca0b{/stages/stage/json,null,UNAVAILABLE,@Spark}
2018-09-18 09:34:47,598   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@5c18016b{/stages/stage,null,UNAVAILABLE,@Spark}
2018-09-18 09:34:47,598   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@1951b871{/stages/json,null,UNAVAILABLE,@Spark}
2018-09-18 09:34:47,598   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@793138bd{/stages,null,UNAVAILABLE,@Spark}
2018-09-18 09:34:47,599   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@5d1659ea{/jobs/job/json,null,UNAVAILABLE,@Spark}
2018-09-18 09:34:47,599   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@25bc0606{/jobs/job,null,UNAVAILABLE,@Spark}
2018-09-18 09:34:47,599   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@3d3ba765{/jobs/json,null,UNAVAILABLE,@Spark}
2018-09-18 09:34:47,599   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@784b990c{/jobs,null,UNAVAILABLE,@Spark}
2018-09-18 09:34:47,600   INFO --- [main]  org.apache.spark.ui.SparkUI(line:54) : Stopped Spark web UI at http://192.168.3.199:4040
2018-09-18 09:34:47,608   INFO --- [dispatcher-event-loop-3]  org.apache.spark.MapOutputTrackerMasterEndpoint(line:54) : MapOutputTrackerMasterEndpoint stopped!
2018-09-18 09:34:47,629   INFO --- [main]  org.apache.spark.storage.memory.MemoryStore(line:54) : MemoryStore cleared
2018-09-18 09:34:47,630   INFO --- [main]  org.apache.spark.storage.BlockManager(line:54) : BlockManager stopped
2018-09-18 09:34:47,635   INFO --- [main]  org.apache.spark.storage.BlockManagerMaster(line:54) : BlockManagerMaster stopped
2018-09-18 09:34:47,637   INFO --- [dispatcher-event-loop-0]  org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint(line:54) : OutputCommitCoordinator stopped!
2018-09-18 09:34:47,642   INFO --- [main]  org.apache.spark.SparkContext(line:54) : Successfully stopped SparkContext
2018-09-18 09:34:47,644   INFO --- [Thread-1]  org.apache.spark.util.ShutdownHookManager(line:54) : Shutdown hook called
2018-09-18 09:34:47,646   INFO --- [Thread-1]  org.apache.spark.util.ShutdownHookManager(line:54) : Deleting directory C:\Users\wshs\AppData\Local\Temp\spark-27020688-d880-463c-9d65-3f41c8d0b6b9
2018-09-18 09:43:02,863   INFO --- [main]  org.apache.spark.SparkContext(line:54) : Running Spark version 2.1.1
2018-09-18 09:43:03,156   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing view acls to: wshs
2018-09-18 09:43:03,158   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing modify acls to: wshs
2018-09-18 09:43:03,159   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing view acls groups to: 
2018-09-18 09:43:03,159   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing modify acls groups to: 
2018-09-18 09:43:03,160   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(wshs); groups with view permissions: Set(); users  with modify permissions: Set(wshs); groups with modify permissions: Set()
2018-09-18 09:43:03,532   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'sparkDriver' on port 53093.
2018-09-18 09:43:03,548   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering MapOutputTracker
2018-09-18 09:43:03,564   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering BlockManagerMaster
2018-09-18 09:43:03,566   INFO --- [main]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-09-18 09:43:03,567   INFO --- [main]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : BlockManagerMasterEndpoint up
2018-09-18 09:43:03,578   INFO --- [main]  org.apache.spark.storage.DiskBlockManager(line:54) : Created local directory at C:\Users\wshs\AppData\Local\Temp\blockmgr-dbc56b30-7238-4625-8135-1b4645c7855b
2018-09-18 09:43:03,593   INFO --- [main]  org.apache.spark.storage.memory.MemoryStore(line:54) : MemoryStore started with capacity 3.0 GB
2018-09-18 09:43:03,650   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering OutputCommitCoordinator
2018-09-18 09:43:03,719   INFO --- [main]  org.spark_project.jetty.util.log(line:186) : Logging initialized @1733ms
2018-09-18 09:43:03,799   INFO --- [main]  org.spark_project.jetty.server.Server(line:327) : jetty-9.2.z-SNAPSHOT
2018-09-18 09:43:03,812   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@784b990c{/jobs,null,AVAILABLE,@Spark}
2018-09-18 09:43:03,812   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@3d3ba765{/jobs/json,null,AVAILABLE,@Spark}
2018-09-18 09:43:03,812   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@25bc0606{/jobs/job,null,AVAILABLE,@Spark}
2018-09-18 09:43:03,813   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@5d1659ea{/jobs/job/json,null,AVAILABLE,@Spark}
2018-09-18 09:43:03,813   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@793138bd{/stages,null,AVAILABLE,@Spark}
2018-09-18 09:43:03,813   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@1951b871{/stages/json,null,AVAILABLE,@Spark}
2018-09-18 09:43:03,813   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@5c18016b{/stages/stage,null,AVAILABLE,@Spark}
2018-09-18 09:43:03,814   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@33aeca0b{/stages/stage/json,null,AVAILABLE,@Spark}
2018-09-18 09:43:03,814   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@43aaf813{/stages/pool,null,AVAILABLE,@Spark}
2018-09-18 09:43:03,814   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@57ac5227{/stages/pool/json,null,AVAILABLE,@Spark}
2018-09-18 09:43:03,814   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@4ba302e0{/storage,null,AVAILABLE,@Spark}
2018-09-18 09:43:03,814   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@e98770d{/storage/json,null,AVAILABLE,@Spark}
2018-09-18 09:43:03,815   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@1ae67cad{/storage/rdd,null,AVAILABLE,@Spark}
2018-09-18 09:43:03,815   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@2f6e28bc{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-09-18 09:43:03,815   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@7c098bb3{/environment,null,AVAILABLE,@Spark}
2018-09-18 09:43:03,815   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@31e4bb20{/environment/json,null,AVAILABLE,@Spark}
2018-09-18 09:43:03,816   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@18cebaa5{/executors,null,AVAILABLE,@Spark}
2018-09-18 09:43:03,816   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@463b4ac8{/executors/json,null,AVAILABLE,@Spark}
2018-09-18 09:43:03,816   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@765f05af{/executors/threadDump,null,AVAILABLE,@Spark}
2018-09-18 09:43:03,816   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@62f68dff{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-09-18 09:43:03,821   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@f001896{/static,null,AVAILABLE,@Spark}
2018-09-18 09:43:03,821   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@13f17eb4{/,null,AVAILABLE,@Spark}
2018-09-18 09:43:03,822   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@1d0d6318{/api,null,AVAILABLE,@Spark}
2018-09-18 09:43:03,822   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@4bc28c33{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-09-18 09:43:03,822   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@4409e975{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-09-18 09:43:03,835   INFO --- [main]  org.spark_project.jetty.server.ServerConnector(line:266) : Started Spark@6035b93b{HTTP/1.1}{0.0.0.0:4040}
2018-09-18 09:43:03,836   INFO --- [main]  org.spark_project.jetty.server.Server(line:379) : Started @1850ms
2018-09-18 09:43:03,837   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'SparkUI' on port 4040.
2018-09-18 09:43:03,839   INFO --- [main]  org.apache.spark.ui.SparkUI(line:54) : Bound SparkUI to 0.0.0.0, and started at http://192.168.3.199:4040
2018-09-18 09:43:03,907   INFO --- [main]  org.apache.spark.executor.Executor(line:54) : Starting executor ID driver on host localhost
2018-09-18 09:43:03,954   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 53135.
2018-09-18 09:43:03,955   INFO --- [main]  org.apache.spark.network.netty.NettyBlockTransferService(line:54) : Server created on 192.168.3.199:53135
2018-09-18 09:43:03,956   INFO --- [main]  org.apache.spark.storage.BlockManager(line:54) : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-09-18 09:43:03,958   INFO --- [main]  org.apache.spark.storage.BlockManagerMaster(line:54) : Registering BlockManager BlockManagerId(driver, 192.168.3.199, 53135, None)
2018-09-18 09:43:03,960   INFO --- [dispatcher-event-loop-2]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : Registering block manager 192.168.3.199:53135 with 3.0 GB RAM, BlockManagerId(driver, 192.168.3.199, 53135, None)
2018-09-18 09:43:03,961   INFO --- [main]  org.apache.spark.storage.BlockManagerMaster(line:54) : Registered BlockManager BlockManagerId(driver, 192.168.3.199, 53135, None)
2018-09-18 09:43:03,962   INFO --- [main]  org.apache.spark.storage.BlockManager(line:54) : Initialized BlockManager: BlockManagerId(driver, 192.168.3.199, 53135, None)
2018-09-18 09:43:04,133   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@3deb2326{/metrics/json,null,AVAILABLE,@Spark}
2018-09-18 09:43:04,183   INFO --- [main]  org.apache.spark.sql.internal.SharedState(line:54) : Warehouse path is 'file:/C:/Users/wshs/IdeaProjects/logdataSession/spark-warehouse/'.
2018-09-18 09:43:04,188   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@63fd4873{/SQL,null,AVAILABLE,@Spark}
2018-09-18 09:43:04,189   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@7544a1e4{/SQL/json,null,AVAILABLE,@Spark}
2018-09-18 09:43:04,190   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@4fdfa676{/SQL/execution,null,AVAILABLE,@Spark}
2018-09-18 09:43:04,190   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@5be82d43{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-09-18 09:43:04,192   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@1734f68{/static/sql,null,AVAILABLE,@Spark}
2018-09-18 09:43:06,194   INFO --- [main]  org.apache.spark.sql.execution.datasources.FileSourceStrategy(line:54) : Pruning directories with: 
2018-09-18 09:43:06,196   INFO --- [main]  org.apache.spark.sql.execution.datasources.FileSourceStrategy(line:54) : Post-Scan Filters: 
2018-09-18 09:43:06,198   INFO --- [main]  org.apache.spark.sql.execution.datasources.FileSourceStrategy(line:54) : Output Data Schema: struct<value: string>
2018-09-18 09:43:06,199   INFO --- [main]  org.apache.spark.sql.execution.datasources.FileSourceStrategy(line:54) : Pushed Filters: 
2018-09-18 09:43:06,683   INFO --- [main]  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator(line:54) : Code generated in 204.501927 ms
2018-09-18 09:43:06,775   INFO --- [main]  org.apache.spark.storage.memory.MemoryStore(line:54) : Block broadcast_0 stored as values in memory (estimated size 131.1 KB, free 3.0 GB)
2018-09-18 09:43:06,902   INFO --- [main]  org.apache.spark.storage.memory.MemoryStore(line:54) : Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.6 KB, free 3.0 GB)
2018-09-18 09:43:06,907   INFO --- [dispatcher-event-loop-4]  org.apache.spark.storage.BlockManagerInfo(line:54) : Added broadcast_0_piece0 in memory on 192.168.3.199:53135 (size: 14.6 KB, free: 3.0 GB)
2018-09-18 09:43:06,910   INFO --- [main]  org.apache.spark.SparkContext(line:54) : Created broadcast 0 from show at logSession.scala:29
2018-09-18 09:43:06,919   INFO --- [main]  org.apache.spark.sql.execution.FileSourceScanExec(line:54) : Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2018-09-18 09:43:07,007   INFO --- [main]  org.apache.spark.SparkContext(line:54) : Starting job: show at logSession.scala:29
2018-09-18 09:43:07,021   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Got job 0 (show at logSession.scala:29) with 1 output partitions
2018-09-18 09:43:07,022   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Final stage: ResultStage 0 (show at logSession.scala:29)
2018-09-18 09:43:07,022   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Parents of final stage: List()
2018-09-18 09:43:07,023   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Missing parents: List()
2018-09-18 09:43:07,027   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Submitting ResultStage 0 (MapPartitionsRDD[2] at show at logSession.scala:29), which has no missing parents
2018-09-18 09:43:07,068   INFO --- [dag-scheduler-event-loop]  org.apache.spark.storage.memory.MemoryStore(line:54) : Block broadcast_1 stored as values in memory (estimated size 6.7 KB, free 3.0 GB)
2018-09-18 09:43:07,072   INFO --- [dag-scheduler-event-loop]  org.apache.spark.storage.memory.MemoryStore(line:54) : Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.6 KB, free 3.0 GB)
2018-09-18 09:43:07,073   INFO --- [dispatcher-event-loop-5]  org.apache.spark.storage.BlockManagerInfo(line:54) : Added broadcast_1_piece0 in memory on 192.168.3.199:53135 (size: 3.6 KB, free: 3.0 GB)
2018-09-18 09:43:07,073   INFO --- [dag-scheduler-event-loop]  org.apache.spark.SparkContext(line:54) : Created broadcast 1 from broadcast at DAGScheduler.scala:996
2018-09-18 09:43:07,076   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at show at logSession.scala:29)
2018-09-18 09:43:07,077   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.TaskSchedulerImpl(line:54) : Adding task set 0.0 with 1 tasks
2018-09-18 09:43:07,113   INFO --- [dispatcher-event-loop-6]  org.apache.spark.scheduler.TaskSetManager(line:54) : Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 6427 bytes)
2018-09-18 09:43:07,123   INFO --- [Executor task launch worker for task 0]  org.apache.spark.executor.Executor(line:54) : Running task 0.0 in stage 0.0 (TID 0)
2018-09-18 09:43:07,165   INFO --- [Executor task launch worker for task 0]  org.apache.spark.sql.execution.datasources.FileScanRDD(line:54) : Reading File path: file:///e:/r_actionopvidio.txt, range: 0-376727, partition values: [empty row]
2018-09-18 09:43:07,184   INFO --- [Executor task launch worker for task 0]  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator(line:54) : Code generated in 9.951234 ms
2018-09-18 09:43:07,216   INFO --- [Executor task launch worker for task 0]  org.apache.spark.executor.Executor(line:54) : Finished task 0.0 in stage 0.0 (TID 0). 1666 bytes result sent to driver
2018-09-18 09:43:07,309   INFO --- [task-result-getter-0]  org.apache.spark.scheduler.TaskSetManager(line:54) : Finished task 0.0 in stage 0.0 (TID 0) in 128 ms on localhost (executor driver) (1/1)
2018-09-18 09:43:07,315   INFO --- [task-result-getter-0]  org.apache.spark.scheduler.TaskSchedulerImpl(line:54) : Removed TaskSet 0.0, whose tasks have all completed, from pool 
2018-09-18 09:43:07,317   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : ResultStage 0 (show at logSession.scala:29) finished in 0.231 s
2018-09-18 09:43:07,322   INFO --- [main]  org.apache.spark.scheduler.DAGScheduler(line:54) : Job 0 finished: show at logSession.scala:29, took 0.313387 s
2018-09-18 09:43:07,344   INFO --- [main]  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator(line:54) : Code generated in 11.352622 ms
2018-09-18 09:43:07,475   INFO --- [main]  org.apache.spark.sql.execution.SparkSqlParser(line:54) : Parsing command: persons
2018-09-18 09:43:07,604   INFO --- [main]  org.spark_project.jetty.server.ServerConnector(line:306) : Stopped Spark@6035b93b{HTTP/1.1}{0.0.0.0:4040}
2018-09-18 09:43:07,606   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@4409e975{/stages/stage/kill,null,UNAVAILABLE,@Spark}
2018-09-18 09:43:07,606   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@4bc28c33{/jobs/job/kill,null,UNAVAILABLE,@Spark}
2018-09-18 09:43:07,606   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@1d0d6318{/api,null,UNAVAILABLE,@Spark}
2018-09-18 09:43:07,606   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@13f17eb4{/,null,UNAVAILABLE,@Spark}
2018-09-18 09:43:07,607   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@f001896{/static,null,UNAVAILABLE,@Spark}
2018-09-18 09:43:07,607   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@62f68dff{/executors/threadDump/json,null,UNAVAILABLE,@Spark}
2018-09-18 09:43:07,607   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@765f05af{/executors/threadDump,null,UNAVAILABLE,@Spark}
2018-09-18 09:43:07,607   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@463b4ac8{/executors/json,null,UNAVAILABLE,@Spark}
2018-09-18 09:43:07,607   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@18cebaa5{/executors,null,UNAVAILABLE,@Spark}
2018-09-18 09:43:07,608   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@31e4bb20{/environment/json,null,UNAVAILABLE,@Spark}
2018-09-18 09:43:07,608   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@7c098bb3{/environment,null,UNAVAILABLE,@Spark}
2018-09-18 09:43:07,608   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@2f6e28bc{/storage/rdd/json,null,UNAVAILABLE,@Spark}
2018-09-18 09:43:07,608   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@1ae67cad{/storage/rdd,null,UNAVAILABLE,@Spark}
2018-09-18 09:43:07,608   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@e98770d{/storage/json,null,UNAVAILABLE,@Spark}
2018-09-18 09:43:07,608   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@4ba302e0{/storage,null,UNAVAILABLE,@Spark}
2018-09-18 09:43:07,609   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@57ac5227{/stages/pool/json,null,UNAVAILABLE,@Spark}
2018-09-18 09:43:07,609   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@43aaf813{/stages/pool,null,UNAVAILABLE,@Spark}
2018-09-18 09:43:07,609   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@33aeca0b{/stages/stage/json,null,UNAVAILABLE,@Spark}
2018-09-18 09:43:07,609   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@5c18016b{/stages/stage,null,UNAVAILABLE,@Spark}
2018-09-18 09:43:07,609   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@1951b871{/stages/json,null,UNAVAILABLE,@Spark}
2018-09-18 09:43:07,609   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@793138bd{/stages,null,UNAVAILABLE,@Spark}
2018-09-18 09:43:07,610   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@5d1659ea{/jobs/job/json,null,UNAVAILABLE,@Spark}
2018-09-18 09:43:07,610   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@25bc0606{/jobs/job,null,UNAVAILABLE,@Spark}
2018-09-18 09:43:07,610   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@3d3ba765{/jobs/json,null,UNAVAILABLE,@Spark}
2018-09-18 09:43:07,610   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@784b990c{/jobs,null,UNAVAILABLE,@Spark}
2018-09-18 09:43:07,611   INFO --- [main]  org.apache.spark.ui.SparkUI(line:54) : Stopped Spark web UI at http://192.168.3.199:4040
2018-09-18 09:43:07,620   INFO --- [dispatcher-event-loop-3]  org.apache.spark.MapOutputTrackerMasterEndpoint(line:54) : MapOutputTrackerMasterEndpoint stopped!
2018-09-18 09:43:07,641   INFO --- [main]  org.apache.spark.storage.memory.MemoryStore(line:54) : MemoryStore cleared
2018-09-18 09:43:07,641   INFO --- [main]  org.apache.spark.storage.BlockManager(line:54) : BlockManager stopped
2018-09-18 09:43:07,646   INFO --- [main]  org.apache.spark.storage.BlockManagerMaster(line:54) : BlockManagerMaster stopped
2018-09-18 09:43:07,648   INFO --- [dispatcher-event-loop-0]  org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint(line:54) : OutputCommitCoordinator stopped!
2018-09-18 09:43:07,653   INFO --- [main]  org.apache.spark.SparkContext(line:54) : Successfully stopped SparkContext
2018-09-18 09:43:07,655   INFO --- [Thread-1]  org.apache.spark.util.ShutdownHookManager(line:54) : Shutdown hook called
2018-09-18 09:43:07,656   INFO --- [Thread-1]  org.apache.spark.util.ShutdownHookManager(line:54) : Deleting directory C:\Users\wshs\AppData\Local\Temp\spark-97eb02ae-e969-4105-be81-171b7918253b
2018-09-18 09:56:33,551   INFO --- [main]  org.apache.spark.SparkContext(line:54) : Running Spark version 2.1.1
2018-09-18 09:56:33,901   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing view acls to: wshs
2018-09-18 09:56:33,904   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing modify acls to: wshs
2018-09-18 09:56:33,905   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing view acls groups to: 
2018-09-18 09:56:33,905   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing modify acls groups to: 
2018-09-18 09:56:33,906   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(wshs); groups with view permissions: Set(); users  with modify permissions: Set(wshs); groups with modify permissions: Set()
2018-09-18 09:56:34,307   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'sparkDriver' on port 53926.
2018-09-18 09:56:34,326   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering MapOutputTracker
2018-09-18 09:56:34,345   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering BlockManagerMaster
2018-09-18 09:56:34,349   INFO --- [main]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-09-18 09:56:34,350   INFO --- [main]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : BlockManagerMasterEndpoint up
2018-09-18 09:56:34,365   INFO --- [main]  org.apache.spark.storage.DiskBlockManager(line:54) : Created local directory at C:\Users\wshs\AppData\Local\Temp\blockmgr-bf1ba6df-db1d-46eb-abdc-f626a18d48a1
2018-09-18 09:56:34,384   INFO --- [main]  org.apache.spark.storage.memory.MemoryStore(line:54) : MemoryStore started with capacity 3.0 GB
2018-09-18 09:56:34,444   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering OutputCommitCoordinator
2018-09-18 09:56:34,516   INFO --- [main]  org.spark_project.jetty.util.log(line:186) : Logging initialized @1964ms
2018-09-18 09:56:34,591   INFO --- [main]  org.spark_project.jetty.server.Server(line:327) : jetty-9.2.z-SNAPSHOT
2018-09-18 09:56:34,603   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@784b990c{/jobs,null,AVAILABLE,@Spark}
2018-09-18 09:56:34,603   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@3d3ba765{/jobs/json,null,AVAILABLE,@Spark}
2018-09-18 09:56:34,604   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@25bc0606{/jobs/job,null,AVAILABLE,@Spark}
2018-09-18 09:56:34,604   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@5d1659ea{/jobs/job/json,null,AVAILABLE,@Spark}
2018-09-18 09:56:34,604   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@793138bd{/stages,null,AVAILABLE,@Spark}
2018-09-18 09:56:34,604   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@1951b871{/stages/json,null,AVAILABLE,@Spark}
2018-09-18 09:56:34,605   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@5c18016b{/stages/stage,null,AVAILABLE,@Spark}
2018-09-18 09:56:34,605   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@33aeca0b{/stages/stage/json,null,AVAILABLE,@Spark}
2018-09-18 09:56:34,605   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@43aaf813{/stages/pool,null,AVAILABLE,@Spark}
2018-09-18 09:56:34,605   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@57ac5227{/stages/pool/json,null,AVAILABLE,@Spark}
2018-09-18 09:56:34,605   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@4ba302e0{/storage,null,AVAILABLE,@Spark}
2018-09-18 09:56:34,606   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@e98770d{/storage/json,null,AVAILABLE,@Spark}
2018-09-18 09:56:34,606   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@1ae67cad{/storage/rdd,null,AVAILABLE,@Spark}
2018-09-18 09:56:34,606   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@2f6e28bc{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-09-18 09:56:34,606   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@7c098bb3{/environment,null,AVAILABLE,@Spark}
2018-09-18 09:56:34,607   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@31e4bb20{/environment/json,null,AVAILABLE,@Spark}
2018-09-18 09:56:34,607   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@18cebaa5{/executors,null,AVAILABLE,@Spark}
2018-09-18 09:56:34,607   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@463b4ac8{/executors/json,null,AVAILABLE,@Spark}
2018-09-18 09:56:34,607   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@765f05af{/executors/threadDump,null,AVAILABLE,@Spark}
2018-09-18 09:56:34,608   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@62f68dff{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-09-18 09:56:34,612   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@f001896{/static,null,AVAILABLE,@Spark}
2018-09-18 09:56:34,613   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@13f17eb4{/,null,AVAILABLE,@Spark}
2018-09-18 09:56:34,614   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@1d0d6318{/api,null,AVAILABLE,@Spark}
2018-09-18 09:56:34,614   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@4bc28c33{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-09-18 09:56:34,614   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@4409e975{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-09-18 09:56:34,625   INFO --- [main]  org.spark_project.jetty.server.ServerConnector(line:266) : Started Spark@6035b93b{HTTP/1.1}{0.0.0.0:4040}
2018-09-18 09:56:34,626   INFO --- [main]  org.spark_project.jetty.server.Server(line:379) : Started @2076ms
2018-09-18 09:56:34,626   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'SparkUI' on port 4040.
2018-09-18 09:56:34,629   INFO --- [main]  org.apache.spark.ui.SparkUI(line:54) : Bound SparkUI to 0.0.0.0, and started at http://192.168.3.199:4040
2018-09-18 09:56:34,707   INFO --- [main]  org.apache.spark.executor.Executor(line:54) : Starting executor ID driver on host localhost
2018-09-18 09:56:34,755   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 53968.
2018-09-18 09:56:34,756   INFO --- [main]  org.apache.spark.network.netty.NettyBlockTransferService(line:54) : Server created on 192.168.3.199:53968
2018-09-18 09:56:34,758   INFO --- [main]  org.apache.spark.storage.BlockManager(line:54) : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-09-18 09:56:34,759   INFO --- [main]  org.apache.spark.storage.BlockManagerMaster(line:54) : Registering BlockManager BlockManagerId(driver, 192.168.3.199, 53968, None)
2018-09-18 09:56:34,762   INFO --- [dispatcher-event-loop-2]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : Registering block manager 192.168.3.199:53968 with 3.0 GB RAM, BlockManagerId(driver, 192.168.3.199, 53968, None)
2018-09-18 09:56:34,764   INFO --- [main]  org.apache.spark.storage.BlockManagerMaster(line:54) : Registered BlockManager BlockManagerId(driver, 192.168.3.199, 53968, None)
2018-09-18 09:56:34,765   INFO --- [main]  org.apache.spark.storage.BlockManager(line:54) : Initialized BlockManager: BlockManagerId(driver, 192.168.3.199, 53968, None)
2018-09-18 09:56:34,910   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@3deb2326{/metrics/json,null,AVAILABLE,@Spark}
2018-09-18 09:56:34,967   INFO --- [main]  org.apache.spark.sql.internal.SharedState(line:54) : Warehouse path is 'file:/C:/Users/wshs/IdeaProjects/logdataSession/spark-warehouse/'.
2018-09-18 09:56:34,972   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@63fd4873{/SQL,null,AVAILABLE,@Spark}
2018-09-18 09:56:34,972   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@7544a1e4{/SQL/json,null,AVAILABLE,@Spark}
2018-09-18 09:56:34,973   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@4fdfa676{/SQL/execution,null,AVAILABLE,@Spark}
2018-09-18 09:56:34,974   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@5be82d43{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-09-18 09:56:34,976   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@1734f68{/static/sql,null,AVAILABLE,@Spark}
2018-09-18 09:56:36,739   INFO --- [main]  org.apache.spark.sql.execution.SparkSqlParser(line:54) : Parsing command: actionopvidio
2018-09-18 09:56:37,152   INFO --- [main]  org.apache.spark.sql.execution.SparkSqlParser(line:54) : Parsing command: SELECT * FROM actionopvidio
2018-09-18 09:56:37,213   INFO --- [main]  org.apache.spark.sql.execution.datasources.FileSourceStrategy(line:54) : Pruning directories with: 
2018-09-18 09:56:37,216   INFO --- [main]  org.apache.spark.sql.execution.datasources.FileSourceStrategy(line:54) : Post-Scan Filters: 
2018-09-18 09:56:37,219   INFO --- [main]  org.apache.spark.sql.execution.datasources.FileSourceStrategy(line:54) : Output Data Schema: struct<value: string>
2018-09-18 09:56:37,221   INFO --- [main]  org.apache.spark.sql.execution.datasources.FileSourceStrategy(line:54) : Pushed Filters: 
2018-09-18 09:56:37,511   INFO --- [main]  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator(line:54) : Code generated in 193.24185 ms
2018-09-18 09:56:37,592   INFO --- [main]  org.apache.spark.storage.memory.MemoryStore(line:54) : Block broadcast_0 stored as values in memory (estimated size 131.1 KB, free 3.0 GB)
2018-09-18 09:56:38,155   INFO --- [main]  org.apache.spark.storage.memory.MemoryStore(line:54) : Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.6 KB, free 3.0 GB)
2018-09-18 09:56:38,158   INFO --- [dispatcher-event-loop-4]  org.apache.spark.storage.BlockManagerInfo(line:54) : Added broadcast_0_piece0 in memory on 192.168.3.199:53968 (size: 14.6 KB, free: 3.0 GB)
2018-09-18 09:56:38,161   INFO --- [main]  org.apache.spark.SparkContext(line:54) : Created broadcast 0 from show at logSession.scala:48
2018-09-18 09:56:38,168   INFO --- [main]  org.apache.spark.sql.execution.FileSourceScanExec(line:54) : Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2018-09-18 09:56:38,335   INFO --- [main]  org.apache.spark.SparkContext(line:54) : Starting job: show at logSession.scala:48
2018-09-18 09:56:38,350   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Got job 0 (show at logSession.scala:48) with 1 output partitions
2018-09-18 09:56:38,350   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Final stage: ResultStage 0 (show at logSession.scala:48)
2018-09-18 09:56:38,351   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Parents of final stage: List()
2018-09-18 09:56:38,352   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Missing parents: List()
2018-09-18 09:56:38,356   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Submitting ResultStage 0 (MapPartitionsRDD[3] at show at logSession.scala:48), which has no missing parents
2018-09-18 09:56:38,403   INFO --- [dag-scheduler-event-loop]  org.apache.spark.storage.memory.MemoryStore(line:54) : Block broadcast_1 stored as values in memory (estimated size 6.7 KB, free 3.0 GB)
2018-09-18 09:56:38,407   INFO --- [dag-scheduler-event-loop]  org.apache.spark.storage.memory.MemoryStore(line:54) : Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.6 KB, free 3.0 GB)
2018-09-18 09:56:38,408   INFO --- [dispatcher-event-loop-5]  org.apache.spark.storage.BlockManagerInfo(line:54) : Added broadcast_1_piece0 in memory on 192.168.3.199:53968 (size: 3.6 KB, free: 3.0 GB)
2018-09-18 09:56:38,409   INFO --- [dag-scheduler-event-loop]  org.apache.spark.SparkContext(line:54) : Created broadcast 1 from broadcast at DAGScheduler.scala:996
2018-09-18 09:56:38,412   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at show at logSession.scala:48)
2018-09-18 09:56:38,413   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.TaskSchedulerImpl(line:54) : Adding task set 0.0 with 1 tasks
2018-09-18 09:56:38,448   INFO --- [dispatcher-event-loop-6]  org.apache.spark.scheduler.TaskSetManager(line:54) : Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 6427 bytes)
2018-09-18 09:56:38,456   INFO --- [Executor task launch worker for task 0]  org.apache.spark.executor.Executor(line:54) : Running task 0.0 in stage 0.0 (TID 0)
2018-09-18 09:56:38,498   INFO --- [Executor task launch worker for task 0]  org.apache.spark.sql.execution.datasources.FileScanRDD(line:54) : Reading File path: file:///e:/r_actionopvidio.txt, range: 0-376727, partition values: [empty row]
2018-09-18 09:56:38,516   INFO --- [Executor task launch worker for task 0]  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator(line:54) : Code generated in 10.204229 ms
2018-09-18 09:56:38,546   INFO --- [Executor task launch worker for task 0]  org.apache.spark.executor.Executor(line:54) : Finished task 0.0 in stage 0.0 (TID 0). 1666 bytes result sent to driver
2018-09-18 09:56:38,552   INFO --- [task-result-getter-0]  org.apache.spark.scheduler.TaskSetManager(line:54) : Finished task 0.0 in stage 0.0 (TID 0) in 121 ms on localhost (executor driver) (1/1)
2018-09-18 09:56:38,553   INFO --- [task-result-getter-0]  org.apache.spark.scheduler.TaskSchedulerImpl(line:54) : Removed TaskSet 0.0, whose tasks have all completed, from pool 
2018-09-18 09:56:38,555   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : ResultStage 0 (show at logSession.scala:48) finished in 0.135 s
2018-09-18 09:56:38,561   INFO --- [main]  org.apache.spark.scheduler.DAGScheduler(line:54) : Job 0 finished: show at logSession.scala:48, took 0.225611 s
2018-09-18 09:56:38,586   INFO --- [main]  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator(line:54) : Code generated in 13.541839 ms
2018-09-18 09:56:38,603   INFO --- [main]  org.spark_project.jetty.server.ServerConnector(line:306) : Stopped Spark@6035b93b{HTTP/1.1}{0.0.0.0:4040}
2018-09-18 09:56:38,605   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@4409e975{/stages/stage/kill,null,UNAVAILABLE,@Spark}
2018-09-18 09:56:38,605   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@4bc28c33{/jobs/job/kill,null,UNAVAILABLE,@Spark}
2018-09-18 09:56:38,605   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@1d0d6318{/api,null,UNAVAILABLE,@Spark}
2018-09-18 09:56:38,606   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@13f17eb4{/,null,UNAVAILABLE,@Spark}
2018-09-18 09:56:38,606   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@f001896{/static,null,UNAVAILABLE,@Spark}
2018-09-18 09:56:38,606   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@62f68dff{/executors/threadDump/json,null,UNAVAILABLE,@Spark}
2018-09-18 09:56:38,606   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@765f05af{/executors/threadDump,null,UNAVAILABLE,@Spark}
2018-09-18 09:56:38,606   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@463b4ac8{/executors/json,null,UNAVAILABLE,@Spark}
2018-09-18 09:56:38,606   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@18cebaa5{/executors,null,UNAVAILABLE,@Spark}
2018-09-18 09:56:38,607   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@31e4bb20{/environment/json,null,UNAVAILABLE,@Spark}
2018-09-18 09:56:38,607   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@7c098bb3{/environment,null,UNAVAILABLE,@Spark}
2018-09-18 09:56:38,607   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@2f6e28bc{/storage/rdd/json,null,UNAVAILABLE,@Spark}
2018-09-18 09:56:38,607   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@1ae67cad{/storage/rdd,null,UNAVAILABLE,@Spark}
2018-09-18 09:56:38,607   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@e98770d{/storage/json,null,UNAVAILABLE,@Spark}
2018-09-18 09:56:38,607   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@4ba302e0{/storage,null,UNAVAILABLE,@Spark}
2018-09-18 09:56:38,608   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@57ac5227{/stages/pool/json,null,UNAVAILABLE,@Spark}
2018-09-18 09:56:38,608   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@43aaf813{/stages/pool,null,UNAVAILABLE,@Spark}
2018-09-18 09:56:38,608   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@33aeca0b{/stages/stage/json,null,UNAVAILABLE,@Spark}
2018-09-18 09:56:38,608   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@5c18016b{/stages/stage,null,UNAVAILABLE,@Spark}
2018-09-18 09:56:38,608   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@1951b871{/stages/json,null,UNAVAILABLE,@Spark}
2018-09-18 09:56:38,608   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@793138bd{/stages,null,UNAVAILABLE,@Spark}
2018-09-18 09:56:38,609   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@5d1659ea{/jobs/job/json,null,UNAVAILABLE,@Spark}
2018-09-18 09:56:38,609   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@25bc0606{/jobs/job,null,UNAVAILABLE,@Spark}
2018-09-18 09:56:38,609   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@3d3ba765{/jobs/json,null,UNAVAILABLE,@Spark}
2018-09-18 09:56:38,609   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@784b990c{/jobs,null,UNAVAILABLE,@Spark}
2018-09-18 09:56:38,611   INFO --- [main]  org.apache.spark.ui.SparkUI(line:54) : Stopped Spark web UI at http://192.168.3.199:4040
2018-09-18 09:56:38,620   INFO --- [dispatcher-event-loop-3]  org.apache.spark.MapOutputTrackerMasterEndpoint(line:54) : MapOutputTrackerMasterEndpoint stopped!
2018-09-18 09:56:38,641   INFO --- [main]  org.apache.spark.storage.memory.MemoryStore(line:54) : MemoryStore cleared
2018-09-18 09:56:38,642   INFO --- [main]  org.apache.spark.storage.BlockManager(line:54) : BlockManager stopped
2018-09-18 09:56:38,647   INFO --- [main]  org.apache.spark.storage.BlockManagerMaster(line:54) : BlockManagerMaster stopped
2018-09-18 09:56:38,649   INFO --- [dispatcher-event-loop-0]  org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint(line:54) : OutputCommitCoordinator stopped!
2018-09-18 09:56:38,654   INFO --- [main]  org.apache.spark.SparkContext(line:54) : Successfully stopped SparkContext
2018-09-18 09:56:38,657   INFO --- [Thread-1]  org.apache.spark.util.ShutdownHookManager(line:54) : Shutdown hook called
2018-09-18 09:56:38,659   INFO --- [Thread-1]  org.apache.spark.util.ShutdownHookManager(line:54) : Deleting directory C:\Users\wshs\AppData\Local\Temp\spark-9f49de95-ac1f-4104-83f6-7ad6404b5e48
2018-09-18 10:13:27,114   INFO --- [main]  org.apache.spark.SparkContext(line:54) : Running Spark version 2.1.1
2018-09-18 10:13:27,445   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing view acls to: wshs
2018-09-18 10:13:27,447   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing modify acls to: wshs
2018-09-18 10:13:27,448   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing view acls groups to: 
2018-09-18 10:13:27,448   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing modify acls groups to: 
2018-09-18 10:13:27,449   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(wshs); groups with view permissions: Set(); users  with modify permissions: Set(wshs); groups with modify permissions: Set()
2018-09-18 10:13:27,829   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'sparkDriver' on port 54941.
2018-09-18 10:13:27,844   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering MapOutputTracker
2018-09-18 10:13:27,861   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering BlockManagerMaster
2018-09-18 10:13:27,863   INFO --- [main]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-09-18 10:13:27,864   INFO --- [main]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : BlockManagerMasterEndpoint up
2018-09-18 10:13:27,875   INFO --- [main]  org.apache.spark.storage.DiskBlockManager(line:54) : Created local directory at C:\Users\wshs\AppData\Local\Temp\blockmgr-939b337c-f6a5-42b1-a08e-891839bc30d8
2018-09-18 10:13:27,891   INFO --- [main]  org.apache.spark.storage.memory.MemoryStore(line:54) : MemoryStore started with capacity 3.0 GB
2018-09-18 10:13:27,956   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering OutputCommitCoordinator
2018-09-18 10:13:28,026   INFO --- [main]  org.spark_project.jetty.util.log(line:186) : Logging initialized @1802ms
2018-09-18 10:13:28,102   INFO --- [main]  org.spark_project.jetty.server.Server(line:327) : jetty-9.2.z-SNAPSHOT
2018-09-18 10:13:28,116   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@784b990c{/jobs,null,AVAILABLE,@Spark}
2018-09-18 10:13:28,116   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@3d3ba765{/jobs/json,null,AVAILABLE,@Spark}
2018-09-18 10:13:28,116   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@25bc0606{/jobs/job,null,AVAILABLE,@Spark}
2018-09-18 10:13:28,117   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@5d1659ea{/jobs/job/json,null,AVAILABLE,@Spark}
2018-09-18 10:13:28,117   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@793138bd{/stages,null,AVAILABLE,@Spark}
2018-09-18 10:13:28,117   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@1951b871{/stages/json,null,AVAILABLE,@Spark}
2018-09-18 10:13:28,117   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@5c18016b{/stages/stage,null,AVAILABLE,@Spark}
2018-09-18 10:13:28,118   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@33aeca0b{/stages/stage/json,null,AVAILABLE,@Spark}
2018-09-18 10:13:28,118   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@43aaf813{/stages/pool,null,AVAILABLE,@Spark}
2018-09-18 10:13:28,118   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@57ac5227{/stages/pool/json,null,AVAILABLE,@Spark}
2018-09-18 10:13:28,118   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@4ba302e0{/storage,null,AVAILABLE,@Spark}
2018-09-18 10:13:28,119   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@e98770d{/storage/json,null,AVAILABLE,@Spark}
2018-09-18 10:13:28,119   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@1ae67cad{/storage/rdd,null,AVAILABLE,@Spark}
2018-09-18 10:13:28,119   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@2f6e28bc{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-09-18 10:13:28,119   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@7c098bb3{/environment,null,AVAILABLE,@Spark}
2018-09-18 10:13:28,120   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@31e4bb20{/environment/json,null,AVAILABLE,@Spark}
2018-09-18 10:13:28,120   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@18cebaa5{/executors,null,AVAILABLE,@Spark}
2018-09-18 10:13:28,120   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@463b4ac8{/executors/json,null,AVAILABLE,@Spark}
2018-09-18 10:13:28,120   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@765f05af{/executors/threadDump,null,AVAILABLE,@Spark}
2018-09-18 10:13:28,121   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@62f68dff{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-09-18 10:13:28,125   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@f001896{/static,null,AVAILABLE,@Spark}
2018-09-18 10:13:28,126   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@13f17eb4{/,null,AVAILABLE,@Spark}
2018-09-18 10:13:28,127   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@1d0d6318{/api,null,AVAILABLE,@Spark}
2018-09-18 10:13:28,127   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@4bc28c33{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-09-18 10:13:28,127   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@4409e975{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-09-18 10:13:28,139   INFO --- [main]  org.spark_project.jetty.server.ServerConnector(line:266) : Started Spark@6035b93b{HTTP/1.1}{0.0.0.0:4040}
2018-09-18 10:13:28,140   INFO --- [main]  org.spark_project.jetty.server.Server(line:379) : Started @1917ms
2018-09-18 10:13:28,140   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'SparkUI' on port 4040.
2018-09-18 10:13:28,143   INFO --- [main]  org.apache.spark.ui.SparkUI(line:54) : Bound SparkUI to 0.0.0.0, and started at http://192.168.3.199:4040
2018-09-18 10:13:28,208   INFO --- [main]  org.apache.spark.executor.Executor(line:54) : Starting executor ID driver on host localhost
2018-09-18 10:13:28,250   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 54982.
2018-09-18 10:13:28,250   INFO --- [main]  org.apache.spark.network.netty.NettyBlockTransferService(line:54) : Server created on 192.168.3.199:54982
2018-09-18 10:13:28,252   INFO --- [main]  org.apache.spark.storage.BlockManager(line:54) : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-09-18 10:13:28,253   INFO --- [main]  org.apache.spark.storage.BlockManagerMaster(line:54) : Registering BlockManager BlockManagerId(driver, 192.168.3.199, 54982, None)
2018-09-18 10:13:28,256   INFO --- [dispatcher-event-loop-2]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : Registering block manager 192.168.3.199:54982 with 3.0 GB RAM, BlockManagerId(driver, 192.168.3.199, 54982, None)
2018-09-18 10:13:28,258   INFO --- [main]  org.apache.spark.storage.BlockManagerMaster(line:54) : Registered BlockManager BlockManagerId(driver, 192.168.3.199, 54982, None)
2018-09-18 10:13:28,259   INFO --- [main]  org.apache.spark.storage.BlockManager(line:54) : Initialized BlockManager: BlockManagerId(driver, 192.168.3.199, 54982, None)
2018-09-18 10:13:28,410   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@3deb2326{/metrics/json,null,AVAILABLE,@Spark}
2018-09-18 10:13:28,457   INFO --- [main]  org.apache.spark.sql.internal.SharedState(line:54) : Warehouse path is 'file:/C:/Users/wshs/IdeaProjects/logdataSession/spark-warehouse/'.
2018-09-18 10:13:28,462   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@63fd4873{/SQL,null,AVAILABLE,@Spark}
2018-09-18 10:13:28,462   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@7544a1e4{/SQL/json,null,AVAILABLE,@Spark}
2018-09-18 10:13:28,463   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@4fdfa676{/SQL/execution,null,AVAILABLE,@Spark}
2018-09-18 10:13:28,463   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@5be82d43{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-09-18 10:13:28,465   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@1734f68{/static/sql,null,AVAILABLE,@Spark}
2018-09-18 10:13:30,243   INFO --- [main]  org.apache.spark.sql.execution.SparkSqlParser(line:54) : Parsing command: actionopvidio
2018-09-18 10:13:30,642   INFO --- [main]  org.apache.spark.sql.execution.SparkSqlParser(line:54) : Parsing command: SELECT id,uid,rid FROM actionopvidio
2018-09-18 10:13:30,694   INFO --- [Thread-1]  org.apache.spark.SparkContext(line:54) : Invoking stop() from shutdown hook
2018-09-18 10:13:30,699   INFO --- [Thread-1]  org.spark_project.jetty.server.ServerConnector(line:306) : Stopped Spark@6035b93b{HTTP/1.1}{0.0.0.0:4040}
2018-09-18 10:13:30,701   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@4409e975{/stages/stage/kill,null,UNAVAILABLE,@Spark}
2018-09-18 10:13:30,701   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@4bc28c33{/jobs/job/kill,null,UNAVAILABLE,@Spark}
2018-09-18 10:13:30,701   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@1d0d6318{/api,null,UNAVAILABLE,@Spark}
2018-09-18 10:13:30,702   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@13f17eb4{/,null,UNAVAILABLE,@Spark}
2018-09-18 10:13:30,702   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@f001896{/static,null,UNAVAILABLE,@Spark}
2018-09-18 10:13:30,702   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@62f68dff{/executors/threadDump/json,null,UNAVAILABLE,@Spark}
2018-09-18 10:13:30,702   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@765f05af{/executors/threadDump,null,UNAVAILABLE,@Spark}
2018-09-18 10:13:30,702   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@463b4ac8{/executors/json,null,UNAVAILABLE,@Spark}
2018-09-18 10:13:30,703   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@18cebaa5{/executors,null,UNAVAILABLE,@Spark}
2018-09-18 10:13:30,703   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@31e4bb20{/environment/json,null,UNAVAILABLE,@Spark}
2018-09-18 10:13:30,703   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@7c098bb3{/environment,null,UNAVAILABLE,@Spark}
2018-09-18 10:13:30,703   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@2f6e28bc{/storage/rdd/json,null,UNAVAILABLE,@Spark}
2018-09-18 10:13:30,703   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@1ae67cad{/storage/rdd,null,UNAVAILABLE,@Spark}
2018-09-18 10:13:30,703   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@e98770d{/storage/json,null,UNAVAILABLE,@Spark}
2018-09-18 10:13:30,704   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@4ba302e0{/storage,null,UNAVAILABLE,@Spark}
2018-09-18 10:13:30,704   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@57ac5227{/stages/pool/json,null,UNAVAILABLE,@Spark}
2018-09-18 10:13:30,704   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@43aaf813{/stages/pool,null,UNAVAILABLE,@Spark}
2018-09-18 10:13:30,704   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@33aeca0b{/stages/stage/json,null,UNAVAILABLE,@Spark}
2018-09-18 10:13:30,704   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@5c18016b{/stages/stage,null,UNAVAILABLE,@Spark}
2018-09-18 10:13:30,705   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@1951b871{/stages/json,null,UNAVAILABLE,@Spark}
2018-09-18 10:13:30,705   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@793138bd{/stages,null,UNAVAILABLE,@Spark}
2018-09-18 10:13:30,705   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@5d1659ea{/jobs/job/json,null,UNAVAILABLE,@Spark}
2018-09-18 10:13:30,705   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@25bc0606{/jobs/job,null,UNAVAILABLE,@Spark}
2018-09-18 10:13:30,705   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@3d3ba765{/jobs/json,null,UNAVAILABLE,@Spark}
2018-09-18 10:13:30,706   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@784b990c{/jobs,null,UNAVAILABLE,@Spark}
2018-09-18 10:13:30,707   INFO --- [Thread-1]  org.apache.spark.ui.SparkUI(line:54) : Stopped Spark web UI at http://192.168.3.199:4040
2018-09-18 10:13:30,716   INFO --- [dispatcher-event-loop-6]  org.apache.spark.MapOutputTrackerMasterEndpoint(line:54) : MapOutputTrackerMasterEndpoint stopped!
2018-09-18 10:13:30,726   INFO --- [Thread-1]  org.apache.spark.storage.memory.MemoryStore(line:54) : MemoryStore cleared
2018-09-18 10:13:30,726   INFO --- [Thread-1]  org.apache.spark.storage.BlockManager(line:54) : BlockManager stopped
2018-09-18 10:13:30,732   INFO --- [Thread-1]  org.apache.spark.storage.BlockManagerMaster(line:54) : BlockManagerMaster stopped
2018-09-18 10:13:30,735   INFO --- [dispatcher-event-loop-3]  org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint(line:54) : OutputCommitCoordinator stopped!
2018-09-18 10:13:30,740   INFO --- [Thread-1]  org.apache.spark.SparkContext(line:54) : Successfully stopped SparkContext
2018-09-18 10:13:30,741   INFO --- [Thread-1]  org.apache.spark.util.ShutdownHookManager(line:54) : Shutdown hook called
2018-09-18 10:13:30,742   INFO --- [Thread-1]  org.apache.spark.util.ShutdownHookManager(line:54) : Deleting directory C:\Users\wshs\AppData\Local\Temp\spark-de890c2b-2e31-4ea1-ad0e-e497961d0b7c
2018-09-18 11:01:50,859   INFO --- [main]  org.apache.spark.SparkContext(line:54) : Running Spark version 2.1.1
2018-09-18 11:01:51,225   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing view acls to: wshs
2018-09-18 11:01:51,226   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing modify acls to: wshs
2018-09-18 11:01:51,227   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing view acls groups to: 
2018-09-18 11:01:51,228   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing modify acls groups to: 
2018-09-18 11:01:51,229   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(wshs); groups with view permissions: Set(); users  with modify permissions: Set(wshs); groups with modify permissions: Set()
2018-09-18 11:01:51,720   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'sparkDriver' on port 58687.
2018-09-18 11:01:51,739   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering MapOutputTracker
2018-09-18 11:01:51,757   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering BlockManagerMaster
2018-09-18 11:01:51,759   INFO --- [main]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-09-18 11:01:51,760   INFO --- [main]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : BlockManagerMasterEndpoint up
2018-09-18 11:01:51,774   INFO --- [main]  org.apache.spark.storage.DiskBlockManager(line:54) : Created local directory at C:\Users\wshs\AppData\Local\Temp\blockmgr-3da85713-f28c-4c6a-b300-b071d01ab73a
2018-09-18 11:01:51,793   INFO --- [main]  org.apache.spark.storage.memory.MemoryStore(line:54) : MemoryStore started with capacity 3.0 GB
2018-09-18 11:01:51,863   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering OutputCommitCoordinator
2018-09-18 11:01:51,961   INFO --- [main]  org.spark_project.jetty.util.log(line:186) : Logging initialized @2063ms
2018-09-18 11:01:52,044   INFO --- [main]  org.spark_project.jetty.server.Server(line:327) : jetty-9.2.z-SNAPSHOT
2018-09-18 11:01:52,060   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@1951b871{/jobs,null,AVAILABLE,@Spark}
2018-09-18 11:01:52,061   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@5c18016b{/jobs/json,null,AVAILABLE,@Spark}
2018-09-18 11:01:52,061   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@33aeca0b{/jobs/job,null,AVAILABLE,@Spark}
2018-09-18 11:01:52,061   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@43aaf813{/jobs/job/json,null,AVAILABLE,@Spark}
2018-09-18 11:01:52,061   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@57ac5227{/stages,null,AVAILABLE,@Spark}
2018-09-18 11:01:52,062   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@4ba302e0{/stages/json,null,AVAILABLE,@Spark}
2018-09-18 11:01:52,062   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@e98770d{/stages/stage,null,AVAILABLE,@Spark}
2018-09-18 11:01:52,063   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@1ae67cad{/stages/stage/json,null,AVAILABLE,@Spark}
2018-09-18 11:01:52,063   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@2f6e28bc{/stages/pool,null,AVAILABLE,@Spark}
2018-09-18 11:01:52,063   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@7c098bb3{/stages/pool/json,null,AVAILABLE,@Spark}
2018-09-18 11:01:52,064   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@31e4bb20{/storage,null,AVAILABLE,@Spark}
2018-09-18 11:01:52,064   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@18cebaa5{/storage/json,null,AVAILABLE,@Spark}
2018-09-18 11:01:52,064   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@463b4ac8{/storage/rdd,null,AVAILABLE,@Spark}
2018-09-18 11:01:52,064   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@765f05af{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-09-18 11:01:52,065   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@62f68dff{/environment,null,AVAILABLE,@Spark}
2018-09-18 11:01:52,065   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@f001896{/environment/json,null,AVAILABLE,@Spark}
2018-09-18 11:01:52,065   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@13f17eb4{/executors,null,AVAILABLE,@Spark}
2018-09-18 11:01:52,066   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@1d0d6318{/executors/json,null,AVAILABLE,@Spark}
2018-09-18 11:01:52,066   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@4bc28c33{/executors/threadDump,null,AVAILABLE,@Spark}
2018-09-18 11:01:52,066   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@4409e975{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-09-18 11:01:52,071   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@5c153b9e{/static,null,AVAILABLE,@Spark}
2018-09-18 11:01:52,072   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@2a7686a7{/,null,AVAILABLE,@Spark}
2018-09-18 11:01:52,072   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@758a34ce{/api,null,AVAILABLE,@Spark}
2018-09-18 11:01:52,072   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@7ec3394b{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-09-18 11:01:52,073   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@bff34c6{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-09-18 11:01:52,085   INFO --- [main]  org.spark_project.jetty.server.ServerConnector(line:266) : Started Spark@1a7288a3{HTTP/1.1}{0.0.0.0:4040}
2018-09-18 11:01:52,085   INFO --- [main]  org.spark_project.jetty.server.Server(line:379) : Started @2189ms
2018-09-18 11:01:52,086   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'SparkUI' on port 4040.
2018-09-18 11:01:52,088   INFO --- [main]  org.apache.spark.ui.SparkUI(line:54) : Bound SparkUI to 0.0.0.0, and started at http://192.168.3.199:4040
2018-09-18 11:01:52,169   INFO --- [main]  org.apache.spark.executor.Executor(line:54) : Starting executor ID driver on host localhost
2018-09-18 11:01:52,225   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 58729.
2018-09-18 11:01:52,225   INFO --- [main]  org.apache.spark.network.netty.NettyBlockTransferService(line:54) : Server created on 192.168.3.199:58729
2018-09-18 11:01:52,227   INFO --- [main]  org.apache.spark.storage.BlockManager(line:54) : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-09-18 11:01:52,228   INFO --- [main]  org.apache.spark.storage.BlockManagerMaster(line:54) : Registering BlockManager BlockManagerId(driver, 192.168.3.199, 58729, None)
2018-09-18 11:01:52,231   INFO --- [dispatcher-event-loop-2]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : Registering block manager 192.168.3.199:58729 with 3.0 GB RAM, BlockManagerId(driver, 192.168.3.199, 58729, None)
2018-09-18 11:01:52,234   INFO --- [main]  org.apache.spark.storage.BlockManagerMaster(line:54) : Registered BlockManager BlockManagerId(driver, 192.168.3.199, 58729, None)
2018-09-18 11:01:52,234   INFO --- [main]  org.apache.spark.storage.BlockManager(line:54) : Initialized BlockManager: BlockManagerId(driver, 192.168.3.199, 58729, None)
2018-09-18 11:01:52,399   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@27cf3151{/metrics/json,null,AVAILABLE,@Spark}
2018-09-18 11:01:52,459   INFO --- [main]  org.apache.spark.sql.internal.SharedState(line:54) : Warehouse path is 'file:/C:/Users/wshs/IdeaProjects/logdataSession/spark-warehouse/'.
2018-09-18 11:01:52,466   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@6ab72419{/SQL,null,AVAILABLE,@Spark}
2018-09-18 11:01:52,467   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@4fdfa676{/SQL/json,null,AVAILABLE,@Spark}
2018-09-18 11:01:52,468   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@5ea502e0{/SQL/execution,null,AVAILABLE,@Spark}
2018-09-18 11:01:52,468   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@473b3b7a{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-09-18 11:01:52,469   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@133e019b{/static/sql,null,AVAILABLE,@Spark}
2018-09-18 11:01:54,499   INFO --- [main]  org.apache.spark.sql.execution.SparkSqlParser(line:54) : Parsing command: actionopvidio
2018-09-18 11:01:54,942   INFO --- [main]  org.apache.spark.sql.execution.SparkSqlParser(line:54) : Parsing command: SELECT id,uid,rid FROM actionopvidio
2018-09-18 11:01:54,997   INFO --- [Thread-1]  org.apache.spark.SparkContext(line:54) : Invoking stop() from shutdown hook
2018-09-18 11:01:55,002   INFO --- [Thread-1]  org.spark_project.jetty.server.ServerConnector(line:306) : Stopped Spark@1a7288a3{HTTP/1.1}{0.0.0.0:4040}
2018-09-18 11:01:55,004   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@bff34c6{/stages/stage/kill,null,UNAVAILABLE,@Spark}
2018-09-18 11:01:55,004   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@7ec3394b{/jobs/job/kill,null,UNAVAILABLE,@Spark}
2018-09-18 11:01:55,005   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@758a34ce{/api,null,UNAVAILABLE,@Spark}
2018-09-18 11:01:55,005   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@2a7686a7{/,null,UNAVAILABLE,@Spark}
2018-09-18 11:01:55,005   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@5c153b9e{/static,null,UNAVAILABLE,@Spark}
2018-09-18 11:01:55,005   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@4409e975{/executors/threadDump/json,null,UNAVAILABLE,@Spark}
2018-09-18 11:01:55,006   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@4bc28c33{/executors/threadDump,null,UNAVAILABLE,@Spark}
2018-09-18 11:01:55,006   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@1d0d6318{/executors/json,null,UNAVAILABLE,@Spark}
2018-09-18 11:01:55,006   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@13f17eb4{/executors,null,UNAVAILABLE,@Spark}
2018-09-18 11:01:55,007   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@f001896{/environment/json,null,UNAVAILABLE,@Spark}
2018-09-18 11:01:55,007   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@62f68dff{/environment,null,UNAVAILABLE,@Spark}
2018-09-18 11:01:55,007   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@765f05af{/storage/rdd/json,null,UNAVAILABLE,@Spark}
2018-09-18 11:01:55,008   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@463b4ac8{/storage/rdd,null,UNAVAILABLE,@Spark}
2018-09-18 11:01:55,008   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@18cebaa5{/storage/json,null,UNAVAILABLE,@Spark}
2018-09-18 11:01:55,008   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@31e4bb20{/storage,null,UNAVAILABLE,@Spark}
2018-09-18 11:01:55,009   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@7c098bb3{/stages/pool/json,null,UNAVAILABLE,@Spark}
2018-09-18 11:01:55,009   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@2f6e28bc{/stages/pool,null,UNAVAILABLE,@Spark}
2018-09-18 11:01:55,009   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@1ae67cad{/stages/stage/json,null,UNAVAILABLE,@Spark}
2018-09-18 11:01:55,009   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@e98770d{/stages/stage,null,UNAVAILABLE,@Spark}
2018-09-18 11:01:55,009   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@4ba302e0{/stages/json,null,UNAVAILABLE,@Spark}
2018-09-18 11:01:55,010   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@57ac5227{/stages,null,UNAVAILABLE,@Spark}
2018-09-18 11:01:55,010   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@43aaf813{/jobs/job/json,null,UNAVAILABLE,@Spark}
2018-09-18 11:01:55,011   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@33aeca0b{/jobs/job,null,UNAVAILABLE,@Spark}
2018-09-18 11:01:55,011   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@5c18016b{/jobs/json,null,UNAVAILABLE,@Spark}
2018-09-18 11:01:55,011   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@1951b871{/jobs,null,UNAVAILABLE,@Spark}
2018-09-18 11:01:55,013   INFO --- [Thread-1]  org.apache.spark.ui.SparkUI(line:54) : Stopped Spark web UI at http://192.168.3.199:4040
2018-09-18 11:01:55,022   INFO --- [dispatcher-event-loop-6]  org.apache.spark.MapOutputTrackerMasterEndpoint(line:54) : MapOutputTrackerMasterEndpoint stopped!
2018-09-18 11:01:55,035   INFO --- [Thread-1]  org.apache.spark.storage.memory.MemoryStore(line:54) : MemoryStore cleared
2018-09-18 11:01:55,035   INFO --- [Thread-1]  org.apache.spark.storage.BlockManager(line:54) : BlockManager stopped
2018-09-18 11:01:55,040   INFO --- [Thread-1]  org.apache.spark.storage.BlockManagerMaster(line:54) : BlockManagerMaster stopped
2018-09-18 11:01:55,043   INFO --- [dispatcher-event-loop-3]  org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint(line:54) : OutputCommitCoordinator stopped!
2018-09-18 11:01:55,049   INFO --- [Thread-1]  org.apache.spark.SparkContext(line:54) : Successfully stopped SparkContext
2018-09-18 11:01:55,049   INFO --- [Thread-1]  org.apache.spark.util.ShutdownHookManager(line:54) : Shutdown hook called
2018-09-18 11:01:55,050   INFO --- [Thread-1]  org.apache.spark.util.ShutdownHookManager(line:54) : Deleting directory C:\Users\wshs\AppData\Local\Temp\spark-fdda26fa-9e4c-4523-931a-b2553cf3056d
2018-09-18 11:11:04,796   INFO --- [main]  org.apache.spark.SparkContext(line:54) : Running Spark version 2.1.1
2018-09-18 11:11:05,178   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing view acls to: wshs
2018-09-18 11:11:05,179   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing modify acls to: wshs
2018-09-18 11:11:05,180   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing view acls groups to: 
2018-09-18 11:11:05,180   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing modify acls groups to: 
2018-09-18 11:11:05,181   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(wshs); groups with view permissions: Set(); users  with modify permissions: Set(wshs); groups with modify permissions: Set()
2018-09-18 11:11:05,618   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'sparkDriver' on port 59486.
2018-09-18 11:11:05,635   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering MapOutputTracker
2018-09-18 11:11:05,653   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering BlockManagerMaster
2018-09-18 11:11:05,656   INFO --- [main]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-09-18 11:11:05,657   INFO --- [main]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : BlockManagerMasterEndpoint up
2018-09-18 11:11:05,670   INFO --- [main]  org.apache.spark.storage.DiskBlockManager(line:54) : Created local directory at C:\Users\wshs\AppData\Local\Temp\blockmgr-60a305c7-4807-49eb-bc44-4805c0e33259
2018-09-18 11:11:05,691   INFO --- [main]  org.apache.spark.storage.memory.MemoryStore(line:54) : MemoryStore started with capacity 3.0 GB
2018-09-18 11:11:05,747   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering OutputCommitCoordinator
2018-09-18 11:11:05,824   INFO --- [main]  org.spark_project.jetty.util.log(line:186) : Logging initialized @2085ms
2018-09-18 11:11:05,901   INFO --- [main]  org.spark_project.jetty.server.Server(line:327) : jetty-9.2.z-SNAPSHOT
2018-09-18 11:11:05,915   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@33aeca0b{/jobs,null,AVAILABLE,@Spark}
2018-09-18 11:11:05,915   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@43aaf813{/jobs/json,null,AVAILABLE,@Spark}
2018-09-18 11:11:05,915   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@57ac5227{/jobs/job,null,AVAILABLE,@Spark}
2018-09-18 11:11:05,916   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@4ba302e0{/jobs/job/json,null,AVAILABLE,@Spark}
2018-09-18 11:11:05,916   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@e98770d{/stages,null,AVAILABLE,@Spark}
2018-09-18 11:11:05,916   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@1ae67cad{/stages/json,null,AVAILABLE,@Spark}
2018-09-18 11:11:05,916   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@2f6e28bc{/stages/stage,null,AVAILABLE,@Spark}
2018-09-18 11:11:05,917   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@7c098bb3{/stages/stage/json,null,AVAILABLE,@Spark}
2018-09-18 11:11:05,917   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@31e4bb20{/stages/pool,null,AVAILABLE,@Spark}
2018-09-18 11:11:05,917   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@18cebaa5{/stages/pool/json,null,AVAILABLE,@Spark}
2018-09-18 11:11:05,917   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@463b4ac8{/storage,null,AVAILABLE,@Spark}
2018-09-18 11:11:05,918   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@765f05af{/storage/json,null,AVAILABLE,@Spark}
2018-09-18 11:11:05,918   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@62f68dff{/storage/rdd,null,AVAILABLE,@Spark}
2018-09-18 11:11:05,918   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@f001896{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-09-18 11:11:05,918   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@13f17eb4{/environment,null,AVAILABLE,@Spark}
2018-09-18 11:11:05,919   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@1d0d6318{/environment/json,null,AVAILABLE,@Spark}
2018-09-18 11:11:05,919   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@4bc28c33{/executors,null,AVAILABLE,@Spark}
2018-09-18 11:11:05,919   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@4409e975{/executors/json,null,AVAILABLE,@Spark}
2018-09-18 11:11:05,919   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@5c153b9e{/executors/threadDump,null,AVAILABLE,@Spark}
2018-09-18 11:11:05,920   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@2a7686a7{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-09-18 11:11:05,925   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@758a34ce{/static,null,AVAILABLE,@Spark}
2018-09-18 11:11:05,925   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@7ec3394b{/,null,AVAILABLE,@Spark}
2018-09-18 11:11:05,925   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@bff34c6{/api,null,AVAILABLE,@Spark}
2018-09-18 11:11:05,925   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@1522d8a0{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-09-18 11:11:05,925   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@312ab28e{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-09-18 11:11:05,938   INFO --- [main]  org.spark_project.jetty.server.ServerConnector(line:266) : Started Spark@58fe0499{HTTP/1.1}{0.0.0.0:4040}
2018-09-18 11:11:05,938   INFO --- [main]  org.spark_project.jetty.server.Server(line:379) : Started @2202ms
2018-09-18 11:11:05,939   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'SparkUI' on port 4040.
2018-09-18 11:11:05,941   INFO --- [main]  org.apache.spark.ui.SparkUI(line:54) : Bound SparkUI to 0.0.0.0, and started at http://192.168.3.199:4040
2018-09-18 11:11:06,012   INFO --- [main]  org.apache.spark.executor.Executor(line:54) : Starting executor ID driver on host localhost
2018-09-18 11:11:06,055   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 59527.
2018-09-18 11:11:06,056   INFO --- [main]  org.apache.spark.network.netty.NettyBlockTransferService(line:54) : Server created on 192.168.3.199:59527
2018-09-18 11:11:06,057   INFO --- [main]  org.apache.spark.storage.BlockManager(line:54) : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-09-18 11:11:06,059   INFO --- [main]  org.apache.spark.storage.BlockManagerMaster(line:54) : Registering BlockManager BlockManagerId(driver, 192.168.3.199, 59527, None)
2018-09-18 11:11:06,062   INFO --- [dispatcher-event-loop-2]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : Registering block manager 192.168.3.199:59527 with 3.0 GB RAM, BlockManagerId(driver, 192.168.3.199, 59527, None)
2018-09-18 11:11:06,064   INFO --- [main]  org.apache.spark.storage.BlockManagerMaster(line:54) : Registered BlockManager BlockManagerId(driver, 192.168.3.199, 59527, None)
2018-09-18 11:11:06,065   INFO --- [main]  org.apache.spark.storage.BlockManager(line:54) : Initialized BlockManager: BlockManagerId(driver, 192.168.3.199, 59527, None)
2018-09-18 11:11:06,233   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@5910de75{/metrics/json,null,AVAILABLE,@Spark}
2018-09-18 11:11:06,290   INFO --- [main]  org.apache.spark.sql.internal.SharedState(line:54) : Warehouse path is 'file:/C:/Users/wshs/IdeaProjects/logdataSession/spark-warehouse/'.
2018-09-18 11:11:06,295   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@4fdfa676{/SQL,null,AVAILABLE,@Spark}
2018-09-18 11:11:06,295   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@5be82d43{/SQL/json,null,AVAILABLE,@Spark}
2018-09-18 11:11:06,295   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@473b3b7a{/SQL/execution,null,AVAILABLE,@Spark}
2018-09-18 11:11:06,296   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@77b7ffa4{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-09-18 11:11:06,297   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@7dac3fd8{/static/sql,null,AVAILABLE,@Spark}
2018-09-18 11:11:08,291   INFO --- [main]  org.apache.spark.sql.execution.SparkSqlParser(line:54) : Parsing command: actionopvidio
2018-09-18 11:11:08,693   INFO --- [main]  org.apache.spark.sql.execution.SparkSqlParser(line:54) : Parsing command: SELECT id,uid,rid FROM actionopvidio
2018-09-18 11:11:08,746   INFO --- [Thread-1]  org.apache.spark.SparkContext(line:54) : Invoking stop() from shutdown hook
2018-09-18 11:11:08,751   INFO --- [Thread-1]  org.spark_project.jetty.server.ServerConnector(line:306) : Stopped Spark@58fe0499{HTTP/1.1}{0.0.0.0:4040}
2018-09-18 11:11:08,753   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@312ab28e{/stages/stage/kill,null,UNAVAILABLE,@Spark}
2018-09-18 11:11:08,753   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@1522d8a0{/jobs/job/kill,null,UNAVAILABLE,@Spark}
2018-09-18 11:11:08,754   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@bff34c6{/api,null,UNAVAILABLE,@Spark}
2018-09-18 11:11:08,754   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@7ec3394b{/,null,UNAVAILABLE,@Spark}
2018-09-18 11:11:08,754   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@758a34ce{/static,null,UNAVAILABLE,@Spark}
2018-09-18 11:11:08,754   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@2a7686a7{/executors/threadDump/json,null,UNAVAILABLE,@Spark}
2018-09-18 11:11:08,754   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@5c153b9e{/executors/threadDump,null,UNAVAILABLE,@Spark}
2018-09-18 11:11:08,754   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@4409e975{/executors/json,null,UNAVAILABLE,@Spark}
2018-09-18 11:11:08,755   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@4bc28c33{/executors,null,UNAVAILABLE,@Spark}
2018-09-18 11:11:08,755   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@1d0d6318{/environment/json,null,UNAVAILABLE,@Spark}
2018-09-18 11:11:08,755   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@13f17eb4{/environment,null,UNAVAILABLE,@Spark}
2018-09-18 11:11:08,755   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@f001896{/storage/rdd/json,null,UNAVAILABLE,@Spark}
2018-09-18 11:11:08,755   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@62f68dff{/storage/rdd,null,UNAVAILABLE,@Spark}
2018-09-18 11:11:08,756   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@765f05af{/storage/json,null,UNAVAILABLE,@Spark}
2018-09-18 11:11:08,756   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@463b4ac8{/storage,null,UNAVAILABLE,@Spark}
2018-09-18 11:11:08,756   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@18cebaa5{/stages/pool/json,null,UNAVAILABLE,@Spark}
2018-09-18 11:11:08,756   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@31e4bb20{/stages/pool,null,UNAVAILABLE,@Spark}
2018-09-18 11:11:08,757   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@7c098bb3{/stages/stage/json,null,UNAVAILABLE,@Spark}
2018-09-18 11:11:08,757   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@2f6e28bc{/stages/stage,null,UNAVAILABLE,@Spark}
2018-09-18 11:11:08,757   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@1ae67cad{/stages/json,null,UNAVAILABLE,@Spark}
2018-09-18 11:11:08,757   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@e98770d{/stages,null,UNAVAILABLE,@Spark}
2018-09-18 11:11:08,758   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@4ba302e0{/jobs/job/json,null,UNAVAILABLE,@Spark}
2018-09-18 11:11:08,758   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@57ac5227{/jobs/job,null,UNAVAILABLE,@Spark}
2018-09-18 11:11:08,758   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@43aaf813{/jobs/json,null,UNAVAILABLE,@Spark}
2018-09-18 11:11:08,758   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@33aeca0b{/jobs,null,UNAVAILABLE,@Spark}
2018-09-18 11:11:08,760   INFO --- [Thread-1]  org.apache.spark.ui.SparkUI(line:54) : Stopped Spark web UI at http://192.168.3.199:4040
2018-09-18 11:11:08,769   INFO --- [dispatcher-event-loop-6]  org.apache.spark.MapOutputTrackerMasterEndpoint(line:54) : MapOutputTrackerMasterEndpoint stopped!
2018-09-18 11:11:08,779   INFO --- [Thread-1]  org.apache.spark.storage.memory.MemoryStore(line:54) : MemoryStore cleared
2018-09-18 11:11:08,780   INFO --- [Thread-1]  org.apache.spark.storage.BlockManager(line:54) : BlockManager stopped
2018-09-18 11:11:08,785   INFO --- [Thread-1]  org.apache.spark.storage.BlockManagerMaster(line:54) : BlockManagerMaster stopped
2018-09-18 11:11:08,788   INFO --- [dispatcher-event-loop-3]  org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint(line:54) : OutputCommitCoordinator stopped!
2018-09-18 11:11:08,793   INFO --- [Thread-1]  org.apache.spark.SparkContext(line:54) : Successfully stopped SparkContext
2018-09-18 11:11:08,794   INFO --- [Thread-1]  org.apache.spark.util.ShutdownHookManager(line:54) : Shutdown hook called
2018-09-18 11:11:08,795   INFO --- [Thread-1]  org.apache.spark.util.ShutdownHookManager(line:54) : Deleting directory C:\Users\wshs\AppData\Local\Temp\spark-24a00ed5-fa22-4c87-b7ee-4dfa38f1547f
2018-09-18 11:15:12,596   INFO --- [main]  org.apache.spark.SparkContext(line:54) : Running Spark version 2.1.1
2018-09-18 11:15:12,967   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing view acls to: wshs
2018-09-18 11:15:12,969   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing modify acls to: wshs
2018-09-18 11:15:12,970   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing view acls groups to: 
2018-09-18 11:15:12,971   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing modify acls groups to: 
2018-09-18 11:15:12,971   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(wshs); groups with view permissions: Set(); users  with modify permissions: Set(wshs); groups with modify permissions: Set()
2018-09-18 11:15:13,437   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'sparkDriver' on port 59953.
2018-09-18 11:15:13,459   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering MapOutputTracker
2018-09-18 11:15:13,479   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering BlockManagerMaster
2018-09-18 11:15:13,482   INFO --- [main]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-09-18 11:15:13,483   INFO --- [main]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : BlockManagerMasterEndpoint up
2018-09-18 11:15:13,494   INFO --- [main]  org.apache.spark.storage.DiskBlockManager(line:54) : Created local directory at C:\Users\wshs\AppData\Local\Temp\blockmgr-d5f5317c-a0f7-4fc5-affd-5b1d30b339bf
2018-09-18 11:15:13,509   INFO --- [main]  org.apache.spark.storage.memory.MemoryStore(line:54) : MemoryStore started with capacity 3.0 GB
2018-09-18 11:15:13,573   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering OutputCommitCoordinator
2018-09-18 11:15:13,642   INFO --- [main]  org.spark_project.jetty.util.log(line:186) : Logging initialized @2088ms
2018-09-18 11:15:13,720   INFO --- [main]  org.spark_project.jetty.server.Server(line:327) : jetty-9.2.z-SNAPSHOT
2018-09-18 11:15:13,736   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@33aeca0b{/jobs,null,AVAILABLE,@Spark}
2018-09-18 11:15:13,736   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@43aaf813{/jobs/json,null,AVAILABLE,@Spark}
2018-09-18 11:15:13,736   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@57ac5227{/jobs/job,null,AVAILABLE,@Spark}
2018-09-18 11:15:13,737   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@4ba302e0{/jobs/job/json,null,AVAILABLE,@Spark}
2018-09-18 11:15:13,737   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@e98770d{/stages,null,AVAILABLE,@Spark}
2018-09-18 11:15:13,737   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@1ae67cad{/stages/json,null,AVAILABLE,@Spark}
2018-09-18 11:15:13,737   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@2f6e28bc{/stages/stage,null,AVAILABLE,@Spark}
2018-09-18 11:15:13,738   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@7c098bb3{/stages/stage/json,null,AVAILABLE,@Spark}
2018-09-18 11:15:13,738   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@31e4bb20{/stages/pool,null,AVAILABLE,@Spark}
2018-09-18 11:15:13,738   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@18cebaa5{/stages/pool/json,null,AVAILABLE,@Spark}
2018-09-18 11:15:13,738   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@463b4ac8{/storage,null,AVAILABLE,@Spark}
2018-09-18 11:15:13,739   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@765f05af{/storage/json,null,AVAILABLE,@Spark}
2018-09-18 11:15:13,739   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@62f68dff{/storage/rdd,null,AVAILABLE,@Spark}
2018-09-18 11:15:13,739   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@f001896{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-09-18 11:15:13,739   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@13f17eb4{/environment,null,AVAILABLE,@Spark}
2018-09-18 11:15:13,739   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@1d0d6318{/environment/json,null,AVAILABLE,@Spark}
2018-09-18 11:15:13,740   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@4bc28c33{/executors,null,AVAILABLE,@Spark}
2018-09-18 11:15:13,740   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@4409e975{/executors/json,null,AVAILABLE,@Spark}
2018-09-18 11:15:13,740   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@5c153b9e{/executors/threadDump,null,AVAILABLE,@Spark}
2018-09-18 11:15:13,740   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@2a7686a7{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-09-18 11:15:13,745   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@758a34ce{/static,null,AVAILABLE,@Spark}
2018-09-18 11:15:13,746   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@7ec3394b{/,null,AVAILABLE,@Spark}
2018-09-18 11:15:13,747   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@bff34c6{/api,null,AVAILABLE,@Spark}
2018-09-18 11:15:13,747   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@1522d8a0{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-09-18 11:15:13,748   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@312ab28e{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-09-18 11:15:13,760   INFO --- [main]  org.spark_project.jetty.server.ServerConnector(line:266) : Started Spark@58fe0499{HTTP/1.1}{0.0.0.0:4040}
2018-09-18 11:15:13,760   INFO --- [main]  org.spark_project.jetty.server.Server(line:379) : Started @2207ms
2018-09-18 11:15:13,760   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'SparkUI' on port 4040.
2018-09-18 11:15:13,763   INFO --- [main]  org.apache.spark.ui.SparkUI(line:54) : Bound SparkUI to 0.0.0.0, and started at http://192.168.3.199:4040
2018-09-18 11:15:13,838   INFO --- [main]  org.apache.spark.executor.Executor(line:54) : Starting executor ID driver on host localhost
2018-09-18 11:15:13,891   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 59995.
2018-09-18 11:15:13,892   INFO --- [main]  org.apache.spark.network.netty.NettyBlockTransferService(line:54) : Server created on 192.168.3.199:59995
2018-09-18 11:15:13,894   INFO --- [main]  org.apache.spark.storage.BlockManager(line:54) : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-09-18 11:15:13,895   INFO --- [main]  org.apache.spark.storage.BlockManagerMaster(line:54) : Registering BlockManager BlockManagerId(driver, 192.168.3.199, 59995, None)
2018-09-18 11:15:13,898   INFO --- [dispatcher-event-loop-2]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : Registering block manager 192.168.3.199:59995 with 3.0 GB RAM, BlockManagerId(driver, 192.168.3.199, 59995, None)
2018-09-18 11:15:13,900   INFO --- [main]  org.apache.spark.storage.BlockManagerMaster(line:54) : Registered BlockManager BlockManagerId(driver, 192.168.3.199, 59995, None)
2018-09-18 11:15:13,901   INFO --- [main]  org.apache.spark.storage.BlockManager(line:54) : Initialized BlockManager: BlockManagerId(driver, 192.168.3.199, 59995, None)
2018-09-18 11:15:14,060   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@5910de75{/metrics/json,null,AVAILABLE,@Spark}
2018-09-18 11:15:14,109   INFO --- [main]  org.apache.spark.sql.internal.SharedState(line:54) : Warehouse path is 'file:/C:/Users/wshs/IdeaProjects/logdataSession/spark-warehouse/'.
2018-09-18 11:15:14,113   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@4fdfa676{/SQL,null,AVAILABLE,@Spark}
2018-09-18 11:15:14,114   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@5be82d43{/SQL/json,null,AVAILABLE,@Spark}
2018-09-18 11:15:14,114   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@473b3b7a{/SQL/execution,null,AVAILABLE,@Spark}
2018-09-18 11:15:14,115   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@77b7ffa4{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-09-18 11:15:14,116   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@7dac3fd8{/static/sql,null,AVAILABLE,@Spark}
2018-09-18 11:15:16,141   INFO --- [main]  org.apache.spark.sql.execution.datasources.FileSourceStrategy(line:54) : Pruning directories with: 
2018-09-18 11:15:16,143   INFO --- [main]  org.apache.spark.sql.execution.datasources.FileSourceStrategy(line:54) : Post-Scan Filters: 
2018-09-18 11:15:16,146   INFO --- [main]  org.apache.spark.sql.execution.datasources.FileSourceStrategy(line:54) : Output Data Schema: struct<value: string>
2018-09-18 11:15:16,147   INFO --- [main]  org.apache.spark.sql.execution.datasources.FileSourceStrategy(line:54) : Pushed Filters: 
2018-09-18 11:15:16,618   INFO --- [main]  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator(line:54) : Code generated in 193.440761 ms
2018-09-18 11:15:16,711   INFO --- [main]  org.apache.spark.storage.memory.MemoryStore(line:54) : Block broadcast_0 stored as values in memory (estimated size 131.1 KB, free 3.0 GB)
2018-09-18 11:15:17,272   INFO --- [main]  org.apache.spark.storage.memory.MemoryStore(line:54) : Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.6 KB, free 3.0 GB)
2018-09-18 11:15:17,275   INFO --- [dispatcher-event-loop-4]  org.apache.spark.storage.BlockManagerInfo(line:54) : Added broadcast_0_piece0 in memory on 192.168.3.199:59995 (size: 14.6 KB, free: 3.0 GB)
2018-09-18 11:15:17,278   INFO --- [main]  org.apache.spark.SparkContext(line:54) : Created broadcast 0 from show at logSession.scala:40
2018-09-18 11:15:17,286   INFO --- [main]  org.apache.spark.sql.execution.FileSourceScanExec(line:54) : Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2018-09-18 11:15:17,370   INFO --- [main]  org.apache.spark.SparkContext(line:54) : Starting job: show at logSession.scala:40
2018-09-18 11:15:17,384   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Got job 0 (show at logSession.scala:40) with 1 output partitions
2018-09-18 11:15:17,384   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Final stage: ResultStage 0 (show at logSession.scala:40)
2018-09-18 11:15:17,385   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Parents of final stage: List()
2018-09-18 11:15:17,386   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Missing parents: List()
2018-09-18 11:15:17,392   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Submitting ResultStage 0 (MapPartitionsRDD[2] at show at logSession.scala:40), which has no missing parents
2018-09-18 11:15:17,436   INFO --- [dag-scheduler-event-loop]  org.apache.spark.storage.memory.MemoryStore(line:54) : Block broadcast_1 stored as values in memory (estimated size 6.7 KB, free 3.0 GB)
2018-09-18 11:15:17,440   INFO --- [dag-scheduler-event-loop]  org.apache.spark.storage.memory.MemoryStore(line:54) : Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.6 KB, free 3.0 GB)
2018-09-18 11:15:17,441   INFO --- [dispatcher-event-loop-5]  org.apache.spark.storage.BlockManagerInfo(line:54) : Added broadcast_1_piece0 in memory on 192.168.3.199:59995 (size: 3.6 KB, free: 3.0 GB)
2018-09-18 11:15:17,441   INFO --- [dag-scheduler-event-loop]  org.apache.spark.SparkContext(line:54) : Created broadcast 1 from broadcast at DAGScheduler.scala:996
2018-09-18 11:15:17,444   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at show at logSession.scala:40)
2018-09-18 11:15:17,445   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.TaskSchedulerImpl(line:54) : Adding task set 0.0 with 1 tasks
2018-09-18 11:15:17,483   INFO --- [dispatcher-event-loop-6]  org.apache.spark.scheduler.TaskSetManager(line:54) : Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 6427 bytes)
2018-09-18 11:15:17,493   INFO --- [Executor task launch worker for task 0]  org.apache.spark.executor.Executor(line:54) : Running task 0.0 in stage 0.0 (TID 0)
2018-09-18 11:15:17,536   INFO --- [Executor task launch worker for task 0]  org.apache.spark.sql.execution.datasources.FileScanRDD(line:54) : Reading File path: file:///e:/r_actionopvidio.txt, range: 0-376727, partition values: [empty row]
2018-09-18 11:15:17,650   INFO --- [Executor task launch worker for task 0]  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator(line:54) : Code generated in 9.94883 ms
2018-09-18 11:15:17,682   INFO --- [Executor task launch worker for task 0]  org.apache.spark.executor.Executor(line:54) : Finished task 0.0 in stage 0.0 (TID 0). 1739 bytes result sent to driver
2018-09-18 11:15:17,690   INFO --- [task-result-getter-0]  org.apache.spark.scheduler.TaskSetManager(line:54) : Finished task 0.0 in stage 0.0 (TID 0) in 226 ms on localhost (executor driver) (1/1)
2018-09-18 11:15:17,692   INFO --- [task-result-getter-0]  org.apache.spark.scheduler.TaskSchedulerImpl(line:54) : Removed TaskSet 0.0, whose tasks have all completed, from pool 
2018-09-18 11:15:17,694   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : ResultStage 0 (show at logSession.scala:40) finished in 0.240 s
2018-09-18 11:15:17,700   INFO --- [main]  org.apache.spark.scheduler.DAGScheduler(line:54) : Job 0 finished: show at logSession.scala:40, took 0.328987 s
2018-09-18 11:15:17,726   INFO --- [main]  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator(line:54) : Code generated in 12.862779 ms
2018-09-18 11:15:17,805   INFO --- [main]  org.apache.spark.sql.execution.SparkSqlParser(line:54) : Parsing command: actionopvidio
2018-09-18 11:15:17,927   INFO --- [main]  org.apache.spark.sql.execution.SparkSqlParser(line:54) : Parsing command: SELECT id,uid,rid FROM actionopvidio
2018-09-18 11:15:17,981   INFO --- [Thread-1]  org.apache.spark.SparkContext(line:54) : Invoking stop() from shutdown hook
2018-09-18 11:15:17,986   INFO --- [Thread-1]  org.spark_project.jetty.server.ServerConnector(line:306) : Stopped Spark@58fe0499{HTTP/1.1}{0.0.0.0:4040}
2018-09-18 11:15:17,989   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@312ab28e{/stages/stage/kill,null,UNAVAILABLE,@Spark}
2018-09-18 11:15:17,989   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@1522d8a0{/jobs/job/kill,null,UNAVAILABLE,@Spark}
2018-09-18 11:15:17,989   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@bff34c6{/api,null,UNAVAILABLE,@Spark}
2018-09-18 11:15:17,990   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@7ec3394b{/,null,UNAVAILABLE,@Spark}
2018-09-18 11:15:17,990   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@758a34ce{/static,null,UNAVAILABLE,@Spark}
2018-09-18 11:15:17,990   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@2a7686a7{/executors/threadDump/json,null,UNAVAILABLE,@Spark}
2018-09-18 11:15:17,990   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@5c153b9e{/executors/threadDump,null,UNAVAILABLE,@Spark}
2018-09-18 11:15:17,991   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@4409e975{/executors/json,null,UNAVAILABLE,@Spark}
2018-09-18 11:15:17,991   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@4bc28c33{/executors,null,UNAVAILABLE,@Spark}
2018-09-18 11:15:17,991   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@1d0d6318{/environment/json,null,UNAVAILABLE,@Spark}
2018-09-18 11:15:17,991   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@13f17eb4{/environment,null,UNAVAILABLE,@Spark}
2018-09-18 11:15:17,992   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@f001896{/storage/rdd/json,null,UNAVAILABLE,@Spark}
2018-09-18 11:15:17,992   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@62f68dff{/storage/rdd,null,UNAVAILABLE,@Spark}
2018-09-18 11:15:17,992   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@765f05af{/storage/json,null,UNAVAILABLE,@Spark}
2018-09-18 11:15:17,992   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@463b4ac8{/storage,null,UNAVAILABLE,@Spark}
2018-09-18 11:15:17,993   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@18cebaa5{/stages/pool/json,null,UNAVAILABLE,@Spark}
2018-09-18 11:15:17,993   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@31e4bb20{/stages/pool,null,UNAVAILABLE,@Spark}
2018-09-18 11:15:17,993   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@7c098bb3{/stages/stage/json,null,UNAVAILABLE,@Spark}
2018-09-18 11:15:17,993   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@2f6e28bc{/stages/stage,null,UNAVAILABLE,@Spark}
2018-09-18 11:15:17,993   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@1ae67cad{/stages/json,null,UNAVAILABLE,@Spark}
2018-09-18 11:15:17,994   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@e98770d{/stages,null,UNAVAILABLE,@Spark}
2018-09-18 11:15:17,994   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@4ba302e0{/jobs/job/json,null,UNAVAILABLE,@Spark}
2018-09-18 11:15:17,994   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@57ac5227{/jobs/job,null,UNAVAILABLE,@Spark}
2018-09-18 11:15:17,994   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@43aaf813{/jobs/json,null,UNAVAILABLE,@Spark}
2018-09-18 11:15:17,995   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@33aeca0b{/jobs,null,UNAVAILABLE,@Spark}
2018-09-18 11:15:17,997   INFO --- [Thread-1]  org.apache.spark.ui.SparkUI(line:54) : Stopped Spark web UI at http://192.168.3.199:4040
2018-09-18 11:15:18,007   INFO --- [dispatcher-event-loop-3]  org.apache.spark.MapOutputTrackerMasterEndpoint(line:54) : MapOutputTrackerMasterEndpoint stopped!
2018-09-18 11:15:18,028   INFO --- [Thread-1]  org.apache.spark.storage.memory.MemoryStore(line:54) : MemoryStore cleared
2018-09-18 11:15:18,029   INFO --- [Thread-1]  org.apache.spark.storage.BlockManager(line:54) : BlockManager stopped
2018-09-18 11:15:18,034   INFO --- [Thread-1]  org.apache.spark.storage.BlockManagerMaster(line:54) : BlockManagerMaster stopped
2018-09-18 11:15:18,036   INFO --- [dispatcher-event-loop-0]  org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint(line:54) : OutputCommitCoordinator stopped!
2018-09-18 11:15:18,042   INFO --- [Thread-1]  org.apache.spark.SparkContext(line:54) : Successfully stopped SparkContext
2018-09-18 11:15:18,042   INFO --- [Thread-1]  org.apache.spark.util.ShutdownHookManager(line:54) : Shutdown hook called
2018-09-18 11:15:18,044   INFO --- [Thread-1]  org.apache.spark.util.ShutdownHookManager(line:54) : Deleting directory C:\Users\wshs\AppData\Local\Temp\spark-efa80abf-5704-4661-a5b8-be7ddc851201
2018-09-18 11:19:12,852   INFO --- [main]  org.apache.spark.SparkContext(line:54) : Running Spark version 2.1.1
2018-09-18 11:19:13,264   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing view acls to: wshs
2018-09-18 11:19:13,265   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing modify acls to: wshs
2018-09-18 11:19:13,265   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing view acls groups to: 
2018-09-18 11:19:13,266   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing modify acls groups to: 
2018-09-18 11:19:13,268   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(wshs); groups with view permissions: Set(); users  with modify permissions: Set(wshs); groups with modify permissions: Set()
2018-09-18 11:19:13,803   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'sparkDriver' on port 60246.
2018-09-18 11:19:13,819   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering MapOutputTracker
2018-09-18 11:19:13,840   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering BlockManagerMaster
2018-09-18 11:19:13,843   INFO --- [main]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-09-18 11:19:13,844   INFO --- [main]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : BlockManagerMasterEndpoint up
2018-09-18 11:19:13,859   INFO --- [main]  org.apache.spark.storage.DiskBlockManager(line:54) : Created local directory at C:\Users\wshs\AppData\Local\Temp\blockmgr-2ec2c78b-ff9a-4e95-8b8a-c4f929c2a38d
2018-09-18 11:19:13,878   INFO --- [main]  org.apache.spark.storage.memory.MemoryStore(line:54) : MemoryStore started with capacity 3.0 GB
2018-09-18 11:19:13,945   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering OutputCommitCoordinator
2018-09-18 11:19:14,026   INFO --- [main]  org.spark_project.jetty.util.log(line:186) : Logging initialized @2088ms
2018-09-18 11:19:14,100   INFO --- [main]  org.spark_project.jetty.server.Server(line:327) : jetty-9.2.z-SNAPSHOT
2018-09-18 11:19:14,113   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@5c8504fd{/jobs,null,AVAILABLE,@Spark}
2018-09-18 11:19:14,114   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@4b7e96a{/jobs/json,null,AVAILABLE,@Spark}
2018-09-18 11:19:14,114   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@6475472c{/jobs/job,null,AVAILABLE,@Spark}
2018-09-18 11:19:14,114   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@3f07b12c{/jobs/job/json,null,AVAILABLE,@Spark}
2018-09-18 11:19:14,115   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@4bd1f8dd{/stages,null,AVAILABLE,@Spark}
2018-09-18 11:19:14,115   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@7096b474{/stages/json,null,AVAILABLE,@Spark}
2018-09-18 11:19:14,115   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@3e14c16d{/stages/stage,null,AVAILABLE,@Spark}
2018-09-18 11:19:14,115   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@3c989952{/stages/stage/json,null,AVAILABLE,@Spark}
2018-09-18 11:19:14,116   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@784b990c{/stages/pool,null,AVAILABLE,@Spark}
2018-09-18 11:19:14,116   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@3d3ba765{/stages/pool/json,null,AVAILABLE,@Spark}
2018-09-18 11:19:14,116   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@25bc0606{/storage,null,AVAILABLE,@Spark}
2018-09-18 11:19:14,117   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@5d1659ea{/storage/json,null,AVAILABLE,@Spark}
2018-09-18 11:19:14,117   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@793138bd{/storage/rdd,null,AVAILABLE,@Spark}
2018-09-18 11:19:14,117   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@1951b871{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-09-18 11:19:14,118   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@5c18016b{/environment,null,AVAILABLE,@Spark}
2018-09-18 11:19:14,118   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@33aeca0b{/environment/json,null,AVAILABLE,@Spark}
2018-09-18 11:19:14,118   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@43aaf813{/executors,null,AVAILABLE,@Spark}
2018-09-18 11:19:14,119   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@57ac5227{/executors/json,null,AVAILABLE,@Spark}
2018-09-18 11:19:14,119   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@4ba302e0{/executors/threadDump,null,AVAILABLE,@Spark}
2018-09-18 11:19:14,119   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@e98770d{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-09-18 11:19:14,124   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@1ae67cad{/static,null,AVAILABLE,@Spark}
2018-09-18 11:19:14,125   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@2f6e28bc{/,null,AVAILABLE,@Spark}
2018-09-18 11:19:14,125   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@7c098bb3{/api,null,AVAILABLE,@Spark}
2018-09-18 11:19:14,126   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@31e4bb20{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-09-18 11:19:14,126   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@18cebaa5{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-09-18 11:19:14,137   INFO --- [main]  org.spark_project.jetty.server.ServerConnector(line:266) : Started Spark@1021f6c9{HTTP/1.1}{0.0.0.0:4040}
2018-09-18 11:19:14,138   INFO --- [main]  org.spark_project.jetty.server.Server(line:379) : Started @2200ms
2018-09-18 11:19:14,138   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'SparkUI' on port 4040.
2018-09-18 11:19:14,141   INFO --- [main]  org.apache.spark.ui.SparkUI(line:54) : Bound SparkUI to 0.0.0.0, and started at http://192.168.3.199:4040
2018-09-18 11:19:14,206   INFO --- [main]  org.apache.spark.executor.Executor(line:54) : Starting executor ID driver on host localhost
2018-09-18 11:19:14,250   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 60288.
2018-09-18 11:19:14,251   INFO --- [main]  org.apache.spark.network.netty.NettyBlockTransferService(line:54) : Server created on 192.168.3.199:60288
2018-09-18 11:19:14,252   INFO --- [main]  org.apache.spark.storage.BlockManager(line:54) : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-09-18 11:19:14,254   INFO --- [main]  org.apache.spark.storage.BlockManagerMaster(line:54) : Registering BlockManager BlockManagerId(driver, 192.168.3.199, 60288, None)
2018-09-18 11:19:14,256   INFO --- [dispatcher-event-loop-2]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : Registering block manager 192.168.3.199:60288 with 3.0 GB RAM, BlockManagerId(driver, 192.168.3.199, 60288, None)
2018-09-18 11:19:14,259   INFO --- [main]  org.apache.spark.storage.BlockManagerMaster(line:54) : Registered BlockManager BlockManagerId(driver, 192.168.3.199, 60288, None)
2018-09-18 11:19:14,259   INFO --- [main]  org.apache.spark.storage.BlockManager(line:54) : Initialized BlockManager: BlockManagerId(driver, 192.168.3.199, 60288, None)
2018-09-18 11:19:14,421   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@1b9ea3e3{/metrics/json,null,AVAILABLE,@Spark}
2018-09-18 11:19:14,438   WARN --- [main]  org.apache.spark.SparkContext(line:66) : Using an existing SparkContext; some configuration may not take effect.
2018-09-18 11:19:14,475   INFO --- [main]  org.apache.spark.sql.internal.SharedState(line:54) : Warehouse path is 'file:/C:/Users/wshs/IdeaProjects/logdataSession/spark-warehouse/'.
2018-09-18 11:19:14,480   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@5be82d43{/SQL,null,AVAILABLE,@Spark}
2018-09-18 11:19:14,481   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@345e5a17{/SQL/json,null,AVAILABLE,@Spark}
2018-09-18 11:19:14,481   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@77b7ffa4{/SQL/execution,null,AVAILABLE,@Spark}
2018-09-18 11:19:14,482   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@402f80f5{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-09-18 11:19:14,484   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@2102a4d5{/static/sql,null,AVAILABLE,@Spark}
2018-09-18 11:19:14,901   INFO --- [main]  org.apache.spark.storage.memory.MemoryStore(line:54) : Block broadcast_0 stored as values in memory (estimated size 127.1 KB, free 3.0 GB)
2018-09-18 11:19:15,028   INFO --- [main]  org.apache.spark.storage.memory.MemoryStore(line:54) : Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.3 KB, free 3.0 GB)
2018-09-18 11:19:15,032   INFO --- [dispatcher-event-loop-4]  org.apache.spark.storage.BlockManagerInfo(line:54) : Added broadcast_0_piece0 in memory on 192.168.3.199:60288 (size: 14.3 KB, free: 3.0 GB)
2018-09-18 11:19:15,036   INFO --- [main]  org.apache.spark.SparkContext(line:54) : Created broadcast 0 from textFile at logSession.scala:38
2018-09-18 11:19:17,126   INFO --- [main]  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator(line:54) : Code generated in 211.887456 ms
2018-09-18 11:19:17,200   INFO --- [main]  org.apache.hadoop.mapred.FileInputFormat(line:253) : Total input paths to process : 1
2018-09-18 11:19:17,223   INFO --- [main]  org.apache.spark.SparkContext(line:54) : Starting job: show at logSession.scala:41
2018-09-18 11:19:17,239   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Got job 0 (show at logSession.scala:41) with 1 output partitions
2018-09-18 11:19:17,240   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Final stage: ResultStage 0 (show at logSession.scala:41)
2018-09-18 11:19:17,240   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Parents of final stage: List()
2018-09-18 11:19:17,242   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Missing parents: List()
2018-09-18 11:19:17,247   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Submitting ResultStage 0 (MapPartitionsRDD[6] at show at logSession.scala:41), which has no missing parents
2018-09-18 11:19:17,283   INFO --- [dag-scheduler-event-loop]  org.apache.spark.storage.memory.MemoryStore(line:54) : Block broadcast_1 stored as values in memory (estimated size 12.1 KB, free 3.0 GB)
2018-09-18 11:19:17,287   INFO --- [dag-scheduler-event-loop]  org.apache.spark.storage.memory.MemoryStore(line:54) : Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.0 KB, free 3.0 GB)
2018-09-18 11:19:17,288   INFO --- [dispatcher-event-loop-5]  org.apache.spark.storage.BlockManagerInfo(line:54) : Added broadcast_1_piece0 in memory on 192.168.3.199:60288 (size: 5.0 KB, free: 3.0 GB)
2018-09-18 11:19:17,289   INFO --- [dag-scheduler-event-loop]  org.apache.spark.SparkContext(line:54) : Created broadcast 1 from broadcast at DAGScheduler.scala:996
2018-09-18 11:19:17,292   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[6] at show at logSession.scala:41)
2018-09-18 11:19:17,294   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.TaskSchedulerImpl(line:54) : Adding task set 0.0 with 1 tasks
2018-09-18 11:19:17,341   INFO --- [dispatcher-event-loop-6]  org.apache.spark.scheduler.TaskSetManager(line:54) : Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 5921 bytes)
2018-09-18 11:19:17,349   INFO --- [Executor task launch worker for task 0]  org.apache.spark.executor.Executor(line:54) : Running task 0.0 in stage 0.0 (TID 0)
2018-09-18 11:19:17,392   INFO --- [Executor task launch worker for task 0]  org.apache.spark.rdd.HadoopRDD(line:54) : Input split: file:/e:/r_actionopvidio.txt:0+188363
2018-09-18 11:19:17,398   INFO --- [Executor task launch worker for task 0]  org.apache.hadoop.conf.Configuration.deprecation(line:840) : mapred.tip.id is deprecated. Instead, use mapreduce.task.id
2018-09-18 11:19:17,398   INFO --- [Executor task launch worker for task 0]  org.apache.hadoop.conf.Configuration.deprecation(line:840) : mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
2018-09-18 11:19:17,398   INFO --- [Executor task launch worker for task 0]  org.apache.hadoop.conf.Configuration.deprecation(line:840) : mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
2018-09-18 11:19:17,398   INFO --- [Executor task launch worker for task 0]  org.apache.hadoop.conf.Configuration.deprecation(line:840) : mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
2018-09-18 11:19:17,399   INFO --- [Executor task launch worker for task 0]  org.apache.hadoop.conf.Configuration.deprecation(line:840) : mapred.job.id is deprecated. Instead, use mapreduce.job.id
2018-09-18 11:19:17,424  ERROR --- [Executor task launch worker for task 0]  org.apache.spark.executor.Executor(line:91) : Exception in task 0.0 in stage 0.0 (TID 0)
java.lang.NumberFormatException: For input string: ""771""
	at java.lang.NumberFormatException.forInputString(NumberFormatException.java:65)
	at java.lang.Integer.parseInt(Integer.java:569)
	at java.lang.Integer.parseInt(Integer.java:615)
	at scala.collection.immutable.StringLike$class.toInt(StringLike.scala:272)
	at scala.collection.immutable.StringOps.toInt(StringOps.scala:29)
	at logSession$$anonfun$2.apply(logSession.scala:40)
	at logSession$$anonfun$2.apply(logSession.scala:40)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1.hasNext(WholeStageCodegenExec.scala:377)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:231)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:225)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:827)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:827)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-09-18 11:19:17,447   WARN --- [task-result-getter-0]  org.apache.spark.scheduler.TaskSetManager(line:66) : Lost task 0.0 in stage 0.0 (TID 0, localhost, executor driver): java.lang.NumberFormatException: For input string: ""771""
	at java.lang.NumberFormatException.forInputString(NumberFormatException.java:65)
	at java.lang.Integer.parseInt(Integer.java:569)
	at java.lang.Integer.parseInt(Integer.java:615)
	at scala.collection.immutable.StringLike$class.toInt(StringLike.scala:272)
	at scala.collection.immutable.StringOps.toInt(StringOps.scala:29)
	at logSession$$anonfun$2.apply(logSession.scala:40)
	at logSession$$anonfun$2.apply(logSession.scala:40)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1.hasNext(WholeStageCodegenExec.scala:377)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:231)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:225)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:827)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:827)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

2018-09-18 11:19:17,449  ERROR --- [task-result-getter-0]  org.apache.spark.scheduler.TaskSetManager(line:70) : Task 0 in stage 0.0 failed 1 times; aborting job
2018-09-18 11:19:17,452   INFO --- [task-result-getter-0]  org.apache.spark.scheduler.TaskSchedulerImpl(line:54) : Removed TaskSet 0.0, whose tasks have all completed, from pool 
2018-09-18 11:19:17,456   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.TaskSchedulerImpl(line:54) : Cancelling stage 0
2018-09-18 11:19:17,457   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : ResultStage 0 (show at logSession.scala:41) failed in 0.153 s due to Job aborted due to stage failure: Task 0 in stage 0.0 failed 1 times, most recent failure: Lost task 0.0 in stage 0.0 (TID 0, localhost, executor driver): java.lang.NumberFormatException: For input string: ""771""
	at java.lang.NumberFormatException.forInputString(NumberFormatException.java:65)
	at java.lang.Integer.parseInt(Integer.java:569)
	at java.lang.Integer.parseInt(Integer.java:615)
	at scala.collection.immutable.StringLike$class.toInt(StringLike.scala:272)
	at scala.collection.immutable.StringOps.toInt(StringOps.scala:29)
	at logSession$$anonfun$2.apply(logSession.scala:40)
	at logSession$$anonfun$2.apply(logSession.scala:40)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1.hasNext(WholeStageCodegenExec.scala:377)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:231)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:225)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:827)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:827)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

Driver stacktrace:
2018-09-18 11:19:17,461   INFO --- [main]  org.apache.spark.scheduler.DAGScheduler(line:54) : Job 0 failed: show at logSession.scala:41, took 0.237329 s
2018-09-18 11:19:17,567   INFO --- [Thread-1]  org.apache.spark.SparkContext(line:54) : Invoking stop() from shutdown hook
2018-09-18 11:19:17,573   INFO --- [Thread-1]  org.spark_project.jetty.server.ServerConnector(line:306) : Stopped Spark@1021f6c9{HTTP/1.1}{0.0.0.0:4040}
2018-09-18 11:19:17,575   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@18cebaa5{/stages/stage/kill,null,UNAVAILABLE,@Spark}
2018-09-18 11:19:17,575   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@31e4bb20{/jobs/job/kill,null,UNAVAILABLE,@Spark}
2018-09-18 11:19:17,575   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@7c098bb3{/api,null,UNAVAILABLE,@Spark}
2018-09-18 11:19:17,576   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@2f6e28bc{/,null,UNAVAILABLE,@Spark}
2018-09-18 11:19:17,576   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@1ae67cad{/static,null,UNAVAILABLE,@Spark}
2018-09-18 11:19:17,576   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@e98770d{/executors/threadDump/json,null,UNAVAILABLE,@Spark}
2018-09-18 11:19:17,576   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@4ba302e0{/executors/threadDump,null,UNAVAILABLE,@Spark}
2018-09-18 11:19:17,577   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@57ac5227{/executors/json,null,UNAVAILABLE,@Spark}
2018-09-18 11:19:17,577   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@43aaf813{/executors,null,UNAVAILABLE,@Spark}
2018-09-18 11:19:17,577   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@33aeca0b{/environment/json,null,UNAVAILABLE,@Spark}
2018-09-18 11:19:17,578   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@5c18016b{/environment,null,UNAVAILABLE,@Spark}
2018-09-18 11:19:17,578   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@1951b871{/storage/rdd/json,null,UNAVAILABLE,@Spark}
2018-09-18 11:19:17,578   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@793138bd{/storage/rdd,null,UNAVAILABLE,@Spark}
2018-09-18 11:19:17,578   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@5d1659ea{/storage/json,null,UNAVAILABLE,@Spark}
2018-09-18 11:19:17,579   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@25bc0606{/storage,null,UNAVAILABLE,@Spark}
2018-09-18 11:19:17,579   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@3d3ba765{/stages/pool/json,null,UNAVAILABLE,@Spark}
2018-09-18 11:19:17,579   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@784b990c{/stages/pool,null,UNAVAILABLE,@Spark}
2018-09-18 11:19:17,580   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@3c989952{/stages/stage/json,null,UNAVAILABLE,@Spark}
2018-09-18 11:19:17,580   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@3e14c16d{/stages/stage,null,UNAVAILABLE,@Spark}
2018-09-18 11:19:17,580   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@7096b474{/stages/json,null,UNAVAILABLE,@Spark}
2018-09-18 11:19:17,580   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@4bd1f8dd{/stages,null,UNAVAILABLE,@Spark}
2018-09-18 11:19:17,580   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@3f07b12c{/jobs/job/json,null,UNAVAILABLE,@Spark}
2018-09-18 11:19:17,580   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@6475472c{/jobs/job,null,UNAVAILABLE,@Spark}
2018-09-18 11:19:17,581   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@4b7e96a{/jobs/json,null,UNAVAILABLE,@Spark}
2018-09-18 11:19:17,581   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@5c8504fd{/jobs,null,UNAVAILABLE,@Spark}
2018-09-18 11:19:17,583   INFO --- [Thread-1]  org.apache.spark.ui.SparkUI(line:54) : Stopped Spark web UI at http://192.168.3.199:4040
2018-09-18 11:19:17,584   INFO --- [dispatcher-event-loop-3]  org.apache.spark.storage.BlockManagerInfo(line:54) : Removed broadcast_0_piece0 on 192.168.3.199:60288 in memory (size: 14.3 KB, free: 3.0 GB)
2018-09-18 11:19:17,595   INFO --- [dispatcher-event-loop-6]  org.apache.spark.MapOutputTrackerMasterEndpoint(line:54) : MapOutputTrackerMasterEndpoint stopped!
2018-09-18 11:19:17,615   INFO --- [Thread-1]  org.apache.spark.storage.memory.MemoryStore(line:54) : MemoryStore cleared
2018-09-18 11:19:17,616   INFO --- [Thread-1]  org.apache.spark.storage.BlockManager(line:54) : BlockManager stopped
2018-09-18 11:19:17,617   INFO --- [Thread-1]  org.apache.spark.storage.BlockManagerMaster(line:54) : BlockManagerMaster stopped
2018-09-18 11:19:17,619   INFO --- [dispatcher-event-loop-3]  org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint(line:54) : OutputCommitCoordinator stopped!
2018-09-18 11:19:17,624   INFO --- [Thread-1]  org.apache.spark.SparkContext(line:54) : Successfully stopped SparkContext
2018-09-18 11:19:17,625   INFO --- [Thread-1]  org.apache.spark.util.ShutdownHookManager(line:54) : Shutdown hook called
2018-09-18 11:19:17,626   INFO --- [Thread-1]  org.apache.spark.util.ShutdownHookManager(line:54) : Deleting directory C:\Users\wshs\AppData\Local\Temp\spark-dc286e00-48e1-42d4-afb0-3324f9d254b6
2018-09-18 11:21:06,249   INFO --- [main]  org.apache.spark.SparkContext(line:54) : Running Spark version 2.1.1
2018-09-18 11:21:06,595   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing view acls to: wshs
2018-09-18 11:21:06,596   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing modify acls to: wshs
2018-09-18 11:21:06,597   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing view acls groups to: 
2018-09-18 11:21:06,597   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing modify acls groups to: 
2018-09-18 11:21:06,599   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(wshs); groups with view permissions: Set(); users  with modify permissions: Set(wshs); groups with modify permissions: Set()
2018-09-18 11:21:07,110   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'sparkDriver' on port 60437.
2018-09-18 11:21:07,131   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering MapOutputTracker
2018-09-18 11:21:07,150   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering BlockManagerMaster
2018-09-18 11:21:07,154   INFO --- [main]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-09-18 11:21:07,155   INFO --- [main]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : BlockManagerMasterEndpoint up
2018-09-18 11:21:07,168   INFO --- [main]  org.apache.spark.storage.DiskBlockManager(line:54) : Created local directory at C:\Users\wshs\AppData\Local\Temp\blockmgr-f7257492-6f0a-4268-ae74-57f41a61c6ca
2018-09-18 11:21:07,187   INFO --- [main]  org.apache.spark.storage.memory.MemoryStore(line:54) : MemoryStore started with capacity 3.0 GB
2018-09-18 11:21:07,252   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering OutputCommitCoordinator
2018-09-18 11:21:07,324   INFO --- [main]  org.spark_project.jetty.util.log(line:186) : Logging initialized @2014ms
2018-09-18 11:21:07,400   INFO --- [main]  org.spark_project.jetty.server.Server(line:327) : jetty-9.2.z-SNAPSHOT
2018-09-18 11:21:07,412   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@5c8504fd{/jobs,null,AVAILABLE,@Spark}
2018-09-18 11:21:07,413   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@4b7e96a{/jobs/json,null,AVAILABLE,@Spark}
2018-09-18 11:21:07,413   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@6475472c{/jobs/job,null,AVAILABLE,@Spark}
2018-09-18 11:21:07,413   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@3f07b12c{/jobs/job/json,null,AVAILABLE,@Spark}
2018-09-18 11:21:07,414   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@4bd1f8dd{/stages,null,AVAILABLE,@Spark}
2018-09-18 11:21:07,414   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@7096b474{/stages/json,null,AVAILABLE,@Spark}
2018-09-18 11:21:07,414   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@3e14c16d{/stages/stage,null,AVAILABLE,@Spark}
2018-09-18 11:21:07,414   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@3c989952{/stages/stage/json,null,AVAILABLE,@Spark}
2018-09-18 11:21:07,414   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@784b990c{/stages/pool,null,AVAILABLE,@Spark}
2018-09-18 11:21:07,415   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@3d3ba765{/stages/pool/json,null,AVAILABLE,@Spark}
2018-09-18 11:21:07,415   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@25bc0606{/storage,null,AVAILABLE,@Spark}
2018-09-18 11:21:07,415   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@5d1659ea{/storage/json,null,AVAILABLE,@Spark}
2018-09-18 11:21:07,415   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@793138bd{/storage/rdd,null,AVAILABLE,@Spark}
2018-09-18 11:21:07,416   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@1951b871{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-09-18 11:21:07,416   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@5c18016b{/environment,null,AVAILABLE,@Spark}
2018-09-18 11:21:07,416   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@33aeca0b{/environment/json,null,AVAILABLE,@Spark}
2018-09-18 11:21:07,417   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@43aaf813{/executors,null,AVAILABLE,@Spark}
2018-09-18 11:21:07,417   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@57ac5227{/executors/json,null,AVAILABLE,@Spark}
2018-09-18 11:21:07,417   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@4ba302e0{/executors/threadDump,null,AVAILABLE,@Spark}
2018-09-18 11:21:07,417   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@e98770d{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-09-18 11:21:07,422   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@1ae67cad{/static,null,AVAILABLE,@Spark}
2018-09-18 11:21:07,423   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@2f6e28bc{/,null,AVAILABLE,@Spark}
2018-09-18 11:21:07,423   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@7c098bb3{/api,null,AVAILABLE,@Spark}
2018-09-18 11:21:07,424   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@31e4bb20{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-09-18 11:21:07,424   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@18cebaa5{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-09-18 11:21:07,434   INFO --- [main]  org.spark_project.jetty.server.ServerConnector(line:266) : Started Spark@1021f6c9{HTTP/1.1}{0.0.0.0:4040}
2018-09-18 11:21:07,435   INFO --- [main]  org.spark_project.jetty.server.Server(line:379) : Started @2127ms
2018-09-18 11:21:07,435   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'SparkUI' on port 4040.
2018-09-18 11:21:07,438   INFO --- [main]  org.apache.spark.ui.SparkUI(line:54) : Bound SparkUI to 0.0.0.0, and started at http://192.168.3.199:4040
2018-09-18 11:21:07,516   INFO --- [main]  org.apache.spark.executor.Executor(line:54) : Starting executor ID driver on host localhost
2018-09-18 11:21:07,566   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 60478.
2018-09-18 11:21:07,567   INFO --- [main]  org.apache.spark.network.netty.NettyBlockTransferService(line:54) : Server created on 192.168.3.199:60478
2018-09-18 11:21:07,569   INFO --- [main]  org.apache.spark.storage.BlockManager(line:54) : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-09-18 11:21:07,570   INFO --- [main]  org.apache.spark.storage.BlockManagerMaster(line:54) : Registering BlockManager BlockManagerId(driver, 192.168.3.199, 60478, None)
2018-09-18 11:21:07,572   INFO --- [dispatcher-event-loop-2]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : Registering block manager 192.168.3.199:60478 with 3.0 GB RAM, BlockManagerId(driver, 192.168.3.199, 60478, None)
2018-09-18 11:21:07,575   INFO --- [main]  org.apache.spark.storage.BlockManagerMaster(line:54) : Registered BlockManager BlockManagerId(driver, 192.168.3.199, 60478, None)
2018-09-18 11:21:07,575   INFO --- [main]  org.apache.spark.storage.BlockManager(line:54) : Initialized BlockManager: BlockManagerId(driver, 192.168.3.199, 60478, None)
2018-09-18 11:21:07,726   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@1b9ea3e3{/metrics/json,null,AVAILABLE,@Spark}
2018-09-18 11:21:07,745   WARN --- [main]  org.apache.spark.SparkContext(line:66) : Using an existing SparkContext; some configuration may not take effect.
2018-09-18 11:21:07,781   INFO --- [main]  org.apache.spark.sql.internal.SharedState(line:54) : Warehouse path is 'file:/C:/Users/wshs/IdeaProjects/logdataSession/spark-warehouse/'.
2018-09-18 11:21:07,786   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@5be82d43{/SQL,null,AVAILABLE,@Spark}
2018-09-18 11:21:07,787   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@345e5a17{/SQL/json,null,AVAILABLE,@Spark}
2018-09-18 11:21:07,787   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@77b7ffa4{/SQL/execution,null,AVAILABLE,@Spark}
2018-09-18 11:21:07,788   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@402f80f5{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-09-18 11:21:07,789   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@2102a4d5{/static/sql,null,AVAILABLE,@Spark}
2018-09-18 11:21:08,191   INFO --- [main]  org.apache.spark.storage.memory.MemoryStore(line:54) : Block broadcast_0 stored as values in memory (estimated size 127.1 KB, free 3.0 GB)
2018-09-18 11:21:08,323   INFO --- [main]  org.apache.spark.storage.memory.MemoryStore(line:54) : Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.3 KB, free 3.0 GB)
2018-09-18 11:21:08,328   INFO --- [dispatcher-event-loop-4]  org.apache.spark.storage.BlockManagerInfo(line:54) : Added broadcast_0_piece0 in memory on 192.168.3.199:60478 (size: 14.3 KB, free: 3.0 GB)
2018-09-18 11:21:08,332   INFO --- [main]  org.apache.spark.SparkContext(line:54) : Created broadcast 0 from textFile at logSession.scala:38
2018-09-18 11:21:08,428   INFO --- [main]  org.apache.hadoop.mapred.FileInputFormat(line:253) : Total input paths to process : 1
2018-09-18 11:21:08,472   INFO --- [main]  org.apache.spark.SparkContext(line:54) : Starting job: collect at logSession.scala:39
2018-09-18 11:21:08,488   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Got job 0 (collect at logSession.scala:39) with 2 output partitions
2018-09-18 11:21:08,488   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Final stage: ResultStage 0 (collect at logSession.scala:39)
2018-09-18 11:21:08,489   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Parents of final stage: List()
2018-09-18 11:21:08,491   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Missing parents: List()
2018-09-18 11:21:08,498   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Submitting ResultStage 0 (e:\r_actionopvidio.txt MapPartitionsRDD[1] at textFile at logSession.scala:38), which has no missing parents
2018-09-18 11:21:08,514   INFO --- [dag-scheduler-event-loop]  org.apache.spark.storage.memory.MemoryStore(line:54) : Block broadcast_1 stored as values in memory (estimated size 3.2 KB, free 3.0 GB)
2018-09-18 11:21:08,519   INFO --- [dag-scheduler-event-loop]  org.apache.spark.storage.memory.MemoryStore(line:54) : Block broadcast_1_piece0 stored as bytes in memory (estimated size 1936.0 B, free 3.0 GB)
2018-09-18 11:21:08,520   INFO --- [dispatcher-event-loop-5]  org.apache.spark.storage.BlockManagerInfo(line:54) : Added broadcast_1_piece0 in memory on 192.168.3.199:60478 (size: 1936.0 B, free: 3.0 GB)
2018-09-18 11:21:08,521   INFO --- [dag-scheduler-event-loop]  org.apache.spark.SparkContext(line:54) : Created broadcast 1 from broadcast at DAGScheduler.scala:996
2018-09-18 11:21:08,551   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Submitting 2 missing tasks from ResultStage 0 (e:\r_actionopvidio.txt MapPartitionsRDD[1] at textFile at logSession.scala:38)
2018-09-18 11:21:08,552   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.TaskSchedulerImpl(line:54) : Adding task set 0.0 with 2 tasks
2018-09-18 11:21:08,592   INFO --- [dispatcher-event-loop-6]  org.apache.spark.scheduler.TaskSetManager(line:54) : Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 5976 bytes)
2018-09-18 11:21:08,594   INFO --- [dispatcher-event-loop-6]  org.apache.spark.scheduler.TaskSetManager(line:54) : Starting task 1.0 in stage 0.0 (TID 1, localhost, executor driver, partition 1, PROCESS_LOCAL, 5976 bytes)
2018-09-18 11:21:08,600   INFO --- [Executor task launch worker for task 1]  org.apache.spark.executor.Executor(line:54) : Running task 1.0 in stage 0.0 (TID 1)
2018-09-18 11:21:08,601   INFO --- [Executor task launch worker for task 0]  org.apache.spark.executor.Executor(line:54) : Running task 0.0 in stage 0.0 (TID 0)
2018-09-18 11:21:08,629   INFO --- [Executor task launch worker for task 1]  org.apache.spark.rdd.HadoopRDD(line:54) : Input split: file:/e:/r_actionopvidio.txt:188363+188364
2018-09-18 11:21:08,629   INFO --- [Executor task launch worker for task 0]  org.apache.spark.rdd.HadoopRDD(line:54) : Input split: file:/e:/r_actionopvidio.txt:0+188363
2018-09-18 11:21:08,637   INFO --- [Executor task launch worker for task 0]  org.apache.hadoop.conf.Configuration.deprecation(line:840) : mapred.tip.id is deprecated. Instead, use mapreduce.task.id
2018-09-18 11:21:08,637   INFO --- [Executor task launch worker for task 1]  org.apache.hadoop.conf.Configuration.deprecation(line:840) : mapred.tip.id is deprecated. Instead, use mapreduce.task.id
2018-09-18 11:21:08,637   INFO --- [Executor task launch worker for task 0]  org.apache.hadoop.conf.Configuration.deprecation(line:840) : mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
2018-09-18 11:21:08,637   INFO --- [Executor task launch worker for task 1]  org.apache.hadoop.conf.Configuration.deprecation(line:840) : mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
2018-09-18 11:21:08,637   INFO --- [Executor task launch worker for task 0]  org.apache.hadoop.conf.Configuration.deprecation(line:840) : mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
2018-09-18 11:21:08,637   INFO --- [Executor task launch worker for task 1]  org.apache.hadoop.conf.Configuration.deprecation(line:840) : mapred.job.id is deprecated. Instead, use mapreduce.job.id
2018-09-18 11:21:08,690   INFO --- [Executor task launch worker for task 0]  org.apache.spark.executor.Executor(line:54) : Finished task 0.0 in stage 0.0 (TID 0). 193193 bytes result sent to driver
2018-09-18 11:21:08,690   INFO --- [Executor task launch worker for task 1]  org.apache.spark.executor.Executor(line:54) : Finished task 1.0 in stage 0.0 (TID 1). 193184 bytes result sent to driver
2018-09-18 11:21:08,707   INFO --- [task-result-getter-1]  org.apache.spark.scheduler.TaskSetManager(line:54) : Finished task 1.0 in stage 0.0 (TID 1) in 112 ms on localhost (executor driver) (1/2)
2018-09-18 11:21:08,707   INFO --- [task-result-getter-0]  org.apache.spark.scheduler.TaskSetManager(line:54) : Finished task 0.0 in stage 0.0 (TID 0) in 136 ms on localhost (executor driver) (2/2)
2018-09-18 11:21:08,709   INFO --- [task-result-getter-0]  org.apache.spark.scheduler.TaskSchedulerImpl(line:54) : Removed TaskSet 0.0, whose tasks have all completed, from pool 
2018-09-18 11:21:08,712   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : ResultStage 0 (collect at logSession.scala:39) finished in 0.151 s
2018-09-18 11:21:08,718   INFO --- [main]  org.apache.spark.scheduler.DAGScheduler(line:54) : Job 0 finished: collect at logSession.scala:39, took 0.245904 s
2018-09-18 11:21:10,871   INFO --- [main]  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator(line:54) : Code generated in 221.298447 ms
2018-09-18 11:21:10,895   INFO --- [main]  org.apache.spark.SparkContext(line:54) : Starting job: show at logSession.scala:42
2018-09-18 11:21:10,896   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Got job 1 (show at logSession.scala:42) with 1 output partitions
2018-09-18 11:21:10,897   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Final stage: ResultStage 1 (show at logSession.scala:42)
2018-09-18 11:21:10,897   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Parents of final stage: List()
2018-09-18 11:21:10,897   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Missing parents: List()
2018-09-18 11:21:10,898   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Submitting ResultStage 1 (MapPartitionsRDD[6] at show at logSession.scala:42), which has no missing parents
2018-09-18 11:21:10,905   INFO --- [dag-scheduler-event-loop]  org.apache.spark.storage.memory.MemoryStore(line:54) : Block broadcast_2 stored as values in memory (estimated size 12.1 KB, free 3.0 GB)
2018-09-18 11:21:10,909   INFO --- [dag-scheduler-event-loop]  org.apache.spark.storage.memory.MemoryStore(line:54) : Block broadcast_2_piece0 stored as bytes in memory (estimated size 5.0 KB, free 3.0 GB)
2018-09-18 11:21:10,912   INFO --- [dispatcher-event-loop-3]  org.apache.spark.storage.BlockManagerInfo(line:54) : Added broadcast_2_piece0 in memory on 192.168.3.199:60478 (size: 5.0 KB, free: 3.0 GB)
2018-09-18 11:21:10,912   INFO --- [dag-scheduler-event-loop]  org.apache.spark.SparkContext(line:54) : Created broadcast 2 from broadcast at DAGScheduler.scala:996
2018-09-18 11:21:10,913   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[6] at show at logSession.scala:42)
2018-09-18 11:21:10,913   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.TaskSchedulerImpl(line:54) : Adding task set 1.0 with 1 tasks
2018-09-18 11:21:10,915   INFO --- [dispatcher-event-loop-4]  org.apache.spark.scheduler.TaskSetManager(line:54) : Starting task 0.0 in stage 1.0 (TID 2, localhost, executor driver, partition 0, PROCESS_LOCAL, 5921 bytes)
2018-09-18 11:21:10,915   INFO --- [Executor task launch worker for task 2]  org.apache.spark.executor.Executor(line:54) : Running task 0.0 in stage 1.0 (TID 2)
2018-09-18 11:21:10,924   INFO --- [Executor task launch worker for task 2]  org.apache.spark.rdd.HadoopRDD(line:54) : Input split: file:/e:/r_actionopvidio.txt:0+188363
2018-09-18 11:21:10,937  ERROR --- [Executor task launch worker for task 2]  org.apache.spark.executor.Executor(line:91) : Exception in task 0.0 in stage 1.0 (TID 2)
java.lang.NumberFormatException: For input string: ""771""
	at java.lang.NumberFormatException.forInputString(NumberFormatException.java:65)
	at java.lang.Integer.parseInt(Integer.java:569)
	at java.lang.Integer.parseInt(Integer.java:615)
	at scala.collection.immutable.StringLike$class.toInt(StringLike.scala:272)
	at scala.collection.immutable.StringOps.toInt(StringOps.scala:29)
	at logSession$$anonfun$2.apply(logSession.scala:41)
	at logSession$$anonfun$2.apply(logSession.scala:41)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1.hasNext(WholeStageCodegenExec.scala:377)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:231)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:225)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:827)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:827)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-09-18 11:21:11,060   WARN --- [task-result-getter-2]  org.apache.spark.scheduler.TaskSetManager(line:66) : Lost task 0.0 in stage 1.0 (TID 2, localhost, executor driver): java.lang.NumberFormatException: For input string: ""771""
	at java.lang.NumberFormatException.forInputString(NumberFormatException.java:65)
	at java.lang.Integer.parseInt(Integer.java:569)
	at java.lang.Integer.parseInt(Integer.java:615)
	at scala.collection.immutable.StringLike$class.toInt(StringLike.scala:272)
	at scala.collection.immutable.StringOps.toInt(StringOps.scala:29)
	at logSession$$anonfun$2.apply(logSession.scala:41)
	at logSession$$anonfun$2.apply(logSession.scala:41)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1.hasNext(WholeStageCodegenExec.scala:377)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:231)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:225)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:827)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:827)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

2018-09-18 11:21:11,062  ERROR --- [task-result-getter-2]  org.apache.spark.scheduler.TaskSetManager(line:70) : Task 0 in stage 1.0 failed 1 times; aborting job
2018-09-18 11:21:11,063   INFO --- [task-result-getter-2]  org.apache.spark.scheduler.TaskSchedulerImpl(line:54) : Removed TaskSet 1.0, whose tasks have all completed, from pool 
2018-09-18 11:21:11,066   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.TaskSchedulerImpl(line:54) : Cancelling stage 1
2018-09-18 11:21:11,068   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : ResultStage 1 (show at logSession.scala:42) failed in 0.154 s due to Job aborted due to stage failure: Task 0 in stage 1.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1.0 (TID 2, localhost, executor driver): java.lang.NumberFormatException: For input string: ""771""
	at java.lang.NumberFormatException.forInputString(NumberFormatException.java:65)
	at java.lang.Integer.parseInt(Integer.java:569)
	at java.lang.Integer.parseInt(Integer.java:615)
	at scala.collection.immutable.StringLike$class.toInt(StringLike.scala:272)
	at scala.collection.immutable.StringOps.toInt(StringOps.scala:29)
	at logSession$$anonfun$2.apply(logSession.scala:41)
	at logSession$$anonfun$2.apply(logSession.scala:41)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1.hasNext(WholeStageCodegenExec.scala:377)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:231)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:225)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:827)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:827)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

Driver stacktrace:
2018-09-18 11:21:11,069   INFO --- [main]  org.apache.spark.scheduler.DAGScheduler(line:54) : Job 1 failed: show at logSession.scala:42, took 0.172558 s
2018-09-18 11:21:11,069   INFO --- [dispatcher-event-loop-2]  org.apache.spark.storage.BlockManagerInfo(line:54) : Removed broadcast_1_piece0 on 192.168.3.199:60478 in memory (size: 1936.0 B, free: 3.0 GB)
2018-09-18 11:21:11,080   INFO --- [Thread-1]  org.apache.spark.SparkContext(line:54) : Invoking stop() from shutdown hook
2018-09-18 11:21:11,084   INFO --- [Thread-1]  org.spark_project.jetty.server.ServerConnector(line:306) : Stopped Spark@1021f6c9{HTTP/1.1}{0.0.0.0:4040}
2018-09-18 11:21:11,086   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@18cebaa5{/stages/stage/kill,null,UNAVAILABLE,@Spark}
2018-09-18 11:21:11,086   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@31e4bb20{/jobs/job/kill,null,UNAVAILABLE,@Spark}
2018-09-18 11:21:11,086   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@7c098bb3{/api,null,UNAVAILABLE,@Spark}
2018-09-18 11:21:11,087   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@2f6e28bc{/,null,UNAVAILABLE,@Spark}
2018-09-18 11:21:11,087   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@1ae67cad{/static,null,UNAVAILABLE,@Spark}
2018-09-18 11:21:11,087   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@e98770d{/executors/threadDump/json,null,UNAVAILABLE,@Spark}
2018-09-18 11:21:11,087   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@4ba302e0{/executors/threadDump,null,UNAVAILABLE,@Spark}
2018-09-18 11:21:11,087   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@57ac5227{/executors/json,null,UNAVAILABLE,@Spark}
2018-09-18 11:21:11,087   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@43aaf813{/executors,null,UNAVAILABLE,@Spark}
2018-09-18 11:21:11,087   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@33aeca0b{/environment/json,null,UNAVAILABLE,@Spark}
2018-09-18 11:21:11,088   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@5c18016b{/environment,null,UNAVAILABLE,@Spark}
2018-09-18 11:21:11,088   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@1951b871{/storage/rdd/json,null,UNAVAILABLE,@Spark}
2018-09-18 11:21:11,088   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@793138bd{/storage/rdd,null,UNAVAILABLE,@Spark}
2018-09-18 11:21:11,088   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@5d1659ea{/storage/json,null,UNAVAILABLE,@Spark}
2018-09-18 11:21:11,088   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@25bc0606{/storage,null,UNAVAILABLE,@Spark}
2018-09-18 11:21:11,089   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@3d3ba765{/stages/pool/json,null,UNAVAILABLE,@Spark}
2018-09-18 11:21:11,089   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@784b990c{/stages/pool,null,UNAVAILABLE,@Spark}
2018-09-18 11:21:11,089   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@3c989952{/stages/stage/json,null,UNAVAILABLE,@Spark}
2018-09-18 11:21:11,089   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@3e14c16d{/stages/stage,null,UNAVAILABLE,@Spark}
2018-09-18 11:21:11,089   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@7096b474{/stages/json,null,UNAVAILABLE,@Spark}
2018-09-18 11:21:11,089   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@4bd1f8dd{/stages,null,UNAVAILABLE,@Spark}
2018-09-18 11:21:11,089   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@3f07b12c{/jobs/job/json,null,UNAVAILABLE,@Spark}
2018-09-18 11:21:11,090   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@6475472c{/jobs/job,null,UNAVAILABLE,@Spark}
2018-09-18 11:21:11,090   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@4b7e96a{/jobs/json,null,UNAVAILABLE,@Spark}
2018-09-18 11:21:11,090   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@5c8504fd{/jobs,null,UNAVAILABLE,@Spark}
2018-09-18 11:21:11,092   INFO --- [Thread-1]  org.apache.spark.ui.SparkUI(line:54) : Stopped Spark web UI at http://192.168.3.199:4040
2018-09-18 11:21:11,100   INFO --- [dispatcher-event-loop-4]  org.apache.spark.MapOutputTrackerMasterEndpoint(line:54) : MapOutputTrackerMasterEndpoint stopped!
2018-09-18 11:21:11,122   INFO --- [Thread-1]  org.apache.spark.storage.memory.MemoryStore(line:54) : MemoryStore cleared
2018-09-18 11:21:11,123   INFO --- [Thread-1]  org.apache.spark.storage.BlockManager(line:54) : BlockManager stopped
2018-09-18 11:21:11,124   INFO --- [Thread-1]  org.apache.spark.storage.BlockManagerMaster(line:54) : BlockManagerMaster stopped
2018-09-18 11:21:11,126   INFO --- [dispatcher-event-loop-2]  org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint(line:54) : OutputCommitCoordinator stopped!
2018-09-18 11:21:11,130   INFO --- [Thread-1]  org.apache.spark.SparkContext(line:54) : Successfully stopped SparkContext
2018-09-18 11:21:11,131   INFO --- [Thread-1]  org.apache.spark.util.ShutdownHookManager(line:54) : Shutdown hook called
2018-09-18 11:21:11,131   INFO --- [Thread-1]  org.apache.spark.util.ShutdownHookManager(line:54) : Deleting directory C:\Users\wshs\AppData\Local\Temp\spark-a4ec764d-5df8-4f18-9335-0262a840bd8b
2018-09-18 11:53:09,135   INFO --- [main]  org.apache.spark.SparkContext(line:54) : Running Spark version 2.1.1
2018-09-18 11:53:09,489   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing view acls to: wshs
2018-09-18 11:53:09,490   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing modify acls to: wshs
2018-09-18 11:53:09,491   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing view acls groups to: 
2018-09-18 11:53:09,492   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing modify acls groups to: 
2018-09-18 11:53:09,494   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(wshs); groups with view permissions: Set(); users  with modify permissions: Set(wshs); groups with modify permissions: Set()
2018-09-18 11:53:10,006   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'sparkDriver' on port 62346.
2018-09-18 11:53:10,025   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering MapOutputTracker
2018-09-18 11:53:10,042   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering BlockManagerMaster
2018-09-18 11:53:10,046   INFO --- [main]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-09-18 11:53:10,047   INFO --- [main]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : BlockManagerMasterEndpoint up
2018-09-18 11:53:10,060   INFO --- [main]  org.apache.spark.storage.DiskBlockManager(line:54) : Created local directory at C:\Users\wshs\AppData\Local\Temp\blockmgr-3ef6a9ac-188d-4829-9af6-d65c32237b26
2018-09-18 11:53:10,078   INFO --- [main]  org.apache.spark.storage.memory.MemoryStore(line:54) : MemoryStore started with capacity 3.0 GB
2018-09-18 11:53:10,140   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering OutputCommitCoordinator
2018-09-18 11:53:10,209   INFO --- [main]  org.spark_project.jetty.util.log(line:186) : Logging initialized @2007ms
2018-09-18 11:53:10,284   INFO --- [main]  org.spark_project.jetty.server.Server(line:327) : jetty-9.2.z-SNAPSHOT
2018-09-18 11:53:10,297   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@5c8504fd{/jobs,null,AVAILABLE,@Spark}
2018-09-18 11:53:10,297   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@4b7e96a{/jobs/json,null,AVAILABLE,@Spark}
2018-09-18 11:53:10,297   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@6475472c{/jobs/job,null,AVAILABLE,@Spark}
2018-09-18 11:53:10,298   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@3f07b12c{/jobs/job/json,null,AVAILABLE,@Spark}
2018-09-18 11:53:10,298   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@4bd1f8dd{/stages,null,AVAILABLE,@Spark}
2018-09-18 11:53:10,298   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@7096b474{/stages/json,null,AVAILABLE,@Spark}
2018-09-18 11:53:10,299   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@3e14c16d{/stages/stage,null,AVAILABLE,@Spark}
2018-09-18 11:53:10,299   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@3c989952{/stages/stage/json,null,AVAILABLE,@Spark}
2018-09-18 11:53:10,299   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@784b990c{/stages/pool,null,AVAILABLE,@Spark}
2018-09-18 11:53:10,299   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@3d3ba765{/stages/pool/json,null,AVAILABLE,@Spark}
2018-09-18 11:53:10,300   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@25bc0606{/storage,null,AVAILABLE,@Spark}
2018-09-18 11:53:10,300   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@5d1659ea{/storage/json,null,AVAILABLE,@Spark}
2018-09-18 11:53:10,300   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@793138bd{/storage/rdd,null,AVAILABLE,@Spark}
2018-09-18 11:53:10,300   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@1951b871{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-09-18 11:53:10,300   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@5c18016b{/environment,null,AVAILABLE,@Spark}
2018-09-18 11:53:10,301   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@33aeca0b{/environment/json,null,AVAILABLE,@Spark}
2018-09-18 11:53:10,301   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@43aaf813{/executors,null,AVAILABLE,@Spark}
2018-09-18 11:53:10,301   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@57ac5227{/executors/json,null,AVAILABLE,@Spark}
2018-09-18 11:53:10,301   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@4ba302e0{/executors/threadDump,null,AVAILABLE,@Spark}
2018-09-18 11:53:10,302   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@e98770d{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-09-18 11:53:10,307   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@1ae67cad{/static,null,AVAILABLE,@Spark}
2018-09-18 11:53:10,307   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@2f6e28bc{/,null,AVAILABLE,@Spark}
2018-09-18 11:53:10,308   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@7c098bb3{/api,null,AVAILABLE,@Spark}
2018-09-18 11:53:10,308   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@31e4bb20{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-09-18 11:53:10,308   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@18cebaa5{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-09-18 11:53:10,320   INFO --- [main]  org.spark_project.jetty.server.ServerConnector(line:266) : Started Spark@1021f6c9{HTTP/1.1}{0.0.0.0:4040}
2018-09-18 11:53:10,321   INFO --- [main]  org.spark_project.jetty.server.Server(line:379) : Started @2119ms
2018-09-18 11:53:10,321   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'SparkUI' on port 4040.
2018-09-18 11:53:10,324   INFO --- [main]  org.apache.spark.ui.SparkUI(line:54) : Bound SparkUI to 0.0.0.0, and started at http://192.168.3.199:4040
2018-09-18 11:53:10,397   INFO --- [main]  org.apache.spark.executor.Executor(line:54) : Starting executor ID driver on host localhost
2018-09-18 11:53:10,445   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 62388.
2018-09-18 11:53:10,446   INFO --- [main]  org.apache.spark.network.netty.NettyBlockTransferService(line:54) : Server created on 192.168.3.199:62388
2018-09-18 11:53:10,447   INFO --- [main]  org.apache.spark.storage.BlockManager(line:54) : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-09-18 11:53:10,449   INFO --- [main]  org.apache.spark.storage.BlockManagerMaster(line:54) : Registering BlockManager BlockManagerId(driver, 192.168.3.199, 62388, None)
2018-09-18 11:53:10,453   INFO --- [dispatcher-event-loop-3]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : Registering block manager 192.168.3.199:62388 with 3.0 GB RAM, BlockManagerId(driver, 192.168.3.199, 62388, None)
2018-09-18 11:53:10,455   INFO --- [main]  org.apache.spark.storage.BlockManagerMaster(line:54) : Registered BlockManager BlockManagerId(driver, 192.168.3.199, 62388, None)
2018-09-18 11:53:10,455   INFO --- [main]  org.apache.spark.storage.BlockManager(line:54) : Initialized BlockManager: BlockManagerId(driver, 192.168.3.199, 62388, None)
2018-09-18 11:53:10,606   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@1b9ea3e3{/metrics/json,null,AVAILABLE,@Spark}
2018-09-18 11:53:10,623   WARN --- [main]  org.apache.spark.SparkContext(line:66) : Using an existing SparkContext; some configuration may not take effect.
2018-09-18 11:53:10,661   INFO --- [main]  org.apache.spark.sql.internal.SharedState(line:54) : Warehouse path is 'file:/C:/Users/wshs/IdeaProjects/logdataSession/spark-warehouse/'.
2018-09-18 11:53:10,667   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@5be82d43{/SQL,null,AVAILABLE,@Spark}
2018-09-18 11:53:10,667   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@345e5a17{/SQL/json,null,AVAILABLE,@Spark}
2018-09-18 11:53:10,668   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@77b7ffa4{/SQL/execution,null,AVAILABLE,@Spark}
2018-09-18 11:53:10,668   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@402f80f5{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-09-18 11:53:10,670   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@2102a4d5{/static/sql,null,AVAILABLE,@Spark}
2018-09-18 11:53:11,075   INFO --- [main]  org.apache.spark.storage.memory.MemoryStore(line:54) : Block broadcast_0 stored as values in memory (estimated size 127.1 KB, free 3.0 GB)
2018-09-18 11:53:11,198   INFO --- [main]  org.apache.spark.storage.memory.MemoryStore(line:54) : Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.3 KB, free 3.0 GB)
2018-09-18 11:53:11,203   INFO --- [dispatcher-event-loop-5]  org.apache.spark.storage.BlockManagerInfo(line:54) : Added broadcast_0_piece0 in memory on 192.168.3.199:62388 (size: 14.3 KB, free: 3.0 GB)
2018-09-18 11:53:11,206   INFO --- [main]  org.apache.spark.SparkContext(line:54) : Created broadcast 0 from textFile at logSession.scala:39
2018-09-18 11:53:11,289   INFO --- [main]  org.apache.hadoop.mapred.FileInputFormat(line:253) : Total input paths to process : 1
2018-09-18 11:53:11,331   INFO --- [main]  org.apache.spark.SparkContext(line:54) : Starting job: collect at logSession.scala:40
2018-09-18 11:53:11,349   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Got job 0 (collect at logSession.scala:40) with 2 output partitions
2018-09-18 11:53:11,349   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Final stage: ResultStage 0 (collect at logSession.scala:40)
2018-09-18 11:53:11,350   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Parents of final stage: List()
2018-09-18 11:53:11,351   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Missing parents: List()
2018-09-18 11:53:11,358   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Submitting ResultStage 0 (e:\r_actionopvidio.txt MapPartitionsRDD[1] at textFile at logSession.scala:39), which has no missing parents
2018-09-18 11:53:11,373   INFO --- [dag-scheduler-event-loop]  org.apache.spark.storage.memory.MemoryStore(line:54) : Block broadcast_1 stored as values in memory (estimated size 3.2 KB, free 3.0 GB)
2018-09-18 11:53:11,377   INFO --- [dag-scheduler-event-loop]  org.apache.spark.storage.memory.MemoryStore(line:54) : Block broadcast_1_piece0 stored as bytes in memory (estimated size 1936.0 B, free 3.0 GB)
2018-09-18 11:53:11,404   INFO --- [dispatcher-event-loop-1]  org.apache.spark.storage.BlockManagerInfo(line:54) : Added broadcast_1_piece0 in memory on 192.168.3.199:62388 (size: 1936.0 B, free: 3.0 GB)
2018-09-18 11:53:11,405   INFO --- [dag-scheduler-event-loop]  org.apache.spark.SparkContext(line:54) : Created broadcast 1 from broadcast at DAGScheduler.scala:996
2018-09-18 11:53:11,409   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Submitting 2 missing tasks from ResultStage 0 (e:\r_actionopvidio.txt MapPartitionsRDD[1] at textFile at logSession.scala:39)
2018-09-18 11:53:11,410   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.TaskSchedulerImpl(line:54) : Adding task set 0.0 with 2 tasks
2018-09-18 11:53:11,446   INFO --- [dispatcher-event-loop-6]  org.apache.spark.scheduler.TaskSetManager(line:54) : Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 5976 bytes)
2018-09-18 11:53:11,449   INFO --- [dispatcher-event-loop-6]  org.apache.spark.scheduler.TaskSetManager(line:54) : Starting task 1.0 in stage 0.0 (TID 1, localhost, executor driver, partition 1, PROCESS_LOCAL, 5976 bytes)
2018-09-18 11:53:11,455   INFO --- [Executor task launch worker for task 1]  org.apache.spark.executor.Executor(line:54) : Running task 1.0 in stage 0.0 (TID 1)
2018-09-18 11:53:11,455   INFO --- [Executor task launch worker for task 0]  org.apache.spark.executor.Executor(line:54) : Running task 0.0 in stage 0.0 (TID 0)
2018-09-18 11:53:11,486   INFO --- [Executor task launch worker for task 0]  org.apache.spark.rdd.HadoopRDD(line:54) : Input split: file:/e:/r_actionopvidio.txt:0+188363
2018-09-18 11:53:11,486   INFO --- [Executor task launch worker for task 1]  org.apache.spark.rdd.HadoopRDD(line:54) : Input split: file:/e:/r_actionopvidio.txt:188363+188364
2018-09-18 11:53:11,493   INFO --- [Executor task launch worker for task 1]  org.apache.hadoop.conf.Configuration.deprecation(line:840) : mapred.tip.id is deprecated. Instead, use mapreduce.task.id
2018-09-18 11:53:11,493   INFO --- [Executor task launch worker for task 0]  org.apache.hadoop.conf.Configuration.deprecation(line:840) : mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
2018-09-18 11:53:11,493   INFO --- [Executor task launch worker for task 1]  org.apache.hadoop.conf.Configuration.deprecation(line:840) : mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
2018-09-18 11:53:11,493   INFO --- [Executor task launch worker for task 0]  org.apache.hadoop.conf.Configuration.deprecation(line:840) : mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
2018-09-18 11:53:11,493   INFO --- [Executor task launch worker for task 1]  org.apache.hadoop.conf.Configuration.deprecation(line:840) : mapred.job.id is deprecated. Instead, use mapreduce.job.id
2018-09-18 11:53:11,543   INFO --- [Executor task launch worker for task 1]  org.apache.spark.executor.Executor(line:54) : Finished task 1.0 in stage 0.0 (TID 1). 193184 bytes result sent to driver
2018-09-18 11:53:11,543   INFO --- [Executor task launch worker for task 0]  org.apache.spark.executor.Executor(line:54) : Finished task 0.0 in stage 0.0 (TID 0). 193193 bytes result sent to driver
2018-09-18 11:53:11,560   INFO --- [task-result-getter-1]  org.apache.spark.scheduler.TaskSetManager(line:54) : Finished task 0.0 in stage 0.0 (TID 0) in 130 ms on localhost (executor driver) (1/2)
2018-09-18 11:53:11,561   INFO --- [task-result-getter-0]  org.apache.spark.scheduler.TaskSetManager(line:54) : Finished task 1.0 in stage 0.0 (TID 1) in 113 ms on localhost (executor driver) (2/2)
2018-09-18 11:53:11,562   INFO --- [task-result-getter-0]  org.apache.spark.scheduler.TaskSchedulerImpl(line:54) : Removed TaskSet 0.0, whose tasks have all completed, from pool 
2018-09-18 11:53:11,565   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : ResultStage 0 (collect at logSession.scala:40) finished in 0.146 s
2018-09-18 11:53:11,569   INFO --- [main]  org.apache.spark.scheduler.DAGScheduler(line:54) : Job 0 finished: collect at logSession.scala:40, took 0.237168 s
2018-09-18 11:53:13,662   INFO --- [main]  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator(line:54) : Code generated in 205.920141 ms
2018-09-18 11:53:13,685   INFO --- [main]  org.apache.spark.SparkContext(line:54) : Starting job: show at logSession.scala:43
2018-09-18 11:53:13,687   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Got job 1 (show at logSession.scala:43) with 1 output partitions
2018-09-18 11:53:13,687   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Final stage: ResultStage 1 (show at logSession.scala:43)
2018-09-18 11:53:13,687   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Parents of final stage: List()
2018-09-18 11:53:13,687   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Missing parents: List()
2018-09-18 11:53:13,688   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Submitting ResultStage 1 (MapPartitionsRDD[6] at show at logSession.scala:43), which has no missing parents
2018-09-18 11:53:13,693   INFO --- [dag-scheduler-event-loop]  org.apache.spark.storage.memory.MemoryStore(line:54) : Block broadcast_2 stored as values in memory (estimated size 12.1 KB, free 3.0 GB)
2018-09-18 11:53:13,698   INFO --- [dag-scheduler-event-loop]  org.apache.spark.storage.memory.MemoryStore(line:54) : Block broadcast_2_piece0 stored as bytes in memory (estimated size 5.0 KB, free 3.0 GB)
2018-09-18 11:53:13,701   INFO --- [dispatcher-event-loop-4]  org.apache.spark.storage.BlockManagerInfo(line:54) : Added broadcast_2_piece0 in memory on 192.168.3.199:62388 (size: 5.0 KB, free: 3.0 GB)
2018-09-18 11:53:13,701   INFO --- [dag-scheduler-event-loop]  org.apache.spark.SparkContext(line:54) : Created broadcast 2 from broadcast at DAGScheduler.scala:996
2018-09-18 11:53:13,702   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[6] at show at logSession.scala:43)
2018-09-18 11:53:13,702   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.TaskSchedulerImpl(line:54) : Adding task set 1.0 with 1 tasks
2018-09-18 11:53:13,703   INFO --- [dispatcher-event-loop-5]  org.apache.spark.scheduler.TaskSetManager(line:54) : Starting task 0.0 in stage 1.0 (TID 2, localhost, executor driver, partition 0, PROCESS_LOCAL, 5921 bytes)
2018-09-18 11:53:13,704   INFO --- [Executor task launch worker for task 2]  org.apache.spark.executor.Executor(line:54) : Running task 0.0 in stage 1.0 (TID 2)
2018-09-18 11:53:13,711   INFO --- [Executor task launch worker for task 2]  org.apache.spark.rdd.HadoopRDD(line:54) : Input split: file:/e:/r_actionopvidio.txt:0+188363
2018-09-18 11:53:13,724  ERROR --- [Executor task launch worker for task 2]  org.apache.spark.executor.Executor(line:91) : Exception in task 0.0 in stage 1.0 (TID 2)
java.lang.NumberFormatException: For input string: ""771""
	at java.lang.NumberFormatException.forInputString(NumberFormatException.java:65)
	at java.lang.Integer.parseInt(Integer.java:569)
	at java.lang.Integer.parseInt(Integer.java:615)
	at scala.collection.immutable.StringLike$class.toInt(StringLike.scala:272)
	at scala.collection.immutable.StringOps.toInt(StringOps.scala:29)
	at logSession$$anonfun$2.apply(logSession.scala:42)
	at logSession$$anonfun$2.apply(logSession.scala:42)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1.hasNext(WholeStageCodegenExec.scala:377)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:231)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:225)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:827)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:827)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-09-18 11:53:13,850   WARN --- [task-result-getter-2]  org.apache.spark.scheduler.TaskSetManager(line:66) : Lost task 0.0 in stage 1.0 (TID 2, localhost, executor driver): java.lang.NumberFormatException: For input string: ""771""
	at java.lang.NumberFormatException.forInputString(NumberFormatException.java:65)
	at java.lang.Integer.parseInt(Integer.java:569)
	at java.lang.Integer.parseInt(Integer.java:615)
	at scala.collection.immutable.StringLike$class.toInt(StringLike.scala:272)
	at scala.collection.immutable.StringOps.toInt(StringOps.scala:29)
	at logSession$$anonfun$2.apply(logSession.scala:42)
	at logSession$$anonfun$2.apply(logSession.scala:42)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1.hasNext(WholeStageCodegenExec.scala:377)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:231)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:225)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:827)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:827)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

2018-09-18 11:53:13,852  ERROR --- [task-result-getter-2]  org.apache.spark.scheduler.TaskSetManager(line:70) : Task 0 in stage 1.0 failed 1 times; aborting job
2018-09-18 11:53:13,853   INFO --- [task-result-getter-2]  org.apache.spark.scheduler.TaskSchedulerImpl(line:54) : Removed TaskSet 1.0, whose tasks have all completed, from pool 
2018-09-18 11:53:13,857   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.TaskSchedulerImpl(line:54) : Cancelling stage 1
2018-09-18 11:53:13,859   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : ResultStage 1 (show at logSession.scala:43) failed in 0.156 s due to Job aborted due to stage failure: Task 0 in stage 1.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1.0 (TID 2, localhost, executor driver): java.lang.NumberFormatException: For input string: ""771""
	at java.lang.NumberFormatException.forInputString(NumberFormatException.java:65)
	at java.lang.Integer.parseInt(Integer.java:569)
	at java.lang.Integer.parseInt(Integer.java:615)
	at scala.collection.immutable.StringLike$class.toInt(StringLike.scala:272)
	at scala.collection.immutable.StringOps.toInt(StringOps.scala:29)
	at logSession$$anonfun$2.apply(logSession.scala:42)
	at logSession$$anonfun$2.apply(logSession.scala:42)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1.hasNext(WholeStageCodegenExec.scala:377)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:231)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:225)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:827)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:827)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

Driver stacktrace:
2018-09-18 11:53:13,860   INFO --- [main]  org.apache.spark.scheduler.DAGScheduler(line:54) : Job 1 failed: show at logSession.scala:43, took 0.174711 s
2018-09-18 11:53:13,863   INFO --- [dispatcher-event-loop-3]  org.apache.spark.storage.BlockManagerInfo(line:54) : Removed broadcast_1_piece0 on 192.168.3.199:62388 in memory (size: 1936.0 B, free: 3.0 GB)
2018-09-18 11:53:13,872   INFO --- [Thread-1]  org.apache.spark.SparkContext(line:54) : Invoking stop() from shutdown hook
2018-09-18 11:53:13,877   INFO --- [Thread-1]  org.spark_project.jetty.server.ServerConnector(line:306) : Stopped Spark@1021f6c9{HTTP/1.1}{0.0.0.0:4040}
2018-09-18 11:53:13,880   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@18cebaa5{/stages/stage/kill,null,UNAVAILABLE,@Spark}
2018-09-18 11:53:13,881   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@31e4bb20{/jobs/job/kill,null,UNAVAILABLE,@Spark}
2018-09-18 11:53:13,881   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@7c098bb3{/api,null,UNAVAILABLE,@Spark}
2018-09-18 11:53:13,882   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@2f6e28bc{/,null,UNAVAILABLE,@Spark}
2018-09-18 11:53:13,882   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@1ae67cad{/static,null,UNAVAILABLE,@Spark}
2018-09-18 11:53:13,882   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@e98770d{/executors/threadDump/json,null,UNAVAILABLE,@Spark}
2018-09-18 11:53:13,882   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@4ba302e0{/executors/threadDump,null,UNAVAILABLE,@Spark}
2018-09-18 11:53:13,883   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@57ac5227{/executors/json,null,UNAVAILABLE,@Spark}
2018-09-18 11:53:13,883   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@43aaf813{/executors,null,UNAVAILABLE,@Spark}
2018-09-18 11:53:13,883   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@33aeca0b{/environment/json,null,UNAVAILABLE,@Spark}
2018-09-18 11:53:13,883   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@5c18016b{/environment,null,UNAVAILABLE,@Spark}
2018-09-18 11:53:13,883   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@1951b871{/storage/rdd/json,null,UNAVAILABLE,@Spark}
2018-09-18 11:53:13,883   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@793138bd{/storage/rdd,null,UNAVAILABLE,@Spark}
2018-09-18 11:53:13,883   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@5d1659ea{/storage/json,null,UNAVAILABLE,@Spark}
2018-09-18 11:53:13,884   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@25bc0606{/storage,null,UNAVAILABLE,@Spark}
2018-09-18 11:53:13,884   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@3d3ba765{/stages/pool/json,null,UNAVAILABLE,@Spark}
2018-09-18 11:53:13,884   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@784b990c{/stages/pool,null,UNAVAILABLE,@Spark}
2018-09-18 11:53:13,884   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@3c989952{/stages/stage/json,null,UNAVAILABLE,@Spark}
2018-09-18 11:53:13,884   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@3e14c16d{/stages/stage,null,UNAVAILABLE,@Spark}
2018-09-18 11:53:13,884   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@7096b474{/stages/json,null,UNAVAILABLE,@Spark}
2018-09-18 11:53:13,884   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@4bd1f8dd{/stages,null,UNAVAILABLE,@Spark}
2018-09-18 11:53:13,887   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@3f07b12c{/jobs/job/json,null,UNAVAILABLE,@Spark}
2018-09-18 11:53:13,887   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@6475472c{/jobs/job,null,UNAVAILABLE,@Spark}
2018-09-18 11:53:13,887   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@4b7e96a{/jobs/json,null,UNAVAILABLE,@Spark}
2018-09-18 11:53:13,887   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@5c8504fd{/jobs,null,UNAVAILABLE,@Spark}
2018-09-18 11:53:13,889   INFO --- [Thread-1]  org.apache.spark.ui.SparkUI(line:54) : Stopped Spark web UI at http://192.168.3.199:4040
2018-09-18 11:53:13,897   INFO --- [dispatcher-event-loop-5]  org.apache.spark.MapOutputTrackerMasterEndpoint(line:54) : MapOutputTrackerMasterEndpoint stopped!
2018-09-18 11:53:13,927   INFO --- [Thread-1]  org.apache.spark.storage.memory.MemoryStore(line:54) : MemoryStore cleared
2018-09-18 11:53:13,927   INFO --- [Thread-1]  org.apache.spark.storage.BlockManager(line:54) : BlockManager stopped
2018-09-18 11:53:13,928   INFO --- [Thread-1]  org.apache.spark.storage.BlockManagerMaster(line:54) : BlockManagerMaster stopped
2018-09-18 11:53:13,930   INFO --- [dispatcher-event-loop-3]  org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint(line:54) : OutputCommitCoordinator stopped!
2018-09-18 11:53:13,935   INFO --- [Thread-1]  org.apache.spark.SparkContext(line:54) : Successfully stopped SparkContext
2018-09-18 11:53:13,936   INFO --- [Thread-1]  org.apache.spark.util.ShutdownHookManager(line:54) : Shutdown hook called
2018-09-18 11:53:13,937   INFO --- [Thread-1]  org.apache.spark.util.ShutdownHookManager(line:54) : Deleting directory C:\Users\wshs\AppData\Local\Temp\spark-14d74d10-944d-49d5-a200-8f8a56b14666
2018-09-18 13:29:08,890   INFO --- [main]  org.apache.spark.SparkContext(line:54) : Running Spark version 2.1.1
2018-09-18 13:29:09,278   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing view acls to: wshs
2018-09-18 13:29:09,279   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing modify acls to: wshs
2018-09-18 13:29:09,279   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing view acls groups to: 
2018-09-18 13:29:09,280   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing modify acls groups to: 
2018-09-18 13:29:09,282   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(wshs); groups with view permissions: Set(); users  with modify permissions: Set(wshs); groups with modify permissions: Set()
2018-09-18 13:29:09,775   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'sparkDriver' on port 51622.
2018-09-18 13:29:09,797   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering MapOutputTracker
2018-09-18 13:29:09,815   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering BlockManagerMaster
2018-09-18 13:29:09,818   INFO --- [main]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-09-18 13:29:09,818   INFO --- [main]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : BlockManagerMasterEndpoint up
2018-09-18 13:29:09,832   INFO --- [main]  org.apache.spark.storage.DiskBlockManager(line:54) : Created local directory at C:\Users\wshs\AppData\Local\Temp\blockmgr-b8da01fe-5af6-47ec-a5da-1964b5a74ef6
2018-09-18 13:29:09,851   INFO --- [main]  org.apache.spark.storage.memory.MemoryStore(line:54) : MemoryStore started with capacity 3.0 GB
2018-09-18 13:29:09,917   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering OutputCommitCoordinator
2018-09-18 13:29:09,989   INFO --- [main]  org.spark_project.jetty.util.log(line:186) : Logging initialized @2026ms
2018-09-18 13:29:10,063   INFO --- [main]  org.spark_project.jetty.server.Server(line:327) : jetty-9.2.z-SNAPSHOT
2018-09-18 13:29:10,076   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@5c8504fd{/jobs,null,AVAILABLE,@Spark}
2018-09-18 13:29:10,076   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@4b7e96a{/jobs/json,null,AVAILABLE,@Spark}
2018-09-18 13:29:10,077   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@6475472c{/jobs/job,null,AVAILABLE,@Spark}
2018-09-18 13:29:10,077   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@3f07b12c{/jobs/job/json,null,AVAILABLE,@Spark}
2018-09-18 13:29:10,078   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@4bd1f8dd{/stages,null,AVAILABLE,@Spark}
2018-09-18 13:29:10,078   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@7096b474{/stages/json,null,AVAILABLE,@Spark}
2018-09-18 13:29:10,078   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@3e14c16d{/stages/stage,null,AVAILABLE,@Spark}
2018-09-18 13:29:10,079   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@3c989952{/stages/stage/json,null,AVAILABLE,@Spark}
2018-09-18 13:29:10,079   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@784b990c{/stages/pool,null,AVAILABLE,@Spark}
2018-09-18 13:29:10,079   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@3d3ba765{/stages/pool/json,null,AVAILABLE,@Spark}
2018-09-18 13:29:10,079   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@25bc0606{/storage,null,AVAILABLE,@Spark}
2018-09-18 13:29:10,079   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@5d1659ea{/storage/json,null,AVAILABLE,@Spark}
2018-09-18 13:29:10,080   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@793138bd{/storage/rdd,null,AVAILABLE,@Spark}
2018-09-18 13:29:10,080   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@1951b871{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-09-18 13:29:10,080   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@5c18016b{/environment,null,AVAILABLE,@Spark}
2018-09-18 13:29:10,080   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@33aeca0b{/environment/json,null,AVAILABLE,@Spark}
2018-09-18 13:29:10,081   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@43aaf813{/executors,null,AVAILABLE,@Spark}
2018-09-18 13:29:10,081   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@57ac5227{/executors/json,null,AVAILABLE,@Spark}
2018-09-18 13:29:10,081   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@4ba302e0{/executors/threadDump,null,AVAILABLE,@Spark}
2018-09-18 13:29:10,081   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@e98770d{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-09-18 13:29:10,086   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@1ae67cad{/static,null,AVAILABLE,@Spark}
2018-09-18 13:29:10,086   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@2f6e28bc{/,null,AVAILABLE,@Spark}
2018-09-18 13:29:10,087   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@7c098bb3{/api,null,AVAILABLE,@Spark}
2018-09-18 13:29:10,088   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@31e4bb20{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-09-18 13:29:10,088   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@18cebaa5{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-09-18 13:29:10,099   INFO --- [main]  org.spark_project.jetty.server.ServerConnector(line:266) : Started Spark@1021f6c9{HTTP/1.1}{0.0.0.0:4040}
2018-09-18 13:29:10,100   INFO --- [main]  org.spark_project.jetty.server.Server(line:379) : Started @2138ms
2018-09-18 13:29:10,100   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'SparkUI' on port 4040.
2018-09-18 13:29:10,103   INFO --- [main]  org.apache.spark.ui.SparkUI(line:54) : Bound SparkUI to 0.0.0.0, and started at http://192.168.3.199:4040
2018-09-18 13:29:10,171   INFO --- [main]  org.apache.spark.executor.Executor(line:54) : Starting executor ID driver on host localhost
2018-09-18 13:29:10,217   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 51663.
2018-09-18 13:29:10,218   INFO --- [main]  org.apache.spark.network.netty.NettyBlockTransferService(line:54) : Server created on 192.168.3.199:51663
2018-09-18 13:29:10,220   INFO --- [main]  org.apache.spark.storage.BlockManager(line:54) : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-09-18 13:29:10,222   INFO --- [main]  org.apache.spark.storage.BlockManagerMaster(line:54) : Registering BlockManager BlockManagerId(driver, 192.168.3.199, 51663, None)
2018-09-18 13:29:10,224   INFO --- [dispatcher-event-loop-7]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : Registering block manager 192.168.3.199:51663 with 3.0 GB RAM, BlockManagerId(driver, 192.168.3.199, 51663, None)
2018-09-18 13:29:10,227   INFO --- [main]  org.apache.spark.storage.BlockManagerMaster(line:54) : Registered BlockManager BlockManagerId(driver, 192.168.3.199, 51663, None)
2018-09-18 13:29:10,227   INFO --- [main]  org.apache.spark.storage.BlockManager(line:54) : Initialized BlockManager: BlockManagerId(driver, 192.168.3.199, 51663, None)
2018-09-18 13:29:10,378   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@1b9ea3e3{/metrics/json,null,AVAILABLE,@Spark}
2018-09-18 13:29:10,397   WARN --- [main]  org.apache.spark.SparkContext(line:66) : Using an existing SparkContext; some configuration may not take effect.
2018-09-18 13:29:10,432   INFO --- [main]  org.apache.spark.sql.internal.SharedState(line:54) : Warehouse path is 'file:/C:/Users/wshs/IdeaProjects/logdataSession/spark-warehouse/'.
2018-09-18 13:29:10,438   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@5be82d43{/SQL,null,AVAILABLE,@Spark}
2018-09-18 13:29:10,439   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@345e5a17{/SQL/json,null,AVAILABLE,@Spark}
2018-09-18 13:29:10,440   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@77b7ffa4{/SQL/execution,null,AVAILABLE,@Spark}
2018-09-18 13:29:10,440   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@402f80f5{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-09-18 13:29:10,442   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@2102a4d5{/static/sql,null,AVAILABLE,@Spark}
2018-09-18 13:29:10,835   INFO --- [main]  org.apache.spark.storage.memory.MemoryStore(line:54) : Block broadcast_0 stored as values in memory (estimated size 127.1 KB, free 3.0 GB)
2018-09-18 13:29:10,976   INFO --- [main]  org.apache.spark.storage.memory.MemoryStore(line:54) : Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.3 KB, free 3.0 GB)
2018-09-18 13:29:10,980   INFO --- [dispatcher-event-loop-4]  org.apache.spark.storage.BlockManagerInfo(line:54) : Added broadcast_0_piece0 in memory on 192.168.3.199:51663 (size: 14.3 KB, free: 3.0 GB)
2018-09-18 13:29:10,985   INFO --- [main]  org.apache.spark.SparkContext(line:54) : Created broadcast 0 from textFile at logSession.scala:39
2018-09-18 13:29:11,065   INFO --- [main]  org.apache.hadoop.mapred.FileInputFormat(line:253) : Total input paths to process : 1
2018-09-18 13:29:11,106   INFO --- [main]  org.apache.spark.SparkContext(line:54) : Starting job: collect at logSession.scala:40
2018-09-18 13:29:11,122   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Got job 0 (collect at logSession.scala:40) with 2 output partitions
2018-09-18 13:29:11,122   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Final stage: ResultStage 0 (collect at logSession.scala:40)
2018-09-18 13:29:11,124   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Parents of final stage: List()
2018-09-18 13:29:11,125   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Missing parents: List()
2018-09-18 13:29:11,132   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Submitting ResultStage 0 (e:\r_actionopvidio.txt MapPartitionsRDD[1] at textFile at logSession.scala:39), which has no missing parents
2018-09-18 13:29:11,146   INFO --- [dag-scheduler-event-loop]  org.apache.spark.storage.memory.MemoryStore(line:54) : Block broadcast_1 stored as values in memory (estimated size 3.2 KB, free 3.0 GB)
2018-09-18 13:29:11,150   INFO --- [dag-scheduler-event-loop]  org.apache.spark.storage.memory.MemoryStore(line:54) : Block broadcast_1_piece0 stored as bytes in memory (estimated size 1936.0 B, free 3.0 GB)
2018-09-18 13:29:11,151   INFO --- [dispatcher-event-loop-3]  org.apache.spark.storage.BlockManagerInfo(line:54) : Added broadcast_1_piece0 in memory on 192.168.3.199:51663 (size: 1936.0 B, free: 3.0 GB)
2018-09-18 13:29:11,177   INFO --- [dag-scheduler-event-loop]  org.apache.spark.SparkContext(line:54) : Created broadcast 1 from broadcast at DAGScheduler.scala:996
2018-09-18 13:29:11,180   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Submitting 2 missing tasks from ResultStage 0 (e:\r_actionopvidio.txt MapPartitionsRDD[1] at textFile at logSession.scala:39)
2018-09-18 13:29:11,182   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.TaskSchedulerImpl(line:54) : Adding task set 0.0 with 2 tasks
2018-09-18 13:29:11,219   INFO --- [dispatcher-event-loop-1]  org.apache.spark.scheduler.TaskSetManager(line:54) : Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 5976 bytes)
2018-09-18 13:29:11,222   INFO --- [dispatcher-event-loop-1]  org.apache.spark.scheduler.TaskSetManager(line:54) : Starting task 1.0 in stage 0.0 (TID 1, localhost, executor driver, partition 1, PROCESS_LOCAL, 5976 bytes)
2018-09-18 13:29:11,228   INFO --- [Executor task launch worker for task 0]  org.apache.spark.executor.Executor(line:54) : Running task 0.0 in stage 0.0 (TID 0)
2018-09-18 13:29:11,228   INFO --- [Executor task launch worker for task 1]  org.apache.spark.executor.Executor(line:54) : Running task 1.0 in stage 0.0 (TID 1)
2018-09-18 13:29:11,263   INFO --- [Executor task launch worker for task 1]  org.apache.spark.rdd.HadoopRDD(line:54) : Input split: file:/e:/r_actionopvidio.txt:188363+188364
2018-09-18 13:29:11,263   INFO --- [Executor task launch worker for task 0]  org.apache.spark.rdd.HadoopRDD(line:54) : Input split: file:/e:/r_actionopvidio.txt:0+188363
2018-09-18 13:29:11,272   INFO --- [Executor task launch worker for task 1]  org.apache.hadoop.conf.Configuration.deprecation(line:840) : mapred.tip.id is deprecated. Instead, use mapreduce.task.id
2018-09-18 13:29:11,272   INFO --- [Executor task launch worker for task 0]  org.apache.hadoop.conf.Configuration.deprecation(line:840) : mapred.tip.id is deprecated. Instead, use mapreduce.task.id
2018-09-18 13:29:11,273   INFO --- [Executor task launch worker for task 1]  org.apache.hadoop.conf.Configuration.deprecation(line:840) : mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
2018-09-18 13:29:11,273   INFO --- [Executor task launch worker for task 0]  org.apache.hadoop.conf.Configuration.deprecation(line:840) : mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
2018-09-18 13:29:11,273   INFO --- [Executor task launch worker for task 1]  org.apache.hadoop.conf.Configuration.deprecation(line:840) : mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
2018-09-18 13:29:11,273   INFO --- [Executor task launch worker for task 0]  org.apache.hadoop.conf.Configuration.deprecation(line:840) : mapred.job.id is deprecated. Instead, use mapreduce.job.id
2018-09-18 13:29:11,326   INFO --- [Executor task launch worker for task 0]  org.apache.spark.executor.Executor(line:54) : Finished task 0.0 in stage 0.0 (TID 0). 193283 bytes result sent to driver
2018-09-18 13:29:11,326   INFO --- [Executor task launch worker for task 1]  org.apache.spark.executor.Executor(line:54) : Finished task 1.0 in stage 0.0 (TID 1). 193094 bytes result sent to driver
2018-09-18 13:29:11,343   INFO --- [task-result-getter-0]  org.apache.spark.scheduler.TaskSetManager(line:54) : Finished task 0.0 in stage 0.0 (TID 0) in 142 ms on localhost (executor driver) (1/2)
2018-09-18 13:29:11,344   INFO --- [task-result-getter-1]  org.apache.spark.scheduler.TaskSetManager(line:54) : Finished task 1.0 in stage 0.0 (TID 1) in 123 ms on localhost (executor driver) (2/2)
2018-09-18 13:29:11,345   INFO --- [task-result-getter-1]  org.apache.spark.scheduler.TaskSchedulerImpl(line:54) : Removed TaskSet 0.0, whose tasks have all completed, from pool 
2018-09-18 13:29:11,348   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : ResultStage 0 (collect at logSession.scala:40) finished in 0.157 s
2018-09-18 13:29:11,353   INFO --- [main]  org.apache.spark.scheduler.DAGScheduler(line:54) : Job 0 finished: collect at logSession.scala:40, took 0.247147 s
2018-09-18 13:29:13,429   INFO --- [main]  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator(line:54) : Code generated in 220.065021 ms
2018-09-18 13:29:13,452   INFO --- [main]  org.apache.spark.SparkContext(line:54) : Starting job: show at logSession.scala:43
2018-09-18 13:29:13,454   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Got job 1 (show at logSession.scala:43) with 1 output partitions
2018-09-18 13:29:13,454   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Final stage: ResultStage 1 (show at logSession.scala:43)
2018-09-18 13:29:13,454   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Parents of final stage: List()
2018-09-18 13:29:13,454   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Missing parents: List()
2018-09-18 13:29:13,455   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Submitting ResultStage 1 (MapPartitionsRDD[6] at show at logSession.scala:43), which has no missing parents
2018-09-18 13:29:13,461   INFO --- [dag-scheduler-event-loop]  org.apache.spark.storage.memory.MemoryStore(line:54) : Block broadcast_2 stored as values in memory (estimated size 12.1 KB, free 3.0 GB)
2018-09-18 13:29:13,464   INFO --- [dag-scheduler-event-loop]  org.apache.spark.storage.memory.MemoryStore(line:54) : Block broadcast_2_piece0 stored as bytes in memory (estimated size 5.0 KB, free 3.0 GB)
2018-09-18 13:29:13,477   INFO --- [dispatcher-event-loop-6]  org.apache.spark.storage.BlockManagerInfo(line:54) : Added broadcast_2_piece0 in memory on 192.168.3.199:51663 (size: 5.0 KB, free: 3.0 GB)
2018-09-18 13:29:13,478   INFO --- [dag-scheduler-event-loop]  org.apache.spark.SparkContext(line:54) : Created broadcast 2 from broadcast at DAGScheduler.scala:996
2018-09-18 13:29:13,478   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[6] at show at logSession.scala:43)
2018-09-18 13:29:13,478   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.TaskSchedulerImpl(line:54) : Adding task set 1.0 with 1 tasks
2018-09-18 13:29:13,480   INFO --- [dispatcher-event-loop-4]  org.apache.spark.scheduler.TaskSetManager(line:54) : Starting task 0.0 in stage 1.0 (TID 2, localhost, executor driver, partition 0, PROCESS_LOCAL, 5921 bytes)
2018-09-18 13:29:13,480   INFO --- [Executor task launch worker for task 2]  org.apache.spark.executor.Executor(line:54) : Running task 0.0 in stage 1.0 (TID 2)
2018-09-18 13:29:13,487   INFO --- [Executor task launch worker for task 2]  org.apache.spark.rdd.HadoopRDD(line:54) : Input split: file:/e:/r_actionopvidio.txt:0+188363
2018-09-18 13:29:13,507  ERROR --- [Executor task launch worker for task 2]  org.apache.spark.executor.Executor(line:91) : Exception in task 0.0 in stage 1.0 (TID 2)
java.lang.NumberFormatException: For input string: "18:05:19"
	at java.lang.NumberFormatException.forInputString(NumberFormatException.java:65)
	at java.lang.Integer.parseInt(Integer.java:580)
	at java.lang.Integer.parseInt(Integer.java:615)
	at scala.collection.immutable.StringLike$class.toInt(StringLike.scala:272)
	at scala.collection.immutable.StringOps.toInt(StringOps.scala:29)
	at logSession$$anonfun$2.apply(logSession.scala:42)
	at logSession$$anonfun$2.apply(logSession.scala:42)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1.hasNext(WholeStageCodegenExec.scala:377)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:231)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:225)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:827)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:827)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-09-18 13:29:13,612   WARN --- [task-result-getter-2]  org.apache.spark.scheduler.TaskSetManager(line:66) : Lost task 0.0 in stage 1.0 (TID 2, localhost, executor driver): java.lang.NumberFormatException: For input string: "18:05:19"
	at java.lang.NumberFormatException.forInputString(NumberFormatException.java:65)
	at java.lang.Integer.parseInt(Integer.java:580)
	at java.lang.Integer.parseInt(Integer.java:615)
	at scala.collection.immutable.StringLike$class.toInt(StringLike.scala:272)
	at scala.collection.immutable.StringOps.toInt(StringOps.scala:29)
	at logSession$$anonfun$2.apply(logSession.scala:42)
	at logSession$$anonfun$2.apply(logSession.scala:42)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1.hasNext(WholeStageCodegenExec.scala:377)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:231)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:225)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:827)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:827)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

2018-09-18 13:29:13,614  ERROR --- [task-result-getter-2]  org.apache.spark.scheduler.TaskSetManager(line:70) : Task 0 in stage 1.0 failed 1 times; aborting job
2018-09-18 13:29:13,615   INFO --- [task-result-getter-2]  org.apache.spark.scheduler.TaskSchedulerImpl(line:54) : Removed TaskSet 1.0, whose tasks have all completed, from pool 
2018-09-18 13:29:13,617   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.TaskSchedulerImpl(line:54) : Cancelling stage 1
2018-09-18 13:29:13,619   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : ResultStage 1 (show at logSession.scala:43) failed in 0.139 s due to Job aborted due to stage failure: Task 0 in stage 1.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1.0 (TID 2, localhost, executor driver): java.lang.NumberFormatException: For input string: "18:05:19"
	at java.lang.NumberFormatException.forInputString(NumberFormatException.java:65)
	at java.lang.Integer.parseInt(Integer.java:580)
	at java.lang.Integer.parseInt(Integer.java:615)
	at scala.collection.immutable.StringLike$class.toInt(StringLike.scala:272)
	at scala.collection.immutable.StringOps.toInt(StringOps.scala:29)
	at logSession$$anonfun$2.apply(logSession.scala:42)
	at logSession$$anonfun$2.apply(logSession.scala:42)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1.hasNext(WholeStageCodegenExec.scala:377)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:231)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:225)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:827)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:827)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

Driver stacktrace:
2018-09-18 13:29:13,620   INFO --- [main]  org.apache.spark.scheduler.DAGScheduler(line:54) : Job 1 failed: show at logSession.scala:43, took 0.168390 s
2018-09-18 13:29:13,621   INFO --- [dispatcher-event-loop-7]  org.apache.spark.storage.BlockManagerInfo(line:54) : Removed broadcast_1_piece0 on 192.168.3.199:51663 in memory (size: 1936.0 B, free: 3.0 GB)
2018-09-18 13:29:13,631   INFO --- [Thread-1]  org.apache.spark.SparkContext(line:54) : Invoking stop() from shutdown hook
2018-09-18 13:29:13,635   INFO --- [Thread-1]  org.spark_project.jetty.server.ServerConnector(line:306) : Stopped Spark@1021f6c9{HTTP/1.1}{0.0.0.0:4040}
2018-09-18 13:29:13,637   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@18cebaa5{/stages/stage/kill,null,UNAVAILABLE,@Spark}
2018-09-18 13:29:13,637   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@31e4bb20{/jobs/job/kill,null,UNAVAILABLE,@Spark}
2018-09-18 13:29:13,638   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@7c098bb3{/api,null,UNAVAILABLE,@Spark}
2018-09-18 13:29:13,638   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@2f6e28bc{/,null,UNAVAILABLE,@Spark}
2018-09-18 13:29:13,638   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@1ae67cad{/static,null,UNAVAILABLE,@Spark}
2018-09-18 13:29:13,638   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@e98770d{/executors/threadDump/json,null,UNAVAILABLE,@Spark}
2018-09-18 13:29:13,639   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@4ba302e0{/executors/threadDump,null,UNAVAILABLE,@Spark}
2018-09-18 13:29:13,639   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@57ac5227{/executors/json,null,UNAVAILABLE,@Spark}
2018-09-18 13:29:13,639   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@43aaf813{/executors,null,UNAVAILABLE,@Spark}
2018-09-18 13:29:13,639   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@33aeca0b{/environment/json,null,UNAVAILABLE,@Spark}
2018-09-18 13:29:13,639   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@5c18016b{/environment,null,UNAVAILABLE,@Spark}
2018-09-18 13:29:13,640   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@1951b871{/storage/rdd/json,null,UNAVAILABLE,@Spark}
2018-09-18 13:29:13,640   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@793138bd{/storage/rdd,null,UNAVAILABLE,@Spark}
2018-09-18 13:29:13,640   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@5d1659ea{/storage/json,null,UNAVAILABLE,@Spark}
2018-09-18 13:29:13,640   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@25bc0606{/storage,null,UNAVAILABLE,@Spark}
2018-09-18 13:29:13,640   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@3d3ba765{/stages/pool/json,null,UNAVAILABLE,@Spark}
2018-09-18 13:29:13,640   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@784b990c{/stages/pool,null,UNAVAILABLE,@Spark}
2018-09-18 13:29:13,641   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@3c989952{/stages/stage/json,null,UNAVAILABLE,@Spark}
2018-09-18 13:29:13,641   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@3e14c16d{/stages/stage,null,UNAVAILABLE,@Spark}
2018-09-18 13:29:13,641   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@7096b474{/stages/json,null,UNAVAILABLE,@Spark}
2018-09-18 13:29:13,641   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@4bd1f8dd{/stages,null,UNAVAILABLE,@Spark}
2018-09-18 13:29:13,641   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@3f07b12c{/jobs/job/json,null,UNAVAILABLE,@Spark}
2018-09-18 13:29:13,642   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@6475472c{/jobs/job,null,UNAVAILABLE,@Spark}
2018-09-18 13:29:13,642   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@4b7e96a{/jobs/json,null,UNAVAILABLE,@Spark}
2018-09-18 13:29:13,642   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@5c8504fd{/jobs,null,UNAVAILABLE,@Spark}
2018-09-18 13:29:13,644   INFO --- [Thread-1]  org.apache.spark.ui.SparkUI(line:54) : Stopped Spark web UI at http://192.168.3.199:4040
2018-09-18 13:29:13,653   INFO --- [dispatcher-event-loop-4]  org.apache.spark.MapOutputTrackerMasterEndpoint(line:54) : MapOutputTrackerMasterEndpoint stopped!
2018-09-18 13:29:13,683   INFO --- [Thread-1]  org.apache.spark.storage.memory.MemoryStore(line:54) : MemoryStore cleared
2018-09-18 13:29:13,683   INFO --- [Thread-1]  org.apache.spark.storage.BlockManager(line:54) : BlockManager stopped
2018-09-18 13:29:13,685   INFO --- [Thread-1]  org.apache.spark.storage.BlockManagerMaster(line:54) : BlockManagerMaster stopped
2018-09-18 13:29:13,687   INFO --- [dispatcher-event-loop-7]  org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint(line:54) : OutputCommitCoordinator stopped!
2018-09-18 13:29:13,692   INFO --- [Thread-1]  org.apache.spark.SparkContext(line:54) : Successfully stopped SparkContext
2018-09-18 13:29:13,692   INFO --- [Thread-1]  org.apache.spark.util.ShutdownHookManager(line:54) : Shutdown hook called
2018-09-18 13:29:13,693   INFO --- [Thread-1]  org.apache.spark.util.ShutdownHookManager(line:54) : Deleting directory C:\Users\wshs\AppData\Local\Temp\spark-d52c9264-37f1-49dc-aa63-6b362dc9cc69
2018-09-18 13:33:38,638   INFO --- [main]  org.apache.spark.SparkContext(line:54) : Running Spark version 2.1.1
2018-09-18 13:33:38,998   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing view acls to: wshs
2018-09-18 13:33:38,999   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing modify acls to: wshs
2018-09-18 13:33:39,000   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing view acls groups to: 
2018-09-18 13:33:39,001   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing modify acls groups to: 
2018-09-18 13:33:39,003   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(wshs); groups with view permissions: Set(); users  with modify permissions: Set(wshs); groups with modify permissions: Set()
2018-09-18 13:33:39,528   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'sparkDriver' on port 51919.
2018-09-18 13:33:39,547   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering MapOutputTracker
2018-09-18 13:33:39,566   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering BlockManagerMaster
2018-09-18 13:33:39,569   INFO --- [main]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-09-18 13:33:39,570   INFO --- [main]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : BlockManagerMasterEndpoint up
2018-09-18 13:33:39,584   INFO --- [main]  org.apache.spark.storage.DiskBlockManager(line:54) : Created local directory at C:\Users\wshs\AppData\Local\Temp\blockmgr-f463318b-a271-4eef-a02b-cc17a8c61e51
2018-09-18 13:33:39,602   INFO --- [main]  org.apache.spark.storage.memory.MemoryStore(line:54) : MemoryStore started with capacity 3.0 GB
2018-09-18 13:33:39,666   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering OutputCommitCoordinator
2018-09-18 13:33:39,738   INFO --- [main]  org.spark_project.jetty.util.log(line:186) : Logging initialized @2033ms
2018-09-18 13:33:39,812   INFO --- [main]  org.spark_project.jetty.server.Server(line:327) : jetty-9.2.z-SNAPSHOT
2018-09-18 13:33:39,825   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@5c8504fd{/jobs,null,AVAILABLE,@Spark}
2018-09-18 13:33:39,825   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@4b7e96a{/jobs/json,null,AVAILABLE,@Spark}
2018-09-18 13:33:39,825   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@6475472c{/jobs/job,null,AVAILABLE,@Spark}
2018-09-18 13:33:39,826   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@3f07b12c{/jobs/job/json,null,AVAILABLE,@Spark}
2018-09-18 13:33:39,826   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@4bd1f8dd{/stages,null,AVAILABLE,@Spark}
2018-09-18 13:33:39,826   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@7096b474{/stages/json,null,AVAILABLE,@Spark}
2018-09-18 13:33:39,827   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@3e14c16d{/stages/stage,null,AVAILABLE,@Spark}
2018-09-18 13:33:39,827   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@3c989952{/stages/stage/json,null,AVAILABLE,@Spark}
2018-09-18 13:33:39,827   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@784b990c{/stages/pool,null,AVAILABLE,@Spark}
2018-09-18 13:33:39,827   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@3d3ba765{/stages/pool/json,null,AVAILABLE,@Spark}
2018-09-18 13:33:39,827   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@25bc0606{/storage,null,AVAILABLE,@Spark}
2018-09-18 13:33:39,828   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@5d1659ea{/storage/json,null,AVAILABLE,@Spark}
2018-09-18 13:33:39,828   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@793138bd{/storage/rdd,null,AVAILABLE,@Spark}
2018-09-18 13:33:39,828   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@1951b871{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-09-18 13:33:39,828   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@5c18016b{/environment,null,AVAILABLE,@Spark}
2018-09-18 13:33:39,829   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@33aeca0b{/environment/json,null,AVAILABLE,@Spark}
2018-09-18 13:33:39,829   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@43aaf813{/executors,null,AVAILABLE,@Spark}
2018-09-18 13:33:39,830   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@57ac5227{/executors/json,null,AVAILABLE,@Spark}
2018-09-18 13:33:39,830   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@4ba302e0{/executors/threadDump,null,AVAILABLE,@Spark}
2018-09-18 13:33:39,830   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@e98770d{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-09-18 13:33:39,835   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@1ae67cad{/static,null,AVAILABLE,@Spark}
2018-09-18 13:33:39,836   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@2f6e28bc{/,null,AVAILABLE,@Spark}
2018-09-18 13:33:39,837   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@7c098bb3{/api,null,AVAILABLE,@Spark}
2018-09-18 13:33:39,838   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@31e4bb20{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-09-18 13:33:39,838   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@18cebaa5{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-09-18 13:33:39,851   INFO --- [main]  org.spark_project.jetty.server.ServerConnector(line:266) : Started Spark@1021f6c9{HTTP/1.1}{0.0.0.0:4040}
2018-09-18 13:33:39,851   INFO --- [main]  org.spark_project.jetty.server.Server(line:379) : Started @2148ms
2018-09-18 13:33:39,852   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'SparkUI' on port 4040.
2018-09-18 13:33:39,855   INFO --- [main]  org.apache.spark.ui.SparkUI(line:54) : Bound SparkUI to 0.0.0.0, and started at http://192.168.3.199:4040
2018-09-18 13:33:39,928   INFO --- [main]  org.apache.spark.executor.Executor(line:54) : Starting executor ID driver on host localhost
2018-09-18 13:33:39,977   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 51961.
2018-09-18 13:33:39,977   INFO --- [main]  org.apache.spark.network.netty.NettyBlockTransferService(line:54) : Server created on 192.168.3.199:51961
2018-09-18 13:33:39,979   INFO --- [main]  org.apache.spark.storage.BlockManager(line:54) : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-09-18 13:33:39,980   INFO --- [main]  org.apache.spark.storage.BlockManagerMaster(line:54) : Registering BlockManager BlockManagerId(driver, 192.168.3.199, 51961, None)
2018-09-18 13:33:39,983   INFO --- [dispatcher-event-loop-2]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : Registering block manager 192.168.3.199:51961 with 3.0 GB RAM, BlockManagerId(driver, 192.168.3.199, 51961, None)
2018-09-18 13:33:39,985   INFO --- [main]  org.apache.spark.storage.BlockManagerMaster(line:54) : Registered BlockManager BlockManagerId(driver, 192.168.3.199, 51961, None)
2018-09-18 13:33:39,986   INFO --- [main]  org.apache.spark.storage.BlockManager(line:54) : Initialized BlockManager: BlockManagerId(driver, 192.168.3.199, 51961, None)
2018-09-18 13:33:40,143   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@1b9ea3e3{/metrics/json,null,AVAILABLE,@Spark}
2018-09-18 13:33:40,161   WARN --- [main]  org.apache.spark.SparkContext(line:66) : Using an existing SparkContext; some configuration may not take effect.
2018-09-18 13:33:40,204   INFO --- [main]  org.apache.spark.sql.internal.SharedState(line:54) : Warehouse path is 'file:/C:/Users/wshs/IdeaProjects/logdataSession/spark-warehouse/'.
2018-09-18 13:33:40,211   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@5be82d43{/SQL,null,AVAILABLE,@Spark}
2018-09-18 13:33:40,212   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@345e5a17{/SQL/json,null,AVAILABLE,@Spark}
2018-09-18 13:33:40,213   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@77b7ffa4{/SQL/execution,null,AVAILABLE,@Spark}
2018-09-18 13:33:40,214   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@402f80f5{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-09-18 13:33:40,216   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@2102a4d5{/static/sql,null,AVAILABLE,@Spark}
2018-09-18 13:33:40,641   INFO --- [main]  org.apache.spark.storage.memory.MemoryStore(line:54) : Block broadcast_0 stored as values in memory (estimated size 127.1 KB, free 3.0 GB)
2018-09-18 13:33:40,762   INFO --- [main]  org.apache.spark.storage.memory.MemoryStore(line:54) : Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.3 KB, free 3.0 GB)
2018-09-18 13:33:40,767   INFO --- [dispatcher-event-loop-4]  org.apache.spark.storage.BlockManagerInfo(line:54) : Added broadcast_0_piece0 in memory on 192.168.3.199:51961 (size: 14.3 KB, free: 3.0 GB)
2018-09-18 13:33:40,771   INFO --- [main]  org.apache.spark.SparkContext(line:54) : Created broadcast 0 from textFile at logSession.scala:39
2018-09-18 13:33:40,848   INFO --- [main]  org.apache.hadoop.mapred.FileInputFormat(line:253) : Total input paths to process : 1
2018-09-18 13:33:40,882   INFO --- [main]  org.apache.spark.SparkContext(line:54) : Starting job: collect at logSession.scala:40
2018-09-18 13:33:40,898   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Got job 0 (collect at logSession.scala:40) with 2 output partitions
2018-09-18 13:33:40,898   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Final stage: ResultStage 0 (collect at logSession.scala:40)
2018-09-18 13:33:40,899   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Parents of final stage: List()
2018-09-18 13:33:40,900   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Missing parents: List()
2018-09-18 13:33:40,909   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Submitting ResultStage 0 (e:\r_actionopvidio.txt MapPartitionsRDD[1] at textFile at logSession.scala:39), which has no missing parents
2018-09-18 13:33:40,921   INFO --- [dag-scheduler-event-loop]  org.apache.spark.storage.memory.MemoryStore(line:54) : Block broadcast_1 stored as values in memory (estimated size 3.2 KB, free 3.0 GB)
2018-09-18 13:33:40,926   INFO --- [dag-scheduler-event-loop]  org.apache.spark.storage.memory.MemoryStore(line:54) : Block broadcast_1_piece0 stored as bytes in memory (estimated size 1936.0 B, free 3.0 GB)
2018-09-18 13:33:40,927   INFO --- [dispatcher-event-loop-5]  org.apache.spark.storage.BlockManagerInfo(line:54) : Added broadcast_1_piece0 in memory on 192.168.3.199:51961 (size: 1936.0 B, free: 3.0 GB)
2018-09-18 13:33:40,927   INFO --- [dag-scheduler-event-loop]  org.apache.spark.SparkContext(line:54) : Created broadcast 1 from broadcast at DAGScheduler.scala:996
2018-09-18 13:33:40,955   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Submitting 2 missing tasks from ResultStage 0 (e:\r_actionopvidio.txt MapPartitionsRDD[1] at textFile at logSession.scala:39)
2018-09-18 13:33:40,957   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.TaskSchedulerImpl(line:54) : Adding task set 0.0 with 2 tasks
2018-09-18 13:33:40,994   INFO --- [dispatcher-event-loop-6]  org.apache.spark.scheduler.TaskSetManager(line:54) : Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 5976 bytes)
2018-09-18 13:33:40,997   INFO --- [dispatcher-event-loop-6]  org.apache.spark.scheduler.TaskSetManager(line:54) : Starting task 1.0 in stage 0.0 (TID 1, localhost, executor driver, partition 1, PROCESS_LOCAL, 5976 bytes)
2018-09-18 13:33:41,002   INFO --- [Executor task launch worker for task 0]  org.apache.spark.executor.Executor(line:54) : Running task 0.0 in stage 0.0 (TID 0)
2018-09-18 13:33:41,002   INFO --- [Executor task launch worker for task 1]  org.apache.spark.executor.Executor(line:54) : Running task 1.0 in stage 0.0 (TID 1)
2018-09-18 13:33:41,033   INFO --- [Executor task launch worker for task 0]  org.apache.spark.rdd.HadoopRDD(line:54) : Input split: file:/e:/r_actionopvidio.txt:0+188363
2018-09-18 13:33:41,033   INFO --- [Executor task launch worker for task 1]  org.apache.spark.rdd.HadoopRDD(line:54) : Input split: file:/e:/r_actionopvidio.txt:188363+188364
2018-09-18 13:33:41,041   INFO --- [Executor task launch worker for task 0]  org.apache.hadoop.conf.Configuration.deprecation(line:840) : mapred.tip.id is deprecated. Instead, use mapreduce.task.id
2018-09-18 13:33:41,041   INFO --- [Executor task launch worker for task 1]  org.apache.hadoop.conf.Configuration.deprecation(line:840) : mapred.tip.id is deprecated. Instead, use mapreduce.task.id
2018-09-18 13:33:41,041   INFO --- [Executor task launch worker for task 0]  org.apache.hadoop.conf.Configuration.deprecation(line:840) : mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
2018-09-18 13:33:41,041   INFO --- [Executor task launch worker for task 1]  org.apache.hadoop.conf.Configuration.deprecation(line:840) : mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
2018-09-18 13:33:41,041   INFO --- [Executor task launch worker for task 0]  org.apache.hadoop.conf.Configuration.deprecation(line:840) : mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
2018-09-18 13:33:41,042   INFO --- [Executor task launch worker for task 1]  org.apache.hadoop.conf.Configuration.deprecation(line:840) : mapred.job.id is deprecated. Instead, use mapreduce.job.id
2018-09-18 13:33:41,090   INFO --- [Executor task launch worker for task 1]  org.apache.spark.executor.Executor(line:54) : Finished task 1.0 in stage 0.0 (TID 1). 193184 bytes result sent to driver
2018-09-18 13:33:41,090   INFO --- [Executor task launch worker for task 0]  org.apache.spark.executor.Executor(line:54) : Finished task 0.0 in stage 0.0 (TID 0). 193193 bytes result sent to driver
2018-09-18 13:33:41,107   INFO --- [task-result-getter-0]  org.apache.spark.scheduler.TaskSetManager(line:54) : Finished task 1.0 in stage 0.0 (TID 1) in 109 ms on localhost (executor driver) (1/2)
2018-09-18 13:33:41,107   INFO --- [task-result-getter-1]  org.apache.spark.scheduler.TaskSetManager(line:54) : Finished task 0.0 in stage 0.0 (TID 0) in 133 ms on localhost (executor driver) (2/2)
2018-09-18 13:33:41,108   INFO --- [task-result-getter-1]  org.apache.spark.scheduler.TaskSchedulerImpl(line:54) : Removed TaskSet 0.0, whose tasks have all completed, from pool 
2018-09-18 13:33:41,112   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : ResultStage 0 (collect at logSession.scala:40) finished in 0.147 s
2018-09-18 13:33:41,117   INFO --- [main]  org.apache.spark.scheduler.DAGScheduler(line:54) : Job 0 finished: collect at logSession.scala:40, took 0.233994 s
2018-09-18 13:33:43,230   INFO --- [main]  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator(line:54) : Code generated in 229.3402 ms
2018-09-18 13:33:43,252   INFO --- [main]  org.apache.spark.SparkContext(line:54) : Starting job: show at logSession.scala:43
2018-09-18 13:33:43,254   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Got job 1 (show at logSession.scala:43) with 1 output partitions
2018-09-18 13:33:43,254   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Final stage: ResultStage 1 (show at logSession.scala:43)
2018-09-18 13:33:43,254   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Parents of final stage: List()
2018-09-18 13:33:43,254   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Missing parents: List()
2018-09-18 13:33:43,255   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Submitting ResultStage 1 (MapPartitionsRDD[6] at show at logSession.scala:43), which has no missing parents
2018-09-18 13:33:43,265   INFO --- [dag-scheduler-event-loop]  org.apache.spark.storage.memory.MemoryStore(line:54) : Block broadcast_2 stored as values in memory (estimated size 12.1 KB, free 3.0 GB)
2018-09-18 13:33:43,270   INFO --- [dag-scheduler-event-loop]  org.apache.spark.storage.memory.MemoryStore(line:54) : Block broadcast_2_piece0 stored as bytes in memory (estimated size 5.0 KB, free 3.0 GB)
2018-09-18 13:33:43,273   INFO --- [dispatcher-event-loop-3]  org.apache.spark.storage.BlockManagerInfo(line:54) : Added broadcast_2_piece0 in memory on 192.168.3.199:51961 (size: 5.0 KB, free: 3.0 GB)
2018-09-18 13:33:43,273   INFO --- [dag-scheduler-event-loop]  org.apache.spark.SparkContext(line:54) : Created broadcast 2 from broadcast at DAGScheduler.scala:996
2018-09-18 13:33:43,274   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[6] at show at logSession.scala:43)
2018-09-18 13:33:43,274   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.TaskSchedulerImpl(line:54) : Adding task set 1.0 with 1 tasks
2018-09-18 13:33:43,276   INFO --- [dispatcher-event-loop-4]  org.apache.spark.scheduler.TaskSetManager(line:54) : Starting task 0.0 in stage 1.0 (TID 2, localhost, executor driver, partition 0, PROCESS_LOCAL, 5921 bytes)
2018-09-18 13:33:43,276   INFO --- [Executor task launch worker for task 2]  org.apache.spark.executor.Executor(line:54) : Running task 0.0 in stage 1.0 (TID 2)
2018-09-18 13:33:43,284   INFO --- [Executor task launch worker for task 2]  org.apache.spark.rdd.HadoopRDD(line:54) : Input split: file:/e:/r_actionopvidio.txt:0+188363
2018-09-18 13:33:43,309  ERROR --- [Executor task launch worker for task 2]  org.apache.spark.executor.Executor(line:91) : Exception in task 0.0 in stage 1.0 (TID 2)
java.lang.NumberFormatException: For input string: ""771""
	at java.lang.NumberFormatException.forInputString(NumberFormatException.java:65)
	at java.lang.Integer.parseInt(Integer.java:569)
	at java.lang.Integer.parseInt(Integer.java:615)
	at scala.collection.immutable.StringLike$class.toInt(StringLike.scala:272)
	at scala.collection.immutable.StringOps.toInt(StringOps.scala:29)
	at logSession$$anonfun$2.apply(logSession.scala:42)
	at logSession$$anonfun$2.apply(logSession.scala:42)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1.hasNext(WholeStageCodegenExec.scala:377)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:231)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:225)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:827)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:827)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-09-18 13:33:43,419   WARN --- [task-result-getter-2]  org.apache.spark.scheduler.TaskSetManager(line:66) : Lost task 0.0 in stage 1.0 (TID 2, localhost, executor driver): java.lang.NumberFormatException: For input string: ""771""
	at java.lang.NumberFormatException.forInputString(NumberFormatException.java:65)
	at java.lang.Integer.parseInt(Integer.java:569)
	at java.lang.Integer.parseInt(Integer.java:615)
	at scala.collection.immutable.StringLike$class.toInt(StringLike.scala:272)
	at scala.collection.immutable.StringOps.toInt(StringOps.scala:29)
	at logSession$$anonfun$2.apply(logSession.scala:42)
	at logSession$$anonfun$2.apply(logSession.scala:42)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1.hasNext(WholeStageCodegenExec.scala:377)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:231)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:225)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:827)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:827)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

2018-09-18 13:33:43,421  ERROR --- [task-result-getter-2]  org.apache.spark.scheduler.TaskSetManager(line:70) : Task 0 in stage 1.0 failed 1 times; aborting job
2018-09-18 13:33:43,422   INFO --- [task-result-getter-2]  org.apache.spark.scheduler.TaskSchedulerImpl(line:54) : Removed TaskSet 1.0, whose tasks have all completed, from pool 
2018-09-18 13:33:43,426   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.TaskSchedulerImpl(line:54) : Cancelling stage 1
2018-09-18 13:33:43,427   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : ResultStage 1 (show at logSession.scala:43) failed in 0.153 s due to Job aborted due to stage failure: Task 0 in stage 1.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1.0 (TID 2, localhost, executor driver): java.lang.NumberFormatException: For input string: ""771""
	at java.lang.NumberFormatException.forInputString(NumberFormatException.java:65)
	at java.lang.Integer.parseInt(Integer.java:569)
	at java.lang.Integer.parseInt(Integer.java:615)
	at scala.collection.immutable.StringLike$class.toInt(StringLike.scala:272)
	at scala.collection.immutable.StringOps.toInt(StringOps.scala:29)
	at logSession$$anonfun$2.apply(logSession.scala:42)
	at logSession$$anonfun$2.apply(logSession.scala:42)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1.hasNext(WholeStageCodegenExec.scala:377)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:231)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:225)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:827)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:827)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

Driver stacktrace:
2018-09-18 13:33:43,428   INFO --- [main]  org.apache.spark.scheduler.DAGScheduler(line:54) : Job 1 failed: show at logSession.scala:43, took 0.175238 s
2018-09-18 13:33:43,430   INFO --- [dispatcher-event-loop-2]  org.apache.spark.storage.BlockManagerInfo(line:54) : Removed broadcast_1_piece0 on 192.168.3.199:51961 in memory (size: 1936.0 B, free: 3.0 GB)
2018-09-18 13:33:43,440   INFO --- [Thread-1]  org.apache.spark.SparkContext(line:54) : Invoking stop() from shutdown hook
2018-09-18 13:33:43,444   INFO --- [Thread-1]  org.spark_project.jetty.server.ServerConnector(line:306) : Stopped Spark@1021f6c9{HTTP/1.1}{0.0.0.0:4040}
2018-09-18 13:33:43,447   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@18cebaa5{/stages/stage/kill,null,UNAVAILABLE,@Spark}
2018-09-18 13:33:43,447   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@31e4bb20{/jobs/job/kill,null,UNAVAILABLE,@Spark}
2018-09-18 13:33:43,447   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@7c098bb3{/api,null,UNAVAILABLE,@Spark}
2018-09-18 13:33:43,448   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@2f6e28bc{/,null,UNAVAILABLE,@Spark}
2018-09-18 13:33:43,448   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@1ae67cad{/static,null,UNAVAILABLE,@Spark}
2018-09-18 13:33:43,448   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@e98770d{/executors/threadDump/json,null,UNAVAILABLE,@Spark}
2018-09-18 13:33:43,448   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@4ba302e0{/executors/threadDump,null,UNAVAILABLE,@Spark}
2018-09-18 13:33:43,448   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@57ac5227{/executors/json,null,UNAVAILABLE,@Spark}
2018-09-18 13:33:43,448   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@43aaf813{/executors,null,UNAVAILABLE,@Spark}
2018-09-18 13:33:43,449   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@33aeca0b{/environment/json,null,UNAVAILABLE,@Spark}
2018-09-18 13:33:43,449   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@5c18016b{/environment,null,UNAVAILABLE,@Spark}
2018-09-18 13:33:43,449   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@1951b871{/storage/rdd/json,null,UNAVAILABLE,@Spark}
2018-09-18 13:33:43,449   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@793138bd{/storage/rdd,null,UNAVAILABLE,@Spark}
2018-09-18 13:33:43,449   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@5d1659ea{/storage/json,null,UNAVAILABLE,@Spark}
2018-09-18 13:33:43,449   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@25bc0606{/storage,null,UNAVAILABLE,@Spark}
2018-09-18 13:33:43,449   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@3d3ba765{/stages/pool/json,null,UNAVAILABLE,@Spark}
2018-09-18 13:33:43,450   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@784b990c{/stages/pool,null,UNAVAILABLE,@Spark}
2018-09-18 13:33:43,450   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@3c989952{/stages/stage/json,null,UNAVAILABLE,@Spark}
2018-09-18 13:33:43,450   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@3e14c16d{/stages/stage,null,UNAVAILABLE,@Spark}
2018-09-18 13:33:43,450   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@7096b474{/stages/json,null,UNAVAILABLE,@Spark}
2018-09-18 13:33:43,450   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@4bd1f8dd{/stages,null,UNAVAILABLE,@Spark}
2018-09-18 13:33:43,453   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@3f07b12c{/jobs/job/json,null,UNAVAILABLE,@Spark}
2018-09-18 13:33:43,453   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@6475472c{/jobs/job,null,UNAVAILABLE,@Spark}
2018-09-18 13:33:43,453   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@4b7e96a{/jobs/json,null,UNAVAILABLE,@Spark}
2018-09-18 13:33:43,453   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@5c8504fd{/jobs,null,UNAVAILABLE,@Spark}
2018-09-18 13:33:43,455   INFO --- [Thread-1]  org.apache.spark.ui.SparkUI(line:54) : Stopped Spark web UI at http://192.168.3.199:4040
2018-09-18 13:33:43,463   INFO --- [dispatcher-event-loop-4]  org.apache.spark.MapOutputTrackerMasterEndpoint(line:54) : MapOutputTrackerMasterEndpoint stopped!
2018-09-18 13:33:43,491   INFO --- [Thread-1]  org.apache.spark.storage.memory.MemoryStore(line:54) : MemoryStore cleared
2018-09-18 13:33:43,492   INFO --- [Thread-1]  org.apache.spark.storage.BlockManager(line:54) : BlockManager stopped
2018-09-18 13:33:43,493   INFO --- [Thread-1]  org.apache.spark.storage.BlockManagerMaster(line:54) : BlockManagerMaster stopped
2018-09-18 13:33:43,494   INFO --- [dispatcher-event-loop-2]  org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint(line:54) : OutputCommitCoordinator stopped!
2018-09-18 13:33:43,500   INFO --- [Thread-1]  org.apache.spark.SparkContext(line:54) : Successfully stopped SparkContext
2018-09-18 13:33:43,500   INFO --- [Thread-1]  org.apache.spark.util.ShutdownHookManager(line:54) : Shutdown hook called
2018-09-18 13:33:43,502   INFO --- [Thread-1]  org.apache.spark.util.ShutdownHookManager(line:54) : Deleting directory C:\Users\wshs\AppData\Local\Temp\spark-0430bdd4-a4cd-43e5-b758-6e491ec1f918
2018-09-18 13:34:28,607   INFO --- [main]  org.apache.spark.SparkContext(line:54) : Running Spark version 2.1.1
2018-09-18 13:34:28,912   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing view acls to: wshs
2018-09-18 13:34:28,913   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing modify acls to: wshs
2018-09-18 13:34:28,913   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing view acls groups to: 
2018-09-18 13:34:28,914   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing modify acls groups to: 
2018-09-18 13:34:28,916   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(wshs); groups with view permissions: Set(); users  with modify permissions: Set(wshs); groups with modify permissions: Set()
2018-09-18 13:34:29,387   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'sparkDriver' on port 52037.
2018-09-18 13:34:29,405   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering MapOutputTracker
2018-09-18 13:34:29,423   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering BlockManagerMaster
2018-09-18 13:34:29,425   INFO --- [main]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-09-18 13:34:29,426   INFO --- [main]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : BlockManagerMasterEndpoint up
2018-09-18 13:34:29,440   INFO --- [main]  org.apache.spark.storage.DiskBlockManager(line:54) : Created local directory at C:\Users\wshs\AppData\Local\Temp\blockmgr-7d640b77-7bf2-476a-bbad-1aff330b4caf
2018-09-18 13:34:29,456   INFO --- [main]  org.apache.spark.storage.memory.MemoryStore(line:54) : MemoryStore started with capacity 3.0 GB
2018-09-18 13:34:29,523   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering OutputCommitCoordinator
2018-09-18 13:34:29,602   INFO --- [main]  org.spark_project.jetty.util.log(line:186) : Logging initialized @1799ms
2018-09-18 13:34:29,685   INFO --- [main]  org.spark_project.jetty.server.Server(line:327) : jetty-9.2.z-SNAPSHOT
2018-09-18 13:34:29,699   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@5c8504fd{/jobs,null,AVAILABLE,@Spark}
2018-09-18 13:34:29,700   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@4b7e96a{/jobs/json,null,AVAILABLE,@Spark}
2018-09-18 13:34:29,700   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@6475472c{/jobs/job,null,AVAILABLE,@Spark}
2018-09-18 13:34:29,700   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@3f07b12c{/jobs/job/json,null,AVAILABLE,@Spark}
2018-09-18 13:34:29,701   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@4bd1f8dd{/stages,null,AVAILABLE,@Spark}
2018-09-18 13:34:29,701   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@7096b474{/stages/json,null,AVAILABLE,@Spark}
2018-09-18 13:34:29,701   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@3e14c16d{/stages/stage,null,AVAILABLE,@Spark}
2018-09-18 13:34:29,702   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@3c989952{/stages/stage/json,null,AVAILABLE,@Spark}
2018-09-18 13:34:29,702   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@784b990c{/stages/pool,null,AVAILABLE,@Spark}
2018-09-18 13:34:29,702   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@3d3ba765{/stages/pool/json,null,AVAILABLE,@Spark}
2018-09-18 13:34:29,702   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@25bc0606{/storage,null,AVAILABLE,@Spark}
2018-09-18 13:34:29,702   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@5d1659ea{/storage/json,null,AVAILABLE,@Spark}
2018-09-18 13:34:29,703   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@793138bd{/storage/rdd,null,AVAILABLE,@Spark}
2018-09-18 13:34:29,703   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@1951b871{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-09-18 13:34:29,703   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@5c18016b{/environment,null,AVAILABLE,@Spark}
2018-09-18 13:34:29,703   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@33aeca0b{/environment/json,null,AVAILABLE,@Spark}
2018-09-18 13:34:29,704   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@43aaf813{/executors,null,AVAILABLE,@Spark}
2018-09-18 13:34:29,704   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@57ac5227{/executors/json,null,AVAILABLE,@Spark}
2018-09-18 13:34:29,704   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@4ba302e0{/executors/threadDump,null,AVAILABLE,@Spark}
2018-09-18 13:34:29,704   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@e98770d{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-09-18 13:34:29,709   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@1ae67cad{/static,null,AVAILABLE,@Spark}
2018-09-18 13:34:29,709   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@2f6e28bc{/,null,AVAILABLE,@Spark}
2018-09-18 13:34:29,710   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@7c098bb3{/api,null,AVAILABLE,@Spark}
2018-09-18 13:34:29,710   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@31e4bb20{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-09-18 13:34:29,711   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@18cebaa5{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-09-18 13:34:29,721   INFO --- [main]  org.spark_project.jetty.server.ServerConnector(line:266) : Started Spark@1021f6c9{HTTP/1.1}{0.0.0.0:4040}
2018-09-18 13:34:29,721   INFO --- [main]  org.spark_project.jetty.server.Server(line:379) : Started @1920ms
2018-09-18 13:34:29,722   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'SparkUI' on port 4040.
2018-09-18 13:34:29,725   INFO --- [main]  org.apache.spark.ui.SparkUI(line:54) : Bound SparkUI to 0.0.0.0, and started at http://192.168.3.199:4040
2018-09-18 13:34:29,788   INFO --- [main]  org.apache.spark.executor.Executor(line:54) : Starting executor ID driver on host localhost
2018-09-18 13:34:29,828   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 52078.
2018-09-18 13:34:29,829   INFO --- [main]  org.apache.spark.network.netty.NettyBlockTransferService(line:54) : Server created on 192.168.3.199:52078
2018-09-18 13:34:29,831   INFO --- [main]  org.apache.spark.storage.BlockManager(line:54) : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-09-18 13:34:29,832   INFO --- [main]  org.apache.spark.storage.BlockManagerMaster(line:54) : Registering BlockManager BlockManagerId(driver, 192.168.3.199, 52078, None)
2018-09-18 13:34:29,834   INFO --- [dispatcher-event-loop-4]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : Registering block manager 192.168.3.199:52078 with 3.0 GB RAM, BlockManagerId(driver, 192.168.3.199, 52078, None)
2018-09-18 13:34:29,837   INFO --- [main]  org.apache.spark.storage.BlockManagerMaster(line:54) : Registered BlockManager BlockManagerId(driver, 192.168.3.199, 52078, None)
2018-09-18 13:34:29,838   INFO --- [main]  org.apache.spark.storage.BlockManager(line:54) : Initialized BlockManager: BlockManagerId(driver, 192.168.3.199, 52078, None)
2018-09-18 13:34:29,998   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@1b9ea3e3{/metrics/json,null,AVAILABLE,@Spark}
2018-09-18 13:34:30,016   WARN --- [main]  org.apache.spark.SparkContext(line:66) : Using an existing SparkContext; some configuration may not take effect.
2018-09-18 13:34:30,054   INFO --- [main]  org.apache.spark.sql.internal.SharedState(line:54) : Warehouse path is 'file:/C:/Users/wshs/IdeaProjects/logdataSession/spark-warehouse/'.
2018-09-18 13:34:30,060   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@5be82d43{/SQL,null,AVAILABLE,@Spark}
2018-09-18 13:34:30,061   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@345e5a17{/SQL/json,null,AVAILABLE,@Spark}
2018-09-18 13:34:30,062   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@77b7ffa4{/SQL/execution,null,AVAILABLE,@Spark}
2018-09-18 13:34:30,062   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@402f80f5{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-09-18 13:34:30,065   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@2102a4d5{/static/sql,null,AVAILABLE,@Spark}
2018-09-18 13:34:30,519   INFO --- [main]  org.apache.spark.storage.memory.MemoryStore(line:54) : Block broadcast_0 stored as values in memory (estimated size 127.1 KB, free 3.0 GB)
2018-09-18 13:34:31,097   INFO --- [main]  org.apache.spark.storage.memory.MemoryStore(line:54) : Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.3 KB, free 3.0 GB)
2018-09-18 13:34:31,102   INFO --- [dispatcher-event-loop-2]  org.apache.spark.storage.BlockManagerInfo(line:54) : Added broadcast_0_piece0 in memory on 192.168.3.199:52078 (size: 14.3 KB, free: 3.0 GB)
2018-09-18 13:34:31,107   INFO --- [main]  org.apache.spark.SparkContext(line:54) : Created broadcast 0 from textFile at logSession.scala:39
2018-09-18 13:34:31,197   INFO --- [main]  org.apache.hadoop.mapred.FileInputFormat(line:253) : Total input paths to process : 1
2018-09-18 13:34:31,240   INFO --- [main]  org.apache.spark.SparkContext(line:54) : Starting job: collect at logSession.scala:40
2018-09-18 13:34:31,258   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Got job 0 (collect at logSession.scala:40) with 2 output partitions
2018-09-18 13:34:31,259   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Final stage: ResultStage 0 (collect at logSession.scala:40)
2018-09-18 13:34:31,260   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Parents of final stage: List()
2018-09-18 13:34:31,261   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Missing parents: List()
2018-09-18 13:34:31,268   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Submitting ResultStage 0 (e:\r_actionopvidio.txt MapPartitionsRDD[1] at textFile at logSession.scala:39), which has no missing parents
2018-09-18 13:34:31,282   INFO --- [dag-scheduler-event-loop]  org.apache.spark.storage.memory.MemoryStore(line:54) : Block broadcast_1 stored as values in memory (estimated size 3.2 KB, free 3.0 GB)
2018-09-18 13:34:31,324   INFO --- [dag-scheduler-event-loop]  org.apache.spark.storage.memory.MemoryStore(line:54) : Block broadcast_1_piece0 stored as bytes in memory (estimated size 1936.0 B, free 3.0 GB)
2018-09-18 13:34:31,325   INFO --- [dispatcher-event-loop-5]  org.apache.spark.storage.BlockManagerInfo(line:54) : Added broadcast_1_piece0 in memory on 192.168.3.199:52078 (size: 1936.0 B, free: 3.0 GB)
2018-09-18 13:34:31,326   INFO --- [dag-scheduler-event-loop]  org.apache.spark.SparkContext(line:54) : Created broadcast 1 from broadcast at DAGScheduler.scala:996
2018-09-18 13:34:31,330   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Submitting 2 missing tasks from ResultStage 0 (e:\r_actionopvidio.txt MapPartitionsRDD[1] at textFile at logSession.scala:39)
2018-09-18 13:34:31,333   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.TaskSchedulerImpl(line:54) : Adding task set 0.0 with 2 tasks
2018-09-18 13:34:31,380   INFO --- [dispatcher-event-loop-6]  org.apache.spark.scheduler.TaskSetManager(line:54) : Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 5976 bytes)
2018-09-18 13:34:31,383   INFO --- [dispatcher-event-loop-6]  org.apache.spark.scheduler.TaskSetManager(line:54) : Starting task 1.0 in stage 0.0 (TID 1, localhost, executor driver, partition 1, PROCESS_LOCAL, 5976 bytes)
2018-09-18 13:34:31,391   INFO --- [Executor task launch worker for task 0]  org.apache.spark.executor.Executor(line:54) : Running task 0.0 in stage 0.0 (TID 0)
2018-09-18 13:34:31,391   INFO --- [Executor task launch worker for task 1]  org.apache.spark.executor.Executor(line:54) : Running task 1.0 in stage 0.0 (TID 1)
2018-09-18 13:34:31,427   INFO --- [Executor task launch worker for task 0]  org.apache.spark.rdd.HadoopRDD(line:54) : Input split: file:/e:/r_actionopvidio.txt:0+188363
2018-09-18 13:34:31,427   INFO --- [Executor task launch worker for task 1]  org.apache.spark.rdd.HadoopRDD(line:54) : Input split: file:/e:/r_actionopvidio.txt:188363+188364
2018-09-18 13:34:31,436   INFO --- [Executor task launch worker for task 0]  org.apache.hadoop.conf.Configuration.deprecation(line:840) : mapred.tip.id is deprecated. Instead, use mapreduce.task.id
2018-09-18 13:34:31,436   INFO --- [Executor task launch worker for task 1]  org.apache.hadoop.conf.Configuration.deprecation(line:840) : mapred.tip.id is deprecated. Instead, use mapreduce.task.id
2018-09-18 13:34:31,436   INFO --- [Executor task launch worker for task 0]  org.apache.hadoop.conf.Configuration.deprecation(line:840) : mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
2018-09-18 13:34:31,437   INFO --- [Executor task launch worker for task 1]  org.apache.hadoop.conf.Configuration.deprecation(line:840) : mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
2018-09-18 13:34:31,437   INFO --- [Executor task launch worker for task 0]  org.apache.hadoop.conf.Configuration.deprecation(line:840) : mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
2018-09-18 13:34:31,437   INFO --- [Executor task launch worker for task 1]  org.apache.hadoop.conf.Configuration.deprecation(line:840) : mapred.job.id is deprecated. Instead, use mapreduce.job.id
2018-09-18 13:34:31,488   INFO --- [Executor task launch worker for task 0]  org.apache.spark.executor.Executor(line:54) : Finished task 0.0 in stage 0.0 (TID 0). 193283 bytes result sent to driver
2018-09-18 13:34:31,488   INFO --- [Executor task launch worker for task 1]  org.apache.spark.executor.Executor(line:54) : Finished task 1.0 in stage 0.0 (TID 1). 193094 bytes result sent to driver
2018-09-18 13:34:31,503   INFO --- [task-result-getter-1]  org.apache.spark.scheduler.TaskSetManager(line:54) : Finished task 1.0 in stage 0.0 (TID 1) in 119 ms on localhost (executor driver) (1/2)
2018-09-18 13:34:31,504   INFO --- [task-result-getter-0]  org.apache.spark.scheduler.TaskSetManager(line:54) : Finished task 0.0 in stage 0.0 (TID 0) in 145 ms on localhost (executor driver) (2/2)
2018-09-18 13:34:31,505   INFO --- [task-result-getter-0]  org.apache.spark.scheduler.TaskSchedulerImpl(line:54) : Removed TaskSet 0.0, whose tasks have all completed, from pool 
2018-09-18 13:34:31,507   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : ResultStage 0 (collect at logSession.scala:40) finished in 0.161 s
2018-09-18 13:34:31,512   INFO --- [main]  org.apache.spark.scheduler.DAGScheduler(line:54) : Job 0 finished: collect at logSession.scala:40, took 0.270733 s
2018-09-18 13:34:33,629   INFO --- [main]  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator(line:54) : Code generated in 222.567928 ms
2018-09-18 13:34:33,651   INFO --- [main]  org.apache.spark.SparkContext(line:54) : Starting job: show at logSession.scala:43
2018-09-18 13:34:33,652   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Got job 1 (show at logSession.scala:43) with 1 output partitions
2018-09-18 13:34:33,652   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Final stage: ResultStage 1 (show at logSession.scala:43)
2018-09-18 13:34:33,652   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Parents of final stage: List()
2018-09-18 13:34:33,653   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Missing parents: List()
2018-09-18 13:34:33,653   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Submitting ResultStage 1 (MapPartitionsRDD[6] at show at logSession.scala:43), which has no missing parents
2018-09-18 13:34:33,659   INFO --- [dag-scheduler-event-loop]  org.apache.spark.storage.memory.MemoryStore(line:54) : Block broadcast_2 stored as values in memory (estimated size 12.1 KB, free 3.0 GB)
2018-09-18 13:34:33,663   INFO --- [dag-scheduler-event-loop]  org.apache.spark.storage.memory.MemoryStore(line:54) : Block broadcast_2_piece0 stored as bytes in memory (estimated size 5.0 KB, free 3.0 GB)
2018-09-18 13:34:33,667   INFO --- [dispatcher-event-loop-1]  org.apache.spark.storage.BlockManagerInfo(line:54) : Added broadcast_2_piece0 in memory on 192.168.3.199:52078 (size: 5.0 KB, free: 3.0 GB)
2018-09-18 13:34:33,667   INFO --- [dag-scheduler-event-loop]  org.apache.spark.SparkContext(line:54) : Created broadcast 2 from broadcast at DAGScheduler.scala:996
2018-09-18 13:34:33,668   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[6] at show at logSession.scala:43)
2018-09-18 13:34:33,668   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.TaskSchedulerImpl(line:54) : Adding task set 1.0 with 1 tasks
2018-09-18 13:34:33,670   INFO --- [dispatcher-event-loop-2]  org.apache.spark.scheduler.TaskSetManager(line:54) : Starting task 0.0 in stage 1.0 (TID 2, localhost, executor driver, partition 0, PROCESS_LOCAL, 5921 bytes)
2018-09-18 13:34:33,671   INFO --- [Executor task launch worker for task 2]  org.apache.spark.executor.Executor(line:54) : Running task 0.0 in stage 1.0 (TID 2)
2018-09-18 13:34:33,678   INFO --- [Executor task launch worker for task 2]  org.apache.spark.rdd.HadoopRDD(line:54) : Input split: file:/e:/r_actionopvidio.txt:0+188363
2018-09-18 13:34:33,692  ERROR --- [Executor task launch worker for task 2]  org.apache.spark.executor.Executor(line:91) : Exception in task 0.0 in stage 1.0 (TID 2)
java.lang.NumberFormatException: For input string: "18:05:19"
	at java.lang.NumberFormatException.forInputString(NumberFormatException.java:65)
	at java.lang.Integer.parseInt(Integer.java:580)
	at java.lang.Integer.parseInt(Integer.java:615)
	at scala.collection.immutable.StringLike$class.toInt(StringLike.scala:272)
	at scala.collection.immutable.StringOps.toInt(StringOps.scala:29)
	at logSession$$anonfun$2.apply(logSession.scala:42)
	at logSession$$anonfun$2.apply(logSession.scala:42)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1.hasNext(WholeStageCodegenExec.scala:377)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:231)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:225)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:827)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:827)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-09-18 13:34:33,802   WARN --- [task-result-getter-2]  org.apache.spark.scheduler.TaskSetManager(line:66) : Lost task 0.0 in stage 1.0 (TID 2, localhost, executor driver): java.lang.NumberFormatException: For input string: "18:05:19"
	at java.lang.NumberFormatException.forInputString(NumberFormatException.java:65)
	at java.lang.Integer.parseInt(Integer.java:580)
	at java.lang.Integer.parseInt(Integer.java:615)
	at scala.collection.immutable.StringLike$class.toInt(StringLike.scala:272)
	at scala.collection.immutable.StringOps.toInt(StringOps.scala:29)
	at logSession$$anonfun$2.apply(logSession.scala:42)
	at logSession$$anonfun$2.apply(logSession.scala:42)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1.hasNext(WholeStageCodegenExec.scala:377)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:231)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:225)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:827)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:827)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

2018-09-18 13:34:33,804  ERROR --- [task-result-getter-2]  org.apache.spark.scheduler.TaskSetManager(line:70) : Task 0 in stage 1.0 failed 1 times; aborting job
2018-09-18 13:34:33,806   INFO --- [task-result-getter-2]  org.apache.spark.scheduler.TaskSchedulerImpl(line:54) : Removed TaskSet 1.0, whose tasks have all completed, from pool 
2018-09-18 13:34:33,808   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.TaskSchedulerImpl(line:54) : Cancelling stage 1
2018-09-18 13:34:33,810   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : ResultStage 1 (show at logSession.scala:43) failed in 0.141 s due to Job aborted due to stage failure: Task 0 in stage 1.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1.0 (TID 2, localhost, executor driver): java.lang.NumberFormatException: For input string: "18:05:19"
	at java.lang.NumberFormatException.forInputString(NumberFormatException.java:65)
	at java.lang.Integer.parseInt(Integer.java:580)
	at java.lang.Integer.parseInt(Integer.java:615)
	at scala.collection.immutable.StringLike$class.toInt(StringLike.scala:272)
	at scala.collection.immutable.StringOps.toInt(StringOps.scala:29)
	at logSession$$anonfun$2.apply(logSession.scala:42)
	at logSession$$anonfun$2.apply(logSession.scala:42)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1.hasNext(WholeStageCodegenExec.scala:377)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:231)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:225)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:827)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:827)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

Driver stacktrace:
2018-09-18 13:34:33,811   INFO --- [main]  org.apache.spark.scheduler.DAGScheduler(line:54) : Job 1 failed: show at logSession.scala:43, took 0.159159 s
2018-09-18 13:34:33,811   INFO --- [dispatcher-event-loop-4]  org.apache.spark.storage.BlockManagerInfo(line:54) : Removed broadcast_1_piece0 on 192.168.3.199:52078 in memory (size: 1936.0 B, free: 3.0 GB)
2018-09-18 13:34:33,819   INFO --- [Thread-1]  org.apache.spark.SparkContext(line:54) : Invoking stop() from shutdown hook
2018-09-18 13:34:33,824   INFO --- [Thread-1]  org.spark_project.jetty.server.ServerConnector(line:306) : Stopped Spark@1021f6c9{HTTP/1.1}{0.0.0.0:4040}
2018-09-18 13:34:33,826   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@18cebaa5{/stages/stage/kill,null,UNAVAILABLE,@Spark}
2018-09-18 13:34:33,826   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@31e4bb20{/jobs/job/kill,null,UNAVAILABLE,@Spark}
2018-09-18 13:34:33,826   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@7c098bb3{/api,null,UNAVAILABLE,@Spark}
2018-09-18 13:34:33,826   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@2f6e28bc{/,null,UNAVAILABLE,@Spark}
2018-09-18 13:34:33,826   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@1ae67cad{/static,null,UNAVAILABLE,@Spark}
2018-09-18 13:34:33,827   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@e98770d{/executors/threadDump/json,null,UNAVAILABLE,@Spark}
2018-09-18 13:34:33,827   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@4ba302e0{/executors/threadDump,null,UNAVAILABLE,@Spark}
2018-09-18 13:34:33,827   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@57ac5227{/executors/json,null,UNAVAILABLE,@Spark}
2018-09-18 13:34:33,827   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@43aaf813{/executors,null,UNAVAILABLE,@Spark}
2018-09-18 13:34:33,827   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@33aeca0b{/environment/json,null,UNAVAILABLE,@Spark}
2018-09-18 13:34:33,827   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@5c18016b{/environment,null,UNAVAILABLE,@Spark}
2018-09-18 13:34:33,827   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@1951b871{/storage/rdd/json,null,UNAVAILABLE,@Spark}
2018-09-18 13:34:33,828   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@793138bd{/storage/rdd,null,UNAVAILABLE,@Spark}
2018-09-18 13:34:33,828   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@5d1659ea{/storage/json,null,UNAVAILABLE,@Spark}
2018-09-18 13:34:33,828   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@25bc0606{/storage,null,UNAVAILABLE,@Spark}
2018-09-18 13:34:33,828   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@3d3ba765{/stages/pool/json,null,UNAVAILABLE,@Spark}
2018-09-18 13:34:33,828   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@784b990c{/stages/pool,null,UNAVAILABLE,@Spark}
2018-09-18 13:34:33,828   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@3c989952{/stages/stage/json,null,UNAVAILABLE,@Spark}
2018-09-18 13:34:33,828   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@3e14c16d{/stages/stage,null,UNAVAILABLE,@Spark}
2018-09-18 13:34:33,828   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@7096b474{/stages/json,null,UNAVAILABLE,@Spark}
2018-09-18 13:34:33,828   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@4bd1f8dd{/stages,null,UNAVAILABLE,@Spark}
2018-09-18 13:34:33,828   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@3f07b12c{/jobs/job/json,null,UNAVAILABLE,@Spark}
2018-09-18 13:34:33,828   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@6475472c{/jobs/job,null,UNAVAILABLE,@Spark}
2018-09-18 13:34:33,828   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@4b7e96a{/jobs/json,null,UNAVAILABLE,@Spark}
2018-09-18 13:34:33,828   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@5c8504fd{/jobs,null,UNAVAILABLE,@Spark}
2018-09-18 13:34:33,831   INFO --- [Thread-1]  org.apache.spark.ui.SparkUI(line:54) : Stopped Spark web UI at http://192.168.3.199:4040
2018-09-18 13:34:33,838   INFO --- [dispatcher-event-loop-2]  org.apache.spark.MapOutputTrackerMasterEndpoint(line:54) : MapOutputTrackerMasterEndpoint stopped!
2018-09-18 13:34:33,870   INFO --- [Thread-1]  org.apache.spark.storage.memory.MemoryStore(line:54) : MemoryStore cleared
2018-09-18 13:34:33,871   INFO --- [Thread-1]  org.apache.spark.storage.BlockManager(line:54) : BlockManager stopped
2018-09-18 13:34:33,872   INFO --- [Thread-1]  org.apache.spark.storage.BlockManagerMaster(line:54) : BlockManagerMaster stopped
2018-09-18 13:34:33,874   INFO --- [dispatcher-event-loop-4]  org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint(line:54) : OutputCommitCoordinator stopped!
2018-09-18 13:34:33,879   INFO --- [Thread-1]  org.apache.spark.SparkContext(line:54) : Successfully stopped SparkContext
2018-09-18 13:34:33,879   INFO --- [Thread-1]  org.apache.spark.util.ShutdownHookManager(line:54) : Shutdown hook called
2018-09-18 13:34:33,880   INFO --- [Thread-1]  org.apache.spark.util.ShutdownHookManager(line:54) : Deleting directory C:\Users\wshs\AppData\Local\Temp\spark-99cbf326-bc79-45d8-bbd8-4d02458d72a9
2018-09-18 13:35:24,292   INFO --- [main]  org.apache.spark.SparkContext(line:54) : Running Spark version 2.1.1
2018-09-18 13:35:24,651   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing view acls to: wshs
2018-09-18 13:35:24,652   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing modify acls to: wshs
2018-09-18 13:35:24,652   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing view acls groups to: 
2018-09-18 13:35:24,653   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing modify acls groups to: 
2018-09-18 13:35:24,654   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(wshs); groups with view permissions: Set(); users  with modify permissions: Set(wshs); groups with modify permissions: Set()
2018-09-18 13:35:25,189   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'sparkDriver' on port 52170.
2018-09-18 13:35:25,211   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering MapOutputTracker
2018-09-18 13:35:25,234   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering BlockManagerMaster
2018-09-18 13:35:25,237   INFO --- [main]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-09-18 13:35:25,238   INFO --- [main]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : BlockManagerMasterEndpoint up
2018-09-18 13:35:25,255   INFO --- [main]  org.apache.spark.storage.DiskBlockManager(line:54) : Created local directory at C:\Users\wshs\AppData\Local\Temp\blockmgr-fe01a706-7afe-4ba8-b6dc-fd5243a75b14
2018-09-18 13:35:25,272   INFO --- [main]  org.apache.spark.storage.memory.MemoryStore(line:54) : MemoryStore started with capacity 3.0 GB
2018-09-18 13:35:25,335   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering OutputCommitCoordinator
2018-09-18 13:35:25,410   INFO --- [main]  org.spark_project.jetty.util.log(line:186) : Logging initialized @2029ms
2018-09-18 13:35:25,485   INFO --- [main]  org.spark_project.jetty.server.Server(line:327) : jetty-9.2.z-SNAPSHOT
2018-09-18 13:35:25,498   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@5c8504fd{/jobs,null,AVAILABLE,@Spark}
2018-09-18 13:35:25,499   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@4b7e96a{/jobs/json,null,AVAILABLE,@Spark}
2018-09-18 13:35:25,499   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@6475472c{/jobs/job,null,AVAILABLE,@Spark}
2018-09-18 13:35:25,499   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@3f07b12c{/jobs/job/json,null,AVAILABLE,@Spark}
2018-09-18 13:35:25,500   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@4bd1f8dd{/stages,null,AVAILABLE,@Spark}
2018-09-18 13:35:25,500   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@7096b474{/stages/json,null,AVAILABLE,@Spark}
2018-09-18 13:35:25,500   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@3e14c16d{/stages/stage,null,AVAILABLE,@Spark}
2018-09-18 13:35:25,500   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@3c989952{/stages/stage/json,null,AVAILABLE,@Spark}
2018-09-18 13:35:25,501   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@784b990c{/stages/pool,null,AVAILABLE,@Spark}
2018-09-18 13:35:25,501   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@3d3ba765{/stages/pool/json,null,AVAILABLE,@Spark}
2018-09-18 13:35:25,501   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@25bc0606{/storage,null,AVAILABLE,@Spark}
2018-09-18 13:35:25,501   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@5d1659ea{/storage/json,null,AVAILABLE,@Spark}
2018-09-18 13:35:25,501   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@793138bd{/storage/rdd,null,AVAILABLE,@Spark}
2018-09-18 13:35:25,502   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@1951b871{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-09-18 13:35:25,502   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@5c18016b{/environment,null,AVAILABLE,@Spark}
2018-09-18 13:35:25,502   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@33aeca0b{/environment/json,null,AVAILABLE,@Spark}
2018-09-18 13:35:25,502   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@43aaf813{/executors,null,AVAILABLE,@Spark}
2018-09-18 13:35:25,503   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@57ac5227{/executors/json,null,AVAILABLE,@Spark}
2018-09-18 13:35:25,503   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@4ba302e0{/executors/threadDump,null,AVAILABLE,@Spark}
2018-09-18 13:35:25,503   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@e98770d{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-09-18 13:35:25,508   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@1ae67cad{/static,null,AVAILABLE,@Spark}
2018-09-18 13:35:25,508   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@2f6e28bc{/,null,AVAILABLE,@Spark}
2018-09-18 13:35:25,509   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@7c098bb3{/api,null,AVAILABLE,@Spark}
2018-09-18 13:35:25,509   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@31e4bb20{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-09-18 13:35:25,509   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@18cebaa5{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-09-18 13:35:25,521   INFO --- [main]  org.spark_project.jetty.server.ServerConnector(line:266) : Started Spark@1021f6c9{HTTP/1.1}{0.0.0.0:4040}
2018-09-18 13:35:25,521   INFO --- [main]  org.spark_project.jetty.server.Server(line:379) : Started @2142ms
2018-09-18 13:35:25,522   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'SparkUI' on port 4040.
2018-09-18 13:35:25,525   INFO --- [main]  org.apache.spark.ui.SparkUI(line:54) : Bound SparkUI to 0.0.0.0, and started at http://192.168.3.199:4040
2018-09-18 13:35:25,595   INFO --- [main]  org.apache.spark.executor.Executor(line:54) : Starting executor ID driver on host localhost
2018-09-18 13:35:25,641   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 52211.
2018-09-18 13:35:25,642   INFO --- [main]  org.apache.spark.network.netty.NettyBlockTransferService(line:54) : Server created on 192.168.3.199:52211
2018-09-18 13:35:25,644   INFO --- [main]  org.apache.spark.storage.BlockManager(line:54) : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-09-18 13:35:25,645   INFO --- [main]  org.apache.spark.storage.BlockManagerMaster(line:54) : Registering BlockManager BlockManagerId(driver, 192.168.3.199, 52211, None)
2018-09-18 13:35:25,647   INFO --- [dispatcher-event-loop-2]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : Registering block manager 192.168.3.199:52211 with 3.0 GB RAM, BlockManagerId(driver, 192.168.3.199, 52211, None)
2018-09-18 13:35:25,650   INFO --- [main]  org.apache.spark.storage.BlockManagerMaster(line:54) : Registered BlockManager BlockManagerId(driver, 192.168.3.199, 52211, None)
2018-09-18 13:35:25,650   INFO --- [main]  org.apache.spark.storage.BlockManager(line:54) : Initialized BlockManager: BlockManagerId(driver, 192.168.3.199, 52211, None)
2018-09-18 13:35:25,794   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@1b9ea3e3{/metrics/json,null,AVAILABLE,@Spark}
2018-09-18 13:35:25,810   WARN --- [main]  org.apache.spark.SparkContext(line:66) : Using an existing SparkContext; some configuration may not take effect.
2018-09-18 13:35:25,845   INFO --- [main]  org.apache.spark.sql.internal.SharedState(line:54) : Warehouse path is 'file:/C:/Users/wshs/IdeaProjects/logdataSession/spark-warehouse/'.
2018-09-18 13:35:25,850   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@5be82d43{/SQL,null,AVAILABLE,@Spark}
2018-09-18 13:35:25,851   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@345e5a17{/SQL/json,null,AVAILABLE,@Spark}
2018-09-18 13:35:25,852   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@77b7ffa4{/SQL/execution,null,AVAILABLE,@Spark}
2018-09-18 13:35:25,852   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@402f80f5{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-09-18 13:35:25,854   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@2102a4d5{/static/sql,null,AVAILABLE,@Spark}
2018-09-18 13:35:26,243   INFO --- [main]  org.apache.spark.storage.memory.MemoryStore(line:54) : Block broadcast_0 stored as values in memory (estimated size 127.1 KB, free 3.0 GB)
2018-09-18 13:35:26,809   INFO --- [main]  org.apache.spark.storage.memory.MemoryStore(line:54) : Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.3 KB, free 3.0 GB)
2018-09-18 13:35:26,814   INFO --- [dispatcher-event-loop-4]  org.apache.spark.storage.BlockManagerInfo(line:54) : Added broadcast_0_piece0 in memory on 192.168.3.199:52211 (size: 14.3 KB, free: 3.0 GB)
2018-09-18 13:35:26,818   INFO --- [main]  org.apache.spark.SparkContext(line:54) : Created broadcast 0 from textFile at logSession.scala:39
2018-09-18 13:35:26,895   INFO --- [main]  org.apache.hadoop.mapred.FileInputFormat(line:253) : Total input paths to process : 1
2018-09-18 13:35:26,931   INFO --- [main]  org.apache.spark.SparkContext(line:54) : Starting job: collect at logSession.scala:40
2018-09-18 13:35:26,946   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Got job 0 (collect at logSession.scala:40) with 2 output partitions
2018-09-18 13:35:26,946   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Final stage: ResultStage 0 (collect at logSession.scala:40)
2018-09-18 13:35:26,947   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Parents of final stage: List()
2018-09-18 13:35:26,949   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Missing parents: List()
2018-09-18 13:35:26,956   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Submitting ResultStage 0 (e:\r_actionopvidio.txt MapPartitionsRDD[1] at textFile at logSession.scala:39), which has no missing parents
2018-09-18 13:35:26,971   INFO --- [dag-scheduler-event-loop]  org.apache.spark.storage.memory.MemoryStore(line:54) : Block broadcast_1 stored as values in memory (estimated size 3.2 KB, free 3.0 GB)
2018-09-18 13:35:26,976   INFO --- [dag-scheduler-event-loop]  org.apache.spark.storage.memory.MemoryStore(line:54) : Block broadcast_1_piece0 stored as bytes in memory (estimated size 1936.0 B, free 3.0 GB)
2018-09-18 13:35:26,977   INFO --- [dispatcher-event-loop-5]  org.apache.spark.storage.BlockManagerInfo(line:54) : Added broadcast_1_piece0 in memory on 192.168.3.199:52211 (size: 1936.0 B, free: 3.0 GB)
2018-09-18 13:35:26,977   INFO --- [dag-scheduler-event-loop]  org.apache.spark.SparkContext(line:54) : Created broadcast 1 from broadcast at DAGScheduler.scala:996
2018-09-18 13:35:26,980   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Submitting 2 missing tasks from ResultStage 0 (e:\r_actionopvidio.txt MapPartitionsRDD[1] at textFile at logSession.scala:39)
2018-09-18 13:35:26,982   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.TaskSchedulerImpl(line:54) : Adding task set 0.0 with 2 tasks
2018-09-18 13:35:27,050   INFO --- [dispatcher-event-loop-6]  org.apache.spark.scheduler.TaskSetManager(line:54) : Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 5976 bytes)
2018-09-18 13:35:27,053   INFO --- [dispatcher-event-loop-6]  org.apache.spark.scheduler.TaskSetManager(line:54) : Starting task 1.0 in stage 0.0 (TID 1, localhost, executor driver, partition 1, PROCESS_LOCAL, 5976 bytes)
2018-09-18 13:35:27,059   INFO --- [Executor task launch worker for task 0]  org.apache.spark.executor.Executor(line:54) : Running task 0.0 in stage 0.0 (TID 0)
2018-09-18 13:35:27,059   INFO --- [Executor task launch worker for task 1]  org.apache.spark.executor.Executor(line:54) : Running task 1.0 in stage 0.0 (TID 1)
2018-09-18 13:35:27,093   INFO --- [Executor task launch worker for task 0]  org.apache.spark.rdd.HadoopRDD(line:54) : Input split: file:/e:/r_actionopvidio.txt:0+188363
2018-09-18 13:35:27,093   INFO --- [Executor task launch worker for task 1]  org.apache.spark.rdd.HadoopRDD(line:54) : Input split: file:/e:/r_actionopvidio.txt:188363+188364
2018-09-18 13:35:27,100   INFO --- [Executor task launch worker for task 1]  org.apache.hadoop.conf.Configuration.deprecation(line:840) : mapred.tip.id is deprecated. Instead, use mapreduce.task.id
2018-09-18 13:35:27,100   INFO --- [Executor task launch worker for task 0]  org.apache.hadoop.conf.Configuration.deprecation(line:840) : mapred.tip.id is deprecated. Instead, use mapreduce.task.id
2018-09-18 13:35:27,100   INFO --- [Executor task launch worker for task 1]  org.apache.hadoop.conf.Configuration.deprecation(line:840) : mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
2018-09-18 13:35:27,100   INFO --- [Executor task launch worker for task 1]  org.apache.hadoop.conf.Configuration.deprecation(line:840) : mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
2018-09-18 13:35:27,100   INFO --- [Executor task launch worker for task 0]  org.apache.hadoop.conf.Configuration.deprecation(line:840) : mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
2018-09-18 13:35:27,100   INFO --- [Executor task launch worker for task 1]  org.apache.hadoop.conf.Configuration.deprecation(line:840) : mapred.job.id is deprecated. Instead, use mapreduce.job.id
2018-09-18 13:35:27,148   INFO --- [Executor task launch worker for task 0]  org.apache.spark.executor.Executor(line:54) : Finished task 0.0 in stage 0.0 (TID 0). 193283 bytes result sent to driver
2018-09-18 13:35:27,148   INFO --- [Executor task launch worker for task 1]  org.apache.spark.executor.Executor(line:54) : Finished task 1.0 in stage 0.0 (TID 1). 193184 bytes result sent to driver
2018-09-18 13:35:27,163   INFO --- [task-result-getter-1]  org.apache.spark.scheduler.TaskSetManager(line:54) : Finished task 1.0 in stage 0.0 (TID 1) in 109 ms on localhost (executor driver) (1/2)
2018-09-18 13:35:27,164   INFO --- [task-result-getter-0]  org.apache.spark.scheduler.TaskSetManager(line:54) : Finished task 0.0 in stage 0.0 (TID 0) in 137 ms on localhost (executor driver) (2/2)
2018-09-18 13:35:27,165   INFO --- [task-result-getter-0]  org.apache.spark.scheduler.TaskSchedulerImpl(line:54) : Removed TaskSet 0.0, whose tasks have all completed, from pool 
2018-09-18 13:35:27,168   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : ResultStage 0 (collect at logSession.scala:40) finished in 0.151 s
2018-09-18 13:35:27,173   INFO --- [main]  org.apache.spark.scheduler.DAGScheduler(line:54) : Job 0 finished: collect at logSession.scala:40, took 0.241653 s
2018-09-18 13:35:29,393   INFO --- [main]  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator(line:54) : Code generated in 243.902732 ms
2018-09-18 13:35:29,418   INFO --- [main]  org.apache.spark.SparkContext(line:54) : Starting job: show at logSession.scala:43
2018-09-18 13:35:29,419   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Got job 1 (show at logSession.scala:43) with 1 output partitions
2018-09-18 13:35:29,419   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Final stage: ResultStage 1 (show at logSession.scala:43)
2018-09-18 13:35:29,420   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Parents of final stage: List()
2018-09-18 13:35:29,420   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Missing parents: List()
2018-09-18 13:35:29,420   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Submitting ResultStage 1 (MapPartitionsRDD[6] at show at logSession.scala:43), which has no missing parents
2018-09-18 13:35:29,427   INFO --- [dag-scheduler-event-loop]  org.apache.spark.storage.memory.MemoryStore(line:54) : Block broadcast_2 stored as values in memory (estimated size 12.1 KB, free 3.0 GB)
2018-09-18 13:35:29,431   INFO --- [dag-scheduler-event-loop]  org.apache.spark.storage.memory.MemoryStore(line:54) : Block broadcast_2_piece0 stored as bytes in memory (estimated size 5.0 KB, free 3.0 GB)
2018-09-18 13:35:29,434   INFO --- [dispatcher-event-loop-3]  org.apache.spark.storage.BlockManagerInfo(line:54) : Added broadcast_2_piece0 in memory on 192.168.3.199:52211 (size: 5.0 KB, free: 3.0 GB)
2018-09-18 13:35:29,435   INFO --- [dag-scheduler-event-loop]  org.apache.spark.SparkContext(line:54) : Created broadcast 2 from broadcast at DAGScheduler.scala:996
2018-09-18 13:35:29,435   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[6] at show at logSession.scala:43)
2018-09-18 13:35:29,435   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.TaskSchedulerImpl(line:54) : Adding task set 1.0 with 1 tasks
2018-09-18 13:35:29,447   INFO --- [dispatcher-event-loop-4]  org.apache.spark.scheduler.TaskSetManager(line:54) : Starting task 0.0 in stage 1.0 (TID 2, localhost, executor driver, partition 0, PROCESS_LOCAL, 5921 bytes)
2018-09-18 13:35:29,448   INFO --- [Executor task launch worker for task 2]  org.apache.spark.executor.Executor(line:54) : Running task 0.0 in stage 1.0 (TID 2)
2018-09-18 13:35:29,454   INFO --- [Executor task launch worker for task 2]  org.apache.spark.rdd.HadoopRDD(line:54) : Input split: file:/e:/r_actionopvidio.txt:0+188363
2018-09-18 13:35:29,554  ERROR --- [Executor task launch worker for task 2]  org.apache.spark.executor.Executor(line:91) : Exception in task 0.0 in stage 1.0 (TID 2)
java.lang.NumberFormatException: For input string: ""
	at java.lang.NumberFormatException.forInputString(NumberFormatException.java:65)
	at java.lang.Integer.parseInt(Integer.java:592)
	at java.lang.Integer.parseInt(Integer.java:615)
	at scala.collection.immutable.StringLike$class.toInt(StringLike.scala:272)
	at scala.collection.immutable.StringOps.toInt(StringOps.scala:29)
	at logSession$$anonfun$2.apply(logSession.scala:42)
	at logSession$$anonfun$2.apply(logSession.scala:42)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1.hasNext(WholeStageCodegenExec.scala:377)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:231)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:225)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:827)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:827)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-09-18 13:35:29,571   INFO --- [dispatcher-event-loop-2]  org.apache.spark.storage.BlockManagerInfo(line:54) : Removed broadcast_1_piece0 on 192.168.3.199:52211 in memory (size: 1936.0 B, free: 3.0 GB)
2018-09-18 13:35:29,574   WARN --- [task-result-getter-2]  org.apache.spark.scheduler.TaskSetManager(line:66) : Lost task 0.0 in stage 1.0 (TID 2, localhost, executor driver): java.lang.NumberFormatException: For input string: ""
	at java.lang.NumberFormatException.forInputString(NumberFormatException.java:65)
	at java.lang.Integer.parseInt(Integer.java:592)
	at java.lang.Integer.parseInt(Integer.java:615)
	at scala.collection.immutable.StringLike$class.toInt(StringLike.scala:272)
	at scala.collection.immutable.StringOps.toInt(StringOps.scala:29)
	at logSession$$anonfun$2.apply(logSession.scala:42)
	at logSession$$anonfun$2.apply(logSession.scala:42)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1.hasNext(WholeStageCodegenExec.scala:377)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:231)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:225)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:827)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:827)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

2018-09-18 13:35:29,575  ERROR --- [task-result-getter-2]  org.apache.spark.scheduler.TaskSetManager(line:70) : Task 0 in stage 1.0 failed 1 times; aborting job
2018-09-18 13:35:29,576   INFO --- [task-result-getter-2]  org.apache.spark.scheduler.TaskSchedulerImpl(line:54) : Removed TaskSet 1.0, whose tasks have all completed, from pool 
2018-09-18 13:35:29,578   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.TaskSchedulerImpl(line:54) : Cancelling stage 1
2018-09-18 13:35:29,579   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : ResultStage 1 (show at logSession.scala:43) failed in 0.144 s due to Job aborted due to stage failure: Task 0 in stage 1.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1.0 (TID 2, localhost, executor driver): java.lang.NumberFormatException: For input string: ""
	at java.lang.NumberFormatException.forInputString(NumberFormatException.java:65)
	at java.lang.Integer.parseInt(Integer.java:592)
	at java.lang.Integer.parseInt(Integer.java:615)
	at scala.collection.immutable.StringLike$class.toInt(StringLike.scala:272)
	at scala.collection.immutable.StringOps.toInt(StringOps.scala:29)
	at logSession$$anonfun$2.apply(logSession.scala:42)
	at logSession$$anonfun$2.apply(logSession.scala:42)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1.hasNext(WholeStageCodegenExec.scala:377)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:231)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:225)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:827)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:827)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

Driver stacktrace:
2018-09-18 13:35:29,580   INFO --- [main]  org.apache.spark.scheduler.DAGScheduler(line:54) : Job 1 failed: show at logSession.scala:43, took 0.161446 s
2018-09-18 13:35:29,587   INFO --- [Thread-1]  org.apache.spark.SparkContext(line:54) : Invoking stop() from shutdown hook
2018-09-18 13:35:29,591   INFO --- [Thread-1]  org.spark_project.jetty.server.ServerConnector(line:306) : Stopped Spark@1021f6c9{HTTP/1.1}{0.0.0.0:4040}
2018-09-18 13:35:29,593   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@18cebaa5{/stages/stage/kill,null,UNAVAILABLE,@Spark}
2018-09-18 13:35:29,593   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@31e4bb20{/jobs/job/kill,null,UNAVAILABLE,@Spark}
2018-09-18 13:35:29,593   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@7c098bb3{/api,null,UNAVAILABLE,@Spark}
2018-09-18 13:35:29,593   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@2f6e28bc{/,null,UNAVAILABLE,@Spark}
2018-09-18 13:35:29,593   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@1ae67cad{/static,null,UNAVAILABLE,@Spark}
2018-09-18 13:35:29,594   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@e98770d{/executors/threadDump/json,null,UNAVAILABLE,@Spark}
2018-09-18 13:35:29,594   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@4ba302e0{/executors/threadDump,null,UNAVAILABLE,@Spark}
2018-09-18 13:35:29,594   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@57ac5227{/executors/json,null,UNAVAILABLE,@Spark}
2018-09-18 13:35:29,594   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@43aaf813{/executors,null,UNAVAILABLE,@Spark}
2018-09-18 13:35:29,594   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@33aeca0b{/environment/json,null,UNAVAILABLE,@Spark}
2018-09-18 13:35:29,594   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@5c18016b{/environment,null,UNAVAILABLE,@Spark}
2018-09-18 13:35:29,594   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@1951b871{/storage/rdd/json,null,UNAVAILABLE,@Spark}
2018-09-18 13:35:29,595   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@793138bd{/storage/rdd,null,UNAVAILABLE,@Spark}
2018-09-18 13:35:29,595   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@5d1659ea{/storage/json,null,UNAVAILABLE,@Spark}
2018-09-18 13:35:29,595   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@25bc0606{/storage,null,UNAVAILABLE,@Spark}
2018-09-18 13:35:29,595   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@3d3ba765{/stages/pool/json,null,UNAVAILABLE,@Spark}
2018-09-18 13:35:29,596   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@784b990c{/stages/pool,null,UNAVAILABLE,@Spark}
2018-09-18 13:35:29,596   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@3c989952{/stages/stage/json,null,UNAVAILABLE,@Spark}
2018-09-18 13:35:29,596   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@3e14c16d{/stages/stage,null,UNAVAILABLE,@Spark}
2018-09-18 13:35:29,596   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@7096b474{/stages/json,null,UNAVAILABLE,@Spark}
2018-09-18 13:35:29,596   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@4bd1f8dd{/stages,null,UNAVAILABLE,@Spark}
2018-09-18 13:35:29,597   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@3f07b12c{/jobs/job/json,null,UNAVAILABLE,@Spark}
2018-09-18 13:35:29,597   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@6475472c{/jobs/job,null,UNAVAILABLE,@Spark}
2018-09-18 13:35:29,597   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@4b7e96a{/jobs/json,null,UNAVAILABLE,@Spark}
2018-09-18 13:35:29,597   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@5c8504fd{/jobs,null,UNAVAILABLE,@Spark}
2018-09-18 13:35:29,599   INFO --- [Thread-1]  org.apache.spark.ui.SparkUI(line:54) : Stopped Spark web UI at http://192.168.3.199:4040
2018-09-18 13:35:29,607   INFO --- [dispatcher-event-loop-4]  org.apache.spark.MapOutputTrackerMasterEndpoint(line:54) : MapOutputTrackerMasterEndpoint stopped!
2018-09-18 13:35:29,636   INFO --- [Thread-1]  org.apache.spark.storage.memory.MemoryStore(line:54) : MemoryStore cleared
2018-09-18 13:35:29,637   INFO --- [Thread-1]  org.apache.spark.storage.BlockManager(line:54) : BlockManager stopped
2018-09-18 13:35:29,638   INFO --- [Thread-1]  org.apache.spark.storage.BlockManagerMaster(line:54) : BlockManagerMaster stopped
2018-09-18 13:35:29,641   INFO --- [dispatcher-event-loop-2]  org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint(line:54) : OutputCommitCoordinator stopped!
2018-09-18 13:35:29,646   INFO --- [Thread-1]  org.apache.spark.SparkContext(line:54) : Successfully stopped SparkContext
2018-09-18 13:35:29,646   INFO --- [Thread-1]  org.apache.spark.util.ShutdownHookManager(line:54) : Shutdown hook called
2018-09-18 13:35:29,647   INFO --- [Thread-1]  org.apache.spark.util.ShutdownHookManager(line:54) : Deleting directory C:\Users\wshs\AppData\Local\Temp\spark-aade7864-eba5-443c-a5fa-4d5e9624c453
2018-09-18 13:35:55,753   INFO --- [main]  org.apache.spark.SparkContext(line:54) : Running Spark version 2.1.1
2018-09-18 13:35:56,150   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing view acls to: wshs
2018-09-18 13:35:56,151   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing modify acls to: wshs
2018-09-18 13:35:56,152   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing view acls groups to: 
2018-09-18 13:35:56,153   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing modify acls groups to: 
2018-09-18 13:35:56,155   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(wshs); groups with view permissions: Set(); users  with modify permissions: Set(wshs); groups with modify permissions: Set()
2018-09-18 13:35:56,687   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'sparkDriver' on port 52283.
2018-09-18 13:35:56,709   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering MapOutputTracker
2018-09-18 13:35:56,730   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering BlockManagerMaster
2018-09-18 13:35:56,733   INFO --- [main]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-09-18 13:35:56,734   INFO --- [main]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : BlockManagerMasterEndpoint up
2018-09-18 13:35:56,749   INFO --- [main]  org.apache.spark.storage.DiskBlockManager(line:54) : Created local directory at C:\Users\wshs\AppData\Local\Temp\blockmgr-7738572d-d757-41f8-ad40-a961a7e611e1
2018-09-18 13:35:56,771   INFO --- [main]  org.apache.spark.storage.memory.MemoryStore(line:54) : MemoryStore started with capacity 3.0 GB
2018-09-18 13:35:56,834   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering OutputCommitCoordinator
2018-09-18 13:35:56,909   INFO --- [main]  org.spark_project.jetty.util.log(line:186) : Logging initialized @2067ms
2018-09-18 13:35:56,982   INFO --- [main]  org.spark_project.jetty.server.Server(line:327) : jetty-9.2.z-SNAPSHOT
2018-09-18 13:35:56,995   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@5c8504fd{/jobs,null,AVAILABLE,@Spark}
2018-09-18 13:35:56,995   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@4b7e96a{/jobs/json,null,AVAILABLE,@Spark}
2018-09-18 13:35:56,995   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@6475472c{/jobs/job,null,AVAILABLE,@Spark}
2018-09-18 13:35:56,996   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@3f07b12c{/jobs/job/json,null,AVAILABLE,@Spark}
2018-09-18 13:35:56,996   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@4bd1f8dd{/stages,null,AVAILABLE,@Spark}
2018-09-18 13:35:56,996   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@7096b474{/stages/json,null,AVAILABLE,@Spark}
2018-09-18 13:35:56,996   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@3e14c16d{/stages/stage,null,AVAILABLE,@Spark}
2018-09-18 13:35:56,996   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@3c989952{/stages/stage/json,null,AVAILABLE,@Spark}
2018-09-18 13:35:56,997   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@784b990c{/stages/pool,null,AVAILABLE,@Spark}
2018-09-18 13:35:56,997   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@3d3ba765{/stages/pool/json,null,AVAILABLE,@Spark}
2018-09-18 13:35:56,997   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@25bc0606{/storage,null,AVAILABLE,@Spark}
2018-09-18 13:35:56,998   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@5d1659ea{/storage/json,null,AVAILABLE,@Spark}
2018-09-18 13:35:56,998   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@793138bd{/storage/rdd,null,AVAILABLE,@Spark}
2018-09-18 13:35:56,998   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@1951b871{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-09-18 13:35:56,998   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@5c18016b{/environment,null,AVAILABLE,@Spark}
2018-09-18 13:35:56,998   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@33aeca0b{/environment/json,null,AVAILABLE,@Spark}
2018-09-18 13:35:56,999   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@43aaf813{/executors,null,AVAILABLE,@Spark}
2018-09-18 13:35:56,999   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@57ac5227{/executors/json,null,AVAILABLE,@Spark}
2018-09-18 13:35:56,999   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@4ba302e0{/executors/threadDump,null,AVAILABLE,@Spark}
2018-09-18 13:35:56,999   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@e98770d{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-09-18 13:35:57,004   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@1ae67cad{/static,null,AVAILABLE,@Spark}
2018-09-18 13:35:57,004   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@2f6e28bc{/,null,AVAILABLE,@Spark}
2018-09-18 13:35:57,005   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@7c098bb3{/api,null,AVAILABLE,@Spark}
2018-09-18 13:35:57,005   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@31e4bb20{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-09-18 13:35:57,005   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@18cebaa5{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-09-18 13:35:57,016   INFO --- [main]  org.spark_project.jetty.server.ServerConnector(line:266) : Started Spark@1021f6c9{HTTP/1.1}{0.0.0.0:4040}
2018-09-18 13:35:57,016   INFO --- [main]  org.spark_project.jetty.server.Server(line:379) : Started @2175ms
2018-09-18 13:35:57,017   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'SparkUI' on port 4040.
2018-09-18 13:35:57,019   INFO --- [main]  org.apache.spark.ui.SparkUI(line:54) : Bound SparkUI to 0.0.0.0, and started at http://192.168.3.199:4040
2018-09-18 13:35:57,085   INFO --- [main]  org.apache.spark.executor.Executor(line:54) : Starting executor ID driver on host localhost
2018-09-18 13:35:57,126   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 52324.
2018-09-18 13:35:57,126   INFO --- [main]  org.apache.spark.network.netty.NettyBlockTransferService(line:54) : Server created on 192.168.3.199:52324
2018-09-18 13:35:57,127   INFO --- [main]  org.apache.spark.storage.BlockManager(line:54) : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-09-18 13:35:57,129   INFO --- [main]  org.apache.spark.storage.BlockManagerMaster(line:54) : Registering BlockManager BlockManagerId(driver, 192.168.3.199, 52324, None)
2018-09-18 13:35:57,131   INFO --- [dispatcher-event-loop-2]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : Registering block manager 192.168.3.199:52324 with 3.0 GB RAM, BlockManagerId(driver, 192.168.3.199, 52324, None)
2018-09-18 13:35:57,134   INFO --- [main]  org.apache.spark.storage.BlockManagerMaster(line:54) : Registered BlockManager BlockManagerId(driver, 192.168.3.199, 52324, None)
2018-09-18 13:35:57,134   INFO --- [main]  org.apache.spark.storage.BlockManager(line:54) : Initialized BlockManager: BlockManagerId(driver, 192.168.3.199, 52324, None)
2018-09-18 13:35:57,286   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@1b9ea3e3{/metrics/json,null,AVAILABLE,@Spark}
2018-09-18 13:35:57,302   WARN --- [main]  org.apache.spark.SparkContext(line:66) : Using an existing SparkContext; some configuration may not take effect.
2018-09-18 13:35:57,339   INFO --- [main]  org.apache.spark.sql.internal.SharedState(line:54) : Warehouse path is 'file:/C:/Users/wshs/IdeaProjects/logdataSession/spark-warehouse/'.
2018-09-18 13:35:57,345   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@5be82d43{/SQL,null,AVAILABLE,@Spark}
2018-09-18 13:35:57,345   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@345e5a17{/SQL/json,null,AVAILABLE,@Spark}
2018-09-18 13:35:57,346   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@77b7ffa4{/SQL/execution,null,AVAILABLE,@Spark}
2018-09-18 13:35:57,346   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@402f80f5{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-09-18 13:35:57,348   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@2102a4d5{/static/sql,null,AVAILABLE,@Spark}
2018-09-18 13:35:57,734   INFO --- [main]  org.apache.spark.storage.memory.MemoryStore(line:54) : Block broadcast_0 stored as values in memory (estimated size 127.1 KB, free 3.0 GB)
2018-09-18 13:35:58,299   INFO --- [main]  org.apache.spark.storage.memory.MemoryStore(line:54) : Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.3 KB, free 3.0 GB)
2018-09-18 13:35:58,303   INFO --- [dispatcher-event-loop-4]  org.apache.spark.storage.BlockManagerInfo(line:54) : Added broadcast_0_piece0 in memory on 192.168.3.199:52324 (size: 14.3 KB, free: 3.0 GB)
2018-09-18 13:35:58,307   INFO --- [main]  org.apache.spark.SparkContext(line:54) : Created broadcast 0 from textFile at logSession.scala:39
2018-09-18 13:35:58,386   INFO --- [main]  org.apache.hadoop.mapred.FileInputFormat(line:253) : Total input paths to process : 1
2018-09-18 13:35:58,424   INFO --- [main]  org.apache.spark.SparkContext(line:54) : Starting job: collect at logSession.scala:40
2018-09-18 13:35:58,440   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Got job 0 (collect at logSession.scala:40) with 2 output partitions
2018-09-18 13:35:58,440   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Final stage: ResultStage 0 (collect at logSession.scala:40)
2018-09-18 13:35:58,441   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Parents of final stage: List()
2018-09-18 13:35:58,442   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Missing parents: List()
2018-09-18 13:35:58,449   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Submitting ResultStage 0 (e:\r_actionopvidio.txt MapPartitionsRDD[1] at textFile at logSession.scala:39), which has no missing parents
2018-09-18 13:35:58,461   INFO --- [dag-scheduler-event-loop]  org.apache.spark.storage.memory.MemoryStore(line:54) : Block broadcast_1 stored as values in memory (estimated size 3.2 KB, free 3.0 GB)
2018-09-18 13:35:58,466   INFO --- [dag-scheduler-event-loop]  org.apache.spark.storage.memory.MemoryStore(line:54) : Block broadcast_1_piece0 stored as bytes in memory (estimated size 1936.0 B, free 3.0 GB)
2018-09-18 13:35:58,467   INFO --- [dispatcher-event-loop-5]  org.apache.spark.storage.BlockManagerInfo(line:54) : Added broadcast_1_piece0 in memory on 192.168.3.199:52324 (size: 1936.0 B, free: 3.0 GB)
2018-09-18 13:35:58,493   INFO --- [dag-scheduler-event-loop]  org.apache.spark.SparkContext(line:54) : Created broadcast 1 from broadcast at DAGScheduler.scala:996
2018-09-18 13:35:58,496   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Submitting 2 missing tasks from ResultStage 0 (e:\r_actionopvidio.txt MapPartitionsRDD[1] at textFile at logSession.scala:39)
2018-09-18 13:35:58,499   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.TaskSchedulerImpl(line:54) : Adding task set 0.0 with 2 tasks
2018-09-18 13:35:58,537   INFO --- [dispatcher-event-loop-6]  org.apache.spark.scheduler.TaskSetManager(line:54) : Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 5976 bytes)
2018-09-18 13:35:58,541   INFO --- [dispatcher-event-loop-6]  org.apache.spark.scheduler.TaskSetManager(line:54) : Starting task 1.0 in stage 0.0 (TID 1, localhost, executor driver, partition 1, PROCESS_LOCAL, 5976 bytes)
2018-09-18 13:35:58,548   INFO --- [Executor task launch worker for task 1]  org.apache.spark.executor.Executor(line:54) : Running task 1.0 in stage 0.0 (TID 1)
2018-09-18 13:35:58,548   INFO --- [Executor task launch worker for task 0]  org.apache.spark.executor.Executor(line:54) : Running task 0.0 in stage 0.0 (TID 0)
2018-09-18 13:35:58,582   INFO --- [Executor task launch worker for task 0]  org.apache.spark.rdd.HadoopRDD(line:54) : Input split: file:/e:/r_actionopvidio.txt:0+188363
2018-09-18 13:35:58,582   INFO --- [Executor task launch worker for task 1]  org.apache.spark.rdd.HadoopRDD(line:54) : Input split: file:/e:/r_actionopvidio.txt:188363+188364
2018-09-18 13:35:58,589   INFO --- [Executor task launch worker for task 0]  org.apache.hadoop.conf.Configuration.deprecation(line:840) : mapred.tip.id is deprecated. Instead, use mapreduce.task.id
2018-09-18 13:35:58,589   INFO --- [Executor task launch worker for task 1]  org.apache.hadoop.conf.Configuration.deprecation(line:840) : mapred.tip.id is deprecated. Instead, use mapreduce.task.id
2018-09-18 13:35:58,589   INFO --- [Executor task launch worker for task 0]  org.apache.hadoop.conf.Configuration.deprecation(line:840) : mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
2018-09-18 13:35:58,589   INFO --- [Executor task launch worker for task 1]  org.apache.hadoop.conf.Configuration.deprecation(line:840) : mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
2018-09-18 13:35:58,589   INFO --- [Executor task launch worker for task 0]  org.apache.hadoop.conf.Configuration.deprecation(line:840) : mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
2018-09-18 13:35:58,589   INFO --- [Executor task launch worker for task 1]  org.apache.hadoop.conf.Configuration.deprecation(line:840) : mapred.job.id is deprecated. Instead, use mapreduce.job.id
2018-09-18 13:35:58,635   INFO --- [Executor task launch worker for task 0]  org.apache.spark.executor.Executor(line:54) : Finished task 0.0 in stage 0.0 (TID 0). 193283 bytes result sent to driver
2018-09-18 13:35:58,635   INFO --- [Executor task launch worker for task 1]  org.apache.spark.executor.Executor(line:54) : Finished task 1.0 in stage 0.0 (TID 1). 193184 bytes result sent to driver
2018-09-18 13:35:58,653   INFO --- [task-result-getter-1]  org.apache.spark.scheduler.TaskSetManager(line:54) : Finished task 1.0 in stage 0.0 (TID 1) in 111 ms on localhost (executor driver) (1/2)
2018-09-18 13:35:58,653   INFO --- [task-result-getter-0]  org.apache.spark.scheduler.TaskSetManager(line:54) : Finished task 0.0 in stage 0.0 (TID 0) in 136 ms on localhost (executor driver) (2/2)
2018-09-18 13:35:58,654   INFO --- [task-result-getter-0]  org.apache.spark.scheduler.TaskSchedulerImpl(line:54) : Removed TaskSet 0.0, whose tasks have all completed, from pool 
2018-09-18 13:35:58,658   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : ResultStage 0 (collect at logSession.scala:40) finished in 0.150 s
2018-09-18 13:35:58,662   INFO --- [main]  org.apache.spark.scheduler.DAGScheduler(line:54) : Job 0 finished: collect at logSession.scala:40, took 0.238690 s
2018-09-18 13:36:00,805   INFO --- [main]  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator(line:54) : Code generated in 216.732219 ms
2018-09-18 13:36:00,829   INFO --- [main]  org.apache.spark.SparkContext(line:54) : Starting job: show at logSession.scala:43
2018-09-18 13:36:00,830   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Got job 1 (show at logSession.scala:43) with 1 output partitions
2018-09-18 13:36:00,831   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Final stage: ResultStage 1 (show at logSession.scala:43)
2018-09-18 13:36:00,831   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Parents of final stage: List()
2018-09-18 13:36:00,831   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Missing parents: List()
2018-09-18 13:36:00,831   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Submitting ResultStage 1 (MapPartitionsRDD[6] at show at logSession.scala:43), which has no missing parents
2018-09-18 13:36:00,837   INFO --- [dag-scheduler-event-loop]  org.apache.spark.storage.memory.MemoryStore(line:54) : Block broadcast_2 stored as values in memory (estimated size 12.1 KB, free 3.0 GB)
2018-09-18 13:36:00,841   INFO --- [dag-scheduler-event-loop]  org.apache.spark.storage.memory.MemoryStore(line:54) : Block broadcast_2_piece0 stored as bytes in memory (estimated size 5.0 KB, free 3.0 GB)
2018-09-18 13:36:00,845   INFO --- [dispatcher-event-loop-3]  org.apache.spark.storage.BlockManagerInfo(line:54) : Added broadcast_2_piece0 in memory on 192.168.3.199:52324 (size: 5.0 KB, free: 3.0 GB)
2018-09-18 13:36:00,845   INFO --- [dag-scheduler-event-loop]  org.apache.spark.SparkContext(line:54) : Created broadcast 2 from broadcast at DAGScheduler.scala:996
2018-09-18 13:36:00,845   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[6] at show at logSession.scala:43)
2018-09-18 13:36:00,846   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.TaskSchedulerImpl(line:54) : Adding task set 1.0 with 1 tasks
2018-09-18 13:36:00,847   INFO --- [dispatcher-event-loop-4]  org.apache.spark.scheduler.TaskSetManager(line:54) : Starting task 0.0 in stage 1.0 (TID 2, localhost, executor driver, partition 0, PROCESS_LOCAL, 5921 bytes)
2018-09-18 13:36:00,847   INFO --- [Executor task launch worker for task 2]  org.apache.spark.executor.Executor(line:54) : Running task 0.0 in stage 1.0 (TID 2)
2018-09-18 13:36:00,865   INFO --- [Executor task launch worker for task 2]  org.apache.spark.rdd.HadoopRDD(line:54) : Input split: file:/e:/r_actionopvidio.txt:0+188363
2018-09-18 13:36:00,879  ERROR --- [Executor task launch worker for task 2]  org.apache.spark.executor.Executor(line:91) : Exception in task 0.0 in stage 1.0 (TID 2)
java.lang.NumberFormatException: For input string: ""
	at java.lang.NumberFormatException.forInputString(NumberFormatException.java:65)
	at java.lang.Integer.parseInt(Integer.java:592)
	at java.lang.Integer.parseInt(Integer.java:615)
	at scala.collection.immutable.StringLike$class.toInt(StringLike.scala:272)
	at scala.collection.immutable.StringOps.toInt(StringOps.scala:29)
	at logSession$$anonfun$2.apply(logSession.scala:42)
	at logSession$$anonfun$2.apply(logSession.scala:42)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1.hasNext(WholeStageCodegenExec.scala:377)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:231)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:225)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:827)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:827)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-09-18 13:36:00,987   WARN --- [task-result-getter-2]  org.apache.spark.scheduler.TaskSetManager(line:66) : Lost task 0.0 in stage 1.0 (TID 2, localhost, executor driver): java.lang.NumberFormatException: For input string: ""
	at java.lang.NumberFormatException.forInputString(NumberFormatException.java:65)
	at java.lang.Integer.parseInt(Integer.java:592)
	at java.lang.Integer.parseInt(Integer.java:615)
	at scala.collection.immutable.StringLike$class.toInt(StringLike.scala:272)
	at scala.collection.immutable.StringOps.toInt(StringOps.scala:29)
	at logSession$$anonfun$2.apply(logSession.scala:42)
	at logSession$$anonfun$2.apply(logSession.scala:42)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1.hasNext(WholeStageCodegenExec.scala:377)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:231)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:225)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:827)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:827)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

2018-09-18 13:36:00,990  ERROR --- [task-result-getter-2]  org.apache.spark.scheduler.TaskSetManager(line:70) : Task 0 in stage 1.0 failed 1 times; aborting job
2018-09-18 13:36:00,991   INFO --- [task-result-getter-2]  org.apache.spark.scheduler.TaskSchedulerImpl(line:54) : Removed TaskSet 1.0, whose tasks have all completed, from pool 
2018-09-18 13:36:00,993   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.TaskSchedulerImpl(line:54) : Cancelling stage 1
2018-09-18 13:36:00,995   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : ResultStage 1 (show at logSession.scala:43) failed in 0.148 s due to Job aborted due to stage failure: Task 0 in stage 1.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1.0 (TID 2, localhost, executor driver): java.lang.NumberFormatException: For input string: ""
	at java.lang.NumberFormatException.forInputString(NumberFormatException.java:65)
	at java.lang.Integer.parseInt(Integer.java:592)
	at java.lang.Integer.parseInt(Integer.java:615)
	at scala.collection.immutable.StringLike$class.toInt(StringLike.scala:272)
	at scala.collection.immutable.StringOps.toInt(StringOps.scala:29)
	at logSession$$anonfun$2.apply(logSession.scala:42)
	at logSession$$anonfun$2.apply(logSession.scala:42)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1.hasNext(WholeStageCodegenExec.scala:377)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:231)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:225)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:827)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:827)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

Driver stacktrace:
2018-09-18 13:36:00,995   INFO --- [dispatcher-event-loop-2]  org.apache.spark.storage.BlockManagerInfo(line:54) : Removed broadcast_1_piece0 on 192.168.3.199:52324 in memory (size: 1936.0 B, free: 3.0 GB)
2018-09-18 13:36:00,996   INFO --- [main]  org.apache.spark.scheduler.DAGScheduler(line:54) : Job 1 failed: show at logSession.scala:43, took 0.166060 s
2018-09-18 13:36:01,003   INFO --- [Thread-1]  org.apache.spark.SparkContext(line:54) : Invoking stop() from shutdown hook
2018-09-18 13:36:01,007   INFO --- [Thread-1]  org.spark_project.jetty.server.ServerConnector(line:306) : Stopped Spark@1021f6c9{HTTP/1.1}{0.0.0.0:4040}
2018-09-18 13:36:01,008   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@18cebaa5{/stages/stage/kill,null,UNAVAILABLE,@Spark}
2018-09-18 13:36:01,009   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@31e4bb20{/jobs/job/kill,null,UNAVAILABLE,@Spark}
2018-09-18 13:36:01,009   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@7c098bb3{/api,null,UNAVAILABLE,@Spark}
2018-09-18 13:36:01,009   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@2f6e28bc{/,null,UNAVAILABLE,@Spark}
2018-09-18 13:36:01,009   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@1ae67cad{/static,null,UNAVAILABLE,@Spark}
2018-09-18 13:36:01,009   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@e98770d{/executors/threadDump/json,null,UNAVAILABLE,@Spark}
2018-09-18 13:36:01,009   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@4ba302e0{/executors/threadDump,null,UNAVAILABLE,@Spark}
2018-09-18 13:36:01,010   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@57ac5227{/executors/json,null,UNAVAILABLE,@Spark}
2018-09-18 13:36:01,010   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@43aaf813{/executors,null,UNAVAILABLE,@Spark}
2018-09-18 13:36:01,010   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@33aeca0b{/environment/json,null,UNAVAILABLE,@Spark}
2018-09-18 13:36:01,010   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@5c18016b{/environment,null,UNAVAILABLE,@Spark}
2018-09-18 13:36:01,010   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@1951b871{/storage/rdd/json,null,UNAVAILABLE,@Spark}
2018-09-18 13:36:01,010   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@793138bd{/storage/rdd,null,UNAVAILABLE,@Spark}
2018-09-18 13:36:01,011   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@5d1659ea{/storage/json,null,UNAVAILABLE,@Spark}
2018-09-18 13:36:01,011   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@25bc0606{/storage,null,UNAVAILABLE,@Spark}
2018-09-18 13:36:01,011   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@3d3ba765{/stages/pool/json,null,UNAVAILABLE,@Spark}
2018-09-18 13:36:01,011   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@784b990c{/stages/pool,null,UNAVAILABLE,@Spark}
2018-09-18 13:36:01,011   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@3c989952{/stages/stage/json,null,UNAVAILABLE,@Spark}
2018-09-18 13:36:01,012   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@3e14c16d{/stages/stage,null,UNAVAILABLE,@Spark}
2018-09-18 13:36:01,012   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@7096b474{/stages/json,null,UNAVAILABLE,@Spark}
2018-09-18 13:36:01,012   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@4bd1f8dd{/stages,null,UNAVAILABLE,@Spark}
2018-09-18 13:36:01,012   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@3f07b12c{/jobs/job/json,null,UNAVAILABLE,@Spark}
2018-09-18 13:36:01,013   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@6475472c{/jobs/job,null,UNAVAILABLE,@Spark}
2018-09-18 13:36:01,016   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@4b7e96a{/jobs/json,null,UNAVAILABLE,@Spark}
2018-09-18 13:36:01,016   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@5c8504fd{/jobs,null,UNAVAILABLE,@Spark}
2018-09-18 13:36:01,019   INFO --- [Thread-1]  org.apache.spark.ui.SparkUI(line:54) : Stopped Spark web UI at http://192.168.3.199:4040
2018-09-18 13:36:01,028   INFO --- [dispatcher-event-loop-4]  org.apache.spark.MapOutputTrackerMasterEndpoint(line:54) : MapOutputTrackerMasterEndpoint stopped!
2018-09-18 13:36:01,060   INFO --- [Thread-1]  org.apache.spark.storage.memory.MemoryStore(line:54) : MemoryStore cleared
2018-09-18 13:36:01,060   INFO --- [Thread-1]  org.apache.spark.storage.BlockManager(line:54) : BlockManager stopped
2018-09-18 13:36:01,062   INFO --- [Thread-1]  org.apache.spark.storage.BlockManagerMaster(line:54) : BlockManagerMaster stopped
2018-09-18 13:36:01,064   INFO --- [dispatcher-event-loop-2]  org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint(line:54) : OutputCommitCoordinator stopped!
2018-09-18 13:36:01,069   INFO --- [Thread-1]  org.apache.spark.SparkContext(line:54) : Successfully stopped SparkContext
2018-09-18 13:36:01,070   INFO --- [Thread-1]  org.apache.spark.util.ShutdownHookManager(line:54) : Shutdown hook called
2018-09-18 13:36:01,071   INFO --- [Thread-1]  org.apache.spark.util.ShutdownHookManager(line:54) : Deleting directory C:\Users\wshs\AppData\Local\Temp\spark-ab218e8d-8650-46c8-8907-d7ac7cd5f8a4
2018-09-18 13:37:41,660   INFO --- [main]  org.apache.spark.SparkContext(line:54) : Running Spark version 2.1.1
2018-09-18 13:37:42,026   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing view acls to: wshs
2018-09-18 13:37:42,026   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing modify acls to: wshs
2018-09-18 13:37:42,027   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing view acls groups to: 
2018-09-18 13:37:42,028   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing modify acls groups to: 
2018-09-18 13:37:42,029   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(wshs); groups with view permissions: Set(); users  with modify permissions: Set(wshs); groups with modify permissions: Set()
2018-09-18 13:37:42,565   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'sparkDriver' on port 52442.
2018-09-18 13:37:42,584   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering MapOutputTracker
2018-09-18 13:37:42,605   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering BlockManagerMaster
2018-09-18 13:37:42,609   INFO --- [main]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-09-18 13:37:42,609   INFO --- [main]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : BlockManagerMasterEndpoint up
2018-09-18 13:37:42,625   INFO --- [main]  org.apache.spark.storage.DiskBlockManager(line:54) : Created local directory at C:\Users\wshs\AppData\Local\Temp\blockmgr-315a2370-5fcd-461f-8943-c631bfd6c842
2018-09-18 13:37:42,641   INFO --- [main]  org.apache.spark.storage.memory.MemoryStore(line:54) : MemoryStore started with capacity 3.0 GB
2018-09-18 13:37:42,709   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering OutputCommitCoordinator
2018-09-18 13:37:42,785   INFO --- [main]  org.spark_project.jetty.util.log(line:186) : Logging initialized @2086ms
2018-09-18 13:37:42,862   INFO --- [main]  org.spark_project.jetty.server.Server(line:327) : jetty-9.2.z-SNAPSHOT
2018-09-18 13:37:42,875   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@32811494{/jobs,null,AVAILABLE,@Spark}
2018-09-18 13:37:42,875   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@4795ded0{/jobs/json,null,AVAILABLE,@Spark}
2018-09-18 13:37:42,875   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@53dacd14{/jobs/job,null,AVAILABLE,@Spark}
2018-09-18 13:37:42,876   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@14d14731{/jobs/job/json,null,AVAILABLE,@Spark}
2018-09-18 13:37:42,876   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@2eced48b{/stages,null,AVAILABLE,@Spark}
2018-09-18 13:37:42,876   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@47c4ecdc{/stages/json,null,AVAILABLE,@Spark}
2018-09-18 13:37:42,876   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@42f33b5d{/stages/stage,null,AVAILABLE,@Spark}
2018-09-18 13:37:42,877   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@5c8504fd{/stages/stage/json,null,AVAILABLE,@Spark}
2018-09-18 13:37:42,877   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@4b7e96a{/stages/pool,null,AVAILABLE,@Spark}
2018-09-18 13:37:42,877   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@6475472c{/stages/pool/json,null,AVAILABLE,@Spark}
2018-09-18 13:37:42,877   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@3f07b12c{/storage,null,AVAILABLE,@Spark}
2018-09-18 13:37:42,878   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@4bd1f8dd{/storage/json,null,AVAILABLE,@Spark}
2018-09-18 13:37:42,878   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@7096b474{/storage/rdd,null,AVAILABLE,@Spark}
2018-09-18 13:37:42,878   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@3e14c16d{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-09-18 13:37:42,878   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@3c989952{/environment,null,AVAILABLE,@Spark}
2018-09-18 13:37:42,879   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@784b990c{/environment/json,null,AVAILABLE,@Spark}
2018-09-18 13:37:42,879   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@3d3ba765{/executors,null,AVAILABLE,@Spark}
2018-09-18 13:37:42,879   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@25bc0606{/executors/json,null,AVAILABLE,@Spark}
2018-09-18 13:37:42,879   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@5d1659ea{/executors/threadDump,null,AVAILABLE,@Spark}
2018-09-18 13:37:42,880   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@793138bd{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-09-18 13:37:42,884   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@1951b871{/static,null,AVAILABLE,@Spark}
2018-09-18 13:37:42,885   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@5c18016b{/,null,AVAILABLE,@Spark}
2018-09-18 13:37:42,885   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@33aeca0b{/api,null,AVAILABLE,@Spark}
2018-09-18 13:37:42,886   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@43aaf813{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-09-18 13:37:42,886   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@57ac5227{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-09-18 13:37:42,895   INFO --- [main]  org.spark_project.jetty.server.ServerConnector(line:266) : Started Spark@3e10dc6{HTTP/1.1}{0.0.0.0:4040}
2018-09-18 13:37:42,896   INFO --- [main]  org.spark_project.jetty.server.Server(line:379) : Started @2198ms
2018-09-18 13:37:42,896   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'SparkUI' on port 4040.
2018-09-18 13:37:42,898   INFO --- [main]  org.apache.spark.ui.SparkUI(line:54) : Bound SparkUI to 0.0.0.0, and started at http://192.168.3.199:4040
2018-09-18 13:37:42,964   INFO --- [main]  org.apache.spark.executor.Executor(line:54) : Starting executor ID driver on host localhost
2018-09-18 13:37:43,007   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 52483.
2018-09-18 13:37:43,008   INFO --- [main]  org.apache.spark.network.netty.NettyBlockTransferService(line:54) : Server created on 192.168.3.199:52483
2018-09-18 13:37:43,009   INFO --- [main]  org.apache.spark.storage.BlockManager(line:54) : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-09-18 13:37:43,011   INFO --- [main]  org.apache.spark.storage.BlockManagerMaster(line:54) : Registering BlockManager BlockManagerId(driver, 192.168.3.199, 52483, None)
2018-09-18 13:37:43,013   INFO --- [dispatcher-event-loop-2]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : Registering block manager 192.168.3.199:52483 with 3.0 GB RAM, BlockManagerId(driver, 192.168.3.199, 52483, None)
2018-09-18 13:37:43,017   INFO --- [main]  org.apache.spark.storage.BlockManagerMaster(line:54) : Registered BlockManager BlockManagerId(driver, 192.168.3.199, 52483, None)
2018-09-18 13:37:43,017   INFO --- [main]  org.apache.spark.storage.BlockManager(line:54) : Initialized BlockManager: BlockManagerId(driver, 192.168.3.199, 52483, None)
2018-09-18 13:37:43,172   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@42257bdd{/metrics/json,null,AVAILABLE,@Spark}
2018-09-18 13:37:43,191   WARN --- [main]  org.apache.spark.SparkContext(line:66) : Using an existing SparkContext; some configuration may not take effect.
2018-09-18 13:37:43,229   INFO --- [main]  org.apache.spark.sql.internal.SharedState(line:54) : Warehouse path is 'file:/C:/Users/wshs/IdeaProjects/logdataSession/spark-warehouse/'.
2018-09-18 13:37:43,235   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@7544a1e4{/SQL,null,AVAILABLE,@Spark}
2018-09-18 13:37:43,236   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@7957dc72{/SQL/json,null,AVAILABLE,@Spark}
2018-09-18 13:37:43,237   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@5be82d43{/SQL/execution,null,AVAILABLE,@Spark}
2018-09-18 13:37:43,238   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@345e5a17{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-09-18 13:37:43,240   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@5ed190be{/static/sql,null,AVAILABLE,@Spark}
2018-09-18 13:37:43,647   INFO --- [main]  org.apache.spark.storage.memory.MemoryStore(line:54) : Block broadcast_0 stored as values in memory (estimated size 127.1 KB, free 3.0 GB)
2018-09-18 13:37:44,229   INFO --- [main]  org.apache.spark.storage.memory.MemoryStore(line:54) : Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.3 KB, free 3.0 GB)
2018-09-18 13:37:44,234   INFO --- [dispatcher-event-loop-4]  org.apache.spark.storage.BlockManagerInfo(line:54) : Added broadcast_0_piece0 in memory on 192.168.3.199:52483 (size: 14.3 KB, free: 3.0 GB)
2018-09-18 13:37:44,239   INFO --- [main]  org.apache.spark.SparkContext(line:54) : Created broadcast 0 from textFile at logSession.scala:39
2018-09-18 13:37:44,324   INFO --- [main]  org.apache.hadoop.mapred.FileInputFormat(line:253) : Total input paths to process : 1
2018-09-18 13:37:44,362   INFO --- [main]  org.apache.spark.SparkContext(line:54) : Starting job: collect at logSession.scala:40
2018-09-18 13:37:44,376   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Got job 0 (collect at logSession.scala:40) with 2 output partitions
2018-09-18 13:37:44,377   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Final stage: ResultStage 0 (collect at logSession.scala:40)
2018-09-18 13:37:44,377   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Parents of final stage: List()
2018-09-18 13:37:44,378   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Missing parents: List()
2018-09-18 13:37:44,385   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Submitting ResultStage 0 (MapPartitionsRDD[2] at map at logSession.scala:40), which has no missing parents
2018-09-18 13:37:44,399   INFO --- [dag-scheduler-event-loop]  org.apache.spark.storage.memory.MemoryStore(line:54) : Block broadcast_1 stored as values in memory (estimated size 3.3 KB, free 3.0 GB)
2018-09-18 13:37:44,404   INFO --- [dag-scheduler-event-loop]  org.apache.spark.storage.memory.MemoryStore(line:54) : Block broadcast_1_piece0 stored as bytes in memory (estimated size 2005.0 B, free 3.0 GB)
2018-09-18 13:37:44,433   INFO --- [dispatcher-event-loop-5]  org.apache.spark.storage.BlockManagerInfo(line:54) : Added broadcast_1_piece0 in memory on 192.168.3.199:52483 (size: 2005.0 B, free: 3.0 GB)
2018-09-18 13:37:44,434   INFO --- [dag-scheduler-event-loop]  org.apache.spark.SparkContext(line:54) : Created broadcast 1 from broadcast at DAGScheduler.scala:996
2018-09-18 13:37:44,438   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Submitting 2 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at map at logSession.scala:40)
2018-09-18 13:37:44,439   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.TaskSchedulerImpl(line:54) : Adding task set 0.0 with 2 tasks
2018-09-18 13:37:44,478   INFO --- [dispatcher-event-loop-6]  org.apache.spark.scheduler.TaskSetManager(line:54) : Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 5976 bytes)
2018-09-18 13:37:44,481   INFO --- [dispatcher-event-loop-6]  org.apache.spark.scheduler.TaskSetManager(line:54) : Starting task 1.0 in stage 0.0 (TID 1, localhost, executor driver, partition 1, PROCESS_LOCAL, 5976 bytes)
2018-09-18 13:37:44,487   INFO --- [Executor task launch worker for task 1]  org.apache.spark.executor.Executor(line:54) : Running task 1.0 in stage 0.0 (TID 1)
2018-09-18 13:37:44,487   INFO --- [Executor task launch worker for task 0]  org.apache.spark.executor.Executor(line:54) : Running task 0.0 in stage 0.0 (TID 0)
2018-09-18 13:37:44,526   INFO --- [Executor task launch worker for task 0]  org.apache.spark.rdd.HadoopRDD(line:54) : Input split: file:/e:/r_actionopvidio.txt:0+188363
2018-09-18 13:37:44,526   INFO --- [Executor task launch worker for task 1]  org.apache.spark.rdd.HadoopRDD(line:54) : Input split: file:/e:/r_actionopvidio.txt:188363+188364
2018-09-18 13:37:44,536   INFO --- [Executor task launch worker for task 0]  org.apache.hadoop.conf.Configuration.deprecation(line:840) : mapred.tip.id is deprecated. Instead, use mapreduce.task.id
2018-09-18 13:37:44,536   INFO --- [Executor task launch worker for task 1]  org.apache.hadoop.conf.Configuration.deprecation(line:840) : mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
2018-09-18 13:37:44,537   INFO --- [Executor task launch worker for task 0]  org.apache.hadoop.conf.Configuration.deprecation(line:840) : mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
2018-09-18 13:37:44,537   INFO --- [Executor task launch worker for task 1]  org.apache.hadoop.conf.Configuration.deprecation(line:840) : mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
2018-09-18 13:37:44,537   INFO --- [Executor task launch worker for task 0]  org.apache.hadoop.conf.Configuration.deprecation(line:840) : mapred.job.id is deprecated. Instead, use mapreduce.job.id
2018-09-18 13:37:44,608   INFO --- [Executor task launch worker for task 0]  org.apache.spark.executor.Executor(line:54) : Finished task 0.0 in stage 0.0 (TID 0). 148828 bytes result sent to driver
2018-09-18 13:37:44,608   INFO --- [Executor task launch worker for task 1]  org.apache.spark.executor.Executor(line:54) : Finished task 1.0 in stage 0.0 (TID 1). 148729 bytes result sent to driver
2018-09-18 13:37:44,622   INFO --- [task-result-getter-1]  org.apache.spark.scheduler.TaskSetManager(line:54) : Finished task 1.0 in stage 0.0 (TID 1) in 139 ms on localhost (executor driver) (1/2)
2018-09-18 13:37:44,622   INFO --- [task-result-getter-0]  org.apache.spark.scheduler.TaskSetManager(line:54) : Finished task 0.0 in stage 0.0 (TID 0) in 164 ms on localhost (executor driver) (2/2)
2018-09-18 13:37:44,624   INFO --- [task-result-getter-0]  org.apache.spark.scheduler.TaskSchedulerImpl(line:54) : Removed TaskSet 0.0, whose tasks have all completed, from pool 
2018-09-18 13:37:44,627   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : ResultStage 0 (collect at logSession.scala:40) finished in 0.179 s
2018-09-18 13:37:44,632   INFO --- [main]  org.apache.spark.scheduler.DAGScheduler(line:54) : Job 0 finished: collect at logSession.scala:40, took 0.270821 s
2018-09-18 13:37:44,676   INFO --- [main]  org.spark_project.jetty.server.ServerConnector(line:306) : Stopped Spark@3e10dc6{HTTP/1.1}{0.0.0.0:4040}
2018-09-18 13:37:44,678   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@57ac5227{/stages/stage/kill,null,UNAVAILABLE,@Spark}
2018-09-18 13:37:44,678   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@43aaf813{/jobs/job/kill,null,UNAVAILABLE,@Spark}
2018-09-18 13:37:44,678   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@33aeca0b{/api,null,UNAVAILABLE,@Spark}
2018-09-18 13:37:44,678   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@5c18016b{/,null,UNAVAILABLE,@Spark}
2018-09-18 13:37:44,679   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@1951b871{/static,null,UNAVAILABLE,@Spark}
2018-09-18 13:37:44,679   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@793138bd{/executors/threadDump/json,null,UNAVAILABLE,@Spark}
2018-09-18 13:37:44,679   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@5d1659ea{/executors/threadDump,null,UNAVAILABLE,@Spark}
2018-09-18 13:37:44,679   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@25bc0606{/executors/json,null,UNAVAILABLE,@Spark}
2018-09-18 13:37:44,679   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@3d3ba765{/executors,null,UNAVAILABLE,@Spark}
2018-09-18 13:37:44,679   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@784b990c{/environment/json,null,UNAVAILABLE,@Spark}
2018-09-18 13:37:44,680   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@3c989952{/environment,null,UNAVAILABLE,@Spark}
2018-09-18 13:37:44,680   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@3e14c16d{/storage/rdd/json,null,UNAVAILABLE,@Spark}
2018-09-18 13:37:44,680   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@7096b474{/storage/rdd,null,UNAVAILABLE,@Spark}
2018-09-18 13:37:44,680   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@4bd1f8dd{/storage/json,null,UNAVAILABLE,@Spark}
2018-09-18 13:37:44,680   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@3f07b12c{/storage,null,UNAVAILABLE,@Spark}
2018-09-18 13:37:44,680   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@6475472c{/stages/pool/json,null,UNAVAILABLE,@Spark}
2018-09-18 13:37:44,681   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@4b7e96a{/stages/pool,null,UNAVAILABLE,@Spark}
2018-09-18 13:37:44,681   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@5c8504fd{/stages/stage/json,null,UNAVAILABLE,@Spark}
2018-09-18 13:37:44,681   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@42f33b5d{/stages/stage,null,UNAVAILABLE,@Spark}
2018-09-18 13:37:44,681   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@47c4ecdc{/stages/json,null,UNAVAILABLE,@Spark}
2018-09-18 13:37:44,681   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@2eced48b{/stages,null,UNAVAILABLE,@Spark}
2018-09-18 13:37:44,681   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@14d14731{/jobs/job/json,null,UNAVAILABLE,@Spark}
2018-09-18 13:37:44,682   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@53dacd14{/jobs/job,null,UNAVAILABLE,@Spark}
2018-09-18 13:37:44,682   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@4795ded0{/jobs/json,null,UNAVAILABLE,@Spark}
2018-09-18 13:37:44,682   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@32811494{/jobs,null,UNAVAILABLE,@Spark}
2018-09-18 13:37:44,683   INFO --- [main]  org.apache.spark.ui.SparkUI(line:54) : Stopped Spark web UI at http://192.168.3.199:4040
2018-09-18 13:37:44,692   INFO --- [dispatcher-event-loop-5]  org.apache.spark.MapOutputTrackerMasterEndpoint(line:54) : MapOutputTrackerMasterEndpoint stopped!
2018-09-18 13:37:44,713   INFO --- [main]  org.apache.spark.storage.memory.MemoryStore(line:54) : MemoryStore cleared
2018-09-18 13:37:44,713   INFO --- [main]  org.apache.spark.storage.BlockManager(line:54) : BlockManager stopped
2018-09-18 13:37:44,718   INFO --- [main]  org.apache.spark.storage.BlockManagerMaster(line:54) : BlockManagerMaster stopped
2018-09-18 13:37:44,720   INFO --- [dispatcher-event-loop-1]  org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint(line:54) : OutputCommitCoordinator stopped!
2018-09-18 13:37:44,725   INFO --- [main]  org.apache.spark.SparkContext(line:54) : Successfully stopped SparkContext
2018-09-18 13:37:44,727   INFO --- [Thread-1]  org.apache.spark.util.ShutdownHookManager(line:54) : Shutdown hook called
2018-09-18 13:37:44,728   INFO --- [Thread-1]  org.apache.spark.util.ShutdownHookManager(line:54) : Deleting directory C:\Users\wshs\AppData\Local\Temp\spark-c3e1cfd7-7624-464a-933c-51d7bdeb78f7
2018-09-18 13:38:34,344   INFO --- [main]  org.apache.spark.SparkContext(line:54) : Running Spark version 2.1.1
2018-09-18 13:38:34,707   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing view acls to: wshs
2018-09-18 13:38:34,708   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing modify acls to: wshs
2018-09-18 13:38:34,708   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing view acls groups to: 
2018-09-18 13:38:34,709   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing modify acls groups to: 
2018-09-18 13:38:34,709   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(wshs); groups with view permissions: Set(); users  with modify permissions: Set(wshs); groups with modify permissions: Set()
2018-09-18 13:38:35,223   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'sparkDriver' on port 52561.
2018-09-18 13:38:35,242   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering MapOutputTracker
2018-09-18 13:38:35,263   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering BlockManagerMaster
2018-09-18 13:38:35,267   INFO --- [main]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-09-18 13:38:35,267   INFO --- [main]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : BlockManagerMasterEndpoint up
2018-09-18 13:38:35,282   INFO --- [main]  org.apache.spark.storage.DiskBlockManager(line:54) : Created local directory at C:\Users\wshs\AppData\Local\Temp\blockmgr-8bb3f4e3-84a2-4b44-8523-8ead57d305d4
2018-09-18 13:38:35,303   INFO --- [main]  org.apache.spark.storage.memory.MemoryStore(line:54) : MemoryStore started with capacity 3.0 GB
2018-09-18 13:38:35,382   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering OutputCommitCoordinator
2018-09-18 13:38:35,487   INFO --- [main]  org.spark_project.jetty.util.log(line:186) : Logging initialized @2042ms
2018-09-18 13:38:35,578   INFO --- [main]  org.spark_project.jetty.server.Server(line:327) : jetty-9.2.z-SNAPSHOT
2018-09-18 13:38:35,591   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@32811494{/jobs,null,AVAILABLE,@Spark}
2018-09-18 13:38:35,592   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@4795ded0{/jobs/json,null,AVAILABLE,@Spark}
2018-09-18 13:38:35,592   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@53dacd14{/jobs/job,null,AVAILABLE,@Spark}
2018-09-18 13:38:35,592   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@14d14731{/jobs/job/json,null,AVAILABLE,@Spark}
2018-09-18 13:38:35,592   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@2eced48b{/stages,null,AVAILABLE,@Spark}
2018-09-18 13:38:35,592   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@47c4ecdc{/stages/json,null,AVAILABLE,@Spark}
2018-09-18 13:38:35,593   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@42f33b5d{/stages/stage,null,AVAILABLE,@Spark}
2018-09-18 13:38:35,593   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@5c8504fd{/stages/stage/json,null,AVAILABLE,@Spark}
2018-09-18 13:38:35,593   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@4b7e96a{/stages/pool,null,AVAILABLE,@Spark}
2018-09-18 13:38:35,593   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@6475472c{/stages/pool/json,null,AVAILABLE,@Spark}
2018-09-18 13:38:35,594   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@3f07b12c{/storage,null,AVAILABLE,@Spark}
2018-09-18 13:38:35,594   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@4bd1f8dd{/storage/json,null,AVAILABLE,@Spark}
2018-09-18 13:38:35,594   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@7096b474{/storage/rdd,null,AVAILABLE,@Spark}
2018-09-18 13:38:35,594   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@3e14c16d{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-09-18 13:38:35,594   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@3c989952{/environment,null,AVAILABLE,@Spark}
2018-09-18 13:38:35,594   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@784b990c{/environment/json,null,AVAILABLE,@Spark}
2018-09-18 13:38:35,594   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@3d3ba765{/executors,null,AVAILABLE,@Spark}
2018-09-18 13:38:35,594   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@25bc0606{/executors/json,null,AVAILABLE,@Spark}
2018-09-18 13:38:35,594   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@5d1659ea{/executors/threadDump,null,AVAILABLE,@Spark}
2018-09-18 13:38:35,595   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@793138bd{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-09-18 13:38:35,599   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@1951b871{/static,null,AVAILABLE,@Spark}
2018-09-18 13:38:35,600   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@5c18016b{/,null,AVAILABLE,@Spark}
2018-09-18 13:38:35,600   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@33aeca0b{/api,null,AVAILABLE,@Spark}
2018-09-18 13:38:35,600   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@43aaf813{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-09-18 13:38:35,601   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@57ac5227{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-09-18 13:38:35,612   INFO --- [main]  org.spark_project.jetty.server.ServerConnector(line:266) : Started Spark@3e10dc6{HTTP/1.1}{0.0.0.0:4040}
2018-09-18 13:38:35,613   INFO --- [main]  org.spark_project.jetty.server.Server(line:379) : Started @2170ms
2018-09-18 13:38:35,613   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'SparkUI' on port 4040.
2018-09-18 13:38:35,616   INFO --- [main]  org.apache.spark.ui.SparkUI(line:54) : Bound SparkUI to 0.0.0.0, and started at http://192.168.3.199:4040
2018-09-18 13:38:35,685   INFO --- [main]  org.apache.spark.executor.Executor(line:54) : Starting executor ID driver on host localhost
2018-09-18 13:38:35,730   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 52603.
2018-09-18 13:38:35,730   INFO --- [main]  org.apache.spark.network.netty.NettyBlockTransferService(line:54) : Server created on 192.168.3.199:52603
2018-09-18 13:38:35,732   INFO --- [main]  org.apache.spark.storage.BlockManager(line:54) : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-09-18 13:38:35,733   INFO --- [main]  org.apache.spark.storage.BlockManagerMaster(line:54) : Registering BlockManager BlockManagerId(driver, 192.168.3.199, 52603, None)
2018-09-18 13:38:35,736   INFO --- [dispatcher-event-loop-2]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : Registering block manager 192.168.3.199:52603 with 3.0 GB RAM, BlockManagerId(driver, 192.168.3.199, 52603, None)
2018-09-18 13:38:35,738   INFO --- [main]  org.apache.spark.storage.BlockManagerMaster(line:54) : Registered BlockManager BlockManagerId(driver, 192.168.3.199, 52603, None)
2018-09-18 13:38:35,739   INFO --- [main]  org.apache.spark.storage.BlockManager(line:54) : Initialized BlockManager: BlockManagerId(driver, 192.168.3.199, 52603, None)
2018-09-18 13:38:35,902   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@42257bdd{/metrics/json,null,AVAILABLE,@Spark}
2018-09-18 13:38:35,921   WARN --- [main]  org.apache.spark.SparkContext(line:66) : Using an existing SparkContext; some configuration may not take effect.
2018-09-18 13:38:35,955   INFO --- [main]  org.apache.spark.sql.internal.SharedState(line:54) : Warehouse path is 'file:/C:/Users/wshs/IdeaProjects/logdataSession/spark-warehouse/'.
2018-09-18 13:38:35,961   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@7544a1e4{/SQL,null,AVAILABLE,@Spark}
2018-09-18 13:38:35,962   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@7957dc72{/SQL/json,null,AVAILABLE,@Spark}
2018-09-18 13:38:35,963   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@5be82d43{/SQL/execution,null,AVAILABLE,@Spark}
2018-09-18 13:38:35,963   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@345e5a17{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-09-18 13:38:35,965   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@5ed190be{/static/sql,null,AVAILABLE,@Spark}
2018-09-18 13:38:36,355   INFO --- [main]  org.apache.spark.storage.memory.MemoryStore(line:54) : Block broadcast_0 stored as values in memory (estimated size 127.1 KB, free 3.0 GB)
2018-09-18 13:38:36,924   INFO --- [main]  org.apache.spark.storage.memory.MemoryStore(line:54) : Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.3 KB, free 3.0 GB)
2018-09-18 13:38:36,928   INFO --- [dispatcher-event-loop-4]  org.apache.spark.storage.BlockManagerInfo(line:54) : Added broadcast_0_piece0 in memory on 192.168.3.199:52603 (size: 14.3 KB, free: 3.0 GB)
2018-09-18 13:38:36,933   INFO --- [main]  org.apache.spark.SparkContext(line:54) : Created broadcast 0 from textFile at logSession.scala:39
2018-09-18 13:38:37,020   INFO --- [main]  org.apache.hadoop.mapred.FileInputFormat(line:253) : Total input paths to process : 1
2018-09-18 13:38:37,055   INFO --- [main]  org.apache.spark.SparkContext(line:54) : Starting job: collect at logSession.scala:40
2018-09-18 13:38:37,070   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Got job 0 (collect at logSession.scala:40) with 2 output partitions
2018-09-18 13:38:37,070   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Final stage: ResultStage 0 (collect at logSession.scala:40)
2018-09-18 13:38:37,071   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Parents of final stage: List()
2018-09-18 13:38:37,072   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Missing parents: List()
2018-09-18 13:38:37,078   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Submitting ResultStage 0 (MapPartitionsRDD[3] at map at logSession.scala:40), which has no missing parents
2018-09-18 13:38:37,093   INFO --- [dag-scheduler-event-loop]  org.apache.spark.storage.memory.MemoryStore(line:54) : Block broadcast_1 stored as values in memory (estimated size 3.5 KB, free 3.0 GB)
2018-09-18 13:38:37,097   INFO --- [dag-scheduler-event-loop]  org.apache.spark.storage.memory.MemoryStore(line:54) : Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.0 KB, free 3.0 GB)
2018-09-18 13:38:37,098   INFO --- [dispatcher-event-loop-5]  org.apache.spark.storage.BlockManagerInfo(line:54) : Added broadcast_1_piece0 in memory on 192.168.3.199:52603 (size: 2.0 KB, free: 3.0 GB)
2018-09-18 13:38:37,125   INFO --- [dag-scheduler-event-loop]  org.apache.spark.SparkContext(line:54) : Created broadcast 1 from broadcast at DAGScheduler.scala:996
2018-09-18 13:38:37,128   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Submitting 2 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at map at logSession.scala:40)
2018-09-18 13:38:37,130   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.TaskSchedulerImpl(line:54) : Adding task set 0.0 with 2 tasks
2018-09-18 13:38:37,172   INFO --- [dispatcher-event-loop-6]  org.apache.spark.scheduler.TaskSetManager(line:54) : Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 5976 bytes)
2018-09-18 13:38:37,175   INFO --- [dispatcher-event-loop-6]  org.apache.spark.scheduler.TaskSetManager(line:54) : Starting task 1.0 in stage 0.0 (TID 1, localhost, executor driver, partition 1, PROCESS_LOCAL, 5976 bytes)
2018-09-18 13:38:37,182   INFO --- [Executor task launch worker for task 1]  org.apache.spark.executor.Executor(line:54) : Running task 1.0 in stage 0.0 (TID 1)
2018-09-18 13:38:37,182   INFO --- [Executor task launch worker for task 0]  org.apache.spark.executor.Executor(line:54) : Running task 0.0 in stage 0.0 (TID 0)
2018-09-18 13:38:37,216   INFO --- [Executor task launch worker for task 1]  org.apache.spark.rdd.HadoopRDD(line:54) : Input split: file:/e:/r_actionopvidio.txt:188363+188364
2018-09-18 13:38:37,216   INFO --- [Executor task launch worker for task 0]  org.apache.spark.rdd.HadoopRDD(line:54) : Input split: file:/e:/r_actionopvidio.txt:0+188363
2018-09-18 13:38:37,223   INFO --- [Executor task launch worker for task 0]  org.apache.hadoop.conf.Configuration.deprecation(line:840) : mapred.tip.id is deprecated. Instead, use mapreduce.task.id
2018-09-18 13:38:37,223   INFO --- [Executor task launch worker for task 1]  org.apache.hadoop.conf.Configuration.deprecation(line:840) : mapred.tip.id is deprecated. Instead, use mapreduce.task.id
2018-09-18 13:38:37,224   INFO --- [Executor task launch worker for task 0]  org.apache.hadoop.conf.Configuration.deprecation(line:840) : mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
2018-09-18 13:38:37,224   INFO --- [Executor task launch worker for task 0]  org.apache.hadoop.conf.Configuration.deprecation(line:840) : mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
2018-09-18 13:38:37,224   INFO --- [Executor task launch worker for task 1]  org.apache.hadoop.conf.Configuration.deprecation(line:840) : mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
2018-09-18 13:38:37,224   INFO --- [Executor task launch worker for task 0]  org.apache.hadoop.conf.Configuration.deprecation(line:840) : mapred.job.id is deprecated. Instead, use mapreduce.job.id
2018-09-18 13:38:37,324   INFO --- [Executor task launch worker for task 1]  org.apache.spark.executor.Executor(line:54) : Finished task 1.0 in stage 0.0 (TID 1). 221000 bytes result sent to driver
2018-09-18 13:38:37,324   INFO --- [Executor task launch worker for task 0]  org.apache.spark.executor.Executor(line:54) : Finished task 0.0 in stage 0.0 (TID 0). 221099 bytes result sent to driver
2018-09-18 13:38:37,367   INFO --- [task-result-getter-0]  org.apache.spark.scheduler.TaskSetManager(line:54) : Finished task 1.0 in stage 0.0 (TID 1) in 191 ms on localhost (executor driver) (1/2)
2018-09-18 13:38:37,367   INFO --- [task-result-getter-1]  org.apache.spark.scheduler.TaskSetManager(line:54) : Finished task 0.0 in stage 0.0 (TID 0) in 218 ms on localhost (executor driver) (2/2)
2018-09-18 13:38:37,369   INFO --- [task-result-getter-1]  org.apache.spark.scheduler.TaskSchedulerImpl(line:54) : Removed TaskSet 0.0, whose tasks have all completed, from pool 
2018-09-18 13:38:37,373   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : ResultStage 0 (collect at logSession.scala:40) finished in 0.234 s
2018-09-18 13:38:37,379   INFO --- [main]  org.apache.spark.scheduler.DAGScheduler(line:54) : Job 0 finished: collect at logSession.scala:40, took 0.324355 s
2018-09-18 13:38:37,422   INFO --- [main]  org.spark_project.jetty.server.ServerConnector(line:306) : Stopped Spark@3e10dc6{HTTP/1.1}{0.0.0.0:4040}
2018-09-18 13:38:37,424   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@57ac5227{/stages/stage/kill,null,UNAVAILABLE,@Spark}
2018-09-18 13:38:37,424   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@43aaf813{/jobs/job/kill,null,UNAVAILABLE,@Spark}
2018-09-18 13:38:37,424   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@33aeca0b{/api,null,UNAVAILABLE,@Spark}
2018-09-18 13:38:37,424   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@5c18016b{/,null,UNAVAILABLE,@Spark}
2018-09-18 13:38:37,425   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@1951b871{/static,null,UNAVAILABLE,@Spark}
2018-09-18 13:38:37,425   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@793138bd{/executors/threadDump/json,null,UNAVAILABLE,@Spark}
2018-09-18 13:38:37,425   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@5d1659ea{/executors/threadDump,null,UNAVAILABLE,@Spark}
2018-09-18 13:38:37,425   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@25bc0606{/executors/json,null,UNAVAILABLE,@Spark}
2018-09-18 13:38:37,425   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@3d3ba765{/executors,null,UNAVAILABLE,@Spark}
2018-09-18 13:38:37,426   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@784b990c{/environment/json,null,UNAVAILABLE,@Spark}
2018-09-18 13:38:37,426   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@3c989952{/environment,null,UNAVAILABLE,@Spark}
2018-09-18 13:38:37,426   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@3e14c16d{/storage/rdd/json,null,UNAVAILABLE,@Spark}
2018-09-18 13:38:37,426   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@7096b474{/storage/rdd,null,UNAVAILABLE,@Spark}
2018-09-18 13:38:37,426   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@4bd1f8dd{/storage/json,null,UNAVAILABLE,@Spark}
2018-09-18 13:38:37,426   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@3f07b12c{/storage,null,UNAVAILABLE,@Spark}
2018-09-18 13:38:37,426   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@6475472c{/stages/pool/json,null,UNAVAILABLE,@Spark}
2018-09-18 13:38:37,427   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@4b7e96a{/stages/pool,null,UNAVAILABLE,@Spark}
2018-09-18 13:38:37,427   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@5c8504fd{/stages/stage/json,null,UNAVAILABLE,@Spark}
2018-09-18 13:38:37,427   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@42f33b5d{/stages/stage,null,UNAVAILABLE,@Spark}
2018-09-18 13:38:37,427   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@47c4ecdc{/stages/json,null,UNAVAILABLE,@Spark}
2018-09-18 13:38:37,427   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@2eced48b{/stages,null,UNAVAILABLE,@Spark}
2018-09-18 13:38:37,428   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@14d14731{/jobs/job/json,null,UNAVAILABLE,@Spark}
2018-09-18 13:38:37,428   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@53dacd14{/jobs/job,null,UNAVAILABLE,@Spark}
2018-09-18 13:38:37,428   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@4795ded0{/jobs/json,null,UNAVAILABLE,@Spark}
2018-09-18 13:38:37,428   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@32811494{/jobs,null,UNAVAILABLE,@Spark}
2018-09-18 13:38:37,430   INFO --- [main]  org.apache.spark.ui.SparkUI(line:54) : Stopped Spark web UI at http://192.168.3.199:4040
2018-09-18 13:38:37,438   INFO --- [dispatcher-event-loop-5]  org.apache.spark.MapOutputTrackerMasterEndpoint(line:54) : MapOutputTrackerMasterEndpoint stopped!
2018-09-18 13:38:37,457   INFO --- [main]  org.apache.spark.storage.memory.MemoryStore(line:54) : MemoryStore cleared
2018-09-18 13:38:37,457   INFO --- [main]  org.apache.spark.storage.BlockManager(line:54) : BlockManager stopped
2018-09-18 13:38:37,462   INFO --- [main]  org.apache.spark.storage.BlockManagerMaster(line:54) : BlockManagerMaster stopped
2018-09-18 13:38:37,464   INFO --- [dispatcher-event-loop-1]  org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint(line:54) : OutputCommitCoordinator stopped!
2018-09-18 13:38:37,469   INFO --- [main]  org.apache.spark.SparkContext(line:54) : Successfully stopped SparkContext
2018-09-18 13:38:37,471   INFO --- [Thread-1]  org.apache.spark.util.ShutdownHookManager(line:54) : Shutdown hook called
2018-09-18 13:38:37,472   INFO --- [Thread-1]  org.apache.spark.util.ShutdownHookManager(line:54) : Deleting directory C:\Users\wshs\AppData\Local\Temp\spark-045486d2-ef12-4d1c-888a-95401896de34
2018-09-18 13:39:25,357   INFO --- [main]  org.apache.spark.SparkContext(line:54) : Running Spark version 2.1.1
2018-09-18 13:39:25,751   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing view acls to: wshs
2018-09-18 13:39:25,752   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing modify acls to: wshs
2018-09-18 13:39:25,753   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing view acls groups to: 
2018-09-18 13:39:25,753   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing modify acls groups to: 
2018-09-18 13:39:25,755   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(wshs); groups with view permissions: Set(); users  with modify permissions: Set(wshs); groups with modify permissions: Set()
2018-09-18 13:39:26,272   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'sparkDriver' on port 52687.
2018-09-18 13:39:26,293   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering MapOutputTracker
2018-09-18 13:39:26,312   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering BlockManagerMaster
2018-09-18 13:39:26,315   INFO --- [main]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-09-18 13:39:26,316   INFO --- [main]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : BlockManagerMasterEndpoint up
2018-09-18 13:39:26,329   INFO --- [main]  org.apache.spark.storage.DiskBlockManager(line:54) : Created local directory at C:\Users\wshs\AppData\Local\Temp\blockmgr-5a999c0c-6687-444e-a805-3c8cc493a59c
2018-09-18 13:39:26,347   INFO --- [main]  org.apache.spark.storage.memory.MemoryStore(line:54) : MemoryStore started with capacity 3.0 GB
2018-09-18 13:39:26,415   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering OutputCommitCoordinator
2018-09-18 13:39:26,486   INFO --- [main]  org.spark_project.jetty.util.log(line:186) : Logging initialized @2118ms
2018-09-18 13:39:26,565   INFO --- [main]  org.spark_project.jetty.server.Server(line:327) : jetty-9.2.z-SNAPSHOT
2018-09-18 13:39:26,578   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@5c8504fd{/jobs,null,AVAILABLE,@Spark}
2018-09-18 13:39:26,578   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@4b7e96a{/jobs/json,null,AVAILABLE,@Spark}
2018-09-18 13:39:26,578   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@6475472c{/jobs/job,null,AVAILABLE,@Spark}
2018-09-18 13:39:26,579   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@3f07b12c{/jobs/job/json,null,AVAILABLE,@Spark}
2018-09-18 13:39:26,579   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@4bd1f8dd{/stages,null,AVAILABLE,@Spark}
2018-09-18 13:39:26,579   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@7096b474{/stages/json,null,AVAILABLE,@Spark}
2018-09-18 13:39:26,579   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@3e14c16d{/stages/stage,null,AVAILABLE,@Spark}
2018-09-18 13:39:26,580   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@3c989952{/stages/stage/json,null,AVAILABLE,@Spark}
2018-09-18 13:39:26,580   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@784b990c{/stages/pool,null,AVAILABLE,@Spark}
2018-09-18 13:39:26,580   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@3d3ba765{/stages/pool/json,null,AVAILABLE,@Spark}
2018-09-18 13:39:26,580   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@25bc0606{/storage,null,AVAILABLE,@Spark}
2018-09-18 13:39:26,581   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@5d1659ea{/storage/json,null,AVAILABLE,@Spark}
2018-09-18 13:39:26,581   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@793138bd{/storage/rdd,null,AVAILABLE,@Spark}
2018-09-18 13:39:26,581   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@1951b871{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-09-18 13:39:26,581   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@5c18016b{/environment,null,AVAILABLE,@Spark}
2018-09-18 13:39:26,581   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@33aeca0b{/environment/json,null,AVAILABLE,@Spark}
2018-09-18 13:39:26,582   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@43aaf813{/executors,null,AVAILABLE,@Spark}
2018-09-18 13:39:26,582   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@57ac5227{/executors/json,null,AVAILABLE,@Spark}
2018-09-18 13:39:26,582   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@4ba302e0{/executors/threadDump,null,AVAILABLE,@Spark}
2018-09-18 13:39:26,582   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@e98770d{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-09-18 13:39:26,587   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@1ae67cad{/static,null,AVAILABLE,@Spark}
2018-09-18 13:39:26,587   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@2f6e28bc{/,null,AVAILABLE,@Spark}
2018-09-18 13:39:26,588   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@7c098bb3{/api,null,AVAILABLE,@Spark}
2018-09-18 13:39:26,588   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@31e4bb20{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-09-18 13:39:26,588   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@18cebaa5{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-09-18 13:39:26,598   INFO --- [main]  org.spark_project.jetty.server.ServerConnector(line:266) : Started Spark@1021f6c9{HTTP/1.1}{0.0.0.0:4040}
2018-09-18 13:39:26,599   INFO --- [main]  org.spark_project.jetty.server.Server(line:379) : Started @2232ms
2018-09-18 13:39:26,599   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'SparkUI' on port 4040.
2018-09-18 13:39:26,601   INFO --- [main]  org.apache.spark.ui.SparkUI(line:54) : Bound SparkUI to 0.0.0.0, and started at http://192.168.3.199:4040
2018-09-18 13:39:26,672   INFO --- [main]  org.apache.spark.executor.Executor(line:54) : Starting executor ID driver on host localhost
2018-09-18 13:39:26,718   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 52729.
2018-09-18 13:39:26,719   INFO --- [main]  org.apache.spark.network.netty.NettyBlockTransferService(line:54) : Server created on 192.168.3.199:52729
2018-09-18 13:39:26,721   INFO --- [main]  org.apache.spark.storage.BlockManager(line:54) : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-09-18 13:39:26,723   INFO --- [main]  org.apache.spark.storage.BlockManagerMaster(line:54) : Registering BlockManager BlockManagerId(driver, 192.168.3.199, 52729, None)
2018-09-18 13:39:26,725   INFO --- [dispatcher-event-loop-2]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : Registering block manager 192.168.3.199:52729 with 3.0 GB RAM, BlockManagerId(driver, 192.168.3.199, 52729, None)
2018-09-18 13:39:26,728   INFO --- [main]  org.apache.spark.storage.BlockManagerMaster(line:54) : Registered BlockManager BlockManagerId(driver, 192.168.3.199, 52729, None)
2018-09-18 13:39:26,729   INFO --- [main]  org.apache.spark.storage.BlockManager(line:54) : Initialized BlockManager: BlockManagerId(driver, 192.168.3.199, 52729, None)
2018-09-18 13:39:26,886   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@1b9ea3e3{/metrics/json,null,AVAILABLE,@Spark}
2018-09-18 13:39:26,904   WARN --- [main]  org.apache.spark.SparkContext(line:66) : Using an existing SparkContext; some configuration may not take effect.
2018-09-18 13:39:26,940   INFO --- [main]  org.apache.spark.sql.internal.SharedState(line:54) : Warehouse path is 'file:/C:/Users/wshs/IdeaProjects/logdataSession/spark-warehouse/'.
2018-09-18 13:39:26,947   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@5be82d43{/SQL,null,AVAILABLE,@Spark}
2018-09-18 13:39:26,948   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@345e5a17{/SQL/json,null,AVAILABLE,@Spark}
2018-09-18 13:39:26,949   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@77b7ffa4{/SQL/execution,null,AVAILABLE,@Spark}
2018-09-18 13:39:26,949   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@402f80f5{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-09-18 13:39:26,951   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@2102a4d5{/static/sql,null,AVAILABLE,@Spark}
2018-09-18 13:39:27,362   INFO --- [main]  org.apache.spark.storage.memory.MemoryStore(line:54) : Block broadcast_0 stored as values in memory (estimated size 127.1 KB, free 3.0 GB)
2018-09-18 13:39:27,511   INFO --- [main]  org.apache.spark.storage.memory.MemoryStore(line:54) : Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.3 KB, free 3.0 GB)
2018-09-18 13:39:27,516   INFO --- [dispatcher-event-loop-4]  org.apache.spark.storage.BlockManagerInfo(line:54) : Added broadcast_0_piece0 in memory on 192.168.3.199:52729 (size: 14.3 KB, free: 3.0 GB)
2018-09-18 13:39:27,521   INFO --- [main]  org.apache.spark.SparkContext(line:54) : Created broadcast 0 from textFile at logSession.scala:39
2018-09-18 13:39:29,641   INFO --- [main]  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator(line:54) : Code generated in 213.695378 ms
2018-09-18 13:39:29,696   INFO --- [main]  org.apache.hadoop.mapred.FileInputFormat(line:253) : Total input paths to process : 1
2018-09-18 13:39:29,708   INFO --- [main]  org.apache.spark.SparkContext(line:54) : Starting job: show at logSession.scala:44
2018-09-18 13:39:29,724   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Got job 0 (show at logSession.scala:44) with 1 output partitions
2018-09-18 13:39:29,724   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Final stage: ResultStage 0 (show at logSession.scala:44)
2018-09-18 13:39:29,725   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Parents of final stage: List()
2018-09-18 13:39:29,726   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Missing parents: List()
2018-09-18 13:39:29,732   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Submitting ResultStage 0 (MapPartitionsRDD[7] at show at logSession.scala:44), which has no missing parents
2018-09-18 13:39:29,766   INFO --- [dag-scheduler-event-loop]  org.apache.spark.storage.memory.MemoryStore(line:54) : Block broadcast_1 stored as values in memory (estimated size 12.2 KB, free 3.0 GB)
2018-09-18 13:39:29,769   INFO --- [dag-scheduler-event-loop]  org.apache.spark.storage.memory.MemoryStore(line:54) : Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.0 KB, free 3.0 GB)
2018-09-18 13:39:29,770   INFO --- [dispatcher-event-loop-5]  org.apache.spark.storage.BlockManagerInfo(line:54) : Added broadcast_1_piece0 in memory on 192.168.3.199:52729 (size: 5.0 KB, free: 3.0 GB)
2018-09-18 13:39:29,770   INFO --- [dag-scheduler-event-loop]  org.apache.spark.SparkContext(line:54) : Created broadcast 1 from broadcast at DAGScheduler.scala:996
2018-09-18 13:39:29,773   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[7] at show at logSession.scala:44)
2018-09-18 13:39:29,774   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.TaskSchedulerImpl(line:54) : Adding task set 0.0 with 1 tasks
2018-09-18 13:39:29,812   INFO --- [dispatcher-event-loop-6]  org.apache.spark.scheduler.TaskSetManager(line:54) : Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 5921 bytes)
2018-09-18 13:39:29,821   INFO --- [Executor task launch worker for task 0]  org.apache.spark.executor.Executor(line:54) : Running task 0.0 in stage 0.0 (TID 0)
2018-09-18 13:39:29,859   INFO --- [Executor task launch worker for task 0]  org.apache.spark.rdd.HadoopRDD(line:54) : Input split: file:/e:/r_actionopvidio.txt:0+188363
2018-09-18 13:39:29,866   INFO --- [Executor task launch worker for task 0]  org.apache.hadoop.conf.Configuration.deprecation(line:840) : mapred.tip.id is deprecated. Instead, use mapreduce.task.id
2018-09-18 13:39:29,866   INFO --- [Executor task launch worker for task 0]  org.apache.hadoop.conf.Configuration.deprecation(line:840) : mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
2018-09-18 13:39:29,866   INFO --- [Executor task launch worker for task 0]  org.apache.hadoop.conf.Configuration.deprecation(line:840) : mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
2018-09-18 13:39:29,866   INFO --- [Executor task launch worker for task 0]  org.apache.hadoop.conf.Configuration.deprecation(line:840) : mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
2018-09-18 13:39:29,867   INFO --- [Executor task launch worker for task 0]  org.apache.hadoop.conf.Configuration.deprecation(line:840) : mapred.job.id is deprecated. Instead, use mapreduce.job.id
2018-09-18 13:39:29,890  ERROR --- [Executor task launch worker for task 0]  org.apache.spark.executor.Executor(line:91) : Exception in task 0.0 in stage 0.0 (TID 0)
java.lang.NumberFormatException: For input string: "18:05:19"
	at java.lang.NumberFormatException.forInputString(NumberFormatException.java:65)
	at java.lang.Integer.parseInt(Integer.java:580)
	at java.lang.Integer.parseInt(Integer.java:615)
	at scala.collection.immutable.StringLike$class.toInt(StringLike.scala:272)
	at scala.collection.immutable.StringOps.toInt(StringOps.scala:29)
	at logSession$$anonfun$3.apply(logSession.scala:40)
	at logSession$$anonfun$3.apply(logSession.scala:40)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1.hasNext(WholeStageCodegenExec.scala:377)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:231)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:225)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:827)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:827)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-09-18 13:39:29,912   WARN --- [task-result-getter-0]  org.apache.spark.scheduler.TaskSetManager(line:66) : Lost task 0.0 in stage 0.0 (TID 0, localhost, executor driver): java.lang.NumberFormatException: For input string: "18:05:19"
	at java.lang.NumberFormatException.forInputString(NumberFormatException.java:65)
	at java.lang.Integer.parseInt(Integer.java:580)
	at java.lang.Integer.parseInt(Integer.java:615)
	at scala.collection.immutable.StringLike$class.toInt(StringLike.scala:272)
	at scala.collection.immutable.StringOps.toInt(StringOps.scala:29)
	at logSession$$anonfun$3.apply(logSession.scala:40)
	at logSession$$anonfun$3.apply(logSession.scala:40)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1.hasNext(WholeStageCodegenExec.scala:377)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:231)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:225)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:827)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:827)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

2018-09-18 13:39:29,914  ERROR --- [task-result-getter-0]  org.apache.spark.scheduler.TaskSetManager(line:70) : Task 0 in stage 0.0 failed 1 times; aborting job
2018-09-18 13:39:29,916   INFO --- [task-result-getter-0]  org.apache.spark.scheduler.TaskSchedulerImpl(line:54) : Removed TaskSet 0.0, whose tasks have all completed, from pool 
2018-09-18 13:39:29,920   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.TaskSchedulerImpl(line:54) : Cancelling stage 0
2018-09-18 13:39:29,923   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : ResultStage 0 (show at logSession.scala:44) failed in 0.139 s due to Job aborted due to stage failure: Task 0 in stage 0.0 failed 1 times, most recent failure: Lost task 0.0 in stage 0.0 (TID 0, localhost, executor driver): java.lang.NumberFormatException: For input string: "18:05:19"
	at java.lang.NumberFormatException.forInputString(NumberFormatException.java:65)
	at java.lang.Integer.parseInt(Integer.java:580)
	at java.lang.Integer.parseInt(Integer.java:615)
	at scala.collection.immutable.StringLike$class.toInt(StringLike.scala:272)
	at scala.collection.immutable.StringOps.toInt(StringOps.scala:29)
	at logSession$$anonfun$3.apply(logSession.scala:40)
	at logSession$$anonfun$3.apply(logSession.scala:40)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1.hasNext(WholeStageCodegenExec.scala:377)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:231)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:225)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:827)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:827)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

Driver stacktrace:
2018-09-18 13:39:29,934   INFO --- [main]  org.apache.spark.scheduler.DAGScheduler(line:54) : Job 0 failed: show at logSession.scala:44, took 0.225366 s
2018-09-18 13:39:30,032   INFO --- [Thread-1]  org.apache.spark.SparkContext(line:54) : Invoking stop() from shutdown hook
2018-09-18 13:39:30,037   INFO --- [Thread-1]  org.spark_project.jetty.server.ServerConnector(line:306) : Stopped Spark@1021f6c9{HTTP/1.1}{0.0.0.0:4040}
2018-09-18 13:39:30,039   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@18cebaa5{/stages/stage/kill,null,UNAVAILABLE,@Spark}
2018-09-18 13:39:30,040   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@31e4bb20{/jobs/job/kill,null,UNAVAILABLE,@Spark}
2018-09-18 13:39:30,040   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@7c098bb3{/api,null,UNAVAILABLE,@Spark}
2018-09-18 13:39:30,040   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@2f6e28bc{/,null,UNAVAILABLE,@Spark}
2018-09-18 13:39:30,040   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@1ae67cad{/static,null,UNAVAILABLE,@Spark}
2018-09-18 13:39:30,041   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@e98770d{/executors/threadDump/json,null,UNAVAILABLE,@Spark}
2018-09-18 13:39:30,041   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@4ba302e0{/executors/threadDump,null,UNAVAILABLE,@Spark}
2018-09-18 13:39:30,041   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@57ac5227{/executors/json,null,UNAVAILABLE,@Spark}
2018-09-18 13:39:30,041   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@43aaf813{/executors,null,UNAVAILABLE,@Spark}
2018-09-18 13:39:30,041   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@33aeca0b{/environment/json,null,UNAVAILABLE,@Spark}
2018-09-18 13:39:30,041   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@5c18016b{/environment,null,UNAVAILABLE,@Spark}
2018-09-18 13:39:30,042   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@1951b871{/storage/rdd/json,null,UNAVAILABLE,@Spark}
2018-09-18 13:39:30,042   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@793138bd{/storage/rdd,null,UNAVAILABLE,@Spark}
2018-09-18 13:39:30,042   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@5d1659ea{/storage/json,null,UNAVAILABLE,@Spark}
2018-09-18 13:39:30,042   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@25bc0606{/storage,null,UNAVAILABLE,@Spark}
2018-09-18 13:39:30,042   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@3d3ba765{/stages/pool/json,null,UNAVAILABLE,@Spark}
2018-09-18 13:39:30,042   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@784b990c{/stages/pool,null,UNAVAILABLE,@Spark}
2018-09-18 13:39:30,043   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@3c989952{/stages/stage/json,null,UNAVAILABLE,@Spark}
2018-09-18 13:39:30,043   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@3e14c16d{/stages/stage,null,UNAVAILABLE,@Spark}
2018-09-18 13:39:30,043   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@7096b474{/stages/json,null,UNAVAILABLE,@Spark}
2018-09-18 13:39:30,043   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@4bd1f8dd{/stages,null,UNAVAILABLE,@Spark}
2018-09-18 13:39:30,043   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@3f07b12c{/jobs/job/json,null,UNAVAILABLE,@Spark}
2018-09-18 13:39:30,043   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@6475472c{/jobs/job,null,UNAVAILABLE,@Spark}
2018-09-18 13:39:30,043   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@4b7e96a{/jobs/json,null,UNAVAILABLE,@Spark}
2018-09-18 13:39:30,044   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@5c8504fd{/jobs,null,UNAVAILABLE,@Spark}
2018-09-18 13:39:30,045   INFO --- [Thread-1]  org.apache.spark.ui.SparkUI(line:54) : Stopped Spark web UI at http://192.168.3.199:4040
2018-09-18 13:39:30,045   INFO --- [dispatcher-event-loop-3]  org.apache.spark.storage.BlockManagerInfo(line:54) : Removed broadcast_0_piece0 on 192.168.3.199:52729 in memory (size: 14.3 KB, free: 3.0 GB)
2018-09-18 13:39:30,055   INFO --- [dispatcher-event-loop-6]  org.apache.spark.MapOutputTrackerMasterEndpoint(line:54) : MapOutputTrackerMasterEndpoint stopped!
2018-09-18 13:39:30,075   INFO --- [Thread-1]  org.apache.spark.storage.memory.MemoryStore(line:54) : MemoryStore cleared
2018-09-18 13:39:30,076   INFO --- [Thread-1]  org.apache.spark.storage.BlockManager(line:54) : BlockManager stopped
2018-09-18 13:39:30,077   INFO --- [Thread-1]  org.apache.spark.storage.BlockManagerMaster(line:54) : BlockManagerMaster stopped
2018-09-18 13:39:30,080   INFO --- [dispatcher-event-loop-3]  org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint(line:54) : OutputCommitCoordinator stopped!
2018-09-18 13:39:30,086   INFO --- [Thread-1]  org.apache.spark.SparkContext(line:54) : Successfully stopped SparkContext
2018-09-18 13:39:30,086   INFO --- [Thread-1]  org.apache.spark.util.ShutdownHookManager(line:54) : Shutdown hook called
2018-09-18 13:39:30,087   INFO --- [Thread-1]  org.apache.spark.util.ShutdownHookManager(line:54) : Deleting directory C:\Users\wshs\AppData\Local\Temp\spark-731a254e-47f8-4721-90f3-e9f16560ce28
2018-09-18 13:50:50,135   INFO --- [main]  org.apache.spark.SparkContext(line:54) : Running Spark version 2.1.1
2018-09-18 13:50:50,472   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing view acls to: wshs
2018-09-18 13:50:50,473   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing modify acls to: wshs
2018-09-18 13:50:50,473   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing view acls groups to: 
2018-09-18 13:50:50,474   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing modify acls groups to: 
2018-09-18 13:50:50,476   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(wshs); groups with view permissions: Set(); users  with modify permissions: Set(wshs); groups with modify permissions: Set()
2018-09-18 13:50:50,947   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'sparkDriver' on port 53339.
2018-09-18 13:50:50,964   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering MapOutputTracker
2018-09-18 13:50:50,982   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering BlockManagerMaster
2018-09-18 13:50:50,985   INFO --- [main]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-09-18 13:50:50,986   INFO --- [main]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : BlockManagerMasterEndpoint up
2018-09-18 13:50:50,997   INFO --- [main]  org.apache.spark.storage.DiskBlockManager(line:54) : Created local directory at C:\Users\wshs\AppData\Local\Temp\blockmgr-3d0646a5-3fc8-4a83-961c-67348b181f05
2018-09-18 13:50:51,011   INFO --- [main]  org.apache.spark.storage.memory.MemoryStore(line:54) : MemoryStore started with capacity 3.0 GB
2018-09-18 13:50:51,069   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering OutputCommitCoordinator
2018-09-18 13:50:51,145   INFO --- [main]  org.spark_project.jetty.util.log(line:186) : Logging initialized @1798ms
2018-09-18 13:50:51,224   INFO --- [main]  org.spark_project.jetty.server.Server(line:327) : jetty-9.2.z-SNAPSHOT
2018-09-18 13:50:51,237   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@5c8504fd{/jobs,null,AVAILABLE,@Spark}
2018-09-18 13:50:51,237   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@4b7e96a{/jobs/json,null,AVAILABLE,@Spark}
2018-09-18 13:50:51,237   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@6475472c{/jobs/job,null,AVAILABLE,@Spark}
2018-09-18 13:50:51,238   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@3f07b12c{/jobs/job/json,null,AVAILABLE,@Spark}
2018-09-18 13:50:51,238   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@4bd1f8dd{/stages,null,AVAILABLE,@Spark}
2018-09-18 13:50:51,238   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@7096b474{/stages/json,null,AVAILABLE,@Spark}
2018-09-18 13:50:51,238   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@3e14c16d{/stages/stage,null,AVAILABLE,@Spark}
2018-09-18 13:50:51,239   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@3c989952{/stages/stage/json,null,AVAILABLE,@Spark}
2018-09-18 13:50:51,239   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@784b990c{/stages/pool,null,AVAILABLE,@Spark}
2018-09-18 13:50:51,239   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@3d3ba765{/stages/pool/json,null,AVAILABLE,@Spark}
2018-09-18 13:50:51,239   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@25bc0606{/storage,null,AVAILABLE,@Spark}
2018-09-18 13:50:51,239   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@5d1659ea{/storage/json,null,AVAILABLE,@Spark}
2018-09-18 13:50:51,240   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@793138bd{/storage/rdd,null,AVAILABLE,@Spark}
2018-09-18 13:50:51,240   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@1951b871{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-09-18 13:50:51,240   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@5c18016b{/environment,null,AVAILABLE,@Spark}
2018-09-18 13:50:51,240   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@33aeca0b{/environment/json,null,AVAILABLE,@Spark}
2018-09-18 13:50:51,241   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@43aaf813{/executors,null,AVAILABLE,@Spark}
2018-09-18 13:50:51,241   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@57ac5227{/executors/json,null,AVAILABLE,@Spark}
2018-09-18 13:50:51,241   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@4ba302e0{/executors/threadDump,null,AVAILABLE,@Spark}
2018-09-18 13:50:51,241   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@e98770d{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-09-18 13:50:51,246   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@1ae67cad{/static,null,AVAILABLE,@Spark}
2018-09-18 13:50:51,246   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@2f6e28bc{/,null,AVAILABLE,@Spark}
2018-09-18 13:50:51,247   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@7c098bb3{/api,null,AVAILABLE,@Spark}
2018-09-18 13:50:51,247   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@31e4bb20{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-09-18 13:50:51,248   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@18cebaa5{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-09-18 13:50:51,262   INFO --- [main]  org.spark_project.jetty.server.ServerConnector(line:266) : Started Spark@1021f6c9{HTTP/1.1}{0.0.0.0:4040}
2018-09-18 13:50:51,263   INFO --- [main]  org.spark_project.jetty.server.Server(line:379) : Started @1917ms
2018-09-18 13:50:51,263   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'SparkUI' on port 4040.
2018-09-18 13:50:51,266   INFO --- [main]  org.apache.spark.ui.SparkUI(line:54) : Bound SparkUI to 0.0.0.0, and started at http://192.168.3.199:4040
2018-09-18 13:50:51,330   INFO --- [main]  org.apache.spark.executor.Executor(line:54) : Starting executor ID driver on host localhost
2018-09-18 13:50:51,368   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 53380.
2018-09-18 13:50:51,369   INFO --- [main]  org.apache.spark.network.netty.NettyBlockTransferService(line:54) : Server created on 192.168.3.199:53380
2018-09-18 13:50:51,370   INFO --- [main]  org.apache.spark.storage.BlockManager(line:54) : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-09-18 13:50:51,372   INFO --- [main]  org.apache.spark.storage.BlockManagerMaster(line:54) : Registering BlockManager BlockManagerId(driver, 192.168.3.199, 53380, None)
2018-09-18 13:50:51,373   INFO --- [dispatcher-event-loop-2]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : Registering block manager 192.168.3.199:53380 with 3.0 GB RAM, BlockManagerId(driver, 192.168.3.199, 53380, None)
2018-09-18 13:50:51,376   INFO --- [main]  org.apache.spark.storage.BlockManagerMaster(line:54) : Registered BlockManager BlockManagerId(driver, 192.168.3.199, 53380, None)
2018-09-18 13:50:51,377   INFO --- [main]  org.apache.spark.storage.BlockManager(line:54) : Initialized BlockManager: BlockManagerId(driver, 192.168.3.199, 53380, None)
2018-09-18 13:50:51,528   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@1b9ea3e3{/metrics/json,null,AVAILABLE,@Spark}
2018-09-18 13:50:51,545   WARN --- [main]  org.apache.spark.SparkContext(line:66) : Using an existing SparkContext; some configuration may not take effect.
2018-09-18 13:50:51,581   INFO --- [main]  org.apache.spark.sql.internal.SharedState(line:54) : Warehouse path is 'file:/C:/Users/wshs/IdeaProjects/logdataSession/spark-warehouse/'.
2018-09-18 13:50:51,586   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@5be82d43{/SQL,null,AVAILABLE,@Spark}
2018-09-18 13:50:51,586   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@345e5a17{/SQL/json,null,AVAILABLE,@Spark}
2018-09-18 13:50:51,587   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@77b7ffa4{/SQL/execution,null,AVAILABLE,@Spark}
2018-09-18 13:50:51,587   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@402f80f5{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-09-18 13:50:51,589   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@2102a4d5{/static/sql,null,AVAILABLE,@Spark}
2018-09-18 13:50:51,986   INFO --- [main]  org.apache.spark.storage.memory.MemoryStore(line:54) : Block broadcast_0 stored as values in memory (estimated size 127.1 KB, free 3.0 GB)
2018-09-18 13:50:52,114   INFO --- [main]  org.apache.spark.storage.memory.MemoryStore(line:54) : Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.3 KB, free 3.0 GB)
2018-09-18 13:50:52,118   INFO --- [dispatcher-event-loop-4]  org.apache.spark.storage.BlockManagerInfo(line:54) : Added broadcast_0_piece0 in memory on 192.168.3.199:53380 (size: 14.3 KB, free: 3.0 GB)
2018-09-18 13:50:52,122   INFO --- [main]  org.apache.spark.SparkContext(line:54) : Created broadcast 0 from textFile at logSession.scala:40
2018-09-18 13:50:54,236   INFO --- [main]  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator(line:54) : Code generated in 219.081286 ms
2018-09-18 13:50:54,290   INFO --- [main]  org.apache.hadoop.mapred.FileInputFormat(line:253) : Total input paths to process : 1
2018-09-18 13:50:54,302   INFO --- [main]  org.apache.spark.SparkContext(line:54) : Starting job: show at logSession.scala:45
2018-09-18 13:50:54,317   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Got job 0 (show at logSession.scala:45) with 1 output partitions
2018-09-18 13:50:54,317   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Final stage: ResultStage 0 (show at logSession.scala:45)
2018-09-18 13:50:54,317   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Parents of final stage: List()
2018-09-18 13:50:54,319   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Missing parents: List()
2018-09-18 13:50:54,323   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Submitting ResultStage 0 (MapPartitionsRDD[7] at show at logSession.scala:45), which has no missing parents
2018-09-18 13:50:54,359   INFO --- [dag-scheduler-event-loop]  org.apache.spark.storage.memory.MemoryStore(line:54) : Block broadcast_1 stored as values in memory (estimated size 13.7 KB, free 3.0 GB)
2018-09-18 13:50:54,363   INFO --- [dag-scheduler-event-loop]  org.apache.spark.storage.memory.MemoryStore(line:54) : Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.3 KB, free 3.0 GB)
2018-09-18 13:50:54,363   INFO --- [dispatcher-event-loop-5]  org.apache.spark.storage.BlockManagerInfo(line:54) : Added broadcast_1_piece0 in memory on 192.168.3.199:53380 (size: 5.3 KB, free: 3.0 GB)
2018-09-18 13:50:54,363   INFO --- [dag-scheduler-event-loop]  org.apache.spark.SparkContext(line:54) : Created broadcast 1 from broadcast at DAGScheduler.scala:996
2018-09-18 13:50:54,367   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[7] at show at logSession.scala:45)
2018-09-18 13:50:54,369   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.TaskSchedulerImpl(line:54) : Adding task set 0.0 with 1 tasks
2018-09-18 13:50:54,408   INFO --- [dispatcher-event-loop-6]  org.apache.spark.scheduler.TaskSetManager(line:54) : Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 5921 bytes)
2018-09-18 13:50:54,417   INFO --- [Executor task launch worker for task 0]  org.apache.spark.executor.Executor(line:54) : Running task 0.0 in stage 0.0 (TID 0)
2018-09-18 13:50:54,456   INFO --- [Executor task launch worker for task 0]  org.apache.spark.rdd.HadoopRDD(line:54) : Input split: file:/e:/r_actionopvidio.txt:0+188363
2018-09-18 13:50:54,464   INFO --- [Executor task launch worker for task 0]  org.apache.hadoop.conf.Configuration.deprecation(line:840) : mapred.tip.id is deprecated. Instead, use mapreduce.task.id
2018-09-18 13:50:54,464   INFO --- [Executor task launch worker for task 0]  org.apache.hadoop.conf.Configuration.deprecation(line:840) : mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
2018-09-18 13:50:54,465   INFO --- [Executor task launch worker for task 0]  org.apache.hadoop.conf.Configuration.deprecation(line:840) : mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
2018-09-18 13:50:54,465   INFO --- [Executor task launch worker for task 0]  org.apache.hadoop.conf.Configuration.deprecation(line:840) : mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
2018-09-18 13:50:54,465   INFO --- [Executor task launch worker for task 0]  org.apache.hadoop.conf.Configuration.deprecation(line:840) : mapred.job.id is deprecated. Instead, use mapreduce.job.id
2018-09-18 13:50:54,498   INFO --- [Executor task launch worker for task 0]  org.apache.spark.executor.Executor(line:54) : Finished task 0.0 in stage 0.0 (TID 0). 1620 bytes result sent to driver
2018-09-18 13:50:54,505   INFO --- [task-result-getter-0]  org.apache.spark.scheduler.TaskSetManager(line:54) : Finished task 0.0 in stage 0.0 (TID 0) in 116 ms on localhost (executor driver) (1/1)
2018-09-18 13:50:54,507   INFO --- [task-result-getter-0]  org.apache.spark.scheduler.TaskSchedulerImpl(line:54) : Removed TaskSet 0.0, whose tasks have all completed, from pool 
2018-09-18 13:50:54,509   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : ResultStage 0 (show at logSession.scala:45) finished in 0.131 s
2018-09-18 13:50:54,514   INFO --- [main]  org.apache.spark.scheduler.DAGScheduler(line:54) : Job 0 finished: show at logSession.scala:45, took 0.211724 s
2018-09-18 13:50:54,636   INFO --- [main]  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator(line:54) : Code generated in 106.231127 ms
2018-09-18 13:50:54,642   INFO --- [dispatcher-event-loop-3]  org.apache.spark.storage.BlockManagerInfo(line:54) : Removed broadcast_1_piece0 on 192.168.3.199:53380 in memory (size: 5.3 KB, free: 3.0 GB)
2018-09-18 13:50:54,655   INFO --- [main]  org.spark_project.jetty.server.ServerConnector(line:306) : Stopped Spark@1021f6c9{HTTP/1.1}{0.0.0.0:4040}
2018-09-18 13:50:54,657   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@18cebaa5{/stages/stage/kill,null,UNAVAILABLE,@Spark}
2018-09-18 13:50:54,657   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@31e4bb20{/jobs/job/kill,null,UNAVAILABLE,@Spark}
2018-09-18 13:50:54,657   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@7c098bb3{/api,null,UNAVAILABLE,@Spark}
2018-09-18 13:50:54,657   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@2f6e28bc{/,null,UNAVAILABLE,@Spark}
2018-09-18 13:50:54,658   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@1ae67cad{/static,null,UNAVAILABLE,@Spark}
2018-09-18 13:50:54,658   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@e98770d{/executors/threadDump/json,null,UNAVAILABLE,@Spark}
2018-09-18 13:50:54,658   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@4ba302e0{/executors/threadDump,null,UNAVAILABLE,@Spark}
2018-09-18 13:50:54,658   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@57ac5227{/executors/json,null,UNAVAILABLE,@Spark}
2018-09-18 13:50:54,658   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@43aaf813{/executors,null,UNAVAILABLE,@Spark}
2018-09-18 13:50:54,658   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@33aeca0b{/environment/json,null,UNAVAILABLE,@Spark}
2018-09-18 13:50:54,659   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@5c18016b{/environment,null,UNAVAILABLE,@Spark}
2018-09-18 13:50:54,659   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@1951b871{/storage/rdd/json,null,UNAVAILABLE,@Spark}
2018-09-18 13:50:54,659   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@793138bd{/storage/rdd,null,UNAVAILABLE,@Spark}
2018-09-18 13:50:54,659   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@5d1659ea{/storage/json,null,UNAVAILABLE,@Spark}
2018-09-18 13:50:54,659   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@25bc0606{/storage,null,UNAVAILABLE,@Spark}
2018-09-18 13:50:54,659   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@3d3ba765{/stages/pool/json,null,UNAVAILABLE,@Spark}
2018-09-18 13:50:54,660   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@784b990c{/stages/pool,null,UNAVAILABLE,@Spark}
2018-09-18 13:50:54,660   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@3c989952{/stages/stage/json,null,UNAVAILABLE,@Spark}
2018-09-18 13:50:54,660   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@3e14c16d{/stages/stage,null,UNAVAILABLE,@Spark}
2018-09-18 13:50:54,660   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@7096b474{/stages/json,null,UNAVAILABLE,@Spark}
2018-09-18 13:50:54,660   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@4bd1f8dd{/stages,null,UNAVAILABLE,@Spark}
2018-09-18 13:50:54,660   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@3f07b12c{/jobs/job/json,null,UNAVAILABLE,@Spark}
2018-09-18 13:50:54,661   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@6475472c{/jobs/job,null,UNAVAILABLE,@Spark}
2018-09-18 13:50:54,661   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@4b7e96a{/jobs/json,null,UNAVAILABLE,@Spark}
2018-09-18 13:50:54,661   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@5c8504fd{/jobs,null,UNAVAILABLE,@Spark}
2018-09-18 13:50:54,663   INFO --- [main]  org.apache.spark.ui.SparkUI(line:54) : Stopped Spark web UI at http://192.168.3.199:4040
2018-09-18 13:50:54,671   INFO --- [dispatcher-event-loop-6]  org.apache.spark.MapOutputTrackerMasterEndpoint(line:54) : MapOutputTrackerMasterEndpoint stopped!
2018-09-18 13:50:54,690   INFO --- [main]  org.apache.spark.storage.memory.MemoryStore(line:54) : MemoryStore cleared
2018-09-18 13:50:54,690   INFO --- [main]  org.apache.spark.storage.BlockManager(line:54) : BlockManager stopped
2018-09-18 13:50:54,691   INFO --- [main]  org.apache.spark.storage.BlockManagerMaster(line:54) : BlockManagerMaster stopped
2018-09-18 13:50:54,693   INFO --- [dispatcher-event-loop-3]  org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint(line:54) : OutputCommitCoordinator stopped!
2018-09-18 13:50:54,698   INFO --- [main]  org.apache.spark.SparkContext(line:54) : Successfully stopped SparkContext
2018-09-18 13:50:54,700   INFO --- [Thread-1]  org.apache.spark.util.ShutdownHookManager(line:54) : Shutdown hook called
2018-09-18 13:50:54,701   INFO --- [Thread-1]  org.apache.spark.util.ShutdownHookManager(line:54) : Deleting directory C:\Users\wshs\AppData\Local\Temp\spark-8e430563-58fe-40a5-860c-188161bd3525
2018-09-18 13:52:49,773   INFO --- [main]  org.apache.spark.SparkContext(line:54) : Running Spark version 2.1.1
2018-09-18 13:52:50,140   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing view acls to: wshs
2018-09-18 13:52:50,141   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing modify acls to: wshs
2018-09-18 13:52:50,141   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing view acls groups to: 
2018-09-18 13:52:50,142   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing modify acls groups to: 
2018-09-18 13:52:50,144   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(wshs); groups with view permissions: Set(); users  with modify permissions: Set(wshs); groups with modify permissions: Set()
2018-09-18 13:52:50,651   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'sparkDriver' on port 53505.
2018-09-18 13:52:50,669   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering MapOutputTracker
2018-09-18 13:52:50,691   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering BlockManagerMaster
2018-09-18 13:52:50,694   INFO --- [main]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-09-18 13:52:50,694   INFO --- [main]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : BlockManagerMasterEndpoint up
2018-09-18 13:52:50,707   INFO --- [main]  org.apache.spark.storage.DiskBlockManager(line:54) : Created local directory at C:\Users\wshs\AppData\Local\Temp\blockmgr-2cffe8a6-7831-4db1-bab1-86013f7fa25f
2018-09-18 13:52:50,725   INFO --- [main]  org.apache.spark.storage.memory.MemoryStore(line:54) : MemoryStore started with capacity 3.0 GB
2018-09-18 13:52:50,787   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering OutputCommitCoordinator
2018-09-18 13:52:50,858   INFO --- [main]  org.spark_project.jetty.util.log(line:186) : Logging initialized @2051ms
2018-09-18 13:52:50,932   INFO --- [main]  org.spark_project.jetty.server.Server(line:327) : jetty-9.2.z-SNAPSHOT
2018-09-18 13:52:50,946   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@5c8504fd{/jobs,null,AVAILABLE,@Spark}
2018-09-18 13:52:50,946   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@4b7e96a{/jobs/json,null,AVAILABLE,@Spark}
2018-09-18 13:52:50,946   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@6475472c{/jobs/job,null,AVAILABLE,@Spark}
2018-09-18 13:52:50,947   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@3f07b12c{/jobs/job/json,null,AVAILABLE,@Spark}
2018-09-18 13:52:50,947   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@4bd1f8dd{/stages,null,AVAILABLE,@Spark}
2018-09-18 13:52:50,947   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@7096b474{/stages/json,null,AVAILABLE,@Spark}
2018-09-18 13:52:50,948   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@3e14c16d{/stages/stage,null,AVAILABLE,@Spark}
2018-09-18 13:52:50,948   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@3c989952{/stages/stage/json,null,AVAILABLE,@Spark}
2018-09-18 13:52:50,948   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@784b990c{/stages/pool,null,AVAILABLE,@Spark}
2018-09-18 13:52:50,948   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@3d3ba765{/stages/pool/json,null,AVAILABLE,@Spark}
2018-09-18 13:52:50,948   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@25bc0606{/storage,null,AVAILABLE,@Spark}
2018-09-18 13:52:50,949   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@5d1659ea{/storage/json,null,AVAILABLE,@Spark}
2018-09-18 13:52:50,949   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@793138bd{/storage/rdd,null,AVAILABLE,@Spark}
2018-09-18 13:52:50,949   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@1951b871{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-09-18 13:52:50,949   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@5c18016b{/environment,null,AVAILABLE,@Spark}
2018-09-18 13:52:50,949   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@33aeca0b{/environment/json,null,AVAILABLE,@Spark}
2018-09-18 13:52:50,950   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@43aaf813{/executors,null,AVAILABLE,@Spark}
2018-09-18 13:52:50,950   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@57ac5227{/executors/json,null,AVAILABLE,@Spark}
2018-09-18 13:52:50,950   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@4ba302e0{/executors/threadDump,null,AVAILABLE,@Spark}
2018-09-18 13:52:50,950   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@e98770d{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-09-18 13:52:50,955   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@1ae67cad{/static,null,AVAILABLE,@Spark}
2018-09-18 13:52:50,955   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@2f6e28bc{/,null,AVAILABLE,@Spark}
2018-09-18 13:52:50,956   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@7c098bb3{/api,null,AVAILABLE,@Spark}
2018-09-18 13:52:50,956   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@31e4bb20{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-09-18 13:52:50,957   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@18cebaa5{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-09-18 13:52:50,968   INFO --- [main]  org.spark_project.jetty.server.ServerConnector(line:266) : Started Spark@1021f6c9{HTTP/1.1}{0.0.0.0:4040}
2018-09-18 13:52:50,969   INFO --- [main]  org.spark_project.jetty.server.Server(line:379) : Started @2163ms
2018-09-18 13:52:50,969   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'SparkUI' on port 4040.
2018-09-18 13:52:50,972   INFO --- [main]  org.apache.spark.ui.SparkUI(line:54) : Bound SparkUI to 0.0.0.0, and started at http://192.168.3.199:4040
2018-09-18 13:52:51,041   INFO --- [main]  org.apache.spark.executor.Executor(line:54) : Starting executor ID driver on host localhost
2018-09-18 13:52:51,090   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 53548.
2018-09-18 13:52:51,091   INFO --- [main]  org.apache.spark.network.netty.NettyBlockTransferService(line:54) : Server created on 192.168.3.199:53548
2018-09-18 13:52:51,093   INFO --- [main]  org.apache.spark.storage.BlockManager(line:54) : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-09-18 13:52:51,094   INFO --- [main]  org.apache.spark.storage.BlockManagerMaster(line:54) : Registering BlockManager BlockManagerId(driver, 192.168.3.199, 53548, None)
2018-09-18 13:52:51,096   INFO --- [dispatcher-event-loop-3]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : Registering block manager 192.168.3.199:53548 with 3.0 GB RAM, BlockManagerId(driver, 192.168.3.199, 53548, None)
2018-09-18 13:52:51,099   INFO --- [main]  org.apache.spark.storage.BlockManagerMaster(line:54) : Registered BlockManager BlockManagerId(driver, 192.168.3.199, 53548, None)
2018-09-18 13:52:51,099   INFO --- [main]  org.apache.spark.storage.BlockManager(line:54) : Initialized BlockManager: BlockManagerId(driver, 192.168.3.199, 53548, None)
2018-09-18 13:52:51,256   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@1b9ea3e3{/metrics/json,null,AVAILABLE,@Spark}
2018-09-18 13:52:51,274   WARN --- [main]  org.apache.spark.SparkContext(line:66) : Using an existing SparkContext; some configuration may not take effect.
2018-09-18 13:52:51,309   INFO --- [main]  org.apache.spark.sql.internal.SharedState(line:54) : Warehouse path is 'file:/C:/Users/wshs/IdeaProjects/logdataSession/spark-warehouse/'.
2018-09-18 13:52:51,314   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@5be82d43{/SQL,null,AVAILABLE,@Spark}
2018-09-18 13:52:51,314   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@345e5a17{/SQL/json,null,AVAILABLE,@Spark}
2018-09-18 13:52:51,315   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@77b7ffa4{/SQL/execution,null,AVAILABLE,@Spark}
2018-09-18 13:52:51,316   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@402f80f5{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-09-18 13:52:51,317   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@2102a4d5{/static/sql,null,AVAILABLE,@Spark}
2018-09-18 13:52:51,729   INFO --- [main]  org.apache.spark.storage.memory.MemoryStore(line:54) : Block broadcast_0 stored as values in memory (estimated size 127.1 KB, free 3.0 GB)
2018-09-18 13:52:52,293   INFO --- [main]  org.apache.spark.storage.memory.MemoryStore(line:54) : Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.3 KB, free 3.0 GB)
2018-09-18 13:52:52,296   INFO --- [dispatcher-event-loop-1]  org.apache.spark.storage.BlockManagerInfo(line:54) : Added broadcast_0_piece0 in memory on 192.168.3.199:53548 (size: 14.3 KB, free: 3.0 GB)
2018-09-18 13:52:52,302   INFO --- [main]  org.apache.spark.SparkContext(line:54) : Created broadcast 0 from textFile at logSession.scala:39
2018-09-18 13:52:53,987   INFO --- [main]  org.apache.spark.sql.execution.SparkSqlParser(line:54) : Parsing command: actionopvidio
2018-09-18 13:52:54,200   INFO --- [main]  org.apache.spark.sql.execution.SparkSqlParser(line:54) : Parsing command: SELECT id,uid,rid FROM actionopvidio
2018-09-18 13:52:54,624   INFO --- [main]  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator(line:54) : Code generated in 204.909664 ms
2018-09-18 13:52:54,679   INFO --- [main]  org.apache.hadoop.mapred.FileInputFormat(line:253) : Total input paths to process : 1
2018-09-18 13:52:54,691   INFO --- [main]  org.apache.spark.SparkContext(line:54) : Starting job: show at logSession.scala:45
2018-09-18 13:52:54,795   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Got job 0 (show at logSession.scala:45) with 1 output partitions
2018-09-18 13:52:54,796   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Final stage: ResultStage 0 (show at logSession.scala:45)
2018-09-18 13:52:54,796   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Parents of final stage: List()
2018-09-18 13:52:54,797   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Missing parents: List()
2018-09-18 13:52:54,802   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Submitting ResultStage 0 (MapPartitionsRDD[8] at show at logSession.scala:45), which has no missing parents
2018-09-18 13:52:54,836   INFO --- [dag-scheduler-event-loop]  org.apache.spark.storage.memory.MemoryStore(line:54) : Block broadcast_1 stored as values in memory (estimated size 9.4 KB, free 3.0 GB)
2018-09-18 13:52:54,840   INFO --- [dag-scheduler-event-loop]  org.apache.spark.storage.memory.MemoryStore(line:54) : Block broadcast_1_piece0 stored as bytes in memory (estimated size 4.4 KB, free 3.0 GB)
2018-09-18 13:52:54,841   INFO --- [dispatcher-event-loop-5]  org.apache.spark.storage.BlockManagerInfo(line:54) : Added broadcast_1_piece0 in memory on 192.168.3.199:53548 (size: 4.4 KB, free: 3.0 GB)
2018-09-18 13:52:54,841   INFO --- [dag-scheduler-event-loop]  org.apache.spark.SparkContext(line:54) : Created broadcast 1 from broadcast at DAGScheduler.scala:996
2018-09-18 13:52:54,845   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[8] at show at logSession.scala:45)
2018-09-18 13:52:54,846   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.TaskSchedulerImpl(line:54) : Adding task set 0.0 with 1 tasks
2018-09-18 13:52:54,882   INFO --- [dispatcher-event-loop-6]  org.apache.spark.scheduler.TaskSetManager(line:54) : Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 5921 bytes)
2018-09-18 13:52:54,891   INFO --- [Executor task launch worker for task 0]  org.apache.spark.executor.Executor(line:54) : Running task 0.0 in stage 0.0 (TID 0)
2018-09-18 13:52:54,926   INFO --- [Executor task launch worker for task 0]  org.apache.spark.rdd.HadoopRDD(line:54) : Input split: file:/e:/r_actionopvidio.txt:0+188363
2018-09-18 13:52:54,932   INFO --- [Executor task launch worker for task 0]  org.apache.hadoop.conf.Configuration.deprecation(line:840) : mapred.tip.id is deprecated. Instead, use mapreduce.task.id
2018-09-18 13:52:54,932   INFO --- [Executor task launch worker for task 0]  org.apache.hadoop.conf.Configuration.deprecation(line:840) : mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
2018-09-18 13:52:54,933   INFO --- [Executor task launch worker for task 0]  org.apache.hadoop.conf.Configuration.deprecation(line:840) : mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
2018-09-18 13:52:54,933   INFO --- [Executor task launch worker for task 0]  org.apache.hadoop.conf.Configuration.deprecation(line:840) : mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
2018-09-18 13:52:54,933   INFO --- [Executor task launch worker for task 0]  org.apache.hadoop.conf.Configuration.deprecation(line:840) : mapred.job.id is deprecated. Instead, use mapreduce.job.id
2018-09-18 13:52:54,959   INFO --- [Executor task launch worker for task 0]  org.apache.spark.executor.Executor(line:54) : Finished task 0.0 in stage 0.0 (TID 0). 1552 bytes result sent to driver
2018-09-18 13:52:54,966   INFO --- [task-result-getter-0]  org.apache.spark.scheduler.TaskSetManager(line:54) : Finished task 0.0 in stage 0.0 (TID 0) in 100 ms on localhost (executor driver) (1/1)
2018-09-18 13:52:54,967   INFO --- [task-result-getter-0]  org.apache.spark.scheduler.TaskSchedulerImpl(line:54) : Removed TaskSet 0.0, whose tasks have all completed, from pool 
2018-09-18 13:52:54,970   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : ResultStage 0 (show at logSession.scala:45) finished in 0.114 s
2018-09-18 13:52:54,976   INFO --- [main]  org.apache.spark.scheduler.DAGScheduler(line:54) : Job 0 finished: show at logSession.scala:45, took 0.284636 s
2018-09-18 13:52:54,998   INFO --- [main]  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator(line:54) : Code generated in 11.356528 ms
2018-09-18 13:52:55,015   INFO --- [main]  org.spark_project.jetty.server.ServerConnector(line:306) : Stopped Spark@1021f6c9{HTTP/1.1}{0.0.0.0:4040}
2018-09-18 13:52:55,016   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@18cebaa5{/stages/stage/kill,null,UNAVAILABLE,@Spark}
2018-09-18 13:52:55,017   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@31e4bb20{/jobs/job/kill,null,UNAVAILABLE,@Spark}
2018-09-18 13:52:55,017   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@7c098bb3{/api,null,UNAVAILABLE,@Spark}
2018-09-18 13:52:55,017   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@2f6e28bc{/,null,UNAVAILABLE,@Spark}
2018-09-18 13:52:55,017   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@1ae67cad{/static,null,UNAVAILABLE,@Spark}
2018-09-18 13:52:55,017   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@e98770d{/executors/threadDump/json,null,UNAVAILABLE,@Spark}
2018-09-18 13:52:55,017   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@4ba302e0{/executors/threadDump,null,UNAVAILABLE,@Spark}
2018-09-18 13:52:55,018   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@57ac5227{/executors/json,null,UNAVAILABLE,@Spark}
2018-09-18 13:52:55,018   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@43aaf813{/executors,null,UNAVAILABLE,@Spark}
2018-09-18 13:52:55,018   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@33aeca0b{/environment/json,null,UNAVAILABLE,@Spark}
2018-09-18 13:52:55,018   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@5c18016b{/environment,null,UNAVAILABLE,@Spark}
2018-09-18 13:52:55,018   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@1951b871{/storage/rdd/json,null,UNAVAILABLE,@Spark}
2018-09-18 13:52:55,018   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@793138bd{/storage/rdd,null,UNAVAILABLE,@Spark}
2018-09-18 13:52:55,019   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@5d1659ea{/storage/json,null,UNAVAILABLE,@Spark}
2018-09-18 13:52:55,019   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@25bc0606{/storage,null,UNAVAILABLE,@Spark}
2018-09-18 13:52:55,019   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@3d3ba765{/stages/pool/json,null,UNAVAILABLE,@Spark}
2018-09-18 13:52:55,019   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@784b990c{/stages/pool,null,UNAVAILABLE,@Spark}
2018-09-18 13:52:55,019   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@3c989952{/stages/stage/json,null,UNAVAILABLE,@Spark}
2018-09-18 13:52:55,019   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@3e14c16d{/stages/stage,null,UNAVAILABLE,@Spark}
2018-09-18 13:52:55,019   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@7096b474{/stages/json,null,UNAVAILABLE,@Spark}
2018-09-18 13:52:55,020   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@4bd1f8dd{/stages,null,UNAVAILABLE,@Spark}
2018-09-18 13:52:55,020   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@3f07b12c{/jobs/job/json,null,UNAVAILABLE,@Spark}
2018-09-18 13:52:55,020   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@6475472c{/jobs/job,null,UNAVAILABLE,@Spark}
2018-09-18 13:52:55,020   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@4b7e96a{/jobs/json,null,UNAVAILABLE,@Spark}
2018-09-18 13:52:55,020   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@5c8504fd{/jobs,null,UNAVAILABLE,@Spark}
2018-09-18 13:52:55,021   INFO --- [main]  org.apache.spark.ui.SparkUI(line:54) : Stopped Spark web UI at http://192.168.3.199:4040
2018-09-18 13:52:55,030   INFO --- [dispatcher-event-loop-4]  org.apache.spark.MapOutputTrackerMasterEndpoint(line:54) : MapOutputTrackerMasterEndpoint stopped!
2018-09-18 13:52:55,053   INFO --- [main]  org.apache.spark.storage.memory.MemoryStore(line:54) : MemoryStore cleared
2018-09-18 13:52:55,054   INFO --- [main]  org.apache.spark.storage.BlockManager(line:54) : BlockManager stopped
2018-09-18 13:52:55,058   INFO --- [main]  org.apache.spark.storage.BlockManagerMaster(line:54) : BlockManagerMaster stopped
2018-09-18 13:52:55,061   INFO --- [dispatcher-event-loop-0]  org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint(line:54) : OutputCommitCoordinator stopped!
2018-09-18 13:52:55,067   INFO --- [main]  org.apache.spark.SparkContext(line:54) : Successfully stopped SparkContext
2018-09-18 13:52:55,069   INFO --- [Thread-1]  org.apache.spark.util.ShutdownHookManager(line:54) : Shutdown hook called
2018-09-18 13:52:55,070   INFO --- [Thread-1]  org.apache.spark.util.ShutdownHookManager(line:54) : Deleting directory C:\Users\wshs\AppData\Local\Temp\spark-09ef0566-93d1-4df4-a89d-8d9cc6161dd9
2018-09-18 14:00:02,821   INFO --- [main]  org.apache.spark.SparkContext(line:54) : Running Spark version 2.1.1
2018-09-18 14:00:03,113   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing view acls to: wshs
2018-09-18 14:00:03,114   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing modify acls to: wshs
2018-09-18 14:00:03,114   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing view acls groups to: 
2018-09-18 14:00:03,115   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing modify acls groups to: 
2018-09-18 14:00:03,116   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(wshs); groups with view permissions: Set(); users  with modify permissions: Set(wshs); groups with modify permissions: Set()
2018-09-18 14:00:03,586   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'sparkDriver' on port 53956.
2018-09-18 14:00:03,603   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering MapOutputTracker
2018-09-18 14:00:03,620   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering BlockManagerMaster
2018-09-18 14:00:03,623   INFO --- [main]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-09-18 14:00:03,623   INFO --- [main]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : BlockManagerMasterEndpoint up
2018-09-18 14:00:03,636   INFO --- [main]  org.apache.spark.storage.DiskBlockManager(line:54) : Created local directory at C:\Users\wshs\AppData\Local\Temp\blockmgr-121a76c9-b11a-4591-905d-84f568a0d6e8
2018-09-18 14:00:03,651   INFO --- [main]  org.apache.spark.storage.memory.MemoryStore(line:54) : MemoryStore started with capacity 3.0 GB
2018-09-18 14:00:03,706   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering OutputCommitCoordinator
2018-09-18 14:00:03,783   INFO --- [main]  org.spark_project.jetty.util.log(line:186) : Logging initialized @1748ms
2018-09-18 14:00:03,860   INFO --- [main]  org.spark_project.jetty.server.Server(line:327) : jetty-9.2.z-SNAPSHOT
2018-09-18 14:00:03,874   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@5c8504fd{/jobs,null,AVAILABLE,@Spark}
2018-09-18 14:00:03,874   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@4b7e96a{/jobs/json,null,AVAILABLE,@Spark}
2018-09-18 14:00:03,874   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@6475472c{/jobs/job,null,AVAILABLE,@Spark}
2018-09-18 14:00:03,874   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@3f07b12c{/jobs/job/json,null,AVAILABLE,@Spark}
2018-09-18 14:00:03,875   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@4bd1f8dd{/stages,null,AVAILABLE,@Spark}
2018-09-18 14:00:03,875   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@7096b474{/stages/json,null,AVAILABLE,@Spark}
2018-09-18 14:00:03,875   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@3e14c16d{/stages/stage,null,AVAILABLE,@Spark}
2018-09-18 14:00:03,875   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@3c989952{/stages/stage/json,null,AVAILABLE,@Spark}
2018-09-18 14:00:03,876   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@784b990c{/stages/pool,null,AVAILABLE,@Spark}
2018-09-18 14:00:03,876   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@3d3ba765{/stages/pool/json,null,AVAILABLE,@Spark}
2018-09-18 14:00:03,876   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@25bc0606{/storage,null,AVAILABLE,@Spark}
2018-09-18 14:00:03,876   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@5d1659ea{/storage/json,null,AVAILABLE,@Spark}
2018-09-18 14:00:03,877   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@793138bd{/storage/rdd,null,AVAILABLE,@Spark}
2018-09-18 14:00:03,877   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@1951b871{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-09-18 14:00:03,877   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@5c18016b{/environment,null,AVAILABLE,@Spark}
2018-09-18 14:00:03,877   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@33aeca0b{/environment/json,null,AVAILABLE,@Spark}
2018-09-18 14:00:03,878   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@43aaf813{/executors,null,AVAILABLE,@Spark}
2018-09-18 14:00:03,878   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@57ac5227{/executors/json,null,AVAILABLE,@Spark}
2018-09-18 14:00:03,878   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@4ba302e0{/executors/threadDump,null,AVAILABLE,@Spark}
2018-09-18 14:00:03,878   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@e98770d{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-09-18 14:00:03,883   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@1ae67cad{/static,null,AVAILABLE,@Spark}
2018-09-18 14:00:03,883   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@2f6e28bc{/,null,AVAILABLE,@Spark}
2018-09-18 14:00:03,884   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@7c098bb3{/api,null,AVAILABLE,@Spark}
2018-09-18 14:00:03,884   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@31e4bb20{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-09-18 14:00:03,884   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@18cebaa5{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-09-18 14:00:03,896   INFO --- [main]  org.spark_project.jetty.server.ServerConnector(line:266) : Started Spark@1021f6c9{HTTP/1.1}{0.0.0.0:4040}
2018-09-18 14:00:03,896   INFO --- [main]  org.spark_project.jetty.server.Server(line:379) : Started @1861ms
2018-09-18 14:00:03,897   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'SparkUI' on port 4040.
2018-09-18 14:00:03,899   INFO --- [main]  org.apache.spark.ui.SparkUI(line:54) : Bound SparkUI to 0.0.0.0, and started at http://192.168.3.199:4040
2018-09-18 14:00:03,971   INFO --- [main]  org.apache.spark.executor.Executor(line:54) : Starting executor ID driver on host localhost
2018-09-18 14:00:04,012   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 53999.
2018-09-18 14:00:04,013   INFO --- [main]  org.apache.spark.network.netty.NettyBlockTransferService(line:54) : Server created on 192.168.3.199:53999
2018-09-18 14:00:04,014   INFO --- [main]  org.apache.spark.storage.BlockManager(line:54) : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-09-18 14:00:04,016   INFO --- [main]  org.apache.spark.storage.BlockManagerMaster(line:54) : Registering BlockManager BlockManagerId(driver, 192.168.3.199, 53999, None)
2018-09-18 14:00:04,017   INFO --- [dispatcher-event-loop-3]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : Registering block manager 192.168.3.199:53999 with 3.0 GB RAM, BlockManagerId(driver, 192.168.3.199, 53999, None)
2018-09-18 14:00:04,019   INFO --- [main]  org.apache.spark.storage.BlockManagerMaster(line:54) : Registered BlockManager BlockManagerId(driver, 192.168.3.199, 53999, None)
2018-09-18 14:00:04,021   INFO --- [main]  org.apache.spark.storage.BlockManager(line:54) : Initialized BlockManager: BlockManagerId(driver, 192.168.3.199, 53999, None)
2018-09-18 14:00:04,182   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@1b9ea3e3{/metrics/json,null,AVAILABLE,@Spark}
2018-09-18 14:00:04,204   WARN --- [main]  org.apache.spark.SparkContext(line:66) : Using an existing SparkContext; some configuration may not take effect.
2018-09-18 14:00:04,244   INFO --- [main]  org.apache.spark.sql.internal.SharedState(line:54) : Warehouse path is 'file:/C:/Users/wshs/IdeaProjects/logdataSession/spark-warehouse/'.
2018-09-18 14:00:04,251   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@5be82d43{/SQL,null,AVAILABLE,@Spark}
2018-09-18 14:00:04,251   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@345e5a17{/SQL/json,null,AVAILABLE,@Spark}
2018-09-18 14:00:04,252   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@77b7ffa4{/SQL/execution,null,AVAILABLE,@Spark}
2018-09-18 14:00:04,252   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@402f80f5{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-09-18 14:00:04,253   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@2102a4d5{/static/sql,null,AVAILABLE,@Spark}
2018-09-18 14:00:04,667   INFO --- [main]  org.apache.spark.storage.memory.MemoryStore(line:54) : Block broadcast_0 stored as values in memory (estimated size 127.1 KB, free 3.0 GB)
2018-09-18 14:00:05,230   INFO --- [main]  org.apache.spark.storage.memory.MemoryStore(line:54) : Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.3 KB, free 3.0 GB)
2018-09-18 14:00:05,234   INFO --- [dispatcher-event-loop-0]  org.apache.spark.storage.BlockManagerInfo(line:54) : Added broadcast_0_piece0 in memory on 192.168.3.199:53999 (size: 14.3 KB, free: 3.0 GB)
2018-09-18 14:00:05,239   INFO --- [main]  org.apache.spark.SparkContext(line:54) : Created broadcast 0 from textFile at logSession.scala:25
2018-09-18 14:00:06,995   INFO --- [main]  org.apache.spark.sql.execution.SparkSqlParser(line:54) : Parsing command: actionopvidio
2018-09-18 14:00:07,208   INFO --- [main]  org.apache.spark.sql.execution.SparkSqlParser(line:54) : Parsing command: SELECT count(*) FROM actionopvidio
2018-09-18 14:00:07,681   INFO --- [Spark Context Cleaner]  org.apache.spark.ContextCleaner(line:54) : Cleaned accumulator 0
2018-09-18 14:00:07,715   INFO --- [main]  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator(line:54) : Code generated in 227.323451 ms
2018-09-18 14:00:07,825   INFO --- [main]  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator(line:54) : Code generated in 10.774519 ms
2018-09-18 14:00:07,881   INFO --- [main]  org.apache.hadoop.mapred.FileInputFormat(line:253) : Total input paths to process : 1
2018-09-18 14:00:07,906   INFO --- [main]  org.apache.spark.SparkContext(line:54) : Starting job: show at logSession.scala:31
2018-09-18 14:00:07,922   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Registering RDD 8 (show at logSession.scala:31)
2018-09-18 14:00:07,924   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Got job 0 (show at logSession.scala:31) with 1 output partitions
2018-09-18 14:00:07,924   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Final stage: ResultStage 1 (show at logSession.scala:31)
2018-09-18 14:00:07,924   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Parents of final stage: List(ShuffleMapStage 0)
2018-09-18 14:00:07,925   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Missing parents: List(ShuffleMapStage 0)
2018-09-18 14:00:07,930   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Submitting ShuffleMapStage 0 (MapPartitionsRDD[8] at show at logSession.scala:31), which has no missing parents
2018-09-18 14:00:07,971   INFO --- [dag-scheduler-event-loop]  org.apache.spark.storage.memory.MemoryStore(line:54) : Block broadcast_1 stored as values in memory (estimated size 11.2 KB, free 3.0 GB)
2018-09-18 14:00:07,974   INFO --- [dag-scheduler-event-loop]  org.apache.spark.storage.memory.MemoryStore(line:54) : Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.7 KB, free 3.0 GB)
2018-09-18 14:00:07,975   INFO --- [dispatcher-event-loop-5]  org.apache.spark.storage.BlockManagerInfo(line:54) : Added broadcast_1_piece0 in memory on 192.168.3.199:53999 (size: 5.7 KB, free: 3.0 GB)
2018-09-18 14:00:07,975   INFO --- [dag-scheduler-event-loop]  org.apache.spark.SparkContext(line:54) : Created broadcast 1 from broadcast at DAGScheduler.scala:996
2018-09-18 14:00:07,978   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Submitting 2 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[8] at show at logSession.scala:31)
2018-09-18 14:00:07,979   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.TaskSchedulerImpl(line:54) : Adding task set 0.0 with 2 tasks
2018-09-18 14:00:08,015   INFO --- [dispatcher-event-loop-6]  org.apache.spark.scheduler.TaskSetManager(line:54) : Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 5910 bytes)
2018-09-18 14:00:08,018   INFO --- [dispatcher-event-loop-6]  org.apache.spark.scheduler.TaskSetManager(line:54) : Starting task 1.0 in stage 0.0 (TID 1, localhost, executor driver, partition 1, PROCESS_LOCAL, 5910 bytes)
2018-09-18 14:00:08,025   INFO --- [Executor task launch worker for task 1]  org.apache.spark.executor.Executor(line:54) : Running task 1.0 in stage 0.0 (TID 1)
2018-09-18 14:00:08,025   INFO --- [Executor task launch worker for task 0]  org.apache.spark.executor.Executor(line:54) : Running task 0.0 in stage 0.0 (TID 0)
2018-09-18 14:00:08,066   INFO --- [Executor task launch worker for task 0]  org.apache.spark.rdd.HadoopRDD(line:54) : Input split: file:/e:/r_actionopvidio.txt:0+188363
2018-09-18 14:00:08,066   INFO --- [Executor task launch worker for task 1]  org.apache.spark.rdd.HadoopRDD(line:54) : Input split: file:/e:/r_actionopvidio.txt:188363+188364
2018-09-18 14:00:08,073   INFO --- [Executor task launch worker for task 1]  org.apache.hadoop.conf.Configuration.deprecation(line:840) : mapred.tip.id is deprecated. Instead, use mapreduce.task.id
2018-09-18 14:00:08,073   INFO --- [Executor task launch worker for task 0]  org.apache.hadoop.conf.Configuration.deprecation(line:840) : mapred.tip.id is deprecated. Instead, use mapreduce.task.id
2018-09-18 14:00:08,073   INFO --- [Executor task launch worker for task 1]  org.apache.hadoop.conf.Configuration.deprecation(line:840) : mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
2018-09-18 14:00:08,073   INFO --- [Executor task launch worker for task 1]  org.apache.hadoop.conf.Configuration.deprecation(line:840) : mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
2018-09-18 14:00:08,073   INFO --- [Executor task launch worker for task 0]  org.apache.hadoop.conf.Configuration.deprecation(line:840) : mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
2018-09-18 14:00:08,073   INFO --- [Executor task launch worker for task 1]  org.apache.hadoop.conf.Configuration.deprecation(line:840) : mapred.job.id is deprecated. Instead, use mapreduce.job.id
2018-09-18 14:00:08,234   INFO --- [Executor task launch worker for task 0]  org.apache.spark.executor.Executor(line:54) : Finished task 0.0 in stage 0.0 (TID 0). 1880 bytes result sent to driver
2018-09-18 14:00:08,234   INFO --- [Executor task launch worker for task 1]  org.apache.spark.executor.Executor(line:54) : Finished task 1.0 in stage 0.0 (TID 1). 2057 bytes result sent to driver
2018-09-18 14:00:08,243   INFO --- [task-result-getter-1]  org.apache.spark.scheduler.TaskSetManager(line:54) : Finished task 1.0 in stage 0.0 (TID 1) in 224 ms on localhost (executor driver) (1/2)
2018-09-18 14:00:08,243   INFO --- [task-result-getter-0]  org.apache.spark.scheduler.TaskSetManager(line:54) : Finished task 0.0 in stage 0.0 (TID 0) in 248 ms on localhost (executor driver) (2/2)
2018-09-18 14:00:08,245   INFO --- [task-result-getter-0]  org.apache.spark.scheduler.TaskSchedulerImpl(line:54) : Removed TaskSet 0.0, whose tasks have all completed, from pool 
2018-09-18 14:00:08,248   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : ShuffleMapStage 0 (show at logSession.scala:31) finished in 0.260 s
2018-09-18 14:00:08,249   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : looking for newly runnable stages
2018-09-18 14:00:08,249   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : running: Set()
2018-09-18 14:00:08,249   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : waiting: Set(ResultStage 1)
2018-09-18 14:00:08,250   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : failed: Set()
2018-09-18 14:00:08,253   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Submitting ResultStage 1 (MapPartitionsRDD[11] at show at logSession.scala:31), which has no missing parents
2018-09-18 14:00:08,260   INFO --- [dag-scheduler-event-loop]  org.apache.spark.storage.memory.MemoryStore(line:54) : Block broadcast_2 stored as values in memory (estimated size 6.9 KB, free 3.0 GB)
2018-09-18 14:00:08,262   INFO --- [dag-scheduler-event-loop]  org.apache.spark.storage.memory.MemoryStore(line:54) : Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.7 KB, free 3.0 GB)
2018-09-18 14:00:08,264   INFO --- [dispatcher-event-loop-4]  org.apache.spark.storage.BlockManagerInfo(line:54) : Added broadcast_2_piece0 in memory on 192.168.3.199:53999 (size: 3.7 KB, free: 3.0 GB)
2018-09-18 14:00:08,265   INFO --- [dag-scheduler-event-loop]  org.apache.spark.SparkContext(line:54) : Created broadcast 2 from broadcast at DAGScheduler.scala:996
2018-09-18 14:00:08,266   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[11] at show at logSession.scala:31)
2018-09-18 14:00:08,266   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.TaskSchedulerImpl(line:54) : Adding task set 1.0 with 1 tasks
2018-09-18 14:00:08,271   INFO --- [dispatcher-event-loop-0]  org.apache.spark.scheduler.TaskSetManager(line:54) : Starting task 0.0 in stage 1.0 (TID 2, localhost, executor driver, partition 0, ANY, 5800 bytes)
2018-09-18 14:00:08,271   INFO --- [Executor task launch worker for task 2]  org.apache.spark.executor.Executor(line:54) : Running task 0.0 in stage 1.0 (TID 2)
2018-09-18 14:00:08,282   INFO --- [Executor task launch worker for task 2]  org.apache.spark.storage.ShuffleBlockFetcherIterator(line:54) : Getting 2 non-empty blocks out of 2 blocks
2018-09-18 14:00:08,284   INFO --- [Executor task launch worker for task 2]  org.apache.spark.storage.ShuffleBlockFetcherIterator(line:54) : Started 0 remote fetches in 4 ms
2018-09-18 14:00:08,326   INFO --- [Executor task launch worker for task 2]  org.apache.spark.executor.Executor(line:54) : Finished task 0.0 in stage 1.0 (TID 2). 1928 bytes result sent to driver
2018-09-18 14:00:08,329   INFO --- [task-result-getter-2]  org.apache.spark.scheduler.TaskSetManager(line:54) : Finished task 0.0 in stage 1.0 (TID 2) in 60 ms on localhost (executor driver) (1/1)
2018-09-18 14:00:08,330   INFO --- [task-result-getter-2]  org.apache.spark.scheduler.TaskSchedulerImpl(line:54) : Removed TaskSet 1.0, whose tasks have all completed, from pool 
2018-09-18 14:00:08,330   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : ResultStage 1 (show at logSession.scala:31) finished in 0.062 s
2018-09-18 14:00:08,343   INFO --- [main]  org.apache.spark.scheduler.DAGScheduler(line:54) : Job 0 finished: show at logSession.scala:31, took 0.436971 s
2018-09-18 14:00:08,359   INFO --- [main]  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator(line:54) : Code generated in 7.305604 ms
2018-09-18 14:00:08,376   INFO --- [main]  org.spark_project.jetty.server.ServerConnector(line:306) : Stopped Spark@1021f6c9{HTTP/1.1}{0.0.0.0:4040}
2018-09-18 14:00:08,378   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@18cebaa5{/stages/stage/kill,null,UNAVAILABLE,@Spark}
2018-09-18 14:00:08,378   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@31e4bb20{/jobs/job/kill,null,UNAVAILABLE,@Spark}
2018-09-18 14:00:08,378   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@7c098bb3{/api,null,UNAVAILABLE,@Spark}
2018-09-18 14:00:08,379   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@2f6e28bc{/,null,UNAVAILABLE,@Spark}
2018-09-18 14:00:08,379   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@1ae67cad{/static,null,UNAVAILABLE,@Spark}
2018-09-18 14:00:08,379   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@e98770d{/executors/threadDump/json,null,UNAVAILABLE,@Spark}
2018-09-18 14:00:08,379   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@4ba302e0{/executors/threadDump,null,UNAVAILABLE,@Spark}
2018-09-18 14:00:08,379   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@57ac5227{/executors/json,null,UNAVAILABLE,@Spark}
2018-09-18 14:00:08,379   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@43aaf813{/executors,null,UNAVAILABLE,@Spark}
2018-09-18 14:00:08,380   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@33aeca0b{/environment/json,null,UNAVAILABLE,@Spark}
2018-09-18 14:00:08,380   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@5c18016b{/environment,null,UNAVAILABLE,@Spark}
2018-09-18 14:00:08,380   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@1951b871{/storage/rdd/json,null,UNAVAILABLE,@Spark}
2018-09-18 14:00:08,380   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@793138bd{/storage/rdd,null,UNAVAILABLE,@Spark}
2018-09-18 14:00:08,380   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@5d1659ea{/storage/json,null,UNAVAILABLE,@Spark}
2018-09-18 14:00:08,380   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@25bc0606{/storage,null,UNAVAILABLE,@Spark}
2018-09-18 14:00:08,380   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@3d3ba765{/stages/pool/json,null,UNAVAILABLE,@Spark}
2018-09-18 14:00:08,381   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@784b990c{/stages/pool,null,UNAVAILABLE,@Spark}
2018-09-18 14:00:08,381   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@3c989952{/stages/stage/json,null,UNAVAILABLE,@Spark}
2018-09-18 14:00:08,381   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@3e14c16d{/stages/stage,null,UNAVAILABLE,@Spark}
2018-09-18 14:00:08,381   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@7096b474{/stages/json,null,UNAVAILABLE,@Spark}
2018-09-18 14:00:08,381   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@4bd1f8dd{/stages,null,UNAVAILABLE,@Spark}
2018-09-18 14:00:08,381   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@3f07b12c{/jobs/job/json,null,UNAVAILABLE,@Spark}
2018-09-18 14:00:08,381   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@6475472c{/jobs/job,null,UNAVAILABLE,@Spark}
2018-09-18 14:00:08,382   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@4b7e96a{/jobs/json,null,UNAVAILABLE,@Spark}
2018-09-18 14:00:08,382   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@5c8504fd{/jobs,null,UNAVAILABLE,@Spark}
2018-09-18 14:00:08,383   INFO --- [main]  org.apache.spark.ui.SparkUI(line:54) : Stopped Spark web UI at http://192.168.3.199:4040
2018-09-18 14:00:08,392   INFO --- [dispatcher-event-loop-3]  org.apache.spark.MapOutputTrackerMasterEndpoint(line:54) : MapOutputTrackerMasterEndpoint stopped!
2018-09-18 14:00:08,449   INFO --- [main]  org.apache.spark.storage.memory.MemoryStore(line:54) : MemoryStore cleared
2018-09-18 14:00:08,450   INFO --- [main]  org.apache.spark.storage.BlockManager(line:54) : BlockManager stopped
2018-09-18 14:00:08,454   INFO --- [main]  org.apache.spark.storage.BlockManagerMaster(line:54) : BlockManagerMaster stopped
2018-09-18 14:00:08,456   INFO --- [dispatcher-event-loop-6]  org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint(line:54) : OutputCommitCoordinator stopped!
2018-09-18 14:00:08,461   INFO --- [main]  org.apache.spark.SparkContext(line:54) : Successfully stopped SparkContext
2018-09-18 14:00:08,464   INFO --- [Thread-1]  org.apache.spark.util.ShutdownHookManager(line:54) : Shutdown hook called
2018-09-18 14:00:08,465   INFO --- [Thread-1]  org.apache.spark.util.ShutdownHookManager(line:54) : Deleting directory C:\Users\wshs\AppData\Local\Temp\spark-aba150bd-bc29-4471-829b-65467f594429
2018-09-18 14:01:35,304   INFO --- [main]  org.apache.spark.SparkContext(line:54) : Running Spark version 2.1.1
2018-09-18 14:01:35,651   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing view acls to: wshs
2018-09-18 14:01:35,652   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing modify acls to: wshs
2018-09-18 14:01:35,652   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing view acls groups to: 
2018-09-18 14:01:35,653   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing modify acls groups to: 
2018-09-18 14:01:35,655   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(wshs); groups with view permissions: Set(); users  with modify permissions: Set(wshs); groups with modify permissions: Set()
2018-09-18 14:01:36,175   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'sparkDriver' on port 54121.
2018-09-18 14:01:36,194   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering MapOutputTracker
2018-09-18 14:01:36,211   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering BlockManagerMaster
2018-09-18 14:01:36,214   INFO --- [main]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-09-18 14:01:36,215   INFO --- [main]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : BlockManagerMasterEndpoint up
2018-09-18 14:01:36,228   INFO --- [main]  org.apache.spark.storage.DiskBlockManager(line:54) : Created local directory at C:\Users\wshs\AppData\Local\Temp\blockmgr-bc2e1c42-2392-462a-8bfc-fa3c6cf7bf0f
2018-09-18 14:01:36,245   INFO --- [main]  org.apache.spark.storage.memory.MemoryStore(line:54) : MemoryStore started with capacity 3.0 GB
2018-09-18 14:01:36,312   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering OutputCommitCoordinator
2018-09-18 14:01:36,385   INFO --- [main]  org.spark_project.jetty.util.log(line:186) : Logging initialized @2006ms
2018-09-18 14:01:36,459   INFO --- [main]  org.spark_project.jetty.server.Server(line:327) : jetty-9.2.z-SNAPSHOT
2018-09-18 14:01:36,472   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@5c8504fd{/jobs,null,AVAILABLE,@Spark}
2018-09-18 14:01:36,472   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@4b7e96a{/jobs/json,null,AVAILABLE,@Spark}
2018-09-18 14:01:36,472   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@6475472c{/jobs/job,null,AVAILABLE,@Spark}
2018-09-18 14:01:36,472   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@3f07b12c{/jobs/job/json,null,AVAILABLE,@Spark}
2018-09-18 14:01:36,473   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@4bd1f8dd{/stages,null,AVAILABLE,@Spark}
2018-09-18 14:01:36,473   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@7096b474{/stages/json,null,AVAILABLE,@Spark}
2018-09-18 14:01:36,473   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@3e14c16d{/stages/stage,null,AVAILABLE,@Spark}
2018-09-18 14:01:36,474   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@3c989952{/stages/stage/json,null,AVAILABLE,@Spark}
2018-09-18 14:01:36,474   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@784b990c{/stages/pool,null,AVAILABLE,@Spark}
2018-09-18 14:01:36,474   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@3d3ba765{/stages/pool/json,null,AVAILABLE,@Spark}
2018-09-18 14:01:36,474   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@25bc0606{/storage,null,AVAILABLE,@Spark}
2018-09-18 14:01:36,474   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@5d1659ea{/storage/json,null,AVAILABLE,@Spark}
2018-09-18 14:01:36,475   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@793138bd{/storage/rdd,null,AVAILABLE,@Spark}
2018-09-18 14:01:36,475   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@1951b871{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-09-18 14:01:36,475   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@5c18016b{/environment,null,AVAILABLE,@Spark}
2018-09-18 14:01:36,475   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@33aeca0b{/environment/json,null,AVAILABLE,@Spark}
2018-09-18 14:01:36,476   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@43aaf813{/executors,null,AVAILABLE,@Spark}
2018-09-18 14:01:36,476   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@57ac5227{/executors/json,null,AVAILABLE,@Spark}
2018-09-18 14:01:36,476   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@4ba302e0{/executors/threadDump,null,AVAILABLE,@Spark}
2018-09-18 14:01:36,476   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@e98770d{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-09-18 14:01:36,481   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@1ae67cad{/static,null,AVAILABLE,@Spark}
2018-09-18 14:01:36,482   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@2f6e28bc{/,null,AVAILABLE,@Spark}
2018-09-18 14:01:36,482   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@7c098bb3{/api,null,AVAILABLE,@Spark}
2018-09-18 14:01:36,482   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@31e4bb20{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-09-18 14:01:36,483   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@18cebaa5{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-09-18 14:01:36,496   INFO --- [main]  org.spark_project.jetty.server.ServerConnector(line:266) : Started Spark@1021f6c9{HTTP/1.1}{0.0.0.0:4040}
2018-09-18 14:01:36,496   INFO --- [main]  org.spark_project.jetty.server.Server(line:379) : Started @2119ms
2018-09-18 14:01:36,497   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'SparkUI' on port 4040.
2018-09-18 14:01:36,500   INFO --- [main]  org.apache.spark.ui.SparkUI(line:54) : Bound SparkUI to 0.0.0.0, and started at http://192.168.3.199:4040
2018-09-18 14:01:36,568   INFO --- [main]  org.apache.spark.executor.Executor(line:54) : Starting executor ID driver on host localhost
2018-09-18 14:01:36,615   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 54162.
2018-09-18 14:01:36,616   INFO --- [main]  org.apache.spark.network.netty.NettyBlockTransferService(line:54) : Server created on 192.168.3.199:54162
2018-09-18 14:01:36,617   INFO --- [main]  org.apache.spark.storage.BlockManager(line:54) : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-09-18 14:01:36,619   INFO --- [main]  org.apache.spark.storage.BlockManagerMaster(line:54) : Registering BlockManager BlockManagerId(driver, 192.168.3.199, 54162, None)
2018-09-18 14:01:36,622   INFO --- [dispatcher-event-loop-3]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : Registering block manager 192.168.3.199:54162 with 3.0 GB RAM, BlockManagerId(driver, 192.168.3.199, 54162, None)
2018-09-18 14:01:36,624   INFO --- [main]  org.apache.spark.storage.BlockManagerMaster(line:54) : Registered BlockManager BlockManagerId(driver, 192.168.3.199, 54162, None)
2018-09-18 14:01:36,625   INFO --- [main]  org.apache.spark.storage.BlockManager(line:54) : Initialized BlockManager: BlockManagerId(driver, 192.168.3.199, 54162, None)
2018-09-18 14:01:36,775   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@1b9ea3e3{/metrics/json,null,AVAILABLE,@Spark}
2018-09-18 14:01:36,792   WARN --- [main]  org.apache.spark.SparkContext(line:66) : Using an existing SparkContext; some configuration may not take effect.
2018-09-18 14:01:36,825   INFO --- [main]  org.apache.spark.sql.internal.SharedState(line:54) : Warehouse path is 'file:/C:/Users/wshs/IdeaProjects/logdataSession/spark-warehouse/'.
2018-09-18 14:01:36,832   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@345e5a17{/SQL,null,AVAILABLE,@Spark}
2018-09-18 14:01:36,833   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@443dbe42{/SQL/json,null,AVAILABLE,@Spark}
2018-09-18 14:01:36,833   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@402f80f5{/SQL/execution,null,AVAILABLE,@Spark}
2018-09-18 14:01:36,834   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@133e019b{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-09-18 14:01:36,835   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@3d4d3fe7{/static/sql,null,AVAILABLE,@Spark}
2018-09-18 14:01:37,229   INFO --- [main]  org.apache.spark.storage.memory.MemoryStore(line:54) : Block broadcast_0 stored as values in memory (estimated size 127.1 KB, free 3.0 GB)
2018-09-18 14:01:37,794   INFO --- [main]  org.apache.spark.storage.memory.MemoryStore(line:54) : Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.3 KB, free 3.0 GB)
2018-09-18 14:01:37,798   INFO --- [dispatcher-event-loop-4]  org.apache.spark.storage.BlockManagerInfo(line:54) : Added broadcast_0_piece0 in memory on 192.168.3.199:54162 (size: 14.3 KB, free: 3.0 GB)
2018-09-18 14:01:37,802   INFO --- [main]  org.apache.spark.SparkContext(line:54) : Created broadcast 0 from textFile at logSession.scala:25
2018-09-18 14:01:39,572   INFO --- [main]  org.apache.spark.sql.execution.SparkSqlParser(line:54) : Parsing command: actionopvidio
2018-09-18 14:01:39,788   INFO --- [main]  org.apache.spark.sql.execution.SparkSqlParser(line:54) : Parsing command: SELECT count(1) FROM actionopvidio
2018-09-18 14:01:40,265   INFO --- [main]  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator(line:54) : Code generated in 198.710087 ms
2018-09-18 14:01:40,371   INFO --- [Spark Context Cleaner]  org.apache.spark.ContextCleaner(line:54) : Cleaned accumulator 0
2018-09-18 14:01:40,382   INFO --- [main]  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator(line:54) : Code generated in 12.101991 ms
2018-09-18 14:01:40,439   INFO --- [main]  org.apache.hadoop.mapred.FileInputFormat(line:253) : Total input paths to process : 1
2018-09-18 14:01:40,459   INFO --- [main]  org.apache.spark.SparkContext(line:54) : Starting job: show at logSession.scala:31
2018-09-18 14:01:40,474   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Registering RDD 8 (show at logSession.scala:31)
2018-09-18 14:01:40,476   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Got job 0 (show at logSession.scala:31) with 1 output partitions
2018-09-18 14:01:40,477   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Final stage: ResultStage 1 (show at logSession.scala:31)
2018-09-18 14:01:40,478   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Parents of final stage: List(ShuffleMapStage 0)
2018-09-18 14:01:40,479   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Missing parents: List(ShuffleMapStage 0)
2018-09-18 14:01:40,484   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Submitting ShuffleMapStage 0 (MapPartitionsRDD[8] at show at logSession.scala:31), which has no missing parents
2018-09-18 14:01:40,522   INFO --- [dag-scheduler-event-loop]  org.apache.spark.storage.memory.MemoryStore(line:54) : Block broadcast_1 stored as values in memory (estimated size 11.2 KB, free 3.0 GB)
2018-09-18 14:01:40,526   INFO --- [dag-scheduler-event-loop]  org.apache.spark.storage.memory.MemoryStore(line:54) : Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.7 KB, free 3.0 GB)
2018-09-18 14:01:40,527   INFO --- [dispatcher-event-loop-5]  org.apache.spark.storage.BlockManagerInfo(line:54) : Added broadcast_1_piece0 in memory on 192.168.3.199:54162 (size: 5.7 KB, free: 3.0 GB)
2018-09-18 14:01:40,527   INFO --- [dag-scheduler-event-loop]  org.apache.spark.SparkContext(line:54) : Created broadcast 1 from broadcast at DAGScheduler.scala:996
2018-09-18 14:01:40,530   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Submitting 2 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[8] at show at logSession.scala:31)
2018-09-18 14:01:40,532   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.TaskSchedulerImpl(line:54) : Adding task set 0.0 with 2 tasks
2018-09-18 14:01:40,568   INFO --- [dispatcher-event-loop-6]  org.apache.spark.scheduler.TaskSetManager(line:54) : Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 5910 bytes)
2018-09-18 14:01:40,571   INFO --- [dispatcher-event-loop-6]  org.apache.spark.scheduler.TaskSetManager(line:54) : Starting task 1.0 in stage 0.0 (TID 1, localhost, executor driver, partition 1, PROCESS_LOCAL, 5910 bytes)
2018-09-18 14:01:40,578   INFO --- [Executor task launch worker for task 1]  org.apache.spark.executor.Executor(line:54) : Running task 1.0 in stage 0.0 (TID 1)
2018-09-18 14:01:40,578   INFO --- [Executor task launch worker for task 0]  org.apache.spark.executor.Executor(line:54) : Running task 0.0 in stage 0.0 (TID 0)
2018-09-18 14:01:40,615   INFO --- [Executor task launch worker for task 0]  org.apache.spark.rdd.HadoopRDD(line:54) : Input split: file:/e:/r_actionopvidio.txt:0+188363
2018-09-18 14:01:40,615   INFO --- [Executor task launch worker for task 1]  org.apache.spark.rdd.HadoopRDD(line:54) : Input split: file:/e:/r_actionopvidio.txt:188363+188364
2018-09-18 14:01:40,622   INFO --- [Executor task launch worker for task 0]  org.apache.hadoop.conf.Configuration.deprecation(line:840) : mapred.tip.id is deprecated. Instead, use mapreduce.task.id
2018-09-18 14:01:40,622   INFO --- [Executor task launch worker for task 1]  org.apache.hadoop.conf.Configuration.deprecation(line:840) : mapred.tip.id is deprecated. Instead, use mapreduce.task.id
2018-09-18 14:01:40,623   INFO --- [Executor task launch worker for task 0]  org.apache.hadoop.conf.Configuration.deprecation(line:840) : mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
2018-09-18 14:01:40,623   INFO --- [Executor task launch worker for task 1]  org.apache.hadoop.conf.Configuration.deprecation(line:840) : mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
2018-09-18 14:01:40,623   INFO --- [Executor task launch worker for task 0]  org.apache.hadoop.conf.Configuration.deprecation(line:840) : mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
2018-09-18 14:01:40,623   INFO --- [Executor task launch worker for task 1]  org.apache.hadoop.conf.Configuration.deprecation(line:840) : mapred.job.id is deprecated. Instead, use mapreduce.job.id
2018-09-18 14:01:40,770   INFO --- [Executor task launch worker for task 1]  org.apache.spark.executor.Executor(line:54) : Finished task 1.0 in stage 0.0 (TID 1). 2057 bytes result sent to driver
2018-09-18 14:01:40,770   INFO --- [Executor task launch worker for task 0]  org.apache.spark.executor.Executor(line:54) : Finished task 0.0 in stage 0.0 (TID 0). 1880 bytes result sent to driver
2018-09-18 14:01:40,778   INFO --- [task-result-getter-1]  org.apache.spark.scheduler.TaskSetManager(line:54) : Finished task 0.0 in stage 0.0 (TID 0) in 229 ms on localhost (executor driver) (1/2)
2018-09-18 14:01:40,778   INFO --- [task-result-getter-0]  org.apache.spark.scheduler.TaskSetManager(line:54) : Finished task 1.0 in stage 0.0 (TID 1) in 209 ms on localhost (executor driver) (2/2)
2018-09-18 14:01:40,779   INFO --- [task-result-getter-0]  org.apache.spark.scheduler.TaskSchedulerImpl(line:54) : Removed TaskSet 0.0, whose tasks have all completed, from pool 
2018-09-18 14:01:40,783   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : ShuffleMapStage 0 (show at logSession.scala:31) finished in 0.243 s
2018-09-18 14:01:40,783   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : looking for newly runnable stages
2018-09-18 14:01:40,784   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : running: Set()
2018-09-18 14:01:40,784   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : waiting: Set(ResultStage 1)
2018-09-18 14:01:40,785   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : failed: Set()
2018-09-18 14:01:40,788   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Submitting ResultStage 1 (MapPartitionsRDD[11] at show at logSession.scala:31), which has no missing parents
2018-09-18 14:01:40,793   INFO --- [dag-scheduler-event-loop]  org.apache.spark.storage.memory.MemoryStore(line:54) : Block broadcast_2 stored as values in memory (estimated size 6.9 KB, free 3.0 GB)
2018-09-18 14:01:40,795   INFO --- [dag-scheduler-event-loop]  org.apache.spark.storage.memory.MemoryStore(line:54) : Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.7 KB, free 3.0 GB)
2018-09-18 14:01:40,797   INFO --- [dispatcher-event-loop-1]  org.apache.spark.storage.BlockManagerInfo(line:54) : Added broadcast_2_piece0 in memory on 192.168.3.199:54162 (size: 3.7 KB, free: 3.0 GB)
2018-09-18 14:01:40,798   INFO --- [dag-scheduler-event-loop]  org.apache.spark.SparkContext(line:54) : Created broadcast 2 from broadcast at DAGScheduler.scala:996
2018-09-18 14:01:40,799   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[11] at show at logSession.scala:31)
2018-09-18 14:01:40,799   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.TaskSchedulerImpl(line:54) : Adding task set 1.0 with 1 tasks
2018-09-18 14:01:40,803   INFO --- [dispatcher-event-loop-4]  org.apache.spark.scheduler.TaskSetManager(line:54) : Starting task 0.0 in stage 1.0 (TID 2, localhost, executor driver, partition 0, ANY, 5800 bytes)
2018-09-18 14:01:40,803   INFO --- [Executor task launch worker for task 2]  org.apache.spark.executor.Executor(line:54) : Running task 0.0 in stage 1.0 (TID 2)
2018-09-18 14:01:40,816   INFO --- [Executor task launch worker for task 2]  org.apache.spark.storage.ShuffleBlockFetcherIterator(line:54) : Getting 2 non-empty blocks out of 2 blocks
2018-09-18 14:01:40,818   INFO --- [Executor task launch worker for task 2]  org.apache.spark.storage.ShuffleBlockFetcherIterator(line:54) : Started 0 remote fetches in 5 ms
2018-09-18 14:01:40,830   INFO --- [Executor task launch worker for task 2]  org.apache.spark.executor.Executor(line:54) : Finished task 0.0 in stage 1.0 (TID 2). 1928 bytes result sent to driver
2018-09-18 14:01:40,831   INFO --- [task-result-getter-2]  org.apache.spark.scheduler.TaskSetManager(line:54) : Finished task 0.0 in stage 1.0 (TID 2) in 30 ms on localhost (executor driver) (1/1)
2018-09-18 14:01:40,832   INFO --- [task-result-getter-2]  org.apache.spark.scheduler.TaskSchedulerImpl(line:54) : Removed TaskSet 1.0, whose tasks have all completed, from pool 
2018-09-18 14:01:40,832   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : ResultStage 1 (show at logSession.scala:31) finished in 0.031 s
2018-09-18 14:01:40,837   INFO --- [main]  org.apache.spark.scheduler.DAGScheduler(line:54) : Job 0 finished: show at logSession.scala:31, took 0.377687 s
2018-09-18 14:01:40,854   INFO --- [main]  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator(line:54) : Code generated in 6.596197 ms
2018-09-18 14:01:40,871   INFO --- [main]  org.spark_project.jetty.server.ServerConnector(line:306) : Stopped Spark@1021f6c9{HTTP/1.1}{0.0.0.0:4040}
2018-09-18 14:01:40,872   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@18cebaa5{/stages/stage/kill,null,UNAVAILABLE,@Spark}
2018-09-18 14:01:40,873   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@31e4bb20{/jobs/job/kill,null,UNAVAILABLE,@Spark}
2018-09-18 14:01:40,873   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@7c098bb3{/api,null,UNAVAILABLE,@Spark}
2018-09-18 14:01:40,873   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@2f6e28bc{/,null,UNAVAILABLE,@Spark}
2018-09-18 14:01:40,873   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@1ae67cad{/static,null,UNAVAILABLE,@Spark}
2018-09-18 14:01:40,874   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@e98770d{/executors/threadDump/json,null,UNAVAILABLE,@Spark}
2018-09-18 14:01:40,874   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@4ba302e0{/executors/threadDump,null,UNAVAILABLE,@Spark}
2018-09-18 14:01:40,874   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@57ac5227{/executors/json,null,UNAVAILABLE,@Spark}
2018-09-18 14:01:40,874   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@43aaf813{/executors,null,UNAVAILABLE,@Spark}
2018-09-18 14:01:40,874   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@33aeca0b{/environment/json,null,UNAVAILABLE,@Spark}
2018-09-18 14:01:40,874   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@5c18016b{/environment,null,UNAVAILABLE,@Spark}
2018-09-18 14:01:40,874   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@1951b871{/storage/rdd/json,null,UNAVAILABLE,@Spark}
2018-09-18 14:01:40,875   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@793138bd{/storage/rdd,null,UNAVAILABLE,@Spark}
2018-09-18 14:01:40,875   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@5d1659ea{/storage/json,null,UNAVAILABLE,@Spark}
2018-09-18 14:01:40,875   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@25bc0606{/storage,null,UNAVAILABLE,@Spark}
2018-09-18 14:01:40,875   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@3d3ba765{/stages/pool/json,null,UNAVAILABLE,@Spark}
2018-09-18 14:01:40,875   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@784b990c{/stages/pool,null,UNAVAILABLE,@Spark}
2018-09-18 14:01:40,875   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@3c989952{/stages/stage/json,null,UNAVAILABLE,@Spark}
2018-09-18 14:01:40,875   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@3e14c16d{/stages/stage,null,UNAVAILABLE,@Spark}
2018-09-18 14:01:40,876   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@7096b474{/stages/json,null,UNAVAILABLE,@Spark}
2018-09-18 14:01:40,876   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@4bd1f8dd{/stages,null,UNAVAILABLE,@Spark}
2018-09-18 14:01:40,876   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@3f07b12c{/jobs/job/json,null,UNAVAILABLE,@Spark}
2018-09-18 14:01:40,876   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@6475472c{/jobs/job,null,UNAVAILABLE,@Spark}
2018-09-18 14:01:40,876   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@4b7e96a{/jobs/json,null,UNAVAILABLE,@Spark}
2018-09-18 14:01:40,876   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@5c8504fd{/jobs,null,UNAVAILABLE,@Spark}
2018-09-18 14:01:40,878   INFO --- [main]  org.apache.spark.ui.SparkUI(line:54) : Stopped Spark web UI at http://192.168.3.199:4040
2018-09-18 14:01:40,886   INFO --- [dispatcher-event-loop-3]  org.apache.spark.MapOutputTrackerMasterEndpoint(line:54) : MapOutputTrackerMasterEndpoint stopped!
2018-09-18 14:01:40,938   INFO --- [main]  org.apache.spark.storage.memory.MemoryStore(line:54) : MemoryStore cleared
2018-09-18 14:01:40,939   INFO --- [main]  org.apache.spark.storage.BlockManager(line:54) : BlockManager stopped
2018-09-18 14:01:40,943   INFO --- [main]  org.apache.spark.storage.BlockManagerMaster(line:54) : BlockManagerMaster stopped
2018-09-18 14:01:40,945   INFO --- [dispatcher-event-loop-6]  org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint(line:54) : OutputCommitCoordinator stopped!
2018-09-18 14:01:40,950   INFO --- [main]  org.apache.spark.SparkContext(line:54) : Successfully stopped SparkContext
2018-09-18 14:01:40,952   INFO --- [Thread-1]  org.apache.spark.util.ShutdownHookManager(line:54) : Shutdown hook called
2018-09-18 14:01:40,953   INFO --- [Thread-1]  org.apache.spark.util.ShutdownHookManager(line:54) : Deleting directory C:\Users\wshs\AppData\Local\Temp\spark-b4672441-a84e-489d-81ba-ad6d5641cbff
2018-09-18 14:09:22,729   INFO --- [main]  org.apache.spark.SparkContext(line:54) : Running Spark version 2.1.1
2018-09-18 14:09:23,065   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing view acls to: wshs
2018-09-18 14:09:23,066   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing modify acls to: wshs
2018-09-18 14:09:23,067   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing view acls groups to: 
2018-09-18 14:09:23,068   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing modify acls groups to: 
2018-09-18 14:09:23,068   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(wshs); groups with view permissions: Set(); users  with modify permissions: Set(wshs); groups with modify permissions: Set()
2018-09-18 14:09:23,708   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'sparkDriver' on port 54947.
2018-09-18 14:09:23,733   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering MapOutputTracker
2018-09-18 14:09:23,755   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering BlockManagerMaster
2018-09-18 14:09:23,759   INFO --- [main]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-09-18 14:09:23,760   INFO --- [main]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : BlockManagerMasterEndpoint up
2018-09-18 14:09:23,778   INFO --- [main]  org.apache.spark.storage.DiskBlockManager(line:54) : Created local directory at C:\Users\wshs\AppData\Local\Temp\blockmgr-be7af316-746e-49cc-81cf-05a5826d8430
2018-09-18 14:09:23,798   INFO --- [main]  org.apache.spark.storage.memory.MemoryStore(line:54) : MemoryStore started with capacity 3.0 GB
2018-09-18 14:09:23,870   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering OutputCommitCoordinator
2018-09-18 14:09:23,967   INFO --- [main]  org.spark_project.jetty.util.log(line:186) : Logging initialized @2151ms
2018-09-18 14:09:24,064   INFO --- [main]  org.spark_project.jetty.server.Server(line:327) : jetty-9.2.z-SNAPSHOT
2018-09-18 14:09:24,077   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@32811494{/jobs,null,AVAILABLE,@Spark}
2018-09-18 14:09:24,078   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@4795ded0{/jobs/json,null,AVAILABLE,@Spark}
2018-09-18 14:09:24,078   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@53dacd14{/jobs/job,null,AVAILABLE,@Spark}
2018-09-18 14:09:24,078   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@14d14731{/jobs/job/json,null,AVAILABLE,@Spark}
2018-09-18 14:09:24,078   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@2eced48b{/stages,null,AVAILABLE,@Spark}
2018-09-18 14:09:24,079   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@47c4ecdc{/stages/json,null,AVAILABLE,@Spark}
2018-09-18 14:09:24,079   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@42f33b5d{/stages/stage,null,AVAILABLE,@Spark}
2018-09-18 14:09:24,079   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@5c8504fd{/stages/stage/json,null,AVAILABLE,@Spark}
2018-09-18 14:09:24,079   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@4b7e96a{/stages/pool,null,AVAILABLE,@Spark}
2018-09-18 14:09:24,080   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@6475472c{/stages/pool/json,null,AVAILABLE,@Spark}
2018-09-18 14:09:24,080   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@3f07b12c{/storage,null,AVAILABLE,@Spark}
2018-09-18 14:09:24,080   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@4bd1f8dd{/storage/json,null,AVAILABLE,@Spark}
2018-09-18 14:09:24,080   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@7096b474{/storage/rdd,null,AVAILABLE,@Spark}
2018-09-18 14:09:24,080   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@3e14c16d{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-09-18 14:09:24,081   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@3c989952{/environment,null,AVAILABLE,@Spark}
2018-09-18 14:09:24,081   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@784b990c{/environment/json,null,AVAILABLE,@Spark}
2018-09-18 14:09:24,081   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@3d3ba765{/executors,null,AVAILABLE,@Spark}
2018-09-18 14:09:24,081   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@25bc0606{/executors/json,null,AVAILABLE,@Spark}
2018-09-18 14:09:24,082   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@5d1659ea{/executors/threadDump,null,AVAILABLE,@Spark}
2018-09-18 14:09:24,082   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@793138bd{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-09-18 14:09:24,086   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@1951b871{/static,null,AVAILABLE,@Spark}
2018-09-18 14:09:24,086   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@5c18016b{/,null,AVAILABLE,@Spark}
2018-09-18 14:09:24,087   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@33aeca0b{/api,null,AVAILABLE,@Spark}
2018-09-18 14:09:24,087   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@43aaf813{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-09-18 14:09:24,087   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@57ac5227{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-09-18 14:09:24,102   INFO --- [main]  org.spark_project.jetty.server.ServerConnector(line:266) : Started Spark@3e10dc6{HTTP/1.1}{0.0.0.0:4040}
2018-09-18 14:09:24,102   INFO --- [main]  org.spark_project.jetty.server.Server(line:379) : Started @2288ms
2018-09-18 14:09:24,103   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'SparkUI' on port 4040.
2018-09-18 14:09:24,106   INFO --- [main]  org.apache.spark.ui.SparkUI(line:54) : Bound SparkUI to 0.0.0.0, and started at http://192.168.3.199:4040
2018-09-18 14:09:24,186   INFO --- [main]  org.apache.spark.executor.Executor(line:54) : Starting executor ID driver on host localhost
2018-09-18 14:09:24,231   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 54990.
2018-09-18 14:09:24,232   INFO --- [main]  org.apache.spark.network.netty.NettyBlockTransferService(line:54) : Server created on 192.168.3.199:54990
2018-09-18 14:09:24,233   INFO --- [main]  org.apache.spark.storage.BlockManager(line:54) : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-09-18 14:09:24,235   INFO --- [main]  org.apache.spark.storage.BlockManagerMaster(line:54) : Registering BlockManager BlockManagerId(driver, 192.168.3.199, 54990, None)
2018-09-18 14:09:24,238   INFO --- [dispatcher-event-loop-2]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : Registering block manager 192.168.3.199:54990 with 3.0 GB RAM, BlockManagerId(driver, 192.168.3.199, 54990, None)
2018-09-18 14:09:24,242   INFO --- [main]  org.apache.spark.storage.BlockManagerMaster(line:54) : Registered BlockManager BlockManagerId(driver, 192.168.3.199, 54990, None)
2018-09-18 14:09:24,242   INFO --- [main]  org.apache.spark.storage.BlockManager(line:54) : Initialized BlockManager: BlockManagerId(driver, 192.168.3.199, 54990, None)
2018-09-18 14:09:24,424   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@42257bdd{/metrics/json,null,AVAILABLE,@Spark}
2018-09-18 14:09:24,444   WARN --- [main]  org.apache.spark.SparkContext(line:66) : Using an existing SparkContext; some configuration may not take effect.
2018-09-18 14:09:24,486   INFO --- [main]  org.apache.spark.sql.internal.SharedState(line:54) : Warehouse path is 'file:/C:/Users/wshs/IdeaProjects/logdataSession/spark-warehouse/'.
2018-09-18 14:09:24,491   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@7544a1e4{/SQL,null,AVAILABLE,@Spark}
2018-09-18 14:09:24,492   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@7957dc72{/SQL/json,null,AVAILABLE,@Spark}
2018-09-18 14:09:24,492   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@5be82d43{/SQL/execution,null,AVAILABLE,@Spark}
2018-09-18 14:09:24,492   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@345e5a17{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-09-18 14:09:24,494   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@5ed190be{/static/sql,null,AVAILABLE,@Spark}
2018-09-18 14:09:24,753   INFO --- [Thread-1]  org.apache.spark.SparkContext(line:54) : Invoking stop() from shutdown hook
2018-09-18 14:09:24,757   INFO --- [Thread-1]  org.spark_project.jetty.server.ServerConnector(line:306) : Stopped Spark@3e10dc6{HTTP/1.1}{0.0.0.0:4040}
2018-09-18 14:09:24,759   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@57ac5227{/stages/stage/kill,null,UNAVAILABLE,@Spark}
2018-09-18 14:09:24,759   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@43aaf813{/jobs/job/kill,null,UNAVAILABLE,@Spark}
2018-09-18 14:09:24,760   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@33aeca0b{/api,null,UNAVAILABLE,@Spark}
2018-09-18 14:09:24,760   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@5c18016b{/,null,UNAVAILABLE,@Spark}
2018-09-18 14:09:24,760   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@1951b871{/static,null,UNAVAILABLE,@Spark}
2018-09-18 14:09:24,760   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@793138bd{/executors/threadDump/json,null,UNAVAILABLE,@Spark}
2018-09-18 14:09:24,760   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@5d1659ea{/executors/threadDump,null,UNAVAILABLE,@Spark}
2018-09-18 14:09:24,761   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@25bc0606{/executors/json,null,UNAVAILABLE,@Spark}
2018-09-18 14:09:24,761   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@3d3ba765{/executors,null,UNAVAILABLE,@Spark}
2018-09-18 14:09:24,761   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@784b990c{/environment/json,null,UNAVAILABLE,@Spark}
2018-09-18 14:09:24,762   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@3c989952{/environment,null,UNAVAILABLE,@Spark}
2018-09-18 14:09:24,762   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@3e14c16d{/storage/rdd/json,null,UNAVAILABLE,@Spark}
2018-09-18 14:09:24,763   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@7096b474{/storage/rdd,null,UNAVAILABLE,@Spark}
2018-09-18 14:09:24,763   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@4bd1f8dd{/storage/json,null,UNAVAILABLE,@Spark}
2018-09-18 14:09:24,763   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@3f07b12c{/storage,null,UNAVAILABLE,@Spark}
2018-09-18 14:09:24,764   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@6475472c{/stages/pool/json,null,UNAVAILABLE,@Spark}
2018-09-18 14:09:24,764   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@4b7e96a{/stages/pool,null,UNAVAILABLE,@Spark}
2018-09-18 14:09:24,764   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@5c8504fd{/stages/stage/json,null,UNAVAILABLE,@Spark}
2018-09-18 14:09:24,764   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@42f33b5d{/stages/stage,null,UNAVAILABLE,@Spark}
2018-09-18 14:09:24,765   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@47c4ecdc{/stages/json,null,UNAVAILABLE,@Spark}
2018-09-18 14:09:24,765   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@2eced48b{/stages,null,UNAVAILABLE,@Spark}
2018-09-18 14:09:24,765   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@14d14731{/jobs/job/json,null,UNAVAILABLE,@Spark}
2018-09-18 14:09:24,765   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@53dacd14{/jobs/job,null,UNAVAILABLE,@Spark}
2018-09-18 14:09:24,765   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@4795ded0{/jobs/json,null,UNAVAILABLE,@Spark}
2018-09-18 14:09:24,765   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@32811494{/jobs,null,UNAVAILABLE,@Spark}
2018-09-18 14:09:24,767   INFO --- [Thread-1]  org.apache.spark.ui.SparkUI(line:54) : Stopped Spark web UI at http://192.168.3.199:4040
2018-09-18 14:09:24,776   INFO --- [dispatcher-event-loop-6]  org.apache.spark.MapOutputTrackerMasterEndpoint(line:54) : MapOutputTrackerMasterEndpoint stopped!
2018-09-18 14:09:24,788   INFO --- [Thread-1]  org.apache.spark.storage.memory.MemoryStore(line:54) : MemoryStore cleared
2018-09-18 14:09:24,789   INFO --- [Thread-1]  org.apache.spark.storage.BlockManager(line:54) : BlockManager stopped
2018-09-18 14:09:24,795   INFO --- [Thread-1]  org.apache.spark.storage.BlockManagerMaster(line:54) : BlockManagerMaster stopped
2018-09-18 14:09:24,800   INFO --- [dispatcher-event-loop-3]  org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint(line:54) : OutputCommitCoordinator stopped!
2018-09-18 14:09:24,806   INFO --- [Thread-1]  org.apache.spark.SparkContext(line:54) : Successfully stopped SparkContext
2018-09-18 14:09:24,807   INFO --- [Thread-1]  org.apache.spark.util.ShutdownHookManager(line:54) : Shutdown hook called
2018-09-18 14:09:24,808   INFO --- [Thread-1]  org.apache.spark.util.ShutdownHookManager(line:54) : Deleting directory C:\Users\wshs\AppData\Local\Temp\spark-2adef773-dd1f-4af9-a4b0-1d3db8fdcb13
2018-09-18 14:12:24,721   INFO --- [main]  org.apache.spark.SparkContext(line:54) : Running Spark version 2.1.1
2018-09-18 14:12:25,096   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing view acls to: wshs
2018-09-18 14:12:25,097   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing modify acls to: wshs
2018-09-18 14:12:25,098   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing view acls groups to: 
2018-09-18 14:12:25,099   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing modify acls groups to: 
2018-09-18 14:12:25,099   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(wshs); groups with view permissions: Set(); users  with modify permissions: Set(wshs); groups with modify permissions: Set()
2018-09-18 14:12:25,723   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'sparkDriver' on port 55268.
2018-09-18 14:12:25,743   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering MapOutputTracker
2018-09-18 14:12:25,763   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering BlockManagerMaster
2018-09-18 14:12:25,769   INFO --- [main]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-09-18 14:12:25,770   INFO --- [main]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : BlockManagerMasterEndpoint up
2018-09-18 14:12:25,786   INFO --- [main]  org.apache.spark.storage.DiskBlockManager(line:54) : Created local directory at C:\Users\wshs\AppData\Local\Temp\blockmgr-796de99a-ebb3-401e-9e56-8e99a8c9571a
2018-09-18 14:12:25,803   INFO --- [main]  org.apache.spark.storage.memory.MemoryStore(line:54) : MemoryStore started with capacity 3.0 GB
2018-09-18 14:12:25,876   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering OutputCommitCoordinator
2018-09-18 14:12:25,960   INFO --- [main]  org.spark_project.jetty.util.log(line:186) : Logging initialized @2204ms
2018-09-18 14:12:26,046   INFO --- [main]  org.spark_project.jetty.server.Server(line:327) : jetty-9.2.z-SNAPSHOT
2018-09-18 14:12:26,063   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@32811494{/jobs,null,AVAILABLE,@Spark}
2018-09-18 14:12:26,063   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@4795ded0{/jobs/json,null,AVAILABLE,@Spark}
2018-09-18 14:12:26,064   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@53dacd14{/jobs/job,null,AVAILABLE,@Spark}
2018-09-18 14:12:26,064   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@14d14731{/jobs/job/json,null,AVAILABLE,@Spark}
2018-09-18 14:12:26,064   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@2eced48b{/stages,null,AVAILABLE,@Spark}
2018-09-18 14:12:26,065   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@47c4ecdc{/stages/json,null,AVAILABLE,@Spark}
2018-09-18 14:12:26,065   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@42f33b5d{/stages/stage,null,AVAILABLE,@Spark}
2018-09-18 14:12:26,065   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@5c8504fd{/stages/stage/json,null,AVAILABLE,@Spark}
2018-09-18 14:12:26,066   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@4b7e96a{/stages/pool,null,AVAILABLE,@Spark}
2018-09-18 14:12:26,066   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@6475472c{/stages/pool/json,null,AVAILABLE,@Spark}
2018-09-18 14:12:26,066   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@3f07b12c{/storage,null,AVAILABLE,@Spark}
2018-09-18 14:12:26,066   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@4bd1f8dd{/storage/json,null,AVAILABLE,@Spark}
2018-09-18 14:12:26,067   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@7096b474{/storage/rdd,null,AVAILABLE,@Spark}
2018-09-18 14:12:26,067   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@3e14c16d{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-09-18 14:12:26,067   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@3c989952{/environment,null,AVAILABLE,@Spark}
2018-09-18 14:12:26,067   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@784b990c{/environment/json,null,AVAILABLE,@Spark}
2018-09-18 14:12:26,068   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@3d3ba765{/executors,null,AVAILABLE,@Spark}
2018-09-18 14:12:26,068   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@25bc0606{/executors/json,null,AVAILABLE,@Spark}
2018-09-18 14:12:26,068   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@5d1659ea{/executors/threadDump,null,AVAILABLE,@Spark}
2018-09-18 14:12:26,068   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@793138bd{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-09-18 14:12:26,073   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@1951b871{/static,null,AVAILABLE,@Spark}
2018-09-18 14:12:26,074   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@5c18016b{/,null,AVAILABLE,@Spark}
2018-09-18 14:12:26,075   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@33aeca0b{/api,null,AVAILABLE,@Spark}
2018-09-18 14:12:26,075   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@43aaf813{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-09-18 14:12:26,075   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@57ac5227{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-09-18 14:12:26,086   INFO --- [main]  org.spark_project.jetty.server.ServerConnector(line:266) : Started Spark@3e10dc6{HTTP/1.1}{0.0.0.0:4040}
2018-09-18 14:12:26,087   INFO --- [main]  org.spark_project.jetty.server.Server(line:379) : Started @2333ms
2018-09-18 14:12:26,088   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'SparkUI' on port 4040.
2018-09-18 14:12:26,091   INFO --- [main]  org.apache.spark.ui.SparkUI(line:54) : Bound SparkUI to 0.0.0.0, and started at http://192.168.3.199:4040
2018-09-18 14:12:26,175   INFO --- [main]  org.apache.spark.executor.Executor(line:54) : Starting executor ID driver on host localhost
2018-09-18 14:12:26,231   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 55310.
2018-09-18 14:12:26,232   INFO --- [main]  org.apache.spark.network.netty.NettyBlockTransferService(line:54) : Server created on 192.168.3.199:55310
2018-09-18 14:12:26,234   INFO --- [main]  org.apache.spark.storage.BlockManager(line:54) : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-09-18 14:12:26,235   INFO --- [main]  org.apache.spark.storage.BlockManagerMaster(line:54) : Registering BlockManager BlockManagerId(driver, 192.168.3.199, 55310, None)
2018-09-18 14:12:26,239   INFO --- [dispatcher-event-loop-3]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : Registering block manager 192.168.3.199:55310 with 3.0 GB RAM, BlockManagerId(driver, 192.168.3.199, 55310, None)
2018-09-18 14:12:26,242   INFO --- [main]  org.apache.spark.storage.BlockManagerMaster(line:54) : Registered BlockManager BlockManagerId(driver, 192.168.3.199, 55310, None)
2018-09-18 14:12:26,243   INFO --- [main]  org.apache.spark.storage.BlockManager(line:54) : Initialized BlockManager: BlockManagerId(driver, 192.168.3.199, 55310, None)
2018-09-18 14:12:26,461   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@42257bdd{/metrics/json,null,AVAILABLE,@Spark}
2018-09-18 14:12:26,480   WARN --- [main]  org.apache.spark.SparkContext(line:66) : Using an existing SparkContext; some configuration may not take effect.
2018-09-18 14:12:26,535   INFO --- [main]  org.apache.spark.sql.internal.SharedState(line:54) : Warehouse path is 'file:/C:/Users/wshs/IdeaProjects/logdataSession/spark-warehouse/'.
2018-09-18 14:12:26,544   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@7957dc72{/SQL,null,AVAILABLE,@Spark}
2018-09-18 14:12:26,546   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@3aacf32a{/SQL/json,null,AVAILABLE,@Spark}
2018-09-18 14:12:26,547   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@345e5a17{/SQL/execution,null,AVAILABLE,@Spark}
2018-09-18 14:12:26,548   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@443dbe42{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-09-18 14:12:26,550   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@5bbc9f97{/static/sql,null,AVAILABLE,@Spark}
2018-09-18 14:12:26,702   INFO --- [Thread-1]  org.apache.spark.SparkContext(line:54) : Invoking stop() from shutdown hook
2018-09-18 14:12:26,708   INFO --- [Thread-1]  org.spark_project.jetty.server.ServerConnector(line:306) : Stopped Spark@3e10dc6{HTTP/1.1}{0.0.0.0:4040}
2018-09-18 14:12:26,710   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@57ac5227{/stages/stage/kill,null,UNAVAILABLE,@Spark}
2018-09-18 14:12:26,711   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@43aaf813{/jobs/job/kill,null,UNAVAILABLE,@Spark}
2018-09-18 14:12:26,711   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@33aeca0b{/api,null,UNAVAILABLE,@Spark}
2018-09-18 14:12:26,711   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@5c18016b{/,null,UNAVAILABLE,@Spark}
2018-09-18 14:12:26,712   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@1951b871{/static,null,UNAVAILABLE,@Spark}
2018-09-18 14:12:26,712   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@793138bd{/executors/threadDump/json,null,UNAVAILABLE,@Spark}
2018-09-18 14:12:26,712   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@5d1659ea{/executors/threadDump,null,UNAVAILABLE,@Spark}
2018-09-18 14:12:26,712   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@25bc0606{/executors/json,null,UNAVAILABLE,@Spark}
2018-09-18 14:12:26,712   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@3d3ba765{/executors,null,UNAVAILABLE,@Spark}
2018-09-18 14:12:26,712   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@784b990c{/environment/json,null,UNAVAILABLE,@Spark}
2018-09-18 14:12:26,713   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@3c989952{/environment,null,UNAVAILABLE,@Spark}
2018-09-18 14:12:26,713   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@3e14c16d{/storage/rdd/json,null,UNAVAILABLE,@Spark}
2018-09-18 14:12:26,713   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@7096b474{/storage/rdd,null,UNAVAILABLE,@Spark}
2018-09-18 14:12:26,713   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@4bd1f8dd{/storage/json,null,UNAVAILABLE,@Spark}
2018-09-18 14:12:26,713   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@3f07b12c{/storage,null,UNAVAILABLE,@Spark}
2018-09-18 14:12:26,713   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@6475472c{/stages/pool/json,null,UNAVAILABLE,@Spark}
2018-09-18 14:12:26,714   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@4b7e96a{/stages/pool,null,UNAVAILABLE,@Spark}
2018-09-18 14:12:26,714   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@5c8504fd{/stages/stage/json,null,UNAVAILABLE,@Spark}
2018-09-18 14:12:26,714   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@42f33b5d{/stages/stage,null,UNAVAILABLE,@Spark}
2018-09-18 14:12:26,714   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@47c4ecdc{/stages/json,null,UNAVAILABLE,@Spark}
2018-09-18 14:12:26,714   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@2eced48b{/stages,null,UNAVAILABLE,@Spark}
2018-09-18 14:12:26,715   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@14d14731{/jobs/job/json,null,UNAVAILABLE,@Spark}
2018-09-18 14:12:26,715   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@53dacd14{/jobs/job,null,UNAVAILABLE,@Spark}
2018-09-18 14:12:26,715   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@4795ded0{/jobs/json,null,UNAVAILABLE,@Spark}
2018-09-18 14:12:26,716   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@32811494{/jobs,null,UNAVAILABLE,@Spark}
2018-09-18 14:12:26,716   INFO --- [Thread-1]  org.apache.spark.ui.SparkUI(line:54) : Stopped Spark web UI at http://192.168.3.199:4040
2018-09-18 14:12:26,733   INFO --- [dispatcher-event-loop-6]  org.apache.spark.MapOutputTrackerMasterEndpoint(line:54) : MapOutputTrackerMasterEndpoint stopped!
2018-09-18 14:12:26,748   INFO --- [Thread-1]  org.apache.spark.storage.memory.MemoryStore(line:54) : MemoryStore cleared
2018-09-18 14:12:26,749   INFO --- [Thread-1]  org.apache.spark.storage.BlockManager(line:54) : BlockManager stopped
2018-09-18 14:12:26,757   INFO --- [Thread-1]  org.apache.spark.storage.BlockManagerMaster(line:54) : BlockManagerMaster stopped
2018-09-18 14:12:26,762   INFO --- [dispatcher-event-loop-4]  org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint(line:54) : OutputCommitCoordinator stopped!
2018-09-18 14:12:26,767   INFO --- [Thread-1]  org.apache.spark.SparkContext(line:54) : Successfully stopped SparkContext
2018-09-18 14:12:26,767   INFO --- [Thread-1]  org.apache.spark.util.ShutdownHookManager(line:54) : Shutdown hook called
2018-09-18 14:12:26,769   INFO --- [Thread-1]  org.apache.spark.util.ShutdownHookManager(line:54) : Deleting directory C:\Users\wshs\AppData\Local\Temp\spark-d02b5525-f79f-4b5b-8323-c6b689d99f57
2018-09-18 14:16:22,252   INFO --- [main]  org.apache.spark.SparkContext(line:54) : Running Spark version 2.1.1
2018-09-18 14:16:22,627   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing view acls to: wshs
2018-09-18 14:16:22,628   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing modify acls to: wshs
2018-09-18 14:16:22,629   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing view acls groups to: 
2018-09-18 14:16:22,629   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing modify acls groups to: 
2018-09-18 14:16:22,630   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(wshs); groups with view permissions: Set(); users  with modify permissions: Set(wshs); groups with modify permissions: Set()
2018-09-18 14:16:23,178   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'sparkDriver' on port 55677.
2018-09-18 14:16:23,196   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering MapOutputTracker
2018-09-18 14:16:23,217   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering BlockManagerMaster
2018-09-18 14:16:23,221   INFO --- [main]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-09-18 14:16:23,222   INFO --- [main]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : BlockManagerMasterEndpoint up
2018-09-18 14:16:23,236   INFO --- [main]  org.apache.spark.storage.DiskBlockManager(line:54) : Created local directory at C:\Users\wshs\AppData\Local\Temp\blockmgr-457816b4-892f-4ba6-b124-d0be1b1d07c1
2018-09-18 14:16:23,253   INFO --- [main]  org.apache.spark.storage.memory.MemoryStore(line:54) : MemoryStore started with capacity 3.0 GB
2018-09-18 14:16:23,319   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering OutputCommitCoordinator
2018-09-18 14:16:23,400   INFO --- [main]  org.spark_project.jetty.util.log(line:186) : Logging initialized @2139ms
2018-09-18 14:16:23,483   INFO --- [main]  org.spark_project.jetty.server.Server(line:327) : jetty-9.2.z-SNAPSHOT
2018-09-18 14:16:23,496   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@53dacd14{/jobs,null,AVAILABLE,@Spark}
2018-09-18 14:16:23,497   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@14d14731{/jobs/json,null,AVAILABLE,@Spark}
2018-09-18 14:16:23,497   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@2eced48b{/jobs/job,null,AVAILABLE,@Spark}
2018-09-18 14:16:23,497   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@47c4ecdc{/jobs/job/json,null,AVAILABLE,@Spark}
2018-09-18 14:16:23,498   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@42f33b5d{/stages,null,AVAILABLE,@Spark}
2018-09-18 14:16:23,498   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@5c8504fd{/stages/json,null,AVAILABLE,@Spark}
2018-09-18 14:16:23,498   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@4b7e96a{/stages/stage,null,AVAILABLE,@Spark}
2018-09-18 14:16:23,498   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@6475472c{/stages/stage/json,null,AVAILABLE,@Spark}
2018-09-18 14:16:23,498   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@3f07b12c{/stages/pool,null,AVAILABLE,@Spark}
2018-09-18 14:16:23,499   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@4bd1f8dd{/stages/pool/json,null,AVAILABLE,@Spark}
2018-09-18 14:16:23,499   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@7096b474{/storage,null,AVAILABLE,@Spark}
2018-09-18 14:16:23,499   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@3e14c16d{/storage/json,null,AVAILABLE,@Spark}
2018-09-18 14:16:23,499   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@3c989952{/storage/rdd,null,AVAILABLE,@Spark}
2018-09-18 14:16:23,500   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@784b990c{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-09-18 14:16:23,500   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@3d3ba765{/environment,null,AVAILABLE,@Spark}
2018-09-18 14:16:23,500   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@25bc0606{/environment/json,null,AVAILABLE,@Spark}
2018-09-18 14:16:23,500   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@5d1659ea{/executors,null,AVAILABLE,@Spark}
2018-09-18 14:16:23,501   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@793138bd{/executors/json,null,AVAILABLE,@Spark}
2018-09-18 14:16:23,501   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@1951b871{/executors/threadDump,null,AVAILABLE,@Spark}
2018-09-18 14:16:23,501   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@5c18016b{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-09-18 14:16:23,506   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@33aeca0b{/static,null,AVAILABLE,@Spark}
2018-09-18 14:16:23,507   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@43aaf813{/,null,AVAILABLE,@Spark}
2018-09-18 14:16:23,507   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@57ac5227{/api,null,AVAILABLE,@Spark}
2018-09-18 14:16:23,508   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@4ba302e0{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-09-18 14:16:23,508   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@e98770d{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-09-18 14:16:23,520   INFO --- [main]  org.spark_project.jetty.server.ServerConnector(line:266) : Started Spark@45e37a7e{HTTP/1.1}{0.0.0.0:4040}
2018-09-18 14:16:23,521   INFO --- [main]  org.spark_project.jetty.server.Server(line:379) : Started @2261ms
2018-09-18 14:16:23,521   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'SparkUI' on port 4040.
2018-09-18 14:16:23,523   INFO --- [main]  org.apache.spark.ui.SparkUI(line:54) : Bound SparkUI to 0.0.0.0, and started at http://192.168.3.199:4040
2018-09-18 14:16:23,594   INFO --- [main]  org.apache.spark.executor.Executor(line:54) : Starting executor ID driver on host localhost
2018-09-18 14:16:23,640   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 55718.
2018-09-18 14:16:23,641   INFO --- [main]  org.apache.spark.network.netty.NettyBlockTransferService(line:54) : Server created on 192.168.3.199:55718
2018-09-18 14:16:23,643   INFO --- [main]  org.apache.spark.storage.BlockManager(line:54) : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-09-18 14:16:23,644   INFO --- [main]  org.apache.spark.storage.BlockManagerMaster(line:54) : Registering BlockManager BlockManagerId(driver, 192.168.3.199, 55718, None)
2018-09-18 14:16:23,647   INFO --- [dispatcher-event-loop-3]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : Registering block manager 192.168.3.199:55718 with 3.0 GB RAM, BlockManagerId(driver, 192.168.3.199, 55718, None)
2018-09-18 14:16:23,650   INFO --- [main]  org.apache.spark.storage.BlockManagerMaster(line:54) : Registered BlockManager BlockManagerId(driver, 192.168.3.199, 55718, None)
2018-09-18 14:16:23,651   INFO --- [main]  org.apache.spark.storage.BlockManager(line:54) : Initialized BlockManager: BlockManagerId(driver, 192.168.3.199, 55718, None)
2018-09-18 14:16:23,831   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@687a762c{/metrics/json,null,AVAILABLE,@Spark}
2018-09-18 14:16:23,848   WARN --- [main]  org.apache.spark.SparkContext(line:66) : Using an existing SparkContext; some configuration may not take effect.
2018-09-18 14:16:23,885   INFO --- [main]  org.apache.spark.sql.internal.SharedState(line:54) : Warehouse path is 'file:/C:/Users/wshs/IdeaProjects/logdataSession/spark-warehouse/'.
2018-09-18 14:16:23,891   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@7957dc72{/SQL,null,AVAILABLE,@Spark}
2018-09-18 14:16:23,892   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@3aacf32a{/SQL/json,null,AVAILABLE,@Spark}
2018-09-18 14:16:23,893   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@345e5a17{/SQL/execution,null,AVAILABLE,@Spark}
2018-09-18 14:16:23,893   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@443dbe42{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-09-18 14:16:23,895   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@5bbc9f97{/static/sql,null,AVAILABLE,@Spark}
2018-09-18 14:16:26,900   INFO --- [main]  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator(line:54) : Code generated in 210.907627 ms
2018-09-18 14:16:26,965   INFO --- [main]  org.apache.spark.SparkContext(line:54) : Starting job: show at logSession.scala:32
2018-09-18 14:16:26,979   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Got job 0 (show at logSession.scala:32) with 1 output partitions
2018-09-18 14:16:26,980   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Final stage: ResultStage 0 (show at logSession.scala:32)
2018-09-18 14:16:26,981   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Parents of final stage: List()
2018-09-18 14:16:26,983   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Missing parents: List()
2018-09-18 14:16:26,988   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Submitting ResultStage 0 (MapPartitionsRDD[2] at show at logSession.scala:32), which has no missing parents
2018-09-18 14:16:27,088   INFO --- [dag-scheduler-event-loop]  org.apache.spark.storage.memory.MemoryStore(line:54) : Block broadcast_0 stored as values in memory (estimated size 8.7 KB, free 3.0 GB)
2018-09-18 14:16:27,638   INFO --- [dag-scheduler-event-loop]  org.apache.spark.storage.memory.MemoryStore(line:54) : Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.5 KB, free 3.0 GB)
2018-09-18 14:16:27,643   INFO --- [dispatcher-event-loop-4]  org.apache.spark.storage.BlockManagerInfo(line:54) : Added broadcast_0_piece0 in memory on 192.168.3.199:55718 (size: 4.5 KB, free: 3.0 GB)
2018-09-18 14:16:27,646   INFO --- [dag-scheduler-event-loop]  org.apache.spark.SparkContext(line:54) : Created broadcast 0 from broadcast at DAGScheduler.scala:996
2018-09-18 14:16:27,650   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at show at logSession.scala:32)
2018-09-18 14:16:27,651   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.TaskSchedulerImpl(line:54) : Adding task set 0.0 with 1 tasks
2018-09-18 14:16:27,687   INFO --- [dispatcher-event-loop-5]  org.apache.spark.scheduler.TaskSetManager(line:54) : Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 5723 bytes)
2018-09-18 14:16:27,694   INFO --- [Executor task launch worker for task 0]  org.apache.spark.executor.Executor(line:54) : Running task 0.0 in stage 0.0 (TID 0)
2018-09-18 14:16:31,641   INFO --- [Executor task launch worker for task 0]  org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD(line:54) : closed connection
2018-09-18 14:16:31,652   INFO --- [Executor task launch worker for task 0]  org.apache.spark.executor.Executor(line:54) : Finished task 0.0 in stage 0.0 (TID 0). 1582 bytes result sent to driver
2018-09-18 14:16:31,660   INFO --- [task-result-getter-0]  org.apache.spark.scheduler.TaskSetManager(line:54) : Finished task 0.0 in stage 0.0 (TID 0) in 3988 ms on localhost (executor driver) (1/1)
2018-09-18 14:16:31,661   INFO --- [task-result-getter-0]  org.apache.spark.scheduler.TaskSchedulerImpl(line:54) : Removed TaskSet 0.0, whose tasks have all completed, from pool 
2018-09-18 14:16:31,664   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : ResultStage 0 (show at logSession.scala:32) finished in 4.004 s
2018-09-18 14:16:31,669   INFO --- [main]  org.apache.spark.scheduler.DAGScheduler(line:54) : Job 0 finished: show at logSession.scala:32, took 4.702913 s
2018-09-18 14:16:31,705   INFO --- [main]  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator(line:54) : Code generated in 18.718921 ms
2018-09-18 14:16:31,721   INFO --- [main]  org.spark_project.jetty.server.ServerConnector(line:306) : Stopped Spark@45e37a7e{HTTP/1.1}{0.0.0.0:4040}
2018-09-18 14:16:31,723   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@e98770d{/stages/stage/kill,null,UNAVAILABLE,@Spark}
2018-09-18 14:16:31,723   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@4ba302e0{/jobs/job/kill,null,UNAVAILABLE,@Spark}
2018-09-18 14:16:31,723   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@57ac5227{/api,null,UNAVAILABLE,@Spark}
2018-09-18 14:16:31,723   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@43aaf813{/,null,UNAVAILABLE,@Spark}
2018-09-18 14:16:31,723   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@33aeca0b{/static,null,UNAVAILABLE,@Spark}
2018-09-18 14:16:31,724   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@5c18016b{/executors/threadDump/json,null,UNAVAILABLE,@Spark}
2018-09-18 14:16:31,724   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@1951b871{/executors/threadDump,null,UNAVAILABLE,@Spark}
2018-09-18 14:16:31,724   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@793138bd{/executors/json,null,UNAVAILABLE,@Spark}
2018-09-18 14:16:31,724   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@5d1659ea{/executors,null,UNAVAILABLE,@Spark}
2018-09-18 14:16:31,724   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@25bc0606{/environment/json,null,UNAVAILABLE,@Spark}
2018-09-18 14:16:31,724   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@3d3ba765{/environment,null,UNAVAILABLE,@Spark}
2018-09-18 14:16:31,724   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@784b990c{/storage/rdd/json,null,UNAVAILABLE,@Spark}
2018-09-18 14:16:31,725   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@3c989952{/storage/rdd,null,UNAVAILABLE,@Spark}
2018-09-18 14:16:31,725   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@3e14c16d{/storage/json,null,UNAVAILABLE,@Spark}
2018-09-18 14:16:31,725   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@7096b474{/storage,null,UNAVAILABLE,@Spark}
2018-09-18 14:16:31,725   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@4bd1f8dd{/stages/pool/json,null,UNAVAILABLE,@Spark}
2018-09-18 14:16:31,725   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@3f07b12c{/stages/pool,null,UNAVAILABLE,@Spark}
2018-09-18 14:16:31,725   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@6475472c{/stages/stage/json,null,UNAVAILABLE,@Spark}
2018-09-18 14:16:31,726   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@4b7e96a{/stages/stage,null,UNAVAILABLE,@Spark}
2018-09-18 14:16:31,726   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@5c8504fd{/stages/json,null,UNAVAILABLE,@Spark}
2018-09-18 14:16:31,726   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@42f33b5d{/stages,null,UNAVAILABLE,@Spark}
2018-09-18 14:16:31,726   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@47c4ecdc{/jobs/job/json,null,UNAVAILABLE,@Spark}
2018-09-18 14:16:31,727   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@2eced48b{/jobs/job,null,UNAVAILABLE,@Spark}
2018-09-18 14:16:31,727   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@14d14731{/jobs/json,null,UNAVAILABLE,@Spark}
2018-09-18 14:16:31,727   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@53dacd14{/jobs,null,UNAVAILABLE,@Spark}
2018-09-18 14:16:31,728   INFO --- [main]  org.apache.spark.ui.SparkUI(line:54) : Stopped Spark web UI at http://192.168.3.199:4040
2018-09-18 14:16:31,737   INFO --- [dispatcher-event-loop-3]  org.apache.spark.MapOutputTrackerMasterEndpoint(line:54) : MapOutputTrackerMasterEndpoint stopped!
2018-09-18 14:16:31,755   INFO --- [main]  org.apache.spark.storage.memory.MemoryStore(line:54) : MemoryStore cleared
2018-09-18 14:16:31,755   INFO --- [main]  org.apache.spark.storage.BlockManager(line:54) : BlockManager stopped
2018-09-18 14:16:31,759   INFO --- [main]  org.apache.spark.storage.BlockManagerMaster(line:54) : BlockManagerMaster stopped
2018-09-18 14:16:31,762   INFO --- [dispatcher-event-loop-7]  org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint(line:54) : OutputCommitCoordinator stopped!
2018-09-18 14:16:31,768   INFO --- [main]  org.apache.spark.SparkContext(line:54) : Successfully stopped SparkContext
2018-09-18 14:16:31,770   INFO --- [Thread-1]  org.apache.spark.util.ShutdownHookManager(line:54) : Shutdown hook called
2018-09-18 14:16:31,771   INFO --- [Thread-1]  org.apache.spark.util.ShutdownHookManager(line:54) : Deleting directory C:\Users\wshs\AppData\Local\Temp\spark-7b4d12f9-6075-45e1-a9ca-75db0d33b514
2018-09-18 14:17:47,190   INFO --- [main]  org.apache.spark.SparkContext(line:54) : Running Spark version 2.1.1
2018-09-18 14:17:47,556   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing view acls to: wshs
2018-09-18 14:17:47,558   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing modify acls to: wshs
2018-09-18 14:17:47,558   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing view acls groups to: 
2018-09-18 14:17:47,559   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing modify acls groups to: 
2018-09-18 14:17:47,560   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(wshs); groups with view permissions: Set(); users  with modify permissions: Set(wshs); groups with modify permissions: Set()
2018-09-18 14:17:48,121   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'sparkDriver' on port 55823.
2018-09-18 14:17:48,143   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering MapOutputTracker
2018-09-18 14:17:48,164   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering BlockManagerMaster
2018-09-18 14:17:48,167   INFO --- [main]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-09-18 14:17:48,168   INFO --- [main]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : BlockManagerMasterEndpoint up
2018-09-18 14:17:48,182   INFO --- [main]  org.apache.spark.storage.DiskBlockManager(line:54) : Created local directory at C:\Users\wshs\AppData\Local\Temp\blockmgr-1562511e-d1d7-4f2a-b6fb-7b5fbf06f23e
2018-09-18 14:17:48,199   INFO --- [main]  org.apache.spark.storage.memory.MemoryStore(line:54) : MemoryStore started with capacity 3.0 GB
2018-09-18 14:17:48,268   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering OutputCommitCoordinator
2018-09-18 14:17:48,352   INFO --- [main]  org.spark_project.jetty.util.log(line:186) : Logging initialized @2125ms
2018-09-18 14:17:48,432   INFO --- [main]  org.spark_project.jetty.server.Server(line:327) : jetty-9.2.z-SNAPSHOT
2018-09-18 14:17:48,445   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@53dacd14{/jobs,null,AVAILABLE,@Spark}
2018-09-18 14:17:48,445   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@14d14731{/jobs/json,null,AVAILABLE,@Spark}
2018-09-18 14:17:48,445   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@2eced48b{/jobs/job,null,AVAILABLE,@Spark}
2018-09-18 14:17:48,445   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@47c4ecdc{/jobs/job/json,null,AVAILABLE,@Spark}
2018-09-18 14:17:48,446   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@42f33b5d{/stages,null,AVAILABLE,@Spark}
2018-09-18 14:17:48,446   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@5c8504fd{/stages/json,null,AVAILABLE,@Spark}
2018-09-18 14:17:48,446   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@4b7e96a{/stages/stage,null,AVAILABLE,@Spark}
2018-09-18 14:17:48,446   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@6475472c{/stages/stage/json,null,AVAILABLE,@Spark}
2018-09-18 14:17:48,447   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@3f07b12c{/stages/pool,null,AVAILABLE,@Spark}
2018-09-18 14:17:48,447   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@4bd1f8dd{/stages/pool/json,null,AVAILABLE,@Spark}
2018-09-18 14:17:48,447   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@7096b474{/storage,null,AVAILABLE,@Spark}
2018-09-18 14:17:48,447   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@3e14c16d{/storage/json,null,AVAILABLE,@Spark}
2018-09-18 14:17:48,447   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@3c989952{/storage/rdd,null,AVAILABLE,@Spark}
2018-09-18 14:17:48,448   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@784b990c{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-09-18 14:17:48,448   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@3d3ba765{/environment,null,AVAILABLE,@Spark}
2018-09-18 14:17:48,448   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@25bc0606{/environment/json,null,AVAILABLE,@Spark}
2018-09-18 14:17:48,448   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@5d1659ea{/executors,null,AVAILABLE,@Spark}
2018-09-18 14:17:48,449   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@793138bd{/executors/json,null,AVAILABLE,@Spark}
2018-09-18 14:17:48,449   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@1951b871{/executors/threadDump,null,AVAILABLE,@Spark}
2018-09-18 14:17:48,449   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@5c18016b{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-09-18 14:17:48,454   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@33aeca0b{/static,null,AVAILABLE,@Spark}
2018-09-18 14:17:48,454   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@43aaf813{/,null,AVAILABLE,@Spark}
2018-09-18 14:17:48,455   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@57ac5227{/api,null,AVAILABLE,@Spark}
2018-09-18 14:17:48,455   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@4ba302e0{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-09-18 14:17:48,455   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@e98770d{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-09-18 14:17:48,466   INFO --- [main]  org.spark_project.jetty.server.ServerConnector(line:266) : Started Spark@45e37a7e{HTTP/1.1}{0.0.0.0:4040}
2018-09-18 14:17:48,466   INFO --- [main]  org.spark_project.jetty.server.Server(line:379) : Started @2240ms
2018-09-18 14:17:48,467   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'SparkUI' on port 4040.
2018-09-18 14:17:48,470   INFO --- [main]  org.apache.spark.ui.SparkUI(line:54) : Bound SparkUI to 0.0.0.0, and started at http://192.168.3.199:4040
2018-09-18 14:17:48,543   INFO --- [main]  org.apache.spark.executor.Executor(line:54) : Starting executor ID driver on host localhost
2018-09-18 14:17:48,586   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 55865.
2018-09-18 14:17:48,587   INFO --- [main]  org.apache.spark.network.netty.NettyBlockTransferService(line:54) : Server created on 192.168.3.199:55865
2018-09-18 14:17:48,588   INFO --- [main]  org.apache.spark.storage.BlockManager(line:54) : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-09-18 14:17:48,590   INFO --- [main]  org.apache.spark.storage.BlockManagerMaster(line:54) : Registering BlockManager BlockManagerId(driver, 192.168.3.199, 55865, None)
2018-09-18 14:17:48,593   INFO --- [dispatcher-event-loop-2]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : Registering block manager 192.168.3.199:55865 with 3.0 GB RAM, BlockManagerId(driver, 192.168.3.199, 55865, None)
2018-09-18 14:17:48,595   INFO --- [main]  org.apache.spark.storage.BlockManagerMaster(line:54) : Registered BlockManager BlockManagerId(driver, 192.168.3.199, 55865, None)
2018-09-18 14:17:48,595   INFO --- [main]  org.apache.spark.storage.BlockManager(line:54) : Initialized BlockManager: BlockManagerId(driver, 192.168.3.199, 55865, None)
2018-09-18 14:17:48,756   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@687a762c{/metrics/json,null,AVAILABLE,@Spark}
2018-09-18 14:17:48,774   WARN --- [main]  org.apache.spark.SparkContext(line:66) : Using an existing SparkContext; some configuration may not take effect.
2018-09-18 14:17:48,811   INFO --- [main]  org.apache.spark.sql.internal.SharedState(line:54) : Warehouse path is 'file:/C:/Users/wshs/IdeaProjects/logdataSession/spark-warehouse/'.
2018-09-18 14:17:48,818   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@7957dc72{/SQL,null,AVAILABLE,@Spark}
2018-09-18 14:17:48,819   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@3aacf32a{/SQL/json,null,AVAILABLE,@Spark}
2018-09-18 14:17:48,819   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@345e5a17{/SQL/execution,null,AVAILABLE,@Spark}
2018-09-18 14:17:48,820   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@443dbe42{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-09-18 14:17:48,821   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@5bbc9f97{/static/sql,null,AVAILABLE,@Spark}
2018-09-18 14:17:51,423   INFO --- [main]  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator(line:54) : Code generated in 216.572069 ms
2018-09-18 14:17:51,485   INFO --- [main]  org.apache.spark.SparkContext(line:54) : Starting job: show at logSession.scala:32
2018-09-18 14:17:51,500   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Got job 0 (show at logSession.scala:32) with 1 output partitions
2018-09-18 14:17:51,501   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Final stage: ResultStage 0 (show at logSession.scala:32)
2018-09-18 14:17:51,501   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Parents of final stage: List()
2018-09-18 14:17:51,502   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Missing parents: List()
2018-09-18 14:17:51,507   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Submitting ResultStage 0 (MapPartitionsRDD[2] at show at logSession.scala:32), which has no missing parents
2018-09-18 14:17:51,608   INFO --- [dag-scheduler-event-loop]  org.apache.spark.storage.memory.MemoryStore(line:54) : Block broadcast_0 stored as values in memory (estimated size 8.7 KB, free 3.0 GB)
2018-09-18 14:17:52,154   INFO --- [dag-scheduler-event-loop]  org.apache.spark.storage.memory.MemoryStore(line:54) : Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.5 KB, free 3.0 GB)
2018-09-18 14:17:52,163   INFO --- [dispatcher-event-loop-4]  org.apache.spark.storage.BlockManagerInfo(line:54) : Added broadcast_0_piece0 in memory on 192.168.3.199:55865 (size: 4.5 KB, free: 3.0 GB)
2018-09-18 14:17:52,165   INFO --- [dag-scheduler-event-loop]  org.apache.spark.SparkContext(line:54) : Created broadcast 0 from broadcast at DAGScheduler.scala:996
2018-09-18 14:17:52,170   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at show at logSession.scala:32)
2018-09-18 14:17:52,172   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.TaskSchedulerImpl(line:54) : Adding task set 0.0 with 1 tasks
2018-09-18 14:17:52,205   INFO --- [dispatcher-event-loop-5]  org.apache.spark.scheduler.TaskSetManager(line:54) : Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 5723 bytes)
2018-09-18 14:17:52,214   INFO --- [Executor task launch worker for task 0]  org.apache.spark.executor.Executor(line:54) : Running task 0.0 in stage 0.0 (TID 0)
2018-09-18 14:17:54,369   INFO --- [Executor task launch worker for task 0]  org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD(line:54) : closed connection
2018-09-18 14:17:54,379   INFO --- [Executor task launch worker for task 0]  org.apache.spark.executor.Executor(line:54) : Finished task 0.0 in stage 0.0 (TID 0). 1582 bytes result sent to driver
2018-09-18 14:17:54,387   INFO --- [task-result-getter-0]  org.apache.spark.scheduler.TaskSetManager(line:54) : Finished task 0.0 in stage 0.0 (TID 0) in 2195 ms on localhost (executor driver) (1/1)
2018-09-18 14:17:54,388   INFO --- [task-result-getter-0]  org.apache.spark.scheduler.TaskSchedulerImpl(line:54) : Removed TaskSet 0.0, whose tasks have all completed, from pool 
2018-09-18 14:17:54,391   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : ResultStage 0 (show at logSession.scala:32) finished in 2.212 s
2018-09-18 14:17:54,395   INFO --- [main]  org.apache.spark.scheduler.DAGScheduler(line:54) : Job 0 finished: show at logSession.scala:32, took 2.909633 s
2018-09-18 14:17:54,430   INFO --- [main]  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator(line:54) : Code generated in 18.130302 ms
2018-09-18 14:17:54,503   INFO --- [main]  org.apache.spark.sql.execution.SparkSqlParser(line:54) : Parsing command: actionopvide
2018-09-18 14:17:54,624   INFO --- [main]  org.apache.spark.sql.execution.SparkSqlParser(line:54) : Parsing command: SELECT count(1) FROM actionopvide
2018-09-18 14:17:54,677   INFO --- [Thread-1]  org.apache.spark.SparkContext(line:54) : Invoking stop() from shutdown hook
2018-09-18 14:17:54,683   INFO --- [Thread-1]  org.spark_project.jetty.server.ServerConnector(line:306) : Stopped Spark@45e37a7e{HTTP/1.1}{0.0.0.0:4040}
2018-09-18 14:17:54,686   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@e98770d{/stages/stage/kill,null,UNAVAILABLE,@Spark}
2018-09-18 14:17:54,686   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@4ba302e0{/jobs/job/kill,null,UNAVAILABLE,@Spark}
2018-09-18 14:17:54,686   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@57ac5227{/api,null,UNAVAILABLE,@Spark}
2018-09-18 14:17:54,687   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@43aaf813{/,null,UNAVAILABLE,@Spark}
2018-09-18 14:17:54,687   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@33aeca0b{/static,null,UNAVAILABLE,@Spark}
2018-09-18 14:17:54,687   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@5c18016b{/executors/threadDump/json,null,UNAVAILABLE,@Spark}
2018-09-18 14:17:54,688   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@1951b871{/executors/threadDump,null,UNAVAILABLE,@Spark}
2018-09-18 14:17:54,688   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@793138bd{/executors/json,null,UNAVAILABLE,@Spark}
2018-09-18 14:17:54,688   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@5d1659ea{/executors,null,UNAVAILABLE,@Spark}
2018-09-18 14:17:54,688   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@25bc0606{/environment/json,null,UNAVAILABLE,@Spark}
2018-09-18 14:17:54,688   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@3d3ba765{/environment,null,UNAVAILABLE,@Spark}
2018-09-18 14:17:54,689   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@784b990c{/storage/rdd/json,null,UNAVAILABLE,@Spark}
2018-09-18 14:17:54,689   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@3c989952{/storage/rdd,null,UNAVAILABLE,@Spark}
2018-09-18 14:17:54,689   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@3e14c16d{/storage/json,null,UNAVAILABLE,@Spark}
2018-09-18 14:17:54,689   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@7096b474{/storage,null,UNAVAILABLE,@Spark}
2018-09-18 14:17:54,689   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@4bd1f8dd{/stages/pool/json,null,UNAVAILABLE,@Spark}
2018-09-18 14:17:54,689   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@3f07b12c{/stages/pool,null,UNAVAILABLE,@Spark}
2018-09-18 14:17:54,690   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@6475472c{/stages/stage/json,null,UNAVAILABLE,@Spark}
2018-09-18 14:17:54,690   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@4b7e96a{/stages/stage,null,UNAVAILABLE,@Spark}
2018-09-18 14:17:54,690   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@5c8504fd{/stages/json,null,UNAVAILABLE,@Spark}
2018-09-18 14:17:54,690   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@42f33b5d{/stages,null,UNAVAILABLE,@Spark}
2018-09-18 14:17:54,690   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@47c4ecdc{/jobs/job/json,null,UNAVAILABLE,@Spark}
2018-09-18 14:17:54,690   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@2eced48b{/jobs/job,null,UNAVAILABLE,@Spark}
2018-09-18 14:17:54,690   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@14d14731{/jobs/json,null,UNAVAILABLE,@Spark}
2018-09-18 14:17:54,691   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@53dacd14{/jobs,null,UNAVAILABLE,@Spark}
2018-09-18 14:17:54,692   INFO --- [Thread-1]  org.apache.spark.ui.SparkUI(line:54) : Stopped Spark web UI at http://192.168.3.199:4040
2018-09-18 14:17:54,702   INFO --- [dispatcher-event-loop-2]  org.apache.spark.MapOutputTrackerMasterEndpoint(line:54) : MapOutputTrackerMasterEndpoint stopped!
2018-09-18 14:17:54,723   INFO --- [Thread-1]  org.apache.spark.storage.memory.MemoryStore(line:54) : MemoryStore cleared
2018-09-18 14:17:54,724   INFO --- [Thread-1]  org.apache.spark.storage.BlockManager(line:54) : BlockManager stopped
2018-09-18 14:17:54,729   INFO --- [Thread-1]  org.apache.spark.storage.BlockManagerMaster(line:54) : BlockManagerMaster stopped
2018-09-18 14:17:54,732   INFO --- [dispatcher-event-loop-7]  org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint(line:54) : OutputCommitCoordinator stopped!
2018-09-18 14:17:54,737   INFO --- [Thread-1]  org.apache.spark.SparkContext(line:54) : Successfully stopped SparkContext
2018-09-18 14:17:54,738   INFO --- [Thread-1]  org.apache.spark.util.ShutdownHookManager(line:54) : Shutdown hook called
2018-09-18 14:17:54,739   INFO --- [Thread-1]  org.apache.spark.util.ShutdownHookManager(line:54) : Deleting directory C:\Users\wshs\AppData\Local\Temp\spark-0624a96c-9ab3-461b-81e3-9b4f4019d64b
2018-09-18 14:20:24,715   INFO --- [main]  org.apache.spark.SparkContext(line:54) : Running Spark version 2.1.1
2018-09-18 14:20:25,154   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing view acls to: wshs
2018-09-18 14:20:25,155   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing modify acls to: wshs
2018-09-18 14:20:25,156   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing view acls groups to: 
2018-09-18 14:20:25,157   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing modify acls groups to: 
2018-09-18 14:20:25,157   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(wshs); groups with view permissions: Set(); users  with modify permissions: Set(wshs); groups with modify permissions: Set()
2018-09-18 14:20:25,698   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'sparkDriver' on port 56054.
2018-09-18 14:20:25,718   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering MapOutputTracker
2018-09-18 14:20:25,737   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering BlockManagerMaster
2018-09-18 14:20:25,741   INFO --- [main]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-09-18 14:20:25,741   INFO --- [main]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : BlockManagerMasterEndpoint up
2018-09-18 14:20:25,757   INFO --- [main]  org.apache.spark.storage.DiskBlockManager(line:54) : Created local directory at C:\Users\wshs\AppData\Local\Temp\blockmgr-4550c38c-9e09-4eca-be41-c65a1d0db284
2018-09-18 14:20:25,774   INFO --- [main]  org.apache.spark.storage.memory.MemoryStore(line:54) : MemoryStore started with capacity 3.0 GB
2018-09-18 14:20:25,836   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering OutputCommitCoordinator
2018-09-18 14:20:25,914   INFO --- [main]  org.spark_project.jetty.util.log(line:186) : Logging initialized @2210ms
2018-09-18 14:20:25,993   INFO --- [main]  org.spark_project.jetty.server.Server(line:327) : jetty-9.2.z-SNAPSHOT
2018-09-18 14:20:26,007   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@53dacd14{/jobs,null,AVAILABLE,@Spark}
2018-09-18 14:20:26,007   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@14d14731{/jobs/json,null,AVAILABLE,@Spark}
2018-09-18 14:20:26,007   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@2eced48b{/jobs/job,null,AVAILABLE,@Spark}
2018-09-18 14:20:26,008   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@47c4ecdc{/jobs/job/json,null,AVAILABLE,@Spark}
2018-09-18 14:20:26,008   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@42f33b5d{/stages,null,AVAILABLE,@Spark}
2018-09-18 14:20:26,008   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@5c8504fd{/stages/json,null,AVAILABLE,@Spark}
2018-09-18 14:20:26,008   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@4b7e96a{/stages/stage,null,AVAILABLE,@Spark}
2018-09-18 14:20:26,008   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@6475472c{/stages/stage/json,null,AVAILABLE,@Spark}
2018-09-18 14:20:26,009   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@3f07b12c{/stages/pool,null,AVAILABLE,@Spark}
2018-09-18 14:20:26,009   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@4bd1f8dd{/stages/pool/json,null,AVAILABLE,@Spark}
2018-09-18 14:20:26,009   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@7096b474{/storage,null,AVAILABLE,@Spark}
2018-09-18 14:20:26,009   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@3e14c16d{/storage/json,null,AVAILABLE,@Spark}
2018-09-18 14:20:26,010   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@3c989952{/storage/rdd,null,AVAILABLE,@Spark}
2018-09-18 14:20:26,010   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@784b990c{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-09-18 14:20:26,010   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@3d3ba765{/environment,null,AVAILABLE,@Spark}
2018-09-18 14:20:26,010   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@25bc0606{/environment/json,null,AVAILABLE,@Spark}
2018-09-18 14:20:26,010   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@5d1659ea{/executors,null,AVAILABLE,@Spark}
2018-09-18 14:20:26,011   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@793138bd{/executors/json,null,AVAILABLE,@Spark}
2018-09-18 14:20:26,012   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@1951b871{/executors/threadDump,null,AVAILABLE,@Spark}
2018-09-18 14:20:26,012   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@5c18016b{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-09-18 14:20:26,017   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@33aeca0b{/static,null,AVAILABLE,@Spark}
2018-09-18 14:20:26,017   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@43aaf813{/,null,AVAILABLE,@Spark}
2018-09-18 14:20:26,018   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@57ac5227{/api,null,AVAILABLE,@Spark}
2018-09-18 14:20:26,018   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@4ba302e0{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-09-18 14:20:26,018   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@e98770d{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-09-18 14:20:26,029   INFO --- [main]  org.spark_project.jetty.server.ServerConnector(line:266) : Started Spark@45e37a7e{HTTP/1.1}{0.0.0.0:4040}
2018-09-18 14:20:26,030   INFO --- [main]  org.spark_project.jetty.server.Server(line:379) : Started @2327ms
2018-09-18 14:20:26,030   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'SparkUI' on port 4040.
2018-09-18 14:20:26,033   INFO --- [main]  org.apache.spark.ui.SparkUI(line:54) : Bound SparkUI to 0.0.0.0, and started at http://192.168.3.199:4040
2018-09-18 14:20:26,100   INFO --- [main]  org.apache.spark.executor.Executor(line:54) : Starting executor ID driver on host localhost
2018-09-18 14:20:26,143   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 56095.
2018-09-18 14:20:26,144   INFO --- [main]  org.apache.spark.network.netty.NettyBlockTransferService(line:54) : Server created on 192.168.3.199:56095
2018-09-18 14:20:26,145   INFO --- [main]  org.apache.spark.storage.BlockManager(line:54) : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-09-18 14:20:26,146   INFO --- [main]  org.apache.spark.storage.BlockManagerMaster(line:54) : Registering BlockManager BlockManagerId(driver, 192.168.3.199, 56095, None)
2018-09-18 14:20:26,149   INFO --- [dispatcher-event-loop-2]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : Registering block manager 192.168.3.199:56095 with 3.0 GB RAM, BlockManagerId(driver, 192.168.3.199, 56095, None)
2018-09-18 14:20:26,151   INFO --- [main]  org.apache.spark.storage.BlockManagerMaster(line:54) : Registered BlockManager BlockManagerId(driver, 192.168.3.199, 56095, None)
2018-09-18 14:20:26,152   INFO --- [main]  org.apache.spark.storage.BlockManager(line:54) : Initialized BlockManager: BlockManagerId(driver, 192.168.3.199, 56095, None)
2018-09-18 14:20:26,311   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@687a762c{/metrics/json,null,AVAILABLE,@Spark}
2018-09-18 14:20:26,329   WARN --- [main]  org.apache.spark.SparkContext(line:66) : Using an existing SparkContext; some configuration may not take effect.
2018-09-18 14:20:26,376   INFO --- [main]  org.apache.spark.sql.internal.SharedState(line:54) : Warehouse path is 'file:/C:/Users/wshs/IdeaProjects/logdataSession/spark-warehouse/'.
2018-09-18 14:20:26,382   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@7957dc72{/SQL,null,AVAILABLE,@Spark}
2018-09-18 14:20:26,383   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@3aacf32a{/SQL/json,null,AVAILABLE,@Spark}
2018-09-18 14:20:26,384   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@345e5a17{/SQL/execution,null,AVAILABLE,@Spark}
2018-09-18 14:20:26,384   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@443dbe42{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-09-18 14:20:26,388   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@5bbc9f97{/static/sql,null,AVAILABLE,@Spark}
2018-09-18 14:20:29,184   INFO --- [main]  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator(line:54) : Code generated in 215.403245 ms
2018-09-18 14:20:29,251   INFO --- [main]  org.apache.spark.SparkContext(line:54) : Starting job: show at logSession.scala:32
2018-09-18 14:20:29,274   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Got job 0 (show at logSession.scala:32) with 1 output partitions
2018-09-18 14:20:29,275   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Final stage: ResultStage 0 (show at logSession.scala:32)
2018-09-18 14:20:29,275   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Parents of final stage: List()
2018-09-18 14:20:29,276   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Missing parents: List()
2018-09-18 14:20:29,281   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Submitting ResultStage 0 (MapPartitionsRDD[2] at show at logSession.scala:32), which has no missing parents
2018-09-18 14:20:29,382   INFO --- [dag-scheduler-event-loop]  org.apache.spark.storage.memory.MemoryStore(line:54) : Block broadcast_0 stored as values in memory (estimated size 8.5 KB, free 3.0 GB)
2018-09-18 14:20:29,931   INFO --- [dag-scheduler-event-loop]  org.apache.spark.storage.memory.MemoryStore(line:54) : Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.5 KB, free 3.0 GB)
2018-09-18 14:20:29,935   INFO --- [dispatcher-event-loop-4]  org.apache.spark.storage.BlockManagerInfo(line:54) : Added broadcast_0_piece0 in memory on 192.168.3.199:56095 (size: 4.5 KB, free: 3.0 GB)
2018-09-18 14:20:29,938   INFO --- [dag-scheduler-event-loop]  org.apache.spark.SparkContext(line:54) : Created broadcast 0 from broadcast at DAGScheduler.scala:996
2018-09-18 14:20:29,942   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at show at logSession.scala:32)
2018-09-18 14:20:29,943   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.TaskSchedulerImpl(line:54) : Adding task set 0.0 with 1 tasks
2018-09-18 14:20:29,978   INFO --- [dispatcher-event-loop-5]  org.apache.spark.scheduler.TaskSetManager(line:54) : Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 5723 bytes)
2018-09-18 14:20:29,986   INFO --- [Executor task launch worker for task 0]  org.apache.spark.executor.Executor(line:54) : Running task 0.0 in stage 0.0 (TID 0)
2018-09-18 14:20:31,635   INFO --- [Executor task launch worker for task 0]  org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD(line:54) : closed connection
2018-09-18 14:20:31,647   INFO --- [Executor task launch worker for task 0]  org.apache.spark.executor.Executor(line:54) : Finished task 0.0 in stage 0.0 (TID 0). 2003 bytes result sent to driver
2018-09-18 14:20:31,654   INFO --- [task-result-getter-0]  org.apache.spark.scheduler.TaskSetManager(line:54) : Finished task 0.0 in stage 0.0 (TID 0) in 1691 ms on localhost (executor driver) (1/1)
2018-09-18 14:20:31,656   INFO --- [task-result-getter-0]  org.apache.spark.scheduler.TaskSchedulerImpl(line:54) : Removed TaskSet 0.0, whose tasks have all completed, from pool 
2018-09-18 14:20:31,659   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : ResultStage 0 (show at logSession.scala:32) finished in 1.709 s
2018-09-18 14:20:31,664   INFO --- [main]  org.apache.spark.scheduler.DAGScheduler(line:54) : Job 0 finished: show at logSession.scala:32, took 2.412284 s
2018-09-18 14:20:31,702   INFO --- [main]  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator(line:54) : Code generated in 20.278655 ms
2018-09-18 14:20:31,775   INFO --- [main]  org.apache.spark.sql.execution.SparkSqlParser(line:54) : Parsing command: actionopvide
2018-09-18 14:20:31,898   INFO --- [main]  org.apache.spark.sql.execution.SparkSqlParser(line:54) : Parsing command: SELECT count(1) FROM actionopvide
2018-09-18 14:20:31,951   INFO --- [Thread-1]  org.apache.spark.SparkContext(line:54) : Invoking stop() from shutdown hook
2018-09-18 14:20:31,957   INFO --- [Thread-1]  org.spark_project.jetty.server.ServerConnector(line:306) : Stopped Spark@45e37a7e{HTTP/1.1}{0.0.0.0:4040}
2018-09-18 14:20:31,959   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@e98770d{/stages/stage/kill,null,UNAVAILABLE,@Spark}
2018-09-18 14:20:31,959   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@4ba302e0{/jobs/job/kill,null,UNAVAILABLE,@Spark}
2018-09-18 14:20:31,960   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@57ac5227{/api,null,UNAVAILABLE,@Spark}
2018-09-18 14:20:31,960   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@43aaf813{/,null,UNAVAILABLE,@Spark}
2018-09-18 14:20:31,960   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@33aeca0b{/static,null,UNAVAILABLE,@Spark}
2018-09-18 14:20:31,961   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@5c18016b{/executors/threadDump/json,null,UNAVAILABLE,@Spark}
2018-09-18 14:20:31,961   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@1951b871{/executors/threadDump,null,UNAVAILABLE,@Spark}
2018-09-18 14:20:31,961   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@793138bd{/executors/json,null,UNAVAILABLE,@Spark}
2018-09-18 14:20:31,961   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@5d1659ea{/executors,null,UNAVAILABLE,@Spark}
2018-09-18 14:20:31,961   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@25bc0606{/environment/json,null,UNAVAILABLE,@Spark}
2018-09-18 14:20:31,962   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@3d3ba765{/environment,null,UNAVAILABLE,@Spark}
2018-09-18 14:20:31,962   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@784b990c{/storage/rdd/json,null,UNAVAILABLE,@Spark}
2018-09-18 14:20:31,962   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@3c989952{/storage/rdd,null,UNAVAILABLE,@Spark}
2018-09-18 14:20:31,962   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@3e14c16d{/storage/json,null,UNAVAILABLE,@Spark}
2018-09-18 14:20:31,962   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@7096b474{/storage,null,UNAVAILABLE,@Spark}
2018-09-18 14:20:31,962   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@4bd1f8dd{/stages/pool/json,null,UNAVAILABLE,@Spark}
2018-09-18 14:20:31,963   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@3f07b12c{/stages/pool,null,UNAVAILABLE,@Spark}
2018-09-18 14:20:31,963   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@6475472c{/stages/stage/json,null,UNAVAILABLE,@Spark}
2018-09-18 14:20:31,963   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@4b7e96a{/stages/stage,null,UNAVAILABLE,@Spark}
2018-09-18 14:20:31,963   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@5c8504fd{/stages/json,null,UNAVAILABLE,@Spark}
2018-09-18 14:20:31,963   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@42f33b5d{/stages,null,UNAVAILABLE,@Spark}
2018-09-18 14:20:31,963   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@47c4ecdc{/jobs/job/json,null,UNAVAILABLE,@Spark}
2018-09-18 14:20:31,963   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@2eced48b{/jobs/job,null,UNAVAILABLE,@Spark}
2018-09-18 14:20:31,964   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@14d14731{/jobs/json,null,UNAVAILABLE,@Spark}
2018-09-18 14:20:31,964   INFO --- [Thread-1]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@53dacd14{/jobs,null,UNAVAILABLE,@Spark}
2018-09-18 14:20:31,965   INFO --- [Thread-1]  org.apache.spark.ui.SparkUI(line:54) : Stopped Spark web UI at http://192.168.3.199:4040
2018-09-18 14:20:31,975   INFO --- [dispatcher-event-loop-2]  org.apache.spark.MapOutputTrackerMasterEndpoint(line:54) : MapOutputTrackerMasterEndpoint stopped!
2018-09-18 14:20:31,995   INFO --- [Thread-1]  org.apache.spark.storage.memory.MemoryStore(line:54) : MemoryStore cleared
2018-09-18 14:20:31,996   INFO --- [Thread-1]  org.apache.spark.storage.BlockManager(line:54) : BlockManager stopped
2018-09-18 14:20:32,002   INFO --- [Thread-1]  org.apache.spark.storage.BlockManagerMaster(line:54) : BlockManagerMaster stopped
2018-09-18 14:20:32,004   INFO --- [dispatcher-event-loop-7]  org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint(line:54) : OutputCommitCoordinator stopped!
2018-09-18 14:20:32,010   INFO --- [Thread-1]  org.apache.spark.SparkContext(line:54) : Successfully stopped SparkContext
2018-09-18 14:20:32,011   INFO --- [Thread-1]  org.apache.spark.util.ShutdownHookManager(line:54) : Shutdown hook called
2018-09-18 14:20:32,013   INFO --- [Thread-1]  org.apache.spark.util.ShutdownHookManager(line:54) : Deleting directory C:\Users\wshs\AppData\Local\Temp\spark-564a7ef8-4db9-41cb-bc18-bccc6126a0ad
2018-09-18 14:24:20,913   INFO --- [main]  org.apache.spark.SparkContext(line:54) : Running Spark version 2.1.1
2018-09-18 14:24:21,250   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing view acls to: wshs
2018-09-18 14:24:21,251   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing modify acls to: wshs
2018-09-18 14:24:21,251   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing view acls groups to: 
2018-09-18 14:24:21,252   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing modify acls groups to: 
2018-09-18 14:24:21,253   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(wshs); groups with view permissions: Set(); users  with modify permissions: Set(wshs); groups with modify permissions: Set()
2018-09-18 14:24:21,769   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'sparkDriver' on port 56567.
2018-09-18 14:24:21,788   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering MapOutputTracker
2018-09-18 14:24:21,804   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering BlockManagerMaster
2018-09-18 14:24:21,807   INFO --- [main]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-09-18 14:24:21,807   INFO --- [main]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : BlockManagerMasterEndpoint up
2018-09-18 14:24:21,820   INFO --- [main]  org.apache.spark.storage.DiskBlockManager(line:54) : Created local directory at C:\Users\wshs\AppData\Local\Temp\blockmgr-c2bdfd0f-e28a-4c32-9902-b50bb49e9379
2018-09-18 14:24:21,836   INFO --- [main]  org.apache.spark.storage.memory.MemoryStore(line:54) : MemoryStore started with capacity 3.0 GB
2018-09-18 14:24:21,895   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering OutputCommitCoordinator
2018-09-18 14:24:21,966   INFO --- [main]  org.spark_project.jetty.util.log(line:186) : Logging initialized @2044ms
2018-09-18 14:24:22,048   INFO --- [main]  org.spark_project.jetty.server.Server(line:327) : jetty-9.2.z-SNAPSHOT
2018-09-18 14:24:22,062   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@53dacd14{/jobs,null,AVAILABLE,@Spark}
2018-09-18 14:24:22,062   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@14d14731{/jobs/json,null,AVAILABLE,@Spark}
2018-09-18 14:24:22,062   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@2eced48b{/jobs/job,null,AVAILABLE,@Spark}
2018-09-18 14:24:22,063   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@47c4ecdc{/jobs/job/json,null,AVAILABLE,@Spark}
2018-09-18 14:24:22,063   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@42f33b5d{/stages,null,AVAILABLE,@Spark}
2018-09-18 14:24:22,063   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@5c8504fd{/stages/json,null,AVAILABLE,@Spark}
2018-09-18 14:24:22,063   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@4b7e96a{/stages/stage,null,AVAILABLE,@Spark}
2018-09-18 14:24:22,064   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@6475472c{/stages/stage/json,null,AVAILABLE,@Spark}
2018-09-18 14:24:22,064   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@3f07b12c{/stages/pool,null,AVAILABLE,@Spark}
2018-09-18 14:24:22,064   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@4bd1f8dd{/stages/pool/json,null,AVAILABLE,@Spark}
2018-09-18 14:24:22,064   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@7096b474{/storage,null,AVAILABLE,@Spark}
2018-09-18 14:24:22,065   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@3e14c16d{/storage/json,null,AVAILABLE,@Spark}
2018-09-18 14:24:22,065   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@3c989952{/storage/rdd,null,AVAILABLE,@Spark}
2018-09-18 14:24:22,065   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@784b990c{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-09-18 14:24:22,065   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@3d3ba765{/environment,null,AVAILABLE,@Spark}
2018-09-18 14:24:22,065   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@25bc0606{/environment/json,null,AVAILABLE,@Spark}
2018-09-18 14:24:22,066   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@5d1659ea{/executors,null,AVAILABLE,@Spark}
2018-09-18 14:24:22,066   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@793138bd{/executors/json,null,AVAILABLE,@Spark}
2018-09-18 14:24:22,066   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@1951b871{/executors/threadDump,null,AVAILABLE,@Spark}
2018-09-18 14:24:22,066   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@5c18016b{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-09-18 14:24:22,071   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@33aeca0b{/static,null,AVAILABLE,@Spark}
2018-09-18 14:24:22,072   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@43aaf813{/,null,AVAILABLE,@Spark}
2018-09-18 14:24:22,073   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@57ac5227{/api,null,AVAILABLE,@Spark}
2018-09-18 14:24:22,073   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@4ba302e0{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-09-18 14:24:22,073   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@e98770d{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-09-18 14:24:22,086   INFO --- [main]  org.spark_project.jetty.server.ServerConnector(line:266) : Started Spark@45e37a7e{HTTP/1.1}{0.0.0.0:4040}
2018-09-18 14:24:22,086   INFO --- [main]  org.spark_project.jetty.server.Server(line:379) : Started @2165ms
2018-09-18 14:24:22,087   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'SparkUI' on port 4040.
2018-09-18 14:24:22,089   INFO --- [main]  org.apache.spark.ui.SparkUI(line:54) : Bound SparkUI to 0.0.0.0, and started at http://192.168.3.199:4040
2018-09-18 14:24:22,164   INFO --- [main]  org.apache.spark.executor.Executor(line:54) : Starting executor ID driver on host localhost
2018-09-18 14:24:22,214   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 56609.
2018-09-18 14:24:22,214   INFO --- [main]  org.apache.spark.network.netty.NettyBlockTransferService(line:54) : Server created on 192.168.3.199:56609
2018-09-18 14:24:22,216   INFO --- [main]  org.apache.spark.storage.BlockManager(line:54) : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-09-18 14:24:22,218   INFO --- [main]  org.apache.spark.storage.BlockManagerMaster(line:54) : Registering BlockManager BlockManagerId(driver, 192.168.3.199, 56609, None)
2018-09-18 14:24:22,221   INFO --- [dispatcher-event-loop-3]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : Registering block manager 192.168.3.199:56609 with 3.0 GB RAM, BlockManagerId(driver, 192.168.3.199, 56609, None)
2018-09-18 14:24:22,223   INFO --- [main]  org.apache.spark.storage.BlockManagerMaster(line:54) : Registered BlockManager BlockManagerId(driver, 192.168.3.199, 56609, None)
2018-09-18 14:24:22,224   INFO --- [main]  org.apache.spark.storage.BlockManager(line:54) : Initialized BlockManager: BlockManagerId(driver, 192.168.3.199, 56609, None)
2018-09-18 14:24:22,383   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@687a762c{/metrics/json,null,AVAILABLE,@Spark}
2018-09-18 14:24:22,399   WARN --- [main]  org.apache.spark.SparkContext(line:66) : Using an existing SparkContext; some configuration may not take effect.
2018-09-18 14:24:22,438   INFO --- [main]  org.apache.spark.sql.internal.SharedState(line:54) : Warehouse path is 'file:/C:/Users/wshs/IdeaProjects/logdataSession/spark-warehouse/'.
2018-09-18 14:24:22,443   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@7957dc72{/SQL,null,AVAILABLE,@Spark}
2018-09-18 14:24:22,443   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@3aacf32a{/SQL/json,null,AVAILABLE,@Spark}
2018-09-18 14:24:22,444   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@345e5a17{/SQL/execution,null,AVAILABLE,@Spark}
2018-09-18 14:24:22,444   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@443dbe42{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-09-18 14:24:22,446   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@5bbc9f97{/static/sql,null,AVAILABLE,@Spark}
2018-09-18 14:24:25,008   INFO --- [main]  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator(line:54) : Code generated in 199.11572 ms
2018-09-18 14:24:25,070   INFO --- [main]  org.apache.spark.SparkContext(line:54) : Starting job: show at logSession.scala:32
2018-09-18 14:24:25,085   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Got job 0 (show at logSession.scala:32) with 1 output partitions
2018-09-18 14:24:25,085   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Final stage: ResultStage 0 (show at logSession.scala:32)
2018-09-18 14:24:25,086   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Parents of final stage: List()
2018-09-18 14:24:25,087   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Missing parents: List()
2018-09-18 14:24:25,092   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Submitting ResultStage 0 (MapPartitionsRDD[2] at show at logSession.scala:32), which has no missing parents
2018-09-18 14:24:25,197   INFO --- [dag-scheduler-event-loop]  org.apache.spark.storage.memory.MemoryStore(line:54) : Block broadcast_0 stored as values in memory (estimated size 8.5 KB, free 3.0 GB)
2018-09-18 14:24:25,746   INFO --- [dag-scheduler-event-loop]  org.apache.spark.storage.memory.MemoryStore(line:54) : Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.5 KB, free 3.0 GB)
2018-09-18 14:24:25,750   INFO --- [dispatcher-event-loop-1]  org.apache.spark.storage.BlockManagerInfo(line:54) : Added broadcast_0_piece0 in memory on 192.168.3.199:56609 (size: 4.5 KB, free: 3.0 GB)
2018-09-18 14:24:25,752   INFO --- [dag-scheduler-event-loop]  org.apache.spark.SparkContext(line:54) : Created broadcast 0 from broadcast at DAGScheduler.scala:996
2018-09-18 14:24:25,756   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at show at logSession.scala:32)
2018-09-18 14:24:25,757   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.TaskSchedulerImpl(line:54) : Adding task set 0.0 with 1 tasks
2018-09-18 14:24:25,791   INFO --- [dispatcher-event-loop-5]  org.apache.spark.scheduler.TaskSetManager(line:54) : Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 5723 bytes)
2018-09-18 14:24:25,799   INFO --- [Executor task launch worker for task 0]  org.apache.spark.executor.Executor(line:54) : Running task 0.0 in stage 0.0 (TID 0)
2018-09-18 14:24:28,420   INFO --- [Executor task launch worker for task 0]  org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD(line:54) : closed connection
2018-09-18 14:24:28,429   INFO --- [Executor task launch worker for task 0]  org.apache.spark.executor.Executor(line:54) : Finished task 0.0 in stage 0.0 (TID 0). 2003 bytes result sent to driver
2018-09-18 14:24:28,437   INFO --- [task-result-getter-0]  org.apache.spark.scheduler.TaskSetManager(line:54) : Finished task 0.0 in stage 0.0 (TID 0) in 2660 ms on localhost (executor driver) (1/1)
2018-09-18 14:24:28,438   INFO --- [task-result-getter-0]  org.apache.spark.scheduler.TaskSchedulerImpl(line:54) : Removed TaskSet 0.0, whose tasks have all completed, from pool 
2018-09-18 14:24:28,441   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : ResultStage 0 (show at logSession.scala:32) finished in 2.674 s
2018-09-18 14:24:28,446   INFO --- [main]  org.apache.spark.scheduler.DAGScheduler(line:54) : Job 0 finished: show at logSession.scala:32, took 3.375289 s
2018-09-18 14:24:28,484   INFO --- [main]  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator(line:54) : Code generated in 21.715498 ms
2018-09-18 14:24:28,560   INFO --- [main]  org.apache.spark.sql.execution.SparkSqlParser(line:54) : Parsing command: actionopvidio
2018-09-18 14:24:28,698   INFO --- [main]  org.apache.spark.sql.execution.SparkSqlParser(line:54) : Parsing command: SELECT count(1) FROM actionopvidio
2018-09-18 14:24:28,895   INFO --- [main]  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator(line:54) : Code generated in 8.936851 ms
2018-09-18 14:24:28,909   INFO --- [main]  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator(line:54) : Code generated in 11.315663 ms
2018-09-18 14:24:28,933   INFO --- [main]  org.apache.spark.SparkContext(line:54) : Starting job: show at logSession.scala:42
2018-09-18 14:24:28,937   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Registering RDD 6 (show at logSession.scala:42)
2018-09-18 14:24:28,938   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Got job 1 (show at logSession.scala:42) with 1 output partitions
2018-09-18 14:24:28,938   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Final stage: ResultStage 2 (show at logSession.scala:42)
2018-09-18 14:24:28,938   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Parents of final stage: List(ShuffleMapStage 1)
2018-09-18 14:24:28,938   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Missing parents: List(ShuffleMapStage 1)
2018-09-18 14:24:28,940   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Submitting ShuffleMapStage 1 (MapPartitionsRDD[6] at show at logSession.scala:42), which has no missing parents
2018-09-18 14:24:28,952   INFO --- [dag-scheduler-event-loop]  org.apache.spark.storage.memory.MemoryStore(line:54) : Block broadcast_1 stored as values in memory (estimated size 9.3 KB, free 3.0 GB)
2018-09-18 14:24:28,955   INFO --- [dag-scheduler-event-loop]  org.apache.spark.storage.memory.MemoryStore(line:54) : Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.0 KB, free 3.0 GB)
2018-09-18 14:24:28,956   INFO --- [dispatcher-event-loop-0]  org.apache.spark.storage.BlockManagerInfo(line:54) : Added broadcast_1_piece0 in memory on 192.168.3.199:56609 (size: 5.0 KB, free: 3.0 GB)
2018-09-18 14:24:28,957   INFO --- [dag-scheduler-event-loop]  org.apache.spark.SparkContext(line:54) : Created broadcast 1 from broadcast at DAGScheduler.scala:996
2018-09-18 14:24:28,958   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[6] at show at logSession.scala:42)
2018-09-18 14:24:28,958   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.TaskSchedulerImpl(line:54) : Adding task set 1.0 with 1 tasks
2018-09-18 14:24:28,961   INFO --- [dispatcher-event-loop-2]  org.apache.spark.scheduler.TaskSetManager(line:54) : Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 5712 bytes)
2018-09-18 14:24:28,962   INFO --- [Executor task launch worker for task 1]  org.apache.spark.executor.Executor(line:54) : Running task 0.0 in stage 1.0 (TID 1)
2018-09-18 14:24:29,446   INFO --- [Executor task launch worker for task 1]  org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD(line:54) : closed connection
2018-09-18 14:24:29,492   INFO --- [Executor task launch worker for task 1]  org.apache.spark.executor.Executor(line:54) : Finished task 0.0 in stage 1.0 (TID 1). 1888 bytes result sent to driver
2018-09-18 14:24:29,495   INFO --- [task-result-getter-1]  org.apache.spark.scheduler.TaskSetManager(line:54) : Finished task 0.0 in stage 1.0 (TID 1) in 536 ms on localhost (executor driver) (1/1)
2018-09-18 14:24:29,495   INFO --- [task-result-getter-1]  org.apache.spark.scheduler.TaskSchedulerImpl(line:54) : Removed TaskSet 1.0, whose tasks have all completed, from pool 
2018-09-18 14:24:29,496   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : ShuffleMapStage 1 (show at logSession.scala:42) finished in 0.537 s
2018-09-18 14:24:29,496   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : looking for newly runnable stages
2018-09-18 14:24:29,497   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : running: Set()
2018-09-18 14:24:29,497   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : waiting: Set(ResultStage 2)
2018-09-18 14:24:29,497   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : failed: Set()
2018-09-18 14:24:29,500   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Submitting ResultStage 2 (MapPartitionsRDD[9] at show at logSession.scala:42), which has no missing parents
2018-09-18 14:24:29,506   INFO --- [dag-scheduler-event-loop]  org.apache.spark.storage.memory.MemoryStore(line:54) : Block broadcast_2 stored as values in memory (estimated size 6.9 KB, free 3.0 GB)
2018-09-18 14:24:29,507   INFO --- [dag-scheduler-event-loop]  org.apache.spark.storage.memory.MemoryStore(line:54) : Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.7 KB, free 3.0 GB)
2018-09-18 14:24:29,509   INFO --- [dispatcher-event-loop-1]  org.apache.spark.storage.BlockManagerInfo(line:54) : Added broadcast_2_piece0 in memory on 192.168.3.199:56609 (size: 3.7 KB, free: 3.0 GB)
2018-09-18 14:24:29,510   INFO --- [dag-scheduler-event-loop]  org.apache.spark.SparkContext(line:54) : Created broadcast 2 from broadcast at DAGScheduler.scala:996
2018-09-18 14:24:29,510   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[9] at show at logSession.scala:42)
2018-09-18 14:24:29,510   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.TaskSchedulerImpl(line:54) : Adding task set 2.0 with 1 tasks
2018-09-18 14:24:29,514   INFO --- [dispatcher-event-loop-5]  org.apache.spark.scheduler.TaskSetManager(line:54) : Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, ANY, 5800 bytes)
2018-09-18 14:24:29,515   INFO --- [Executor task launch worker for task 2]  org.apache.spark.executor.Executor(line:54) : Running task 0.0 in stage 2.0 (TID 2)
2018-09-18 14:24:29,526   INFO --- [Executor task launch worker for task 2]  org.apache.spark.storage.ShuffleBlockFetcherIterator(line:54) : Getting 1 non-empty blocks out of 1 blocks
2018-09-18 14:24:29,528   INFO --- [Executor task launch worker for task 2]  org.apache.spark.storage.ShuffleBlockFetcherIterator(line:54) : Started 0 remote fetches in 5 ms
2018-09-18 14:24:29,542   INFO --- [Executor task launch worker for task 2]  org.apache.spark.executor.Executor(line:54) : Finished task 0.0 in stage 2.0 (TID 2). 1928 bytes result sent to driver
2018-09-18 14:24:29,543   INFO --- [task-result-getter-2]  org.apache.spark.scheduler.TaskSetManager(line:54) : Finished task 0.0 in stage 2.0 (TID 2) in 30 ms on localhost (executor driver) (1/1)
2018-09-18 14:24:29,544   INFO --- [task-result-getter-2]  org.apache.spark.scheduler.TaskSchedulerImpl(line:54) : Removed TaskSet 2.0, whose tasks have all completed, from pool 
2018-09-18 14:24:29,544   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : ResultStage 2 (show at logSession.scala:42) finished in 0.031 s
2018-09-18 14:24:29,545   INFO --- [main]  org.apache.spark.scheduler.DAGScheduler(line:54) : Job 1 finished: show at logSession.scala:42, took 0.611533 s
2018-09-18 14:24:29,552   INFO --- [main]  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator(line:54) : Code generated in 4.858585 ms
2018-09-18 14:24:29,557   INFO --- [main]  org.spark_project.jetty.server.ServerConnector(line:306) : Stopped Spark@45e37a7e{HTTP/1.1}{0.0.0.0:4040}
2018-09-18 14:24:29,559   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@e98770d{/stages/stage/kill,null,UNAVAILABLE,@Spark}
2018-09-18 14:24:29,559   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@4ba302e0{/jobs/job/kill,null,UNAVAILABLE,@Spark}
2018-09-18 14:24:29,559   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@57ac5227{/api,null,UNAVAILABLE,@Spark}
2018-09-18 14:24:29,560   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@43aaf813{/,null,UNAVAILABLE,@Spark}
2018-09-18 14:24:29,560   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@33aeca0b{/static,null,UNAVAILABLE,@Spark}
2018-09-18 14:24:29,560   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@5c18016b{/executors/threadDump/json,null,UNAVAILABLE,@Spark}
2018-09-18 14:24:29,560   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@1951b871{/executors/threadDump,null,UNAVAILABLE,@Spark}
2018-09-18 14:24:29,560   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@793138bd{/executors/json,null,UNAVAILABLE,@Spark}
2018-09-18 14:24:29,561   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@5d1659ea{/executors,null,UNAVAILABLE,@Spark}
2018-09-18 14:24:29,561   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@25bc0606{/environment/json,null,UNAVAILABLE,@Spark}
2018-09-18 14:24:29,561   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@3d3ba765{/environment,null,UNAVAILABLE,@Spark}
2018-09-18 14:24:29,561   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@784b990c{/storage/rdd/json,null,UNAVAILABLE,@Spark}
2018-09-18 14:24:29,562   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@3c989952{/storage/rdd,null,UNAVAILABLE,@Spark}
2018-09-18 14:24:29,562   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@3e14c16d{/storage/json,null,UNAVAILABLE,@Spark}
2018-09-18 14:24:29,562   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@7096b474{/storage,null,UNAVAILABLE,@Spark}
2018-09-18 14:24:29,562   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@4bd1f8dd{/stages/pool/json,null,UNAVAILABLE,@Spark}
2018-09-18 14:24:29,562   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@3f07b12c{/stages/pool,null,UNAVAILABLE,@Spark}
2018-09-18 14:24:29,562   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@6475472c{/stages/stage/json,null,UNAVAILABLE,@Spark}
2018-09-18 14:24:29,563   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@4b7e96a{/stages/stage,null,UNAVAILABLE,@Spark}
2018-09-18 14:24:29,563   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@5c8504fd{/stages/json,null,UNAVAILABLE,@Spark}
2018-09-18 14:24:29,563   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@42f33b5d{/stages,null,UNAVAILABLE,@Spark}
2018-09-18 14:24:29,563   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@47c4ecdc{/jobs/job/json,null,UNAVAILABLE,@Spark}
2018-09-18 14:24:29,563   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@2eced48b{/jobs/job,null,UNAVAILABLE,@Spark}
2018-09-18 14:24:29,563   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@14d14731{/jobs/json,null,UNAVAILABLE,@Spark}
2018-09-18 14:24:29,563   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@53dacd14{/jobs,null,UNAVAILABLE,@Spark}
2018-09-18 14:24:29,565   INFO --- [main]  org.apache.spark.ui.SparkUI(line:54) : Stopped Spark web UI at http://192.168.3.199:4040
2018-09-18 14:24:29,574   INFO --- [dispatcher-event-loop-3]  org.apache.spark.MapOutputTrackerMasterEndpoint(line:54) : MapOutputTrackerMasterEndpoint stopped!
2018-09-18 14:24:29,615   INFO --- [main]  org.apache.spark.storage.memory.MemoryStore(line:54) : MemoryStore cleared
2018-09-18 14:24:29,615   INFO --- [main]  org.apache.spark.storage.BlockManager(line:54) : BlockManager stopped
2018-09-18 14:24:29,622   INFO --- [main]  org.apache.spark.storage.BlockManagerMaster(line:54) : BlockManagerMaster stopped
2018-09-18 14:24:29,624   INFO --- [dispatcher-event-loop-7]  org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint(line:54) : OutputCommitCoordinator stopped!
2018-09-18 14:24:29,629   INFO --- [main]  org.apache.spark.SparkContext(line:54) : Successfully stopped SparkContext
2018-09-18 14:24:29,632   INFO --- [Thread-1]  org.apache.spark.util.ShutdownHookManager(line:54) : Shutdown hook called
2018-09-18 14:24:29,633   INFO --- [Thread-1]  org.apache.spark.util.ShutdownHookManager(line:54) : Deleting directory C:\Users\wshs\AppData\Local\Temp\spark-7e13acfb-6e03-4ed6-989a-b5eecb66b8d4
2018-09-18 14:25:17,854   INFO --- [main]  org.apache.spark.SparkContext(line:54) : Running Spark version 2.1.1
2018-09-18 14:25:18,214   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing view acls to: wshs
2018-09-18 14:25:18,215   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing modify acls to: wshs
2018-09-18 14:25:18,215   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing view acls groups to: 
2018-09-18 14:25:18,216   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing modify acls groups to: 
2018-09-18 14:25:18,217   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(wshs); groups with view permissions: Set(); users  with modify permissions: Set(wshs); groups with modify permissions: Set()
2018-09-18 14:25:18,813   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'sparkDriver' on port 56694.
2018-09-18 14:25:18,833   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering MapOutputTracker
2018-09-18 14:25:18,851   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering BlockManagerMaster
2018-09-18 14:25:18,854   INFO --- [main]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-09-18 14:25:18,854   INFO --- [main]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : BlockManagerMasterEndpoint up
2018-09-18 14:25:18,868   INFO --- [main]  org.apache.spark.storage.DiskBlockManager(line:54) : Created local directory at C:\Users\wshs\AppData\Local\Temp\blockmgr-abcecba1-ef6c-4bba-bde2-daaab3eec83c
2018-09-18 14:25:18,885   INFO --- [main]  org.apache.spark.storage.memory.MemoryStore(line:54) : MemoryStore started with capacity 3.0 GB
2018-09-18 14:25:18,962   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering OutputCommitCoordinator
2018-09-18 14:25:19,041   INFO --- [main]  org.spark_project.jetty.util.log(line:186) : Logging initialized @2164ms
2018-09-18 14:25:19,120   INFO --- [main]  org.spark_project.jetty.server.Server(line:327) : jetty-9.2.z-SNAPSHOT
2018-09-18 14:25:19,133   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@53dacd14{/jobs,null,AVAILABLE,@Spark}
2018-09-18 14:25:19,134   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@14d14731{/jobs/json,null,AVAILABLE,@Spark}
2018-09-18 14:25:19,134   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@2eced48b{/jobs/job,null,AVAILABLE,@Spark}
2018-09-18 14:25:19,135   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@47c4ecdc{/jobs/job/json,null,AVAILABLE,@Spark}
2018-09-18 14:25:19,135   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@42f33b5d{/stages,null,AVAILABLE,@Spark}
2018-09-18 14:25:19,135   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@5c8504fd{/stages/json,null,AVAILABLE,@Spark}
2018-09-18 14:25:19,135   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@4b7e96a{/stages/stage,null,AVAILABLE,@Spark}
2018-09-18 14:25:19,136   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@6475472c{/stages/stage/json,null,AVAILABLE,@Spark}
2018-09-18 14:25:19,136   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@3f07b12c{/stages/pool,null,AVAILABLE,@Spark}
2018-09-18 14:25:19,136   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@4bd1f8dd{/stages/pool/json,null,AVAILABLE,@Spark}
2018-09-18 14:25:19,137   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@7096b474{/storage,null,AVAILABLE,@Spark}
2018-09-18 14:25:19,137   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@3e14c16d{/storage/json,null,AVAILABLE,@Spark}
2018-09-18 14:25:19,137   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@3c989952{/storage/rdd,null,AVAILABLE,@Spark}
2018-09-18 14:25:19,137   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@784b990c{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-09-18 14:25:19,138   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@3d3ba765{/environment,null,AVAILABLE,@Spark}
2018-09-18 14:25:19,138   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@25bc0606{/environment/json,null,AVAILABLE,@Spark}
2018-09-18 14:25:19,138   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@5d1659ea{/executors,null,AVAILABLE,@Spark}
2018-09-18 14:25:19,138   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@793138bd{/executors/json,null,AVAILABLE,@Spark}
2018-09-18 14:25:19,138   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@1951b871{/executors/threadDump,null,AVAILABLE,@Spark}
2018-09-18 14:25:19,139   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@5c18016b{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-09-18 14:25:19,143   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@33aeca0b{/static,null,AVAILABLE,@Spark}
2018-09-18 14:25:19,144   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@43aaf813{/,null,AVAILABLE,@Spark}
2018-09-18 14:25:19,144   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@57ac5227{/api,null,AVAILABLE,@Spark}
2018-09-18 14:25:19,145   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@4ba302e0{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-09-18 14:25:19,145   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@e98770d{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-09-18 14:25:19,156   INFO --- [main]  org.spark_project.jetty.server.ServerConnector(line:266) : Started Spark@45e37a7e{HTTP/1.1}{0.0.0.0:4040}
2018-09-18 14:25:19,156   INFO --- [main]  org.spark_project.jetty.server.Server(line:379) : Started @2281ms
2018-09-18 14:25:19,157   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'SparkUI' on port 4040.
2018-09-18 14:25:19,159   INFO --- [main]  org.apache.spark.ui.SparkUI(line:54) : Bound SparkUI to 0.0.0.0, and started at http://192.168.3.199:4040
2018-09-18 14:25:19,228   INFO --- [main]  org.apache.spark.executor.Executor(line:54) : Starting executor ID driver on host localhost
2018-09-18 14:25:19,273   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 56736.
2018-09-18 14:25:19,273   INFO --- [main]  org.apache.spark.network.netty.NettyBlockTransferService(line:54) : Server created on 192.168.3.199:56736
2018-09-18 14:25:19,274   INFO --- [main]  org.apache.spark.storage.BlockManager(line:54) : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-09-18 14:25:19,276   INFO --- [main]  org.apache.spark.storage.BlockManagerMaster(line:54) : Registering BlockManager BlockManagerId(driver, 192.168.3.199, 56736, None)
2018-09-18 14:25:19,278   INFO --- [dispatcher-event-loop-2]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : Registering block manager 192.168.3.199:56736 with 3.0 GB RAM, BlockManagerId(driver, 192.168.3.199, 56736, None)
2018-09-18 14:25:19,282   INFO --- [main]  org.apache.spark.storage.BlockManagerMaster(line:54) : Registered BlockManager BlockManagerId(driver, 192.168.3.199, 56736, None)
2018-09-18 14:25:19,283   INFO --- [main]  org.apache.spark.storage.BlockManager(line:54) : Initialized BlockManager: BlockManagerId(driver, 192.168.3.199, 56736, None)
2018-09-18 14:25:19,435   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@687a762c{/metrics/json,null,AVAILABLE,@Spark}
2018-09-18 14:25:19,452   WARN --- [main]  org.apache.spark.SparkContext(line:66) : Using an existing SparkContext; some configuration may not take effect.
2018-09-18 14:25:19,489   INFO --- [main]  org.apache.spark.sql.internal.SharedState(line:54) : Warehouse path is 'file:/C:/Users/wshs/IdeaProjects/logdataSession/spark-warehouse/'.
2018-09-18 14:25:19,494   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@7957dc72{/SQL,null,AVAILABLE,@Spark}
2018-09-18 14:25:19,495   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@3aacf32a{/SQL/json,null,AVAILABLE,@Spark}
2018-09-18 14:25:19,495   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@345e5a17{/SQL/execution,null,AVAILABLE,@Spark}
2018-09-18 14:25:19,496   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@443dbe42{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-09-18 14:25:19,498   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@5bbc9f97{/static/sql,null,AVAILABLE,@Spark}
2018-09-18 14:25:22,224   INFO --- [main]  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator(line:54) : Code generated in 204.114022 ms
2018-09-18 14:25:22,287   INFO --- [main]  org.apache.spark.SparkContext(line:54) : Starting job: show at logSession.scala:32
2018-09-18 14:25:22,302   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Got job 0 (show at logSession.scala:32) with 1 output partitions
2018-09-18 14:25:22,303   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Final stage: ResultStage 0 (show at logSession.scala:32)
2018-09-18 14:25:22,304   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Parents of final stage: List()
2018-09-18 14:25:22,305   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Missing parents: List()
2018-09-18 14:25:22,311   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Submitting ResultStage 0 (MapPartitionsRDD[2] at show at logSession.scala:32), which has no missing parents
2018-09-18 14:25:22,413   INFO --- [dag-scheduler-event-loop]  org.apache.spark.storage.memory.MemoryStore(line:54) : Block broadcast_0 stored as values in memory (estimated size 8.7 KB, free 3.0 GB)
2018-09-18 14:25:22,525   INFO --- [dag-scheduler-event-loop]  org.apache.spark.storage.memory.MemoryStore(line:54) : Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.5 KB, free 3.0 GB)
2018-09-18 14:25:22,530   INFO --- [dispatcher-event-loop-4]  org.apache.spark.storage.BlockManagerInfo(line:54) : Added broadcast_0_piece0 in memory on 192.168.3.199:56736 (size: 4.5 KB, free: 3.0 GB)
2018-09-18 14:25:22,534   INFO --- [dag-scheduler-event-loop]  org.apache.spark.SparkContext(line:54) : Created broadcast 0 from broadcast at DAGScheduler.scala:996
2018-09-18 14:25:22,538   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at show at logSession.scala:32)
2018-09-18 14:25:22,540   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.TaskSchedulerImpl(line:54) : Adding task set 0.0 with 1 tasks
2018-09-18 14:25:22,574   INFO --- [dispatcher-event-loop-5]  org.apache.spark.scheduler.TaskSetManager(line:54) : Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 5723 bytes)
2018-09-18 14:25:22,583   INFO --- [Executor task launch worker for task 0]  org.apache.spark.executor.Executor(line:54) : Running task 0.0 in stage 0.0 (TID 0)
2018-09-18 14:25:23,883   INFO --- [Executor task launch worker for task 0]  org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD(line:54) : closed connection
2018-09-18 14:25:23,894   INFO --- [Executor task launch worker for task 0]  org.apache.spark.executor.Executor(line:54) : Finished task 0.0 in stage 0.0 (TID 0). 1582 bytes result sent to driver
2018-09-18 14:25:23,901   INFO --- [task-result-getter-0]  org.apache.spark.scheduler.TaskSetManager(line:54) : Finished task 0.0 in stage 0.0 (TID 0) in 1339 ms on localhost (executor driver) (1/1)
2018-09-18 14:25:23,903   INFO --- [task-result-getter-0]  org.apache.spark.scheduler.TaskSchedulerImpl(line:54) : Removed TaskSet 0.0, whose tasks have all completed, from pool 
2018-09-18 14:25:23,905   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : ResultStage 0 (show at logSession.scala:32) finished in 1.356 s
2018-09-18 14:25:23,910   INFO --- [main]  org.apache.spark.scheduler.DAGScheduler(line:54) : Job 0 finished: show at logSession.scala:32, took 1.622739 s
2018-09-18 14:25:23,946   INFO --- [main]  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator(line:54) : Code generated in 21.025621 ms
2018-09-18 14:25:24,018   INFO --- [main]  org.apache.spark.sql.execution.SparkSqlParser(line:54) : Parsing command: actionopvidio
2018-09-18 14:25:24,136   INFO --- [main]  org.apache.spark.sql.execution.SparkSqlParser(line:54) : Parsing command: SELECT count(1) FROM actionopvidio
2018-09-18 14:25:24,323   INFO --- [main]  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator(line:54) : Code generated in 9.49993 ms
2018-09-18 14:25:24,335   INFO --- [main]  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator(line:54) : Code generated in 8.248175 ms
2018-09-18 14:25:24,359   INFO --- [main]  org.apache.spark.SparkContext(line:54) : Starting job: show at logSession.scala:42
2018-09-18 14:25:24,362   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Registering RDD 6 (show at logSession.scala:42)
2018-09-18 14:25:24,362   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Got job 1 (show at logSession.scala:42) with 1 output partitions
2018-09-18 14:25:24,362   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Final stage: ResultStage 2 (show at logSession.scala:42)
2018-09-18 14:25:24,363   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Parents of final stage: List(ShuffleMapStage 1)
2018-09-18 14:25:24,363   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Missing parents: List(ShuffleMapStage 1)
2018-09-18 14:25:24,364   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Submitting ShuffleMapStage 1 (MapPartitionsRDD[6] at show at logSession.scala:42), which has no missing parents
2018-09-18 14:25:24,375   INFO --- [dag-scheduler-event-loop]  org.apache.spark.storage.memory.MemoryStore(line:54) : Block broadcast_1 stored as values in memory (estimated size 9.3 KB, free 3.0 GB)
2018-09-18 14:25:24,378   INFO --- [dag-scheduler-event-loop]  org.apache.spark.storage.memory.MemoryStore(line:54) : Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.0 KB, free 3.0 GB)
2018-09-18 14:25:24,379   INFO --- [dispatcher-event-loop-0]  org.apache.spark.storage.BlockManagerInfo(line:54) : Added broadcast_1_piece0 in memory on 192.168.3.199:56736 (size: 5.0 KB, free: 3.0 GB)
2018-09-18 14:25:24,379   INFO --- [dag-scheduler-event-loop]  org.apache.spark.SparkContext(line:54) : Created broadcast 1 from broadcast at DAGScheduler.scala:996
2018-09-18 14:25:24,381   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[6] at show at logSession.scala:42)
2018-09-18 14:25:24,381   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.TaskSchedulerImpl(line:54) : Adding task set 1.0 with 1 tasks
2018-09-18 14:25:24,384   INFO --- [dispatcher-event-loop-1]  org.apache.spark.scheduler.TaskSetManager(line:54) : Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 5712 bytes)
2018-09-18 14:25:24,384   INFO --- [Executor task launch worker for task 1]  org.apache.spark.executor.Executor(line:54) : Running task 0.0 in stage 1.0 (TID 1)
2018-09-18 14:25:25,049   INFO --- [Executor task launch worker for task 1]  org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD(line:54) : closed connection
2018-09-18 14:25:25,094   INFO --- [Executor task launch worker for task 1]  org.apache.spark.executor.Executor(line:54) : Finished task 0.0 in stage 1.0 (TID 1). 1978 bytes result sent to driver
2018-09-18 14:25:25,097   INFO --- [task-result-getter-1]  org.apache.spark.scheduler.TaskSetManager(line:54) : Finished task 0.0 in stage 1.0 (TID 1) in 715 ms on localhost (executor driver) (1/1)
2018-09-18 14:25:25,097   INFO --- [task-result-getter-1]  org.apache.spark.scheduler.TaskSchedulerImpl(line:54) : Removed TaskSet 1.0, whose tasks have all completed, from pool 
2018-09-18 14:25:25,098   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : ShuffleMapStage 1 (show at logSession.scala:42) finished in 0.716 s
2018-09-18 14:25:25,098   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : looking for newly runnable stages
2018-09-18 14:25:25,099   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : running: Set()
2018-09-18 14:25:25,099   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : waiting: Set(ResultStage 2)
2018-09-18 14:25:25,100   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : failed: Set()
2018-09-18 14:25:25,103   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Submitting ResultStage 2 (MapPartitionsRDD[9] at show at logSession.scala:42), which has no missing parents
2018-09-18 14:25:25,108   INFO --- [dag-scheduler-event-loop]  org.apache.spark.storage.memory.MemoryStore(line:54) : Block broadcast_2 stored as values in memory (estimated size 6.9 KB, free 3.0 GB)
2018-09-18 14:25:25,110   INFO --- [dag-scheduler-event-loop]  org.apache.spark.storage.memory.MemoryStore(line:54) : Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.7 KB, free 3.0 GB)
2018-09-18 14:25:25,112   INFO --- [dispatcher-event-loop-4]  org.apache.spark.storage.BlockManagerInfo(line:54) : Added broadcast_2_piece0 in memory on 192.168.3.199:56736 (size: 3.7 KB, free: 3.0 GB)
2018-09-18 14:25:25,112   INFO --- [dag-scheduler-event-loop]  org.apache.spark.SparkContext(line:54) : Created broadcast 2 from broadcast at DAGScheduler.scala:996
2018-09-18 14:25:25,112   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[9] at show at logSession.scala:42)
2018-09-18 14:25:25,113   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.TaskSchedulerImpl(line:54) : Adding task set 2.0 with 1 tasks
2018-09-18 14:25:25,115   INFO --- [dispatcher-event-loop-5]  org.apache.spark.scheduler.TaskSetManager(line:54) : Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, ANY, 5800 bytes)
2018-09-18 14:25:25,116   INFO --- [Executor task launch worker for task 2]  org.apache.spark.executor.Executor(line:54) : Running task 0.0 in stage 2.0 (TID 2)
2018-09-18 14:25:25,128   INFO --- [Executor task launch worker for task 2]  org.apache.spark.storage.ShuffleBlockFetcherIterator(line:54) : Getting 1 non-empty blocks out of 1 blocks
2018-09-18 14:25:25,129   INFO --- [Executor task launch worker for task 2]  org.apache.spark.storage.ShuffleBlockFetcherIterator(line:54) : Started 0 remote fetches in 4 ms
2018-09-18 14:25:25,142   INFO --- [Executor task launch worker for task 2]  org.apache.spark.executor.Executor(line:54) : Finished task 0.0 in stage 2.0 (TID 2). 1928 bytes result sent to driver
2018-09-18 14:25:25,143   INFO --- [task-result-getter-2]  org.apache.spark.scheduler.TaskSetManager(line:54) : Finished task 0.0 in stage 2.0 (TID 2) in 29 ms on localhost (executor driver) (1/1)
2018-09-18 14:25:25,143   INFO --- [task-result-getter-2]  org.apache.spark.scheduler.TaskSchedulerImpl(line:54) : Removed TaskSet 2.0, whose tasks have all completed, from pool 
2018-09-18 14:25:25,144   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : ResultStage 2 (show at logSession.scala:42) finished in 0.030 s
2018-09-18 14:25:25,144   INFO --- [main]  org.apache.spark.scheduler.DAGScheduler(line:54) : Job 1 finished: show at logSession.scala:42, took 0.785600 s
2018-09-18 14:25:25,150   INFO --- [main]  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator(line:54) : Code generated in 4.807505 ms
2018-09-18 14:25:25,156   INFO --- [main]  org.spark_project.jetty.server.ServerConnector(line:306) : Stopped Spark@45e37a7e{HTTP/1.1}{0.0.0.0:4040}
2018-09-18 14:25:25,158   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@e98770d{/stages/stage/kill,null,UNAVAILABLE,@Spark}
2018-09-18 14:25:25,158   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@4ba302e0{/jobs/job/kill,null,UNAVAILABLE,@Spark}
2018-09-18 14:25:25,158   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@57ac5227{/api,null,UNAVAILABLE,@Spark}
2018-09-18 14:25:25,158   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@43aaf813{/,null,UNAVAILABLE,@Spark}
2018-09-18 14:25:25,158   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@33aeca0b{/static,null,UNAVAILABLE,@Spark}
2018-09-18 14:25:25,158   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@5c18016b{/executors/threadDump/json,null,UNAVAILABLE,@Spark}
2018-09-18 14:25:25,159   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@1951b871{/executors/threadDump,null,UNAVAILABLE,@Spark}
2018-09-18 14:25:25,159   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@793138bd{/executors/json,null,UNAVAILABLE,@Spark}
2018-09-18 14:25:25,159   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@5d1659ea{/executors,null,UNAVAILABLE,@Spark}
2018-09-18 14:25:25,159   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@25bc0606{/environment/json,null,UNAVAILABLE,@Spark}
2018-09-18 14:25:25,159   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@3d3ba765{/environment,null,UNAVAILABLE,@Spark}
2018-09-18 14:25:25,159   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@784b990c{/storage/rdd/json,null,UNAVAILABLE,@Spark}
2018-09-18 14:25:25,159   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@3c989952{/storage/rdd,null,UNAVAILABLE,@Spark}
2018-09-18 14:25:25,160   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@3e14c16d{/storage/json,null,UNAVAILABLE,@Spark}
2018-09-18 14:25:25,160   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@7096b474{/storage,null,UNAVAILABLE,@Spark}
2018-09-18 14:25:25,160   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@4bd1f8dd{/stages/pool/json,null,UNAVAILABLE,@Spark}
2018-09-18 14:25:25,160   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@3f07b12c{/stages/pool,null,UNAVAILABLE,@Spark}
2018-09-18 14:25:25,160   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@6475472c{/stages/stage/json,null,UNAVAILABLE,@Spark}
2018-09-18 14:25:25,160   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@4b7e96a{/stages/stage,null,UNAVAILABLE,@Spark}
2018-09-18 14:25:25,161   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@5c8504fd{/stages/json,null,UNAVAILABLE,@Spark}
2018-09-18 14:25:25,161   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@42f33b5d{/stages,null,UNAVAILABLE,@Spark}
2018-09-18 14:25:25,161   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@47c4ecdc{/jobs/job/json,null,UNAVAILABLE,@Spark}
2018-09-18 14:25:25,161   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@2eced48b{/jobs/job,null,UNAVAILABLE,@Spark}
2018-09-18 14:25:25,161   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@14d14731{/jobs/json,null,UNAVAILABLE,@Spark}
2018-09-18 14:25:25,162   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@53dacd14{/jobs,null,UNAVAILABLE,@Spark}
2018-09-18 14:25:25,163   INFO --- [main]  org.apache.spark.ui.SparkUI(line:54) : Stopped Spark web UI at http://192.168.3.199:4040
2018-09-18 14:25:25,173   INFO --- [dispatcher-event-loop-2]  org.apache.spark.MapOutputTrackerMasterEndpoint(line:54) : MapOutputTrackerMasterEndpoint stopped!
2018-09-18 14:25:25,211   INFO --- [main]  org.apache.spark.storage.memory.MemoryStore(line:54) : MemoryStore cleared
2018-09-18 14:25:25,212   INFO --- [main]  org.apache.spark.storage.BlockManager(line:54) : BlockManager stopped
2018-09-18 14:25:25,216   INFO --- [main]  org.apache.spark.storage.BlockManagerMaster(line:54) : BlockManagerMaster stopped
2018-09-18 14:25:25,219   INFO --- [dispatcher-event-loop-7]  org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint(line:54) : OutputCommitCoordinator stopped!
2018-09-18 14:25:25,225   INFO --- [main]  org.apache.spark.SparkContext(line:54) : Successfully stopped SparkContext
2018-09-18 14:25:25,228   INFO --- [Thread-1]  org.apache.spark.util.ShutdownHookManager(line:54) : Shutdown hook called
2018-09-18 14:25:25,228   INFO --- [Thread-1]  org.apache.spark.util.ShutdownHookManager(line:54) : Deleting directory C:\Users\wshs\AppData\Local\Temp\spark-1851b2fc-8ea0-46a3-bbf5-67f5d7b1171c
2018-09-18 14:25:44,105   INFO --- [main]  org.apache.spark.SparkContext(line:54) : Running Spark version 2.1.1
2018-09-18 14:25:44,475   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing view acls to: wshs
2018-09-18 14:25:44,476   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing modify acls to: wshs
2018-09-18 14:25:44,476   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing view acls groups to: 
2018-09-18 14:25:44,477   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing modify acls groups to: 
2018-09-18 14:25:44,477   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(wshs); groups with view permissions: Set(); users  with modify permissions: Set(wshs); groups with modify permissions: Set()
2018-09-18 14:25:45,039   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'sparkDriver' on port 56797.
2018-09-18 14:25:45,056   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering MapOutputTracker
2018-09-18 14:25:45,076   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering BlockManagerMaster
2018-09-18 14:25:45,080   INFO --- [main]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-09-18 14:25:45,080   INFO --- [main]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : BlockManagerMasterEndpoint up
2018-09-18 14:25:45,095   INFO --- [main]  org.apache.spark.storage.DiskBlockManager(line:54) : Created local directory at C:\Users\wshs\AppData\Local\Temp\blockmgr-bfd269b5-8ba7-4153-a9a9-6e971ace4c83
2018-09-18 14:25:45,112   INFO --- [main]  org.apache.spark.storage.memory.MemoryStore(line:54) : MemoryStore started with capacity 3.0 GB
2018-09-18 14:25:45,178   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering OutputCommitCoordinator
2018-09-18 14:25:45,252   INFO --- [main]  org.spark_project.jetty.util.log(line:186) : Logging initialized @2091ms
2018-09-18 14:25:45,329   INFO --- [main]  org.spark_project.jetty.server.Server(line:327) : jetty-9.2.z-SNAPSHOT
2018-09-18 14:25:45,343   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@32811494{/jobs,null,AVAILABLE,@Spark}
2018-09-18 14:25:45,343   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@4795ded0{/jobs/json,null,AVAILABLE,@Spark}
2018-09-18 14:25:45,343   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@53dacd14{/jobs/job,null,AVAILABLE,@Spark}
2018-09-18 14:25:45,344   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@14d14731{/jobs/job/json,null,AVAILABLE,@Spark}
2018-09-18 14:25:45,344   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@2eced48b{/stages,null,AVAILABLE,@Spark}
2018-09-18 14:25:45,344   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@47c4ecdc{/stages/json,null,AVAILABLE,@Spark}
2018-09-18 14:25:45,344   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@42f33b5d{/stages/stage,null,AVAILABLE,@Spark}
2018-09-18 14:25:45,345   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@5c8504fd{/stages/stage/json,null,AVAILABLE,@Spark}
2018-09-18 14:25:45,345   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@4b7e96a{/stages/pool,null,AVAILABLE,@Spark}
2018-09-18 14:25:45,345   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@6475472c{/stages/pool/json,null,AVAILABLE,@Spark}
2018-09-18 14:25:45,346   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@3f07b12c{/storage,null,AVAILABLE,@Spark}
2018-09-18 14:25:45,346   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@4bd1f8dd{/storage/json,null,AVAILABLE,@Spark}
2018-09-18 14:25:45,346   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@7096b474{/storage/rdd,null,AVAILABLE,@Spark}
2018-09-18 14:25:45,347   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@3e14c16d{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-09-18 14:25:45,347   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@3c989952{/environment,null,AVAILABLE,@Spark}
2018-09-18 14:25:45,347   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@784b990c{/environment/json,null,AVAILABLE,@Spark}
2018-09-18 14:25:45,347   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@3d3ba765{/executors,null,AVAILABLE,@Spark}
2018-09-18 14:25:45,348   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@25bc0606{/executors/json,null,AVAILABLE,@Spark}
2018-09-18 14:25:45,348   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@5d1659ea{/executors/threadDump,null,AVAILABLE,@Spark}
2018-09-18 14:25:45,348   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@793138bd{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-09-18 14:25:45,353   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@1951b871{/static,null,AVAILABLE,@Spark}
2018-09-18 14:25:45,353   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@5c18016b{/,null,AVAILABLE,@Spark}
2018-09-18 14:25:45,354   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@33aeca0b{/api,null,AVAILABLE,@Spark}
2018-09-18 14:25:45,354   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@43aaf813{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-09-18 14:25:45,354   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@57ac5227{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-09-18 14:25:45,365   INFO --- [main]  org.spark_project.jetty.server.ServerConnector(line:266) : Started Spark@3e10dc6{HTTP/1.1}{0.0.0.0:4040}
2018-09-18 14:25:45,365   INFO --- [main]  org.spark_project.jetty.server.Server(line:379) : Started @2205ms
2018-09-18 14:25:45,366   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'SparkUI' on port 4040.
2018-09-18 14:25:45,368   INFO --- [main]  org.apache.spark.ui.SparkUI(line:54) : Bound SparkUI to 0.0.0.0, and started at http://192.168.3.199:4040
2018-09-18 14:25:45,439   INFO --- [main]  org.apache.spark.executor.Executor(line:54) : Starting executor ID driver on host localhost
2018-09-18 14:25:45,489   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 56838.
2018-09-18 14:25:45,490   INFO --- [main]  org.apache.spark.network.netty.NettyBlockTransferService(line:54) : Server created on 192.168.3.199:56838
2018-09-18 14:25:45,492   INFO --- [main]  org.apache.spark.storage.BlockManager(line:54) : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-09-18 14:25:45,494   INFO --- [main]  org.apache.spark.storage.BlockManagerMaster(line:54) : Registering BlockManager BlockManagerId(driver, 192.168.3.199, 56838, None)
2018-09-18 14:25:45,496   INFO --- [dispatcher-event-loop-2]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : Registering block manager 192.168.3.199:56838 with 3.0 GB RAM, BlockManagerId(driver, 192.168.3.199, 56838, None)
2018-09-18 14:25:45,499   INFO --- [main]  org.apache.spark.storage.BlockManagerMaster(line:54) : Registered BlockManager BlockManagerId(driver, 192.168.3.199, 56838, None)
2018-09-18 14:25:45,499   INFO --- [main]  org.apache.spark.storage.BlockManager(line:54) : Initialized BlockManager: BlockManagerId(driver, 192.168.3.199, 56838, None)
2018-09-18 14:25:45,652   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@3670f00{/metrics/json,null,AVAILABLE,@Spark}
2018-09-18 14:25:45,670   WARN --- [main]  org.apache.spark.SparkContext(line:66) : Using an existing SparkContext; some configuration may not take effect.
2018-09-18 14:25:45,708   INFO --- [main]  org.apache.spark.sql.internal.SharedState(line:54) : Warehouse path is 'file:/C:/Users/wshs/IdeaProjects/logdataSession/spark-warehouse/'.
2018-09-18 14:25:45,714   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@2ef8a8c3{/SQL,null,AVAILABLE,@Spark}
2018-09-18 14:25:45,715   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@63fd4873{/SQL/json,null,AVAILABLE,@Spark}
2018-09-18 14:25:45,716   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@6ab72419{/SQL/execution,null,AVAILABLE,@Spark}
2018-09-18 14:25:45,716   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@4fdfa676{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-09-18 14:25:45,718   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:744) : Started o.s.j.s.ServletContextHandler@443dbe42{/static/sql,null,AVAILABLE,@Spark}
2018-09-18 14:25:48,696   INFO --- [main]  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator(line:54) : Code generated in 211.293429 ms
2018-09-18 14:25:48,768   INFO --- [main]  org.apache.spark.SparkContext(line:54) : Starting job: show at logSession.scala:32
2018-09-18 14:25:48,783   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Got job 0 (show at logSession.scala:32) with 1 output partitions
2018-09-18 14:25:48,783   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Final stage: ResultStage 0 (show at logSession.scala:32)
2018-09-18 14:25:48,784   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Parents of final stage: List()
2018-09-18 14:25:48,785   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Missing parents: List()
2018-09-18 14:25:48,790   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Submitting ResultStage 0 (MapPartitionsRDD[2] at show at logSession.scala:32), which has no missing parents
2018-09-18 14:25:48,892   INFO --- [dag-scheduler-event-loop]  org.apache.spark.storage.memory.MemoryStore(line:54) : Block broadcast_0 stored as values in memory (estimated size 8.7 KB, free 3.0 GB)
2018-09-18 14:25:49,444   INFO --- [dag-scheduler-event-loop]  org.apache.spark.storage.memory.MemoryStore(line:54) : Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.5 KB, free 3.0 GB)
2018-09-18 14:25:49,447   INFO --- [dispatcher-event-loop-4]  org.apache.spark.storage.BlockManagerInfo(line:54) : Added broadcast_0_piece0 in memory on 192.168.3.199:56838 (size: 4.5 KB, free: 3.0 GB)
2018-09-18 14:25:49,450   INFO --- [dag-scheduler-event-loop]  org.apache.spark.SparkContext(line:54) : Created broadcast 0 from broadcast at DAGScheduler.scala:996
2018-09-18 14:25:49,454   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at show at logSession.scala:32)
2018-09-18 14:25:49,456   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.TaskSchedulerImpl(line:54) : Adding task set 0.0 with 1 tasks
2018-09-18 14:25:49,490   INFO --- [dispatcher-event-loop-5]  org.apache.spark.scheduler.TaskSetManager(line:54) : Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 5723 bytes)
2018-09-18 14:25:49,499   INFO --- [Executor task launch worker for task 0]  org.apache.spark.executor.Executor(line:54) : Running task 0.0 in stage 0.0 (TID 0)
2018-09-18 14:25:50,733   INFO --- [Executor task launch worker for task 0]  org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD(line:54) : closed connection
2018-09-18 14:25:50,745   INFO --- [Executor task launch worker for task 0]  org.apache.spark.executor.Executor(line:54) : Finished task 0.0 in stage 0.0 (TID 0). 1582 bytes result sent to driver
2018-09-18 14:25:50,753   INFO --- [task-result-getter-0]  org.apache.spark.scheduler.TaskSetManager(line:54) : Finished task 0.0 in stage 0.0 (TID 0) in 1277 ms on localhost (executor driver) (1/1)
2018-09-18 14:25:50,754   INFO --- [task-result-getter-0]  org.apache.spark.scheduler.TaskSchedulerImpl(line:54) : Removed TaskSet 0.0, whose tasks have all completed, from pool 
2018-09-18 14:25:50,756   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : ResultStage 0 (show at logSession.scala:32) finished in 1.292 s
2018-09-18 14:25:50,760   INFO --- [main]  org.apache.spark.scheduler.DAGScheduler(line:54) : Job 0 finished: show at logSession.scala:32, took 1.991978 s
2018-09-18 14:25:50,798   INFO --- [main]  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator(line:54) : Code generated in 20.364589 ms
2018-09-18 14:25:50,869   INFO --- [main]  org.apache.spark.sql.execution.SparkSqlParser(line:54) : Parsing command: actionopvidio
2018-09-18 14:25:50,993   INFO --- [main]  org.apache.spark.sql.execution.SparkSqlParser(line:54) : Parsing command: SELECT id,uid,ct FROM actionopvidio
2018-09-18 14:25:51,109   INFO --- [main]  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator(line:54) : Code generated in 9.502934 ms
2018-09-18 14:25:51,118   INFO --- [main]  org.apache.spark.SparkContext(line:54) : Starting job: show at logSession.scala:42
2018-09-18 14:25:51,120   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Got job 1 (show at logSession.scala:42) with 1 output partitions
2018-09-18 14:25:51,120   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Final stage: ResultStage 1 (show at logSession.scala:42)
2018-09-18 14:25:51,120   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Parents of final stage: List()
2018-09-18 14:25:51,121   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Missing parents: List()
2018-09-18 14:25:51,121   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Submitting ResultStage 1 (MapPartitionsRDD[6] at show at logSession.scala:42), which has no missing parents
2018-09-18 14:25:51,124   INFO --- [dag-scheduler-event-loop]  org.apache.spark.storage.memory.MemoryStore(line:54) : Block broadcast_1 stored as values in memory (estimated size 7.3 KB, free 3.0 GB)
2018-09-18 14:25:51,129   INFO --- [dag-scheduler-event-loop]  org.apache.spark.storage.memory.MemoryStore(line:54) : Block broadcast_1_piece0 stored as bytes in memory (estimated size 4.1 KB, free 3.0 GB)
2018-09-18 14:25:51,129   INFO --- [dispatcher-event-loop-0]  org.apache.spark.storage.BlockManagerInfo(line:54) : Added broadcast_1_piece0 in memory on 192.168.3.199:56838 (size: 4.1 KB, free: 3.0 GB)
2018-09-18 14:25:51,131   INFO --- [dag-scheduler-event-loop]  org.apache.spark.SparkContext(line:54) : Created broadcast 1 from broadcast at DAGScheduler.scala:996
2018-09-18 14:25:51,131   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[6] at show at logSession.scala:42)
2018-09-18 14:25:51,131   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.TaskSchedulerImpl(line:54) : Adding task set 1.0 with 1 tasks
2018-09-18 14:25:51,133   INFO --- [dispatcher-event-loop-1]  org.apache.spark.scheduler.TaskSetManager(line:54) : Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 5723 bytes)
2018-09-18 14:25:51,133   INFO --- [Executor task launch worker for task 1]  org.apache.spark.executor.Executor(line:54) : Running task 0.0 in stage 1.0 (TID 1)
2018-09-18 14:25:53,104   INFO --- [Executor task launch worker for task 1]  org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD(line:54) : closed connection
2018-09-18 14:25:53,105   INFO --- [Executor task launch worker for task 1]  org.apache.spark.executor.Executor(line:54) : Finished task 0.0 in stage 1.0 (TID 1). 1480 bytes result sent to driver
2018-09-18 14:25:53,106   INFO --- [task-result-getter-1]  org.apache.spark.scheduler.TaskSetManager(line:54) : Finished task 0.0 in stage 1.0 (TID 1) in 1974 ms on localhost (executor driver) (1/1)
2018-09-18 14:25:53,107   INFO --- [task-result-getter-1]  org.apache.spark.scheduler.TaskSchedulerImpl(line:54) : Removed TaskSet 1.0, whose tasks have all completed, from pool 
2018-09-18 14:25:53,107   INFO --- [dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler(line:54) : ResultStage 1 (show at logSession.scala:42) finished in 1.975 s
2018-09-18 14:25:53,107   INFO --- [main]  org.apache.spark.scheduler.DAGScheduler(line:54) : Job 1 finished: show at logSession.scala:42, took 1.988550 s
2018-09-18 14:25:53,117   INFO --- [main]  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator(line:54) : Code generated in 9.484305 ms
2018-09-18 14:25:53,123   INFO --- [main]  org.spark_project.jetty.server.ServerConnector(line:306) : Stopped Spark@3e10dc6{HTTP/1.1}{0.0.0.0:4040}
2018-09-18 14:25:53,125   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@57ac5227{/stages/stage/kill,null,UNAVAILABLE,@Spark}
2018-09-18 14:25:53,125   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@43aaf813{/jobs/job/kill,null,UNAVAILABLE,@Spark}
2018-09-18 14:25:53,125   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@33aeca0b{/api,null,UNAVAILABLE,@Spark}
2018-09-18 14:25:53,125   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@5c18016b{/,null,UNAVAILABLE,@Spark}
2018-09-18 14:25:53,125   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@1951b871{/static,null,UNAVAILABLE,@Spark}
2018-09-18 14:25:53,126   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@793138bd{/executors/threadDump/json,null,UNAVAILABLE,@Spark}
2018-09-18 14:25:53,126   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@5d1659ea{/executors/threadDump,null,UNAVAILABLE,@Spark}
2018-09-18 14:25:53,126   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@25bc0606{/executors/json,null,UNAVAILABLE,@Spark}
2018-09-18 14:25:53,126   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@3d3ba765{/executors,null,UNAVAILABLE,@Spark}
2018-09-18 14:25:53,126   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@784b990c{/environment/json,null,UNAVAILABLE,@Spark}
2018-09-18 14:25:53,126   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@3c989952{/environment,null,UNAVAILABLE,@Spark}
2018-09-18 14:25:53,126   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@3e14c16d{/storage/rdd/json,null,UNAVAILABLE,@Spark}
2018-09-18 14:25:53,127   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@7096b474{/storage/rdd,null,UNAVAILABLE,@Spark}
2018-09-18 14:25:53,127   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@4bd1f8dd{/storage/json,null,UNAVAILABLE,@Spark}
2018-09-18 14:25:53,127   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@3f07b12c{/storage,null,UNAVAILABLE,@Spark}
2018-09-18 14:25:53,127   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@6475472c{/stages/pool/json,null,UNAVAILABLE,@Spark}
2018-09-18 14:25:53,127   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@4b7e96a{/stages/pool,null,UNAVAILABLE,@Spark}
2018-09-18 14:25:53,127   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@5c8504fd{/stages/stage/json,null,UNAVAILABLE,@Spark}
2018-09-18 14:25:53,128   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@42f33b5d{/stages/stage,null,UNAVAILABLE,@Spark}
2018-09-18 14:25:53,128   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@47c4ecdc{/stages/json,null,UNAVAILABLE,@Spark}
2018-09-18 14:25:53,128   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@2eced48b{/stages,null,UNAVAILABLE,@Spark}
2018-09-18 14:25:53,128   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@14d14731{/jobs/job/json,null,UNAVAILABLE,@Spark}
2018-09-18 14:25:53,128   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@53dacd14{/jobs/job,null,UNAVAILABLE,@Spark}
2018-09-18 14:25:53,128   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@4795ded0{/jobs/json,null,UNAVAILABLE,@Spark}
2018-09-18 14:25:53,129   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:865) : Stopped o.s.j.s.ServletContextHandler@32811494{/jobs,null,UNAVAILABLE,@Spark}
2018-09-18 14:25:53,130   INFO --- [main]  org.apache.spark.ui.SparkUI(line:54) : Stopped Spark web UI at http://192.168.3.199:4040
2018-09-18 14:25:53,139   INFO --- [dispatcher-event-loop-6]  org.apache.spark.MapOutputTrackerMasterEndpoint(line:54) : MapOutputTrackerMasterEndpoint stopped!
2018-09-18 14:25:53,158   INFO --- [main]  org.apache.spark.storage.memory.MemoryStore(line:54) : MemoryStore cleared
2018-09-18 14:25:53,159   INFO --- [main]  org.apache.spark.storage.BlockManager(line:54) : BlockManager stopped
2018-09-18 14:25:53,163   INFO --- [main]  org.apache.spark.storage.BlockManagerMaster(line:54) : BlockManagerMaster stopped
2018-09-18 14:25:53,165   INFO --- [dispatcher-event-loop-3]  org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint(line:54) : OutputCommitCoordinator stopped!
2018-09-18 14:25:53,172   INFO --- [main]  org.apache.spark.SparkContext(line:54) : Successfully stopped SparkContext
2018-09-18 14:25:53,174   INFO --- [Thread-1]  org.apache.spark.util.ShutdownHookManager(line:54) : Shutdown hook called
2018-09-18 14:25:53,175   INFO --- [Thread-1]  org.apache.spark.util.ShutdownHookManager(line:54) : Deleting directory C:\Users\wshs\AppData\Local\Temp\spark-3e94dac5-6395-459c-bde3-86a206bd83bd
2018-09-18 14:58:42,249   INFO --- [main]  org.apache.spark.SparkContext(line:54) : Running Spark version 2.1.1
2018-09-18 14:58:42,661   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing view acls to: wshs
2018-09-18 14:58:42,662   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing modify acls to: wshs
2018-09-18 14:58:42,662   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing view acls groups to: 
2018-09-18 14:58:42,663   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing modify acls groups to: 
2018-09-18 14:58:42,664   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(wshs); groups with view permissions: Set(); users  with modify permissions: Set(wshs); groups with modify permissions: Set()
2018-09-18 14:58:43,184   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'sparkDriver' on port 58631.
2018-09-18 14:58:43,204   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering MapOutputTracker
2018-09-18 14:58:43,225   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering BlockManagerMaster
2018-09-18 14:58:43,229   INFO --- [main]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-09-18 14:58:43,229   INFO --- [main]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : BlockManagerMasterEndpoint up
2018-09-18 14:58:43,245   INFO --- [main]  org.apache.spark.storage.DiskBlockManager(line:54) : Created local directory at C:\Users\wshs\AppData\Local\Temp\blockmgr-feb4fdb5-882f-414a-9ac6-60fb9003154f
2018-09-18 14:58:43,265   INFO --- [main]  org.apache.spark.storage.memory.MemoryStore(line:54) : MemoryStore started with capacity 3.0 GB
2018-09-18 14:58:43,329   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering OutputCommitCoordinator
2018-09-18 14:58:43,411   INFO --- [main]  org.spark_project.jetty.util.log(line:186) : Logging initialized @2100ms
2018-09-18 14:58:43,489   INFO --- [main]  org.spark_project.jetty.server.Server(line:327) : jetty-9.2.z-SNAPSHOT
